---
tags:
- literature-note
- TTA
title: CoTTA
publish: true
date: '2025-07-30T10:59:00+08:00'
categories:
- literature-note
---
# Setting

**Continual Test-Time Domain Adaptation** 是一种更具挑战性的模型适应设定。在此设定下，一个在源数据上预训练好的模型，在测试时会遇到一个**非平稳**且**持续变化**的目标环境 。

CoTTA 与以下方法不同：
- **Standard Domain Adaptation**：需要同时访问源数据和（静态的）目标数据进行训练。
- **Standard Test-Time Adaptation / Fully Test-Time Adaptation**：通常假设目标域是固定的或静态的，而 CoTTA 关注的是持续变化的目标域。
- **Test-Time Training (TTT)**：需要修改源模型的训练过程以加入辅助任务，因此无法使用任意的“开箱即用”预训练模型。

相比之下，CoTTA 专门解决在**无源数据**的条件下，模型如何在线适应一个**持续变化的**数据流，同时克服现有方法中常见的**错误累积**和**灾难性遗忘**问题。

## Method

论文的核心贡献是提出了**CoTTA (Continual Test-Time Adaptation)** 方法，旨在通过**减少错误累积**和**避免灾难性遗忘**，实现模型在非平稳环境下的长期稳定适应，主要有两个关键部分。

### 1. 减少错误累积 (Reducing Error Accumulation)

为了生成更可靠的自训练信号，CoTTA 采用了平均化的伪标签策略，该策略结合了权重平均和数据增强平均。

- **权重平均伪标签 (Weight-Averaged Pseudo-Labels)** 
    - 该方法采用一个**教师 - 学生 (teacher-student)** 框架。学生模型 (student model) 在线进行学习和更新。
    - 教师模型 (teacher model) 的权重是学生模型权重的**指数移动平均 (Exponential Moving Average, EMA)**。
    - 由于教师模型的更新更平滑，其预测结果通常比学生模型更准确，因此用它来生成伪标签，可以有效减少错误累积。学生模型通过最小化与教师伪标签的**一致性损失** (consistency loss) 来进行更新。
- **数据增强平均伪标签 (Augmentation-Averaged Pseudo-Labels)**
    - 为了进一步提升伪标签在遇到较大域偏移时的质量，CoTTA 会有条件地使用数据增强。
    - 它首先使用**原始预训练模型**评估当前测试数据的**预测置信度**，以此来近似域差异的大小。
    - **条件性应用**：
        - 如果置信度**高**（域差异小），则直接使用教师模型的预测作为伪标签。
        - 如果置信度**低**（域差异大），则对输入数据进行 N 次随机增强，并将教师模型对这些增强样本的平均预测结果作为伪标签。这可以进一步提高伪标签的鲁棒性。
### 2. 避免灾难性遗忘 (Avoiding Catastrophic Forgetting)

为了在长期适应过程中保留从源域学到的知识，CoTTA 引入了**随机恢复 (Stochastic Restoration)** 机制。

- **核心思想**：在每次模型更新后，以一个很小的概率 `p`，将模型中的一小部分权重参数随机地**恢复到其原始的、预训练时的状态**。
- **优势**：
    - 这种机制可以看作一种特殊的 Dropout。它能有效防止模型在适应新数据时“漂移”得离源模型太远，从而显式地保留了源知识，避免了灾难性遗忘。
    - 通过保留源知识，CoTTA 能够安全地更新网络中的**所有参数**，而不仅仅是归一化层，这为模型适应提供了更大的容量。

### Algorithm

**CoTTA** 算法的在线流程如下：

- **Initialization (初始化)**：
    - 加载一个“开箱即用”的预训练源模型 {{< imath >}}f_{\theta_{0}}{{< /imath >}} 
    - 用源模型权重初始化教师模型 {{< imath >}}f_{\theta'_{0}}{{< /imath >}} 
- **Iteration (迭代)**：对于在线输入的每个测试数据 {{< imath >}}x_{t}{{< /imath >}}​：
    1. **生成伪标签**：使用教师模型 {{< imath >}}f_{\theta'_{t}}{{< /imath >}}​​，并结合条件性数据增强，生成权重和增强平均的伪标签。
    2. **更新学生模型**：通过一致性损失更新学生模型 {{< imath >}}f_{\theta_{t}}{{< /imath >}}
    3. **更新教师模型**：使用 EMA 更新教师模型的权重 {{< imath >}}f_{\theta'_{t+1}}{{< /imath >}}
    4. **随机恢复**：对学生模型的权重进行随机恢复
- **Output (输出)**：使用教师模型 {{< imath >}}f_{\theta'_{t}}{{< /imath >}}​​ 进行在线预测，并传递更新后的学生和教师模型到下一个时间步。

## Experiments

论文在多个图像分类和语义分割任务上对 **CoTTA** 进行了评估，特别是在一个持续变化的测试环境中。

### Continual Adaptation on Corrupted Images

在 CIFAR10-C、CIFAR100-C 和 ImageNet-C 数据集上，模型被顺序输入 15 种不同类型的损坏图像。

- **主要发现**：
    - 在 CIFAR10-C 上，**CoTTA** 的平均错误率仅为 **16.2%**，显著优于 Source-only 基线 (43.5%) 和 TENT-continual (20.7%)。
    - 在更难的 CIFAR100-C 上，TENT 等方法因错误累积导致性能随时间推移而**急剧下降**（错误率从 37.2% 恶化到 90.4%），而 **CoTTA** 表现稳定，平均错误率仅为 **32.5%** 。
    - 实验表明，TENT 在持续适应的后期会因错误累积而性能崩溃，而 CoTTA 的随机恢复机制成功避免了这一点。

### Continual Adaptation on Semantic Segmentation

在一个从 Cityscapes (晴天) 到 ACDC (雾、夜、雨、雪等恶劣天气) 的持续语义分割任务中，模型会循环经历这四种天气条件 10 次，以测试其长期适应和遗忘情况。

- **主要发现**：
    - **CoTTA** 将平均 mIoU 提升至 **58.6%**，优于源模型 (56.7%) 和其他适应方法。
    - TENT 在此任务上表现不佳，因为其依赖的批量归一化 (Batch Normalization) 层在 Transformer 架构 (Segformer) 中很少。
    - **CoTTA** 不依赖于特定层，因此在基于 Transformer 的架构上同样有效，展现了其通用性。

## Analysis

通过消融实验验证了 CoTTA 各个组件的有效性。

- **权重平均的作用**：仅使用权重平均的伪标签，就将错误率从 20.7% (TENT-continual) 降至 18.3%，证明了教师模型伪标签的优越性。
- **数据增强平均的作用**：在权重平均的基础上再加入条件性数据增强，错误率进一步降至 17.4%。
- **随机恢复的作用**：最后加入随机恢复机制，错误率最终降至 **16.2%**，并且解决了长期适应中的性能衰退问题，证明了其在避免灾难性遗忘中的关键作用。

## Related Work

论文回顾了与 **CoTTA** 相关的领域：
- **Test-Time Adaptation (TTA)**：现有工作大多关注静态目标域，在持续变化的环境中，基于熵最小化或伪标签的方法容易因伪标签噪声而累积错误。
- **Continuous Domain Adaptation**：与 CoTTA 目标相似，但现有方法通常需要访问源数据来对齐分布。
- **Continual Learning**：CoTTA 借鉴了该领域的思想来解决**灾难性遗忘**问题，但将其应用在了一个无监督、测试时适应的独特场景中。
- **Source-Free Domain Adaptation**：CoTTA 属于此范畴，其新颖之处在于它专为**在线**和**持续变化**的环境设计，而这是先前工作很少考虑的。

## Discussion

**CoTTA** 成功地解决了在无源数据、非平稳环境下进行**持续测试时适应**的挑战。它通过创新的机制同时解决了**错误累积**和**灾难性遗忘**这两个核心难题。

- **优势总结**：
    - **稳定与长效**：通过随机恢复机制，CoTTA 实现了在长期持续适应过程中的性能稳定，避免了性能崩溃。
    - **实用与通用**：无需访问源数据，也无需修改模型训练过程，可直接用于各类“开箱即用”的预训练模型（包括 CNN 和 Transformer） 。
    - **高效**：整个适应过程在线进行，模型根据当前数据流即时更新和预测。

总而言之，**CoTTA** 为模型在真实世界中部署后的持续自我进化提供了一个强大且实用的框架，使模型能够鲁棒地适应不断变化的操作环境。