<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Posts | diefish's blog</title><meta name=keywords content><meta name=description content="Posts - diefish's blog"><meta name=author content="diefish"><link rel=canonical href=https://diefish1024.github.io/posts/><link crossorigin=anonymous href=/assets/css/stylesheet.8fe10233a706bc87f2e08b3cf97b8bd4c0a80f10675a143675d59212121037c0.css integrity="sha256-j+ECM6cGvIfy4Is8+XuL1MCoDxBnWhQ2ddWSEhIQN8A=" rel="preload stylesheet" as=style><link rel=icon href=https://diefish1024.github.io/images/avatar.jpg><link rel=icon type=image/png sizes=16x16 href=https://diefish1024.github.io/images/avatar.jpg><link rel=icon type=image/png sizes=32x32 href=https://diefish1024.github.io/images/avatar.jpg><link rel=apple-touch-icon href=https://diefish1024.github.io/images/avatar.jpg><link rel=mask-icon href=https://diefish1024.github.io/images/avatar.jpg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate type=application/rss+xml href=https://diefish1024.github.io/posts/index.xml><link rel=alternate hreflang=en href=https://diefish1024.github.io/posts/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.css integrity=sha384-MlJdn/WNKDGXveldHDdyRP1R4CTHr3FeuDNfhsLPYrq2t0UBkUdK2jyTnXPEK1NQ crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.js integrity=sha384-VQ8d8WVFw0yHhCk5E8I86oOhv48xLpnDZx5T9GogA/Y84DcCKWXDmSDfn13bzFZY crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/contrib/auto-render.min.js integrity=sha384-+XBljXPPiv+OzfbB3cVmLHf4hdUFHlWNZN5spNQ7rmHTXpd7WvJum6fIACpNNfIR crossorigin=anonymous></script><script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}]})})</script><meta property="og:url" content="https://diefish1024.github.io/posts/"><meta property="og:site_name" content="diefish's blog"><meta property="og:title" content="Posts"><meta property="og:description" content="A freshman at SJTU John class."><meta property="og:locale" content="zh-cn"><meta property="og:type" content="website"><meta property="og:image" content="https://diefish1024.github.io/images/avatar.jpg"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://diefish1024.github.io/images/avatar.jpg"><meta name=twitter:title content="Posts"><meta name=twitter:description content="A freshman at SJTU John class."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://diefish1024.github.io/posts/"}]}</script></head><body class=list id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://diefish1024.github.io/ accesskey=h title="Home (Alt + H)"><img src=https://diefish1024.github.io/images/avatar.jpg alt aria-label=logo height=35>Home</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://diefish1024.github.io/archives/ title=archives><span>archives</span></a></li><li><a href=https://diefish1024.github.io/tags/ title=tags><span>tags</span></a></li><li><a href=https://diefish1024.github.io/categories/ title=categories><span>categories</span></a></li><li><a href=https://diefish1024.github.io/search/ title="search (Alt + /)" accesskey=/><span>search</span></a></li></ul></nav></header><main class=main><header class=page-header><div class=breadcrumbs><a href=https://diefish1024.github.io/>Home</a></div><h1>Posts</h1></header><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>17. 并发 Bugs</h2></header><div class=entry-content><p>数据竞争 大多并发 bug 最后都会体现为数据竞争 (Data Race)
对于顺序程序而言，函数 f() 返回之后就已经完成了所有的状态修改，对于其他部分而言这个修改是立即生效的；如果对于并发程序而言模式的切换也在瞬间完成，那就不会导致并发的问题
然而实际上模式的切换需要时间，执行的操作在未来一段时间之后才会就绪，但是我们在实际编程时总是容易有“立即生效”的肌肉记忆，这就导致了并发问题的可能性
不过对于函数式编程而言，操作不存在对外状态的修改，没有副作用（只会操作局部变量），这就不会导致并发问题
Data Race 发生的实质是不同的线程同时访问同一内存，并且至少有一个是写，形象的理解就是不同的内存访问在“赛跑”，跑赢的操作先执行
Not that easy: 虽然我们将数据竞争形象地比喻为“赛跑”，但实际上，哪一个操作能“跑赢”并没有想象中那么简单和确定，其复杂性主要体现在以下几个方面
弱内存模型 (Weak memory model)：在现代处理器架构中，为了提升性能，处理器可能会对内存操作进行重排序。这意味着，不同的线程或“观察者”在不同时间点看到共享内存的状态可能是不一致的。一个线程对内存的写入操作，可能不会立即对所有其他线程可见，导致不同线程观察到不同的结果。这种内存模型的一致性问题使得确定哪个操作“先发生”变得非常困难且不确定。
未定义行为 (Undefined Behavior)：从 C++11 标准开始，数据竞争被明确规定为未定义行为。这意味着，如果你的程序发生了数据竞争，编译器可以自由地产生任何行为，无论是崩溃、产生错误结果，还是看似正常运行但结果不可预测。这使得数据竞争成为非常危险且难以调试的并发错误，因为它的表现可能是不确定、不稳定的。
多线程与多内存的复杂交互：在实际的并发程序中，通常会有多个线程同时访问多个共享内存位置。这些线程和内存之间存在复杂的读（R）写（W）交互。一个线程对一个内存位置的写入可能影响到其他多个线程对该位置的读取，同时，多个内存位置之间也可能存在复杂的依赖关系和缓存一致性问题。这种错综复杂的交互网络进一步加剧了数据竞争的不可预测性。
为了消灭数据竞争，我们需要保证程序的 serializability ，可能竞争的内存访问要么互斥，要么同步
实际编程中遇到的数据竞争 bug 大多属于上错了锁和忘记上锁两种情况的变种
Case 1: 上错了锁
1 2 void T_1() { spin_lock(&amp;A); sum++; spin_unlock(&amp;A); } void T_2() { spin_lock(&amp;B); sum++; spin_unlock(&amp;B); } Case 2: 忘记上锁
1 2 void T_1() { spin_lock(&amp;A); sum++; spin_unlock(&amp;A); } void T_2() { sum++; } 但是实际系统面临的情况比这复杂的多，因为
内存可以是地址空间的任何内存，比如全局变量、堆内存分配的变量、程序的栈…… 访问可以发生在任何代码，比如自己的代码、框架代码、一行没读到的汇编指令、某条 ret 指令 “一行没读到的汇编指令”造成的访问的情况有编译器优化造成的指令重排、硬件层面弱内存模型的内存访问重排、还有一些高层语言操作的隐式内存访问 实际系统中虽然难以避免，但是会尽可能保证底层的结构对上层尽可能封闭来防止这种错误 死锁 死锁 (Deadlock) 是指一个群体中的每个成员都在等待其他成员（包括自身）采取行动的状态
死锁有两种：
AA-Deadlock: 自己等待自己
1 2 3 4 5 6 7 lock(&amp;lk); // lk->locked == ✅; proceed ... // Possibly in interrupt handler lock(&amp;lk); // while (lk->locked == ❌) ; 这样的错误虽然看起来很傻，但是在真实程序复杂的控制流中是可能出现的
...</p></div><footer class=entry-footer><span title='2025-07-31 12:12:00 +0800 +0800'>July 31, 2025</span>&nbsp;·&nbsp;2 min&nbsp;·&nbsp;diefish</footer><a class=entry-link aria-label="post link to 17. 并发 Bugs" href=https://diefish1024.github.io/posts/nju-os-2025/17-%E5%B9%B6%E5%8F%91-bugs/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>KV Cache 入门</h2></header><div class=entry-content><p>推理效率对于 llm 是一个至关重要的问题。当模型生成文本时，尤其是以自回归方式逐词生成时，效率瓶颈会变得非常明显。KV Cache 就是为了解决这一问题而诞生的技术。
1. What is KV Cache? KV Cache，全称 Key-Value Cache，是一种优化技术，用于加速 Transformer 架构在自回归生成过程中的推理速度。它的核心思想是缓存并重用在注意力机制中计算得到的 Key (K) 和 Value (V) 向量。
2. Transformer Attention Mechanism Review 要理解 KV Cache，首先需要对 Transformer 架构中的自注意力机制有一个基本认识。自注意力机制允许模型在处理序列中的某个词时，考虑序列中所有其他词的重要性。
每个输入 token（词或子词）在进入注意力层时，都会被转换成三个不同的向量：
Q 向量：代表当前 token 的“查询”信息 K 向量：代表所有 token 的“键”信息，用于与 Query 进行匹配 V 向量：代表所有 token 的“值”信息，用于加权求和，得到最终的输出 自注意力机制的计算过程为以下步骤：
计算 Query 与所有 Key 的点积，得到注意力分数 将注意力分数进行缩放，除以 $ \sqrt{d_k} $（$ d_k $ 是 Key 向量的维度) 对缩放后的分数进行 Softmax，将其转换为注意力权重，表示每个 token 对当前 token 的重要性 将注意力权重与 Value 向量进行加权求和，得到当前 token 的注意力输出 公式为： $$ \text{Attention}(Q, K, V) = \text{softmax}\left(\frac{QK^T}{\sqrt{d_k}}\right)V $$ 其中矩阵 $ Q,K,V \in \mathbb{R}^{L \times d} $ ，$ L $ 为当前上下文长度
...</p></div><footer class=entry-footer><span title='2025-07-30 22:21:00 +0800 +0800'>July 30, 2025</span>&nbsp;·&nbsp;3 min&nbsp;·&nbsp;diefish</footer><a class=entry-link aria-label="post link to KV Cache 入门" href=https://diefish1024.github.io/posts/ai-infra/kv-cache-%E5%85%A5%E9%97%A8/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>EmT</h2></header><div class=entry-content><p>Abstract 问题：现有 EEG 情绪识别方法对长期上下文信息关注不足，导致跨被试泛化能力减弱 方案：提出 Emotion Transformer (EmT) ，为 Graph-Transformer 混和架构 核心模块： TGC：将 EEG 信号转换为时序图序列 RMPG：使用残差多视图金字塔 GCN，学习动态、多尺度的空间连接模式，生成 token（核心） TCT：使用任务自适应的 Transformer，学习 token 序列上下文（核心） TSO：输出分类/回归结果 成果：在多个公开数据集的广义跨被试任务上面超过了 baseline Introduction & Related Work 为什么 EEG 难以使用跨被试 (cross-subject) 的场景？
个体差异：不同被试生理结构和认知策略差异，导致 EEG 模式不同 低信噪比：EEG 信号容易受到外源噪声干扰（肌电、眼电……） 目标是学习一种跨被试共享、具有泛化能力的情绪表征
Gpaph Neural Networks 核心思想：EEG 数据具有非欧图结构，适合使用 GNN 来处理 代表工作： ChebyNet：使用切比雪夫多项式近似光谱滤波，EmT 模型中采用其作为 GCN 层 GCN：通过局部一阶聚合近似光谱滤波 DGCNN / RGNN：使用 GNNs 提取 EEG 空间信息；依赖单一的邻接矩阵，忽略时序上下文，具有局限性；而 EmT 通过多视图可学习邻接矩阵和时序图来弥补 Temporal Context Learning 核心理念: 情绪是连续认知过程，EEG 信号中嵌入时序上下文信息 代表工作： LSTM / TCN / TESANet / Conformer / AMDET 局限性：这些方法通常从扁平化的 EEG 特征向量学习，可能未能有效学习空间关系；EmT 则通过并行 GCN 和 STA 层更有效地捕捉时空信息 EEG Emotion Recognition 核心理念：EEG 情绪识别面临个体差异大、信噪比低等挑战，需提取光谱、空间、时序特征 代表工作： GCB-Net / TSception 局限性：没有关注长时序上下文信息 Method EmT 是一个端到端的框架，包含四大模块：
...</p></div><footer class=entry-footer><span title='2025-07-30 12:55:00 +0800 +0800'>July 30, 2025</span>&nbsp;·&nbsp;6 min&nbsp;·&nbsp;diefish</footer><a class=entry-link aria-label="post link to EmT" href=https://diefish1024.github.io/posts/literature-notes/emt/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>SSA</h2></header><div class=entry-content><p>Introduction TTA 在回归任务上的局限：为分类任务设计，一般基于熵最小化和特征对齐；熵最小化不适用，回归模型产生单一值，不产生概率分布；简单特征对齐对回归模型效果不佳，可能反而会稀释需要学习的特征
Problem Setting 考虑一个回归模型 $ f_\theta: \mathcal{X} \to \mathbb{R} $，可以进一步分解为特征提取器 $ g_\phi: \mathcal{X} \to \mathbb{R}^D $（从输入 $ \mathcal{X} $ 提取 $ D $ 维特征 $ z $）和线性回归器 $ h_\psi(z) = w^T z + b $（或者 $ h_{\psi}(z)=Wz+b $）
$ f_\theta $ 首先在一个有标签的源数据集 $ S = \{(x_i, y_i)\}_{i=1}^{N_s} $ 上进行预训练，数据从源域分布 $ p_s $ 中采样
目标是使用一个无标签的目标数据集 $ T = \{x_j\}_{j=1}^{N_t} $ 来适应预训练好的模型 $ f_\theta $ 到目标域
我们假设存在 covariate shift ，这意味着：
...</p></div><footer class=entry-footer><span title='2025-07-30 11:00:00 +0800 +0800'>July 30, 2025</span>&nbsp;·&nbsp;4 min&nbsp;·&nbsp;diefish</footer><a class=entry-link aria-label="post link to SSA" href=https://diefish1024.github.io/posts/literature-notes/ssa/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>T-TIME</h2></header><div class=entry-content><p>Method Problem Set EEG 数据 $ \{ X_{s,l}^{i},y_{s,l}^{i} \}_{i=1}^{n_{s,l}} $ ，进行无监督在线 K 分类
Source Model Training 对源数据做 Euclidean alignment (EA) 数据对齐，减少不同个体 EEG 信号差异
EA 计算每个个体所有 EEG 试次协方差矩阵的算术平均值 $$ R_{s,l} = \dfrac{1}{n}\sum_{i=1}^{n} X_{i}(X_{i})^{T} \implies \bar{X}_{i} = R_{s,l}^{-1/2}X_{i} $$ 之后再整合经过对齐的受试者数据，形成“源域”
在整合后的数据上独立训练 $ M $ 个模型
Incremental EA on Target Data 对新数据增量式更新协方差矩阵，再用新的矩阵更新所有测试数据
Target Label Prediction 用训练好的 $ M $ 模型初始化用于适应目标域的 $ M $ 个 TTA 模型 $ f_{m} $
新的 $ X_{a} $ 经过 IEA 被变换为 $ X_{a}' $ 后被输入到每个模型 $ f_{m} $ 中进行分类，输出概率向量 $ f_{m}(X_{a}') $
...</p></div><footer class=entry-footer><span title='2025-07-30 11:00:00 +0800 +0800'>July 30, 2025</span>&nbsp;·&nbsp;1 min&nbsp;·&nbsp;diefish</footer><a class=entry-link aria-label="post link to T-TIME" href=https://diefish1024.github.io/posts/literature-notes/t-time/></a></article><footer class=page-footer><nav class=pagination><a class=prev href=https://diefish1024.github.io/posts/>«&nbsp;Prev&nbsp;
</a><a class=next href=https://diefish1024.github.io/posts/page/3/>Next&nbsp;&nbsp;»</a></nav></footer></main><footer class=footer><span>&copy; 2025 <a href=https://diefish1024.github.io/>diefish's blog</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>