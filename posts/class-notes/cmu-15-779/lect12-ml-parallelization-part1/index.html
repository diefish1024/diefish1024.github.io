<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Lect12-ML Parallelization-part1 | diefish's blog</title><meta name=keywords content="learning,CS,AI-Infra"><meta name=description content="整理自 CMU 15-779 Lect 12，从数据并行到 ZeRO，解答了是如何把大模型塞进有限的显存里的问题。
Data Parallelism

训练本质上是计算梯度并更新权重。数据并行直观理解就是如果有 $ N $ 个 GPU，那么把总的 Batch Size 分成 $ N $ 份。
在第 $ k $ 个 GPU上的计算过程：

Local Gradient：基于本地数据 $ x^{(k)} $ 计算梯度 $$ 
g^{(k)} = \nabla L(w_t, x^{(k)})
 $$
All-Reduce：计算全局平均梯度 $$ 
\bar{g} = \frac{1}{N} \sum_{k=1}^{N} g^{(k)}
 $$
Weight Update：所有 GPU 使用相同的 $ \bar{g} $ 更新权重 $$ 
w_{t+1} = w_t - \eta \cdot \text{Optimizer}(\bar{g}, \text{State}_t)
 $$
这时每个 GPU 上都会有一样的完整模型副本，各算各的梯度，最后在汇总计算。

实现方法"><meta name=author content="diefish"><link rel=canonical href=https://diefish1024.github.io/posts/class-notes/cmu-15-779/lect12-ml-parallelization-part1/><link crossorigin=anonymous href=/assets/css/stylesheet.7e33168b13c822c8560dd6cce14b81ffdf7b6c118596a21d43f319d693f61534.css integrity="sha256-fjMWixPIIshWDdbM4UuB/997bBGFlqIdQ/MZ1pP2FTQ=" rel="preload stylesheet" as=style><link rel=icon href=https://diefish1024.github.io/images/avatar.jpg><link rel=icon type=image/png sizes=16x16 href=https://diefish1024.github.io/images/avatar.jpg><link rel=icon type=image/png sizes=32x32 href=https://diefish1024.github.io/images/avatar.jpg><link rel=apple-touch-icon href=https://diefish1024.github.io/images/avatar.jpg><link rel=mask-icon href=https://diefish1024.github.io/images/avatar.jpg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://diefish1024.github.io/posts/class-notes/cmu-15-779/lect12-ml-parallelization-part1/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.css integrity=sha384-MlJdn/WNKDGXveldHDdyRP1R4CTHr3FeuDNfhsLPYrq2t0UBkUdK2jyTnXPEK1NQ crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.js integrity=sha384-VQ8d8WVFw0yHhCk5E8I86oOhv48xLpnDZx5T9GogA/Y84DcCKWXDmSDfn13bzFZY crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/contrib/auto-render.min.js integrity=sha384-+XBljXPPiv+OzfbB3cVmLHf4hdUFHlWNZN5spNQ7rmHTXpd7WvJum6fIACpNNfIR crossorigin=anonymous></script><script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}]})})</script><meta property="og:url" content="https://diefish1024.github.io/posts/class-notes/cmu-15-779/lect12-ml-parallelization-part1/"><meta property="og:site_name" content="diefish's blog"><meta property="og:title" content="Lect12-ML Parallelization-part1"><meta property="og:description" content="整理自 CMU 15-779 Lect 12，从数据并行到 ZeRO，解答了是如何把大模型塞进有限的显存里的问题。
Data Parallelism 训练本质上是计算梯度并更新权重。数据并行直观理解就是如果有 $ N $ 个 GPU，那么把总的 Batch Size 分成 $ N $ 份。
在第 $ k $ 个 GPU上的计算过程：
Local Gradient：基于本地数据 $ x^{(k)} $ 计算梯度 $$ g^{(k)} = \nabla L(w_t, x^{(k)}) $$ All-Reduce：计算全局平均梯度 $$ \bar{g} = \frac{1}{N} \sum_{k=1}^{N} g^{(k)} $$ Weight Update：所有 GPU 使用相同的 $ \bar{g} $ 更新权重 $$ w_{t+1} = w_t - \eta \cdot \text{Optimizer}(\bar{g}, \text{State}_t) $$ 这时每个 GPU 上都会有一样的完整模型副本，各算各的梯度，最后在汇总计算。 实现方法"><meta property="og:locale" content="zh-cn"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2026-02-06T13:29:00+08:00"><meta property="article:modified_time" content="2026-02-06T13:29:00+08:00"><meta property="article:tag" content="Learning"><meta property="article:tag" content="CS"><meta property="article:tag" content="AI-Infra"><meta property="og:image" content="https://diefish1024.github.io/images/avatar.jpg"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://diefish1024.github.io/images/avatar.jpg"><meta name=twitter:title content="Lect12-ML Parallelization-part1"><meta name=twitter:description content="整理自 CMU 15-779 Lect 12，从数据并行到 ZeRO，解答了是如何把大模型塞进有限的显存里的问题。
Data Parallelism

训练本质上是计算梯度并更新权重。数据并行直观理解就是如果有 $ N $ 个 GPU，那么把总的 Batch Size 分成 $ N $ 份。
在第 $ k $ 个 GPU上的计算过程：

Local Gradient：基于本地数据 $ x^{(k)} $ 计算梯度 $$ 
g^{(k)} = \nabla L(w_t, x^{(k)})
 $$
All-Reduce：计算全局平均梯度 $$ 
\bar{g} = \frac{1}{N} \sum_{k=1}^{N} g^{(k)}
 $$
Weight Update：所有 GPU 使用相同的 $ \bar{g} $ 更新权重 $$ 
w_{t+1} = w_t - \eta \cdot \text{Optimizer}(\bar{g}, \text{State}_t)
 $$
这时每个 GPU 上都会有一样的完整模型副本，各算各的梯度，最后在汇总计算。

实现方法"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://diefish1024.github.io/posts/"},{"@type":"ListItem","position":2,"name":"Class Notes","item":"https://diefish1024.github.io/posts/class-notes/"},{"@type":"ListItem","position":3,"name":"CMU 15-779","item":"https://diefish1024.github.io/posts/class-notes/cmu-15-779/"},{"@type":"ListItem","position":4,"name":"Lect12-ML Parallelization-part1","item":"https://diefish1024.github.io/posts/class-notes/cmu-15-779/lect12-ml-parallelization-part1/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Lect12-ML Parallelization-part1","name":"Lect12-ML Parallelization-part1","description":"整理自 CMU 15-779 Lect 12，从数据并行到 ZeRO，解答了是如何把大模型塞进有限的显存里的问题。\nData Parallelism 训练本质上是计算梯度并更新权重。数据并行直观理解就是如果有 $ N $ 个 GPU，那么把总的 Batch Size 分成 $ N $ 份。\n在第 $ k $ 个 GPU上的计算过程：\nLocal Gradient：基于本地数据 $ x^{(k)} $ 计算梯度 $$ g^{(k)} = \\nabla L(w_t, x^{(k)}) $$ All-Reduce：计算全局平均梯度 $$ \\bar{g} = \\frac{1}{N} \\sum_{k=1}^{N} g^{(k)} $$ Weight Update：所有 GPU 使用相同的 $ \\bar{g} $ 更新权重 $$ w_{t+1} = w_t - \\eta \\cdot \\text{Optimizer}(\\bar{g}, \\text{State}_t) $$ 这时每个 GPU 上都会有一样的完整模型副本，各算各的梯度，最后在汇总计算。 实现方法\n","keywords":["learning","CS","AI-Infra"],"articleBody":"整理自 CMU 15-779 Lect 12，从数据并行到 ZeRO，解答了是如何把大模型塞进有限的显存里的问题。\nData Parallelism 训练本质上是计算梯度并更新权重。数据并行直观理解就是如果有 $ N $ 个 GPU，那么把总的 Batch Size 分成 $ N $ 份。\n在第 $ k $ 个 GPU上的计算过程：\nLocal Gradient：基于本地数据 $ x^{(k)} $ 计算梯度 $$ g^{(k)} = \\nabla L(w_t, x^{(k)}) $$ All-Reduce：计算全局平均梯度 $$ \\bar{g} = \\frac{1}{N} \\sum_{k=1}^{N} g^{(k)} $$ Weight Update：所有 GPU 使用相同的 $ \\bar{g} $ 更新权重 $$ w_{t+1} = w_t - \\eta \\cdot \\text{Optimizer}(\\bar{g}, \\text{State}_t) $$ 这时每个 GPU 上都会有一样的完整模型副本，各算各的梯度，最后在汇总计算。 实现方法\n早期的实现方案是使用一个 Parameter Server，当 Server 接收到所有人的梯度以后再汇总更新。但是这样当 GPU 数量增多时，中心服务器的带宽就会出现不足，从而导致无法扩展。\n这就引出了下面的核心问题，“如何去中心化？”。\nAll-Reduce 我们可以把上面的问题抽象为，如何让 $ N $ 个设备在没有一个“中心”的情况下，通过互相通信，最终每个设备都能得到数据的均值？这个过程在数学上被称为 AllReduce。 $$ \\text{out}[i] = \\sum \\text{in}^{(k)}[i] $$ 一般除了 Naive 外一般有 Ring AllReduce, Tree AllReduce, Butterfly AllReduce 三种方法实现 AllReduce，其中 Ring AllReduce 最好，因此其余方法在此处略过。\nRing AllReduce\n分为 Scatter-Reduce 和 All-Gather 两个阶段。\nScatter-Reduce 阶段的目标是让每张 GPU 负责算出模型参数中某一块片段的总和。原理：假设参数量是 $ M $，有 $ N $ 张卡。我们将数据切成 $ N $ 块。在 $ N-1 $ 轮迭代中，每张卡同时发送自己的一块数据给邻居，并接收邻居传来的另一块数据进行累加。每一块数据在环里转了一圈，最终汇聚到了对应的 GPU 上。\nAll-Gather 阶段的目的是把第一轮的结果广播给所有人。每次迭代把算好的数据传递给下一个设备，并收到上一个设备的数据存下来。迭代 $ N-1 $ 轮后每个设备就都存有完整的数据了。\n整个过程中每个设备只用和邻居通信，因此发送的数据总量大致是 $ 2M $，和 $ N $ 无关，很适合大规模的集群训练，不会因为加卡而出现单卡通讯瓶颈。\nThe Memory Wall 虽然通信问题得到了解决，但是随着模型参数量逐渐加大，单卡的显存也成为了瓶颈。传统数据并行方案中每张卡都要存储完整的模型和状态，随着参数量增大，不可能跑得动大模型。 想要解决这个问题，首先需要知道显存到底被谁消耗了？实际上除了模型权重本身，还有更多的显存消耗在了梯度和优化器状态上。\n真实的训练过程中，为了确保精度的同时加速计算，通常会采用混合精度的方法，同时维护 FP16 和 FP32 两种格式的数据。\n以 1B 的模型为例，FP16 的参数显存占用 $ 1 \\text{B} \\times 2 \\text{ bytes} = 2 \\text{GB} $；FP16 的梯度显存占用 $ 1 \\text{B} \\times 2 \\text{ bytes} = 2 \\text{GB} $；FP32 的优化器状态（为了数值的稳定性，一般需要更高的精度）通常包含 $ 3 $ 个 FP32 的变量，从而显存占用达到了 $ 16\\text{GB} $。从而光是加载这么一个模型，就已经占用了 $ 20\\text{GB} $ 的显存。\n并且在训练时，还需要保存前向传播每一层输出的结果，用于反向传播计算梯度。对于长文本训练，这里动态的显存占用也同样是一个很大的开销。\nZeRO ZeRO 的目标就是解决上面遇到的显存问题，核心思想很简单，就是把这些通用的数据公用，分摊开销。\nZeRO 根据切分的粒度，分成了 $ 3 $ 个 Stage。 Stage 1: $ P_{\\text{os}} $ 切分优化器的状态。这是最直观也是性价比最高的一步。在上面的例子里，单优化器的状态就占了 $ 80\\% $ 的显存，并且每张卡上存储的优化器状态时完全一样的。因此很自然就想到每张卡只负责维护 $ \\frac{1}{N} $ 的优化器状态。\n工作流程\nForward \u0026 Backward：每张卡正常进行前向和反向传播，计算出完整的梯度。 Scatter-Reduce：这是关键的一步。不同于传统的数据并行（直接做 All-Reduce 得到完整梯度），ZeRO Stage 1 只做 Scatter-Reduce。 结果：GPU 0 只需要收集并聚合第 0 块梯度的总和，GPU 1 只需要第 1 块… 以此类推。 注：此时每张卡手里只有它负责的那一小块平均梯度。 Optimizer Step：GPU $ k $ 使用它持有的那 $ \\frac{1}{N} $ 块平均梯度，去更新它显存里维护的那 $ \\frac{1}{N} $ 块优化器状态和模型参数。 All-Gather：现在每张卡上的模型参数只有 $ \\frac{1}{N} $ 是最新的。为了进行下一轮训练，大家立刻执行 All-Gather，将各自更新好的参数广播给所有设备。 收益与代价\n显存：节省了巨大的 FP32 状态显存。 通信：通信量没有增加。原本的 Ring AllReduce 分为 Scatter-Reduce + All-Gather 两个阶段。ZeRO Stage 1 只是把这两个阶段拆开了，先做 Scatter-Reduce 拿到梯度，更新完参数后，再做 All-Gather。总量依然是 $ 2 \\times M $。 Stage 2: $ P_{\\text{os+g}} $ 既然已经切了优化器状态，同样梯度也一样可以切。原理是每张卡不再保存完整的梯度，只保存它负责更新的那 $ 1/N $ 的梯度，这样又节省了梯度的显存占用。（和 Stage 1 的区别是显式增加了梯度部分缓存的释放）\n工作流程\nBackward：算出梯度后，立刻进行 Reduce-Scatter 操作。 Reduce-Scatter：互相传阅梯度，最后每块 GPU 只保留自己负责的 $ \\frac{1}{N} $ 块梯度和。 释放显存：其他部分的梯度在 Reduce-Scatter 之后就可以立刻扔掉（释放显存），不需要一直存着。 收益：进一步节省了显存，通信量依然保持不变。\nStage 3: $ P_{\\text{os+g+p}} $ 更加激进的一步，连着参数一起切分，每张卡上不再有完整的模型。原理是前向传播时“用时再取”，用通信量换取显存。\n工作流程\nForward: 当 GPU 要计算第 1 层 (Conv1) 时，每个设备只有 Conv1 的一小块碎片。 Action：立刻发起一次 All-Gather，把自己手里的 Conv1 碎片拼起来。 Compute：拼好完整的 Conv1 后，进行计算。 Discard：算完 Conv1，立刻把借来的参数扔掉，只保留自己负责的那一小块碎片，释放显存。 接着算 Conv2… 重复上述过程。 Backward: 反向传播时同理。要算 Conv2 的梯度，再次 All-Gather 拼出完整的 Conv2 参数，算完梯度后再次扔掉。 收益与代价\n显存：显存占用降到了极致。随着 GPU 数量 N 增加，单卡显存占用线性下降。理论上你可以训练无限大的模型。 通信：通信量增加了 50% (1.5x)。因为每次前向和反向都要重新 All-Gather 参数，比之前多了一次全量的参数广播。 Summary 在 64 卡的设置下，ZeRO-3 能把单卡显存占用从 120GB 压到 1.9GB。\n在 PyTorch 中，这个技术对应的是 FSDP (Fully Sharded Data Parallel)。 本质就是在 Compute (计算)、Memory (显存) 和 Communication (通信) 这三者之间做 Trade-off。\n","wordCount":"389","inLanguage":"en","image":"https://diefish1024.github.io/images/avatar.jpg","datePublished":"2026-02-06T13:29:00+08:00","dateModified":"2026-02-06T13:29:00+08:00","author":{"@type":"Person","name":"diefish"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://diefish1024.github.io/posts/class-notes/cmu-15-779/lect12-ml-parallelization-part1/"},"publisher":{"@type":"Organization","name":"diefish's blog","logo":{"@type":"ImageObject","url":"https://diefish1024.github.io/images/avatar.jpg"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://diefish1024.github.io/ accesskey=h title="Home (Alt + H)"><img src=https://diefish1024.github.io/images/avatar.jpg alt aria-label=logo height=35>Home</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://diefish1024.github.io/posts/ title=Posts><span>Posts</span></a></li><li><a href=https://diefish1024.github.io/tags/ title=Tags><span>Tags</span></a></li><li><a href=https://diefish1024.github.io/categories/ title=Categories><span>Categories</span></a></li><li><a href=https://diefish1024.github.io/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li><li><a href=https://diefish1024.github.io/archives/ title=Archives><span>Archives</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://diefish1024.github.io/>Home</a>&nbsp;»&nbsp;<a href=https://diefish1024.github.io/posts/>Posts</a>&nbsp;»&nbsp;<a href=https://diefish1024.github.io/posts/class-notes/>Class Notes</a>&nbsp;»&nbsp;<a href=https://diefish1024.github.io/posts/class-notes/cmu-15-779/>CMU 15-779</a></div><h1 class="post-title entry-hint-parent">Lect12-ML Parallelization-part1</h1><div class=post-meta><span title='2026-02-06 13:29:00 +0800 +0800'>February 6, 2026</span>&nbsp;·&nbsp;2 min&nbsp;·&nbsp;diefish&nbsp;|&nbsp;<a href=https://github.com/diefish1024/diefish1024.github.io/blob/main/content/posts/Class%20Notes/CMU%2015-779/lect12-ml-parallelization-part1.md rel="noopener noreferrer edit" target=_blank>Suggest Changes</a></div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#data-parallelism aria-label="Data Parallelism">Data Parallelism</a></li><li><a href=#all-reduce aria-label=All-Reduce>All-Reduce</a></li><li><a href=#the-memory-wall aria-label="The Memory Wall">The Memory Wall</a></li><li><a href=#zero aria-label=ZeRO>ZeRO</a><ul><li><a href=#stage-1-hahahugoshortcode34s23hbhb aria-label="Stage 1: $ P_{\text{os}} $">Stage 1: $ P_{\text{os}} $</a></li><li><a href=#stage-2-hahahugoshortcode34s31hbhb aria-label="Stage 2: $ P_{\text{os+g}} $">Stage 2: $ P_{\text{os+g}} $</a></li><li><a href=#stage-3-hahahugoshortcode34s34hbhb aria-label="Stage 3: $ P_{\text{os+g+p}} $">Stage 3: $ P_{\text{os+g+p}} $</a></li></ul></li><li><a href=#summary aria-label=Summary>Summary</a></li></ul></div></details></div><div class=post-content><p>整理自 CMU 15-779 Lect 12，从数据并行到 ZeRO，解答了是如何把大模型塞进有限的显存里的问题。</p><h2 id=data-parallelism>Data Parallelism<a hidden class=anchor aria-hidden=true href=#data-parallelism>#</a></h2><p><img loading=lazy src=/images/lect12-ml-parallelization-part1/pasted-image-20260206223357.png></p><p>训练本质上是计算梯度并更新权重。数据并行直观理解就是如果有 $ N $ 个 GPU，那么把总的 Batch Size 分成 $ N $ 份。</p><p>在第 $ k $ 个 GPU上的计算过程：</p><ol><li><strong>Local Gradient</strong>：基于本地数据 $ x^{(k)} $ 计算梯度 $$
g^{(k)} = \nabla L(w_t, x^{(k)})
$$</li><li><strong>All-Reduce</strong>：计算全局平均梯度 $$
\bar{g} = \frac{1}{N} \sum_{k=1}^{N} g^{(k)}
$$</li><li><strong>Weight Update</strong>：所有 GPU 使用相同的 $ \bar{g} $ 更新权重 $$
w_{t+1} = w_t - \eta \cdot \text{Optimizer}(\bar{g}, \text{State}_t)
$$
这时每个 GPU 上都会有一样的完整模型副本，各算各的梯度，最后在汇总计算。</li></ol><p><strong>实现方法</strong></p><p><img loading=lazy src=/images/lect12-ml-parallelization-part1/pasted-image-20260206224408.png></p><p>早期的实现方案是使用一个 Parameter Server，当 Server 接收到所有人的梯度以后再汇总更新。但是这样当 GPU 数量增多时，中心服务器的带宽就会出现不足，从而导致无法扩展。</p><p>这就引出了下面的核心问题，“<strong>如何去中心化？</strong>”。</p><h2 id=all-reduce>All-Reduce<a hidden class=anchor aria-hidden=true href=#all-reduce>#</a></h2><p><img loading=lazy src=/images/lect12-ml-parallelization-part1/pasted-image-20260206225435.png></p><p>我们可以把上面的问题抽象为，如何让 $ N $ 个设备在没有一个“中心”的情况下，通过互相通信，最终每个设备都能得到数据的均值？这个过程在数学上被称为 <strong>AllReduce</strong>。
$$
\text{out}[i] = \sum \text{in}^{(k)}[i]
$$
一般除了 Naive 外一般有 Ring AllReduce, Tree AllReduce, Butterfly AllReduce 三种方法实现 AllReduce，其中 Ring AllReduce 最好，因此其余方法在此处略过。</p><p><strong>Ring AllReduce</strong></p><p><img loading=lazy src=/images/lect12-ml-parallelization-part1/pasted-image-20260206225917.png>
分为 <strong>Scatter-Reduce</strong> 和 <strong>All-Gather</strong> 两个阶段。</p><p><strong>Scatter-Reduce</strong> 阶段的目标是让每张 GPU 负责算出模型参数中某一块片段的总和。<strong>原理</strong>：假设参数量是 $ M $，有 $ N $ 张卡。我们将数据切成 $ N $ 块。在 $ N-1 $ 轮迭代中，每张卡同时发送自己的一块数据给邻居，并接收邻居传来的另一块数据进行累加。每一块数据在环里转了一圈，最终汇聚到了对应的 GPU 上。</p><p><strong>All-Gather</strong> 阶段的目的是把第一轮的结果广播给所有人。每次迭代把算好的数据传递给下一个设备，并收到上一个设备的数据存下来。迭代 $ N-1 $ 轮后每个设备就都存有完整的数据了。</p><p>整个过程中每个设备只用和邻居通信，因此发送的数据总量大致是 $ 2M $，和 $ N $ 无关，很适合大规模的集群训练，不会因为加卡而出现单卡通讯瓶颈。</p><h2 id=the-memory-wall>The Memory Wall<a hidden class=anchor aria-hidden=true href=#the-memory-wall>#</a></h2><p>虽然通信问题得到了解决，但是随着模型参数量逐渐加大，单卡的显存也成为了瓶颈。传统数据并行方案中每张卡都要存储完整的模型和状态，随着参数量增大，不可能跑得动大模型。
<img loading=lazy src=/images/lect12-ml-parallelization-part1/pasted-image-20260206234949.png></p><p>想要解决这个问题，首先需要知道显存到底被谁消耗了？实际上除了模型<strong>权重</strong>本身，还有更多的显存消耗在了<strong>梯度</strong>和<strong>优化器状态</strong>上。</p><p>真实的训练过程中，为了确保精度的同时加速计算，通常会采用混合精度的方法，同时维护 FP16 和 FP32 两种格式的数据。</p><p><img loading=lazy src=/images/lect12-ml-parallelization-part1/pasted-image-20260206235523.png>
以 1B 的模型为例，FP16 的参数显存占用 $ 1 \text{B} \times 2 \text{ bytes} = 2 \text{GB} $；FP16 的梯度显存占用 $ 1 \text{B} \times 2 \text{ bytes} = 2 \text{GB} $；FP32 的优化器状态（为了数值的稳定性，一般需要更高的精度）通常包含 $ 3 $ 个 FP32 的变量，从而显存占用达到了 $ 16\text{GB} $。从而光是加载这么一个模型，就已经占用了 $ 20\text{GB} $ 的显存。</p><p>并且在训练时，还需要保存前向传播每一层输出的结果，用于反向传播计算梯度。对于长文本训练，这里动态的显存占用也同样是一个很大的开销。</p><h2 id=zero>ZeRO<a hidden class=anchor aria-hidden=true href=#zero>#</a></h2><p>ZeRO 的目标就是解决上面遇到的显存问题，核心思想很简单，就是把这些通用的数据公用，分摊开销。</p><p>ZeRO 根据切分的粒度，分成了 $ 3 $ 个 Stage。
<img loading=lazy src=/images/lect12-ml-parallelization-part1/pasted-image-20260207001245.png></p><h3 id=stage-1-hahahugoshortcode34s23hbhb>Stage 1: $ P_{\text{os}} $<a hidden class=anchor aria-hidden=true href=#stage-1-hahahugoshortcode34s23hbhb>#</a></h3><p><strong>切分优化器的状态</strong>。这是最直观也是性价比最高的一步。在上面的例子里，单优化器的状态就占了 $ 80\% $ 的显存，并且每张卡上存储的优化器状态时完全一样的。因此很自然就想到每张卡只负责维护 $ \frac{1}{N} $ 的优化器状态。</p><p><strong>工作流程</strong></p><ol><li><strong>Forward & Backward</strong>：每张卡正常进行前向和反向传播，计算出完整的梯度。</li><li><strong>Scatter-Reduce</strong>：这是关键的一步。不同于传统的数据并行（直接做 All-Reduce 得到完整梯度），ZeRO Stage 1 只做 <strong>Scatter-Reduce</strong>。<ul><li>结果：GPU 0 只需要收集并聚合<strong>第 0 块</strong>梯度的总和，GPU 1 只需要第 1 块&mldr; 以此类推。</li><li><em>注：此时每张卡手里只有它负责的那一小块平均梯度。</em></li></ul></li><li><strong>Optimizer Step</strong>：GPU $ k $ 使用它持有的那 $ \frac{1}{N} $ 块平均梯度，去更新它显存里维护的那 $ \frac{1}{N} $ 块<strong>优化器状态</strong>和<strong>模型参数</strong>。</li><li><strong>All-Gather</strong>：现在每张卡上的模型参数只有 $ \frac{1}{N} $ 是最新的。为了进行下一轮训练，大家立刻执行 <strong>All-Gather</strong>，将各自更新好的参数广播给所有设备。</li></ol><p><img loading=lazy src=/images/lect12-ml-parallelization-part1/pasted-image-20260207001716.png></p><p><strong>收益与代价</strong></p><ul><li><strong>显存</strong>：节省了巨大的 FP32 状态显存。</li><li><strong>通信</strong>：<strong>通信量没有增加</strong>。原本的 Ring AllReduce 分为 Scatter-Reduce + All-Gather 两个阶段。ZeRO Stage 1 只是把这两个阶段拆开了，先做 Scatter-Reduce 拿到梯度，更新完参数后，再做 All-Gather。总量依然是 $ 2 \times M $。</li></ul><h3 id=stage-2-hahahugoshortcode34s31hbhb>Stage 2: $ P_{\text{os+g}} $<a hidden class=anchor aria-hidden=true href=#stage-2-hahahugoshortcode34s31hbhb>#</a></h3><p>既然已经切了优化器状态，同样<strong>梯度</strong>也一样可以切。原理是每张卡不再保存完整的梯度，只保存它负责更新的那 <strong>$ 1/N $</strong> 的梯度，这样又节省了梯度的显存占用。（和 Stage 1 的区别是显式增加了梯度部分缓存的释放）</p><p><strong>工作流程</strong></p><ol><li><strong>Backward</strong>：算出梯度后，立刻进行 <strong>Reduce-Scatter</strong> 操作。</li><li><strong>Reduce-Scatter</strong>：互相传阅梯度，最后每块 GPU 只保留自己负责的 $ \frac{1}{N} $ 块梯度和。</li><li><strong>释放显存</strong>：其他部分的梯度在 Reduce-Scatter 之后就可以立刻扔掉（释放显存），不需要一直存着。</li></ol><p><strong>收益</strong>：进一步节省了显存，通信量依然保持不变。</p><h3 id=stage-3-hahahugoshortcode34s34hbhb>Stage 3: $ P_{\text{os+g+p}} $<a hidden class=anchor aria-hidden=true href=#stage-3-hahahugoshortcode34s34hbhb>#</a></h3><p>更加激进的一步，连着参数一起切分，每张卡上不再有完整的模型。原理是前向传播时“<strong>用时再取</strong>”，用通信量换取显存。</p><p><strong>工作流程</strong></p><p><img loading=lazy src=/images/lect12-ml-parallelization-part1/pasted-image-20260207003645.png></p><ol><li><strong>Forward:</strong><ul><li>当 GPU 要计算第 1 层 (Conv1) 时，每个设备只有 Conv1 的一小块碎片。</li><li><strong>Action</strong>：立刻发起一次 <strong>All-Gather</strong>，把自己手里的 Conv1 碎片拼起来。</li><li><strong>Compute</strong>：拼好完整的 Conv1 后，进行计算。</li><li><strong>Discard</strong>：算完 Conv1，立刻<strong>把借来的参数扔掉</strong>，只保留自己负责的那一小块碎片，释放显存。</li><li>接着算 Conv2&mldr; 重复上述过程。</li></ul></li><li><strong>Backward:</strong><ul><li>反向传播时同理。要算 Conv2 的梯度，再次 All-Gather 拼出完整的 Conv2 参数，算完梯度后再次扔掉。</li></ul></li></ol><p><strong>收益与代价</strong></p><ul><li><strong>显存</strong>：显存占用降到了极致。随着 GPU 数量 N 增加，单卡显存占用线性下降。理论上你可以训练无限大的模型。</li><li><strong>通信</strong>：<strong>通信量增加了 50% (1.5x)</strong>。因为每次前向和反向都要重新 All-Gather 参数，比之前多了一次全量的参数广播。</li></ul><h2 id=summary>Summary<a hidden class=anchor aria-hidden=true href=#summary>#</a></h2><p><img loading=lazy src=/images/lect12-ml-parallelization-part1/pasted-image-20260207004035.png>
在 64 卡的设置下，ZeRO-3 能把单卡显存占用从 <strong>120GB</strong> 压到 <strong>1.9GB</strong>。</p><p>在 PyTorch 中，这个技术对应的是 <strong>FSDP (Fully Sharded Data Parallel)</strong>。
<img loading=lazy src=/images/lect12-ml-parallelization-part1/pasted-image-20260207004219.png>
本质就是在 <strong>Compute (计算)</strong>、<strong>Memory (显存)</strong> 和 <strong>Communication (通信)</strong> 这三者之间做 Trade-off。</p></div><footer class=post-footer><ul class=post-tags><li><a href=https://diefish1024.github.io/tags/learning/>Learning</a></li><li><a href=https://diefish1024.github.io/tags/cs/>CS</a></li><li><a href=https://diefish1024.github.io/tags/ai-infra/>AI-Infra</a></li></ul><nav class=paginav><a class=next href=https://diefish1024.github.io/posts/class-notes/math1205h-linear-algebra/math1205h-hw26/><span class=title>Next »</span><br><span>MATH1205H HW26</span></a></nav><ul class=share-buttons><li><a target=_blank rel="noopener noreferrer" aria-label="share Lect12-ML Parallelization-part1 on x" href="https://x.com/intent/tweet/?text=Lect12-ML%20Parallelization-part1&amp;url=https%3a%2f%2fdiefish1024.github.io%2fposts%2fclass-notes%2fcmu-15-779%2flect12-ml-parallelization-part1%2f&amp;hashtags=learning%2cCS%2cAI-Infra"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446C483.971.0 512 28.03 512 62.554zM269.951 190.75 182.567 75.216H56L207.216 272.95 63.9 436.783h61.366L235.9 310.383l96.667 126.4H456L298.367 228.367l134-153.151H371.033zM127.633 110h36.468l219.38 290.065H349.5z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Lect12-ML Parallelization-part1 on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fdiefish1024.github.io%2fposts%2fclass-notes%2fcmu-15-779%2flect12-ml-parallelization-part1%2f&amp;title=Lect12-ML%20Parallelization-part1&amp;summary=Lect12-ML%20Parallelization-part1&amp;source=https%3a%2f%2fdiefish1024.github.io%2fposts%2fclass-notes%2fcmu-15-779%2flect12-ml-parallelization-part1%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Lect12-ML Parallelization-part1 on reddit" href="https://reddit.com/submit?url=https%3a%2f%2fdiefish1024.github.io%2fposts%2fclass-notes%2fcmu-15-779%2flect12-ml-parallelization-part1%2f&title=Lect12-ML%20Parallelization-part1"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Lect12-ML Parallelization-part1 on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fdiefish1024.github.io%2fposts%2fclass-notes%2fcmu-15-779%2flect12-ml-parallelization-part1%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Lect12-ML Parallelization-part1 on whatsapp" href="https://api.whatsapp.com/send?text=Lect12-ML%20Parallelization-part1%20-%20https%3a%2f%2fdiefish1024.github.io%2fposts%2fclass-notes%2fcmu-15-779%2flect12-ml-parallelization-part1%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Lect12-ML Parallelization-part1 on telegram" href="https://telegram.me/share/url?text=Lect12-ML%20Parallelization-part1&amp;url=https%3a%2f%2fdiefish1024.github.io%2fposts%2fclass-notes%2fcmu-15-779%2flect12-ml-parallelization-part1%2f"><svg viewBox="2 2 28 28" height="30" width="30" fill="currentColor"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Lect12-ML Parallelization-part1 on ycombinator" href="https://news.ycombinator.com/submitlink?t=Lect12-ML%20Parallelization-part1&u=https%3a%2f%2fdiefish1024.github.io%2fposts%2fclass-notes%2fcmu-15-779%2flect12-ml-parallelization-part1%2f"><svg width="30" height="30" viewBox="0 0 512 512" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446zM183.8767 87.9921h-62.034L230.6673 292.4508V424.0079h50.6655V292.4508L390.1575 87.9921H328.1233L256 238.2489z"/></svg></a></li></ul></footer></article></main><footer class=footer><span>&copy; 2026 <a href=https://diefish1024.github.io/>diefish's blog</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>