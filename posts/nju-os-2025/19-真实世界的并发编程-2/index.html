<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>19. 真实世界的并发编程 (2) | diefish's blog</title><meta name=keywords content="learning,CS,nju-os"><meta name=description content="CPU 内的并行编程
CPU 的功耗 $ P=C\cdot V^{2}\cdot f $ 导致纵使有更大的电路，热功耗限制了性能上限，从而有一堵“功耗墙”限制了 CPU 的性能，为此需要考虑如何在降低 $ V $ 和 $ f $ 的同时用面积换性能
有两个思路：


让一条指令能处理更多的数据：SIMD (Single Instruction, Multiple Data)

“一条指令” 浪费的能量大致是定数
处理的数据越多，浪费越少



用更多更简单的处理器：多处理器系统、异构多处理器

同等面积，处理器越简单，数量越多
异构计算：最经典的例子是大小核架构（如 Apple M1）



SIMD
SIMD 的核心思想是在硬件层面实现数据级并行，它通过引入专门的硬件单元来达成这个目标：


宽位寄存器 (Wide Registers)：CPU 内部增加了比通用寄存器宽很多的专用寄存器

Intel 的 SSE 指令集引入了 128 位的 XMM 寄存器，而最新的 AVX-512 拥有 512 位的 ZMM 寄存器
这些宽位寄存器可以一次性装入多个数据元素，比如一个 128 位的寄存器可以同时容纳 4 个 32 位的浮点数，或者 16 个 8 位的整数
这些被打包在一起的数据被称为 Vector



向量处理单元 (Vector ALU)：CPU 内部也配备了能够对整个向量进行并行计算的 ALU"><meta name=author content="diefish"><link rel=canonical href=https://diefish1024.github.io/posts/nju-os-2025/19-%E7%9C%9F%E5%AE%9E%E4%B8%96%E7%95%8C%E7%9A%84%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B-2/><link crossorigin=anonymous href=/assets/css/stylesheet.8fe10233a706bc87f2e08b3cf97b8bd4c0a80f10675a143675d59212121037c0.css integrity="sha256-j+ECM6cGvIfy4Is8+XuL1MCoDxBnWhQ2ddWSEhIQN8A=" rel="preload stylesheet" as=style><link rel=icon href=https://diefish1024.github.io/images/avatar.jpg><link rel=icon type=image/png sizes=16x16 href=https://diefish1024.github.io/images/avatar.jpg><link rel=icon type=image/png sizes=32x32 href=https://diefish1024.github.io/images/avatar.jpg><link rel=apple-touch-icon href=https://diefish1024.github.io/images/avatar.jpg><link rel=mask-icon href=https://diefish1024.github.io/images/avatar.jpg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://diefish1024.github.io/posts/nju-os-2025/19-%E7%9C%9F%E5%AE%9E%E4%B8%96%E7%95%8C%E7%9A%84%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B-2/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.css integrity=sha384-MlJdn/WNKDGXveldHDdyRP1R4CTHr3FeuDNfhsLPYrq2t0UBkUdK2jyTnXPEK1NQ crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.js integrity=sha384-VQ8d8WVFw0yHhCk5E8I86oOhv48xLpnDZx5T9GogA/Y84DcCKWXDmSDfn13bzFZY crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/contrib/auto-render.min.js integrity=sha384-+XBljXPPiv+OzfbB3cVmLHf4hdUFHlWNZN5spNQ7rmHTXpd7WvJum6fIACpNNfIR crossorigin=anonymous></script><script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}]})})</script><meta property="og:url" content="https://diefish1024.github.io/posts/nju-os-2025/19-%E7%9C%9F%E5%AE%9E%E4%B8%96%E7%95%8C%E7%9A%84%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B-2/"><meta property="og:site_name" content="diefish's blog"><meta property="og:title" content="19. 真实世界的并发编程 (2)"><meta property="og:description" content="CPU 内的并行编程 CPU 的功耗 $ P=C\cdot V^{2}\cdot f $ 导致纵使有更大的电路，热功耗限制了性能上限，从而有一堵“功耗墙”限制了 CPU 的性能，为此需要考虑如何在降低 $ V $ 和 $ f $ 的同时用面积换性能
有两个思路：
让一条指令能处理更多的数据：SIMD (Single Instruction, Multiple Data)
“一条指令” 浪费的能量大致是定数 处理的数据越多，浪费越少 用更多更简单的处理器：多处理器系统、异构多处理器
同等面积，处理器越简单，数量越多 异构计算：最经典的例子是大小核架构（如 Apple M1） SIMD SIMD 的核心思想是在硬件层面实现数据级并行，它通过引入专门的硬件单元来达成这个目标：
宽位寄存器 (Wide Registers)：CPU 内部增加了比通用寄存器宽很多的专用寄存器
Intel 的 SSE 指令集引入了 128 位的 XMM 寄存器，而最新的 AVX-512 拥有 512 位的 ZMM 寄存器 这些宽位寄存器可以一次性装入多个数据元素，比如一个 128 位的寄存器可以同时容纳 4 个 32 位的浮点数，或者 16 个 8 位的整数 这些被打包在一起的数据被称为 Vector 向量处理单元 (Vector ALU)：CPU 内部也配备了能够对整个向量进行并行计算的 ALU"><meta property="og:locale" content="zh-cn"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:tag" content="Learning"><meta property="article:tag" content="CS"><meta property="article:tag" content="Nju-Os"><meta property="og:image" content="https://diefish1024.github.io/images/avatar.jpg"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://diefish1024.github.io/images/avatar.jpg"><meta name=twitter:title content="19. 真实世界的并发编程 (2)"><meta name=twitter:description content="CPU 内的并行编程
CPU 的功耗 $ P=C\cdot V^{2}\cdot f $ 导致纵使有更大的电路，热功耗限制了性能上限，从而有一堵“功耗墙”限制了 CPU 的性能，为此需要考虑如何在降低 $ V $ 和 $ f $ 的同时用面积换性能
有两个思路：


让一条指令能处理更多的数据：SIMD (Single Instruction, Multiple Data)

“一条指令” 浪费的能量大致是定数
处理的数据越多，浪费越少



用更多更简单的处理器：多处理器系统、异构多处理器

同等面积，处理器越简单，数量越多
异构计算：最经典的例子是大小核架构（如 Apple M1）



SIMD
SIMD 的核心思想是在硬件层面实现数据级并行，它通过引入专门的硬件单元来达成这个目标：


宽位寄存器 (Wide Registers)：CPU 内部增加了比通用寄存器宽很多的专用寄存器

Intel 的 SSE 指令集引入了 128 位的 XMM 寄存器，而最新的 AVX-512 拥有 512 位的 ZMM 寄存器
这些宽位寄存器可以一次性装入多个数据元素，比如一个 128 位的寄存器可以同时容纳 4 个 32 位的浮点数，或者 16 个 8 位的整数
这些被打包在一起的数据被称为 Vector



向量处理单元 (Vector ALU)：CPU 内部也配备了能够对整个向量进行并行计算的 ALU"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://diefish1024.github.io/posts/"},{"@type":"ListItem","position":2,"name":"19. 真实世界的并发编程 (2)","item":"https://diefish1024.github.io/posts/nju-os-2025/19-%E7%9C%9F%E5%AE%9E%E4%B8%96%E7%95%8C%E7%9A%84%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B-2/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"19. 真实世界的并发编程 (2)","name":"19. 真实世界的并发编程 (2)","description":"CPU 内的并行编程 CPU 的功耗 $ P=C\\cdot V^{2}\\cdot f $ 导致纵使有更大的电路，热功耗限制了性能上限，从而有一堵“功耗墙”限制了 CPU 的性能，为此需要考虑如何在降低 $ V $ 和 $ f $ 的同时用面积换性能\n有两个思路：\n让一条指令能处理更多的数据：SIMD (Single Instruction, Multiple Data)\n“一条指令” 浪费的能量大致是定数 处理的数据越多，浪费越少 用更多更简单的处理器：多处理器系统、异构多处理器\n同等面积，处理器越简单，数量越多 异构计算：最经典的例子是大小核架构（如 Apple M1） SIMD SIMD 的核心思想是在硬件层面实现数据级并行，它通过引入专门的硬件单元来达成这个目标：\n宽位寄存器 (Wide Registers)：CPU 内部增加了比通用寄存器宽很多的专用寄存器\nIntel 的 SSE 指令集引入了 128 位的 XMM 寄存器，而最新的 AVX-512 拥有 512 位的 ZMM 寄存器 这些宽位寄存器可以一次性装入多个数据元素，比如一个 128 位的寄存器可以同时容纳 4 个 32 位的浮点数，或者 16 个 8 位的整数 这些被打包在一起的数据被称为 Vector 向量处理单元 (Vector ALU)：CPU 内部也配备了能够对整个向量进行并行计算的 ALU\n","keywords":["learning","CS","nju-os"],"articleBody":"CPU 内的并行编程 CPU 的功耗 $ P=C\\cdot V^{2}\\cdot f $ 导致纵使有更大的电路，热功耗限制了性能上限，从而有一堵“功耗墙”限制了 CPU 的性能，为此需要考虑如何在降低 $ V $ 和 $ f $ 的同时用面积换性能\n有两个思路：\n让一条指令能处理更多的数据：SIMD (Single Instruction, Multiple Data)\n“一条指令” 浪费的能量大致是定数 处理的数据越多，浪费越少 用更多更简单的处理器：多处理器系统、异构多处理器\n同等面积，处理器越简单，数量越多 异构计算：最经典的例子是大小核架构（如 Apple M1） SIMD SIMD 的核心思想是在硬件层面实现数据级并行，它通过引入专门的硬件单元来达成这个目标：\n宽位寄存器 (Wide Registers)：CPU 内部增加了比通用寄存器宽很多的专用寄存器\nIntel 的 SSE 指令集引入了 128 位的 XMM 寄存器，而最新的 AVX-512 拥有 512 位的 ZMM 寄存器 这些宽位寄存器可以一次性装入多个数据元素，比如一个 128 位的寄存器可以同时容纳 4 个 32 位的浮点数，或者 16 个 8 位的整数 这些被打包在一起的数据被称为 Vector 向量处理单元 (Vector ALU)：CPU 内部也配备了能够对整个向量进行并行计算的 ALU\n当执行一条 SIMD 指令时，这个特殊的 ALU 会在同一个时钟周期内，同时对寄存器中的 4 对浮点数分别执行操作 例子：假设我们要计算两个数组 A 和 B 的和，存入数组 C，每个数组都有 4 个元素。\nTraditional：\nload A[0] load B[0] add -\u003e store C[0] load A[1] load B[1] add -\u003e store C[1] … 重复 4 次，需要执行 4 轮独立的“load-compute-store”指令 SIMD：\nLOAD：将数组 A 的 4 个元素一次性加载到一个 128 位的 XMM 寄存器中 LOAD：将数组 B 的 4 个元素加载到另一个 XMM 寄存器中 VADDPS：CPU 的向量处理单元对这两个寄存器中的 4 对元素 同时 进行加法运算 STORE：将计算结果寄存器中的 4 个和值一次性存回内存中的数组 C 通过这种方式，原来需要循环多次的计算被压缩成了几条高效的向量指令，极大地提升了吞吐率，尤其是在图像处理、视频编解码、科学计算和人工智能等需要大量重复性计算的领域，效果非常显著\nGPU 和 GPGPU 第二种克服“功耗墙”的思路——使用更多、更简单的处理器——直接催生了 GPU (Graphics Processing Unit) 的发展，它最初为图形渲染这种高度并行的任务而设计，其架构被证明非常有效，最终演变成了一个通用计算的强大引擎\n从 PPU 到 GPU 对专用图形硬件的需求在早期游戏机中就很明显：CPU 在渲染方面效率极低，计算屏幕上每个像素的颜色，每秒重复 60 次，这种“大规模并行”任务会完全压垮为串行任务设计的 CPU\n早期方案 - PPU：早期系统将图形任务交给 PPU (Picture Processing Unit) 处理，这是一种领域专用硬件，它操作的是高级图形对象，如 tiles (8x8 像素块) 和 sprites (可移动的前景角色)，而非单个像素，CPU 的工作被简化为告诉 PPU 该画 哪个 图块以及画在 哪里\n固定功能 Pipeline：随着 3D 图形的出现，简单的 PPU 模型演变为更复杂但仍然固化的 “固定功能管线” (Fixed-Function Pipeline)，它有一系列硬件实现的固定阶段，虽然功能强大，但除了调整预设参数外，几乎没有创造性空间\n随后开发者为了自定义视觉效果，把图形管线中的关键部分被替换为可编程单元，发展出了可编程的特性\n这种可编程性赋予了开发者前所未有的控制力，也标志着现代 GPU 的诞生\nGPGPU 人们很快意识到，一个为像素并行执行数百万个简单程序的芯片，用途远不止于图形\n早期的 hack ：最初的 GPGPU (General-Purpose computing on GPU) 是开发者将一个科学问题（如矩阵乘法）伪装成一个图形任务，例如将矩阵作为“纹理”加载，然后编写一个“片元着色器”来进行乘法计算，最后将结果“颜色”写出 演变为计算平台：这种强大但繁琐的方法证明了其可行性，硬件厂商（比如 Nvidia）随即推出了专用的编程框架（CUDA）和开放标准（OpenCL），这些平台彻底剥离了图形接口，将 GPU 强大的并行计算能力直接暴露给开发者 AI 时代的并行编程 随着 GPGPU 平台的成熟，可编程的 Shader 模型也演变成了更通用的线程模型，最终在 AI 时代大放异彩\nSIMT：单指令，多线程 CUDA 编程模型的核心是 SIMT (Single Instruction, Multiple Threads)，这是对 SIMD 思想的扩展\nGPU 程序中每个像素执行一次的“着色器”，在 CUDA 被看作是一个 Kernel 函数，会被成千上万甚至数百万个 线程 并行执行\nSIMT 的魔法在于，GPU 会将线程分组（通常 32 个线程为一个 Warp），一个 Warp 内的所有线程共享同一个程序计数器 (PC)，在硬件层面，它们在同一时刻执行完全相同的指令\n这实际上创造了一种类似巨型 SIMD 的效果，每个线程虽然有自己独立的寄存器和数据（通过 threadIdx 等内置变量区分），但它们的执行流被捆绑在一起，这使得控制单元的设计可以极其简化，从而在芯片上集成海量的计算核心\nChallenges SIMT 架构在带来巨大并行优势的同时，也给带来了挑战：\n内存合并 (Memory Coalescing)：当一个 Warp 中的多个线程连续访问内存时，GPU 硬件能将这 32 个独立的访问请求合并成一笔或几笔大的内存事务，这是 CUDA 性能优化的关键\n分支发散 (Branch Divergence)：SIMT 最大的难点在于处理分支，如果一个 Warp 内的线程在 if-else 语句上做出不同选择，由于它们共享同一个 PC，硬件必须串行地执行 if 路径和 else 路径，并在执行每个路径时，将另一部分线程暂时屏蔽，这会使 Warp 的执行速度取决于内部执行最慢的线程\n共享内存 (Shared Memory)：虽然 CUDA 线程可以访问共享内存，但如何避免访问冲突 (Bank Conflict)，如何组织数据以最大化并行加载，都会增加 CUDA 程序的编写难度\n尽管编写高效的 CUDA 程序充满挑战，但其回报是巨大的，尤其对于那些计算密集、模式固定的任务，例如深度学习中的矩阵乘法和卷积运算，GPU 能提供比 CPU 高出数个数量级的性能和能效比\n","wordCount":"289","inLanguage":"en","image":"https://diefish1024.github.io/images/avatar.jpg","datePublished":"0001-01-01T00:00:00Z","dateModified":"0001-01-01T00:00:00Z","author":{"@type":"Person","name":"diefish"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://diefish1024.github.io/posts/nju-os-2025/19-%E7%9C%9F%E5%AE%9E%E4%B8%96%E7%95%8C%E7%9A%84%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B-2/"},"publisher":{"@type":"Organization","name":"diefish's blog","logo":{"@type":"ImageObject","url":"https://diefish1024.github.io/images/avatar.jpg"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://diefish1024.github.io/ accesskey=h title="Home (Alt + H)"><img src=https://diefish1024.github.io/images/avatar.jpg alt aria-label=logo height=35>Home</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://diefish1024.github.io/posts/ title=posts><span>posts</span></a></li><li><a href=https://diefish1024.github.io/tags/ title=tags><span>tags</span></a></li><li><a href=https://diefish1024.github.io/search title="search (Alt + /)" accesskey=/><span>search</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://diefish1024.github.io/>Home</a>&nbsp;»&nbsp;<a href=https://diefish1024.github.io/posts/>Posts</a></div><h1 class="post-title entry-hint-parent">19. 真实世界的并发编程 (2)</h1><div class=post-meta>2 min&nbsp;·&nbsp;diefish&nbsp;|&nbsp;<a href=https://github.com/diefish1024/diefish1024.github.io/blob/main/content/posts/nju-os-2025/19-%e7%9c%9f%e5%ae%9e%e4%b8%96%e7%95%8c%e7%9a%84%e5%b9%b6%e5%8f%91%e7%bc%96%e7%a8%8b-2.md rel="noopener noreferrer edit" target=_blank>Suggest Changes</a></div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#cpu-%e5%86%85%e7%9a%84%e5%b9%b6%e8%a1%8c%e7%bc%96%e7%a8%8b aria-label="CPU 内的并行编程">CPU 内的并行编程</a><ul><li><a href=#simd aria-label=SIMD>SIMD</a></li></ul></li><li><a href=#gpu-%e5%92%8c-gpgpu aria-label="GPU 和 GPGPU">GPU 和 GPGPU</a><ul><ul><li><a href=#%e4%bb%8e-ppu-%e5%88%b0-gpu aria-label="从 PPU 到 GPU">从 PPU 到 GPU</a></li></ul><li><a href=#gpgpu aria-label=GPGPU>GPGPU</a></li></ul></li><li><a href=#ai-%e6%97%b6%e4%bb%a3%e7%9a%84%e5%b9%b6%e8%a1%8c%e7%bc%96%e7%a8%8b aria-label="AI 时代的并行编程">AI 时代的并行编程</a><ul><li><a href=#simt%e5%8d%95%e6%8c%87%e4%bb%a4%e5%a4%9a%e7%ba%bf%e7%a8%8b aria-label=SIMT：单指令，多线程>SIMT：单指令，多线程</a></li><li><a href=#challenges aria-label=Challenges>Challenges</a></li></ul></li></ul></div></details></div><div class=post-content><h2 id=cpu-内的并行编程>CPU 内的并行编程<a hidden class=anchor aria-hidden=true href=#cpu-内的并行编程>#</a></h2><p>CPU 的功耗 $ P=C\cdot V^{2}\cdot f $ 导致纵使有更大的电路，热功耗限制了性能上限，从而有一堵“功耗墙”限制了 CPU 的性能，为此需要考虑如何在降低 $ V $ 和 $ f $ 的同时用面积换性能</p><p>有两个思路：</p><ol><li><p><strong>让一条指令能处理更多的数据</strong>：SIMD (Single Instruction, Multiple Data)</p><ul><li>“一条指令” 浪费的能量大致是定数</li><li>处理的数据越多，浪费越少</li></ul></li><li><p><strong>用更多更简单的处理器</strong>：多处理器系统、异构多处理器</p><ul><li>同等面积，处理器越简单，数量越多</li><li><strong>异构计算</strong>：最经典的例子是<strong>大小核架构</strong>（如 Apple M1）</li></ul></li></ol><h3 id=simd>SIMD<a hidden class=anchor aria-hidden=true href=#simd>#</a></h3><p>SIMD 的核心思想是在硬件层面实现数据级并行，它通过引入专门的硬件单元来达成这个目标：</p><ol><li><p><strong>宽位寄存器 (Wide Registers)</strong>：CPU 内部增加了比通用寄存器宽很多的专用寄存器</p><ul><li>Intel 的 SSE 指令集引入了 128 位的 XMM 寄存器，而最新的 AVX-512 拥有 512 位的 ZMM 寄存器</li><li>这些宽位寄存器可以一次性装入多个数据元素，比如一个 128 位的寄存器可以同时容纳 4 个 32 位的浮点数，或者 16 个 8 位的整数</li><li>这些被打包在一起的数据被称为 Vector</li></ul></li><li><p><strong>向量处理单元 (Vector ALU)</strong>：CPU 内部也配备了能够对整个向量进行并行计算的 ALU</p><ul><li>当执行一条 SIMD 指令时，这个特殊的 ALU 会在同一个时钟周期内，同时对寄存器中的 4 对浮点数分别执行操作</li></ul></li></ol><p><strong>例子</strong>：假设我们要计算两个数组 <code>A</code> 和 <code>B</code> 的和，存入数组 <code>C</code>，每个数组都有 4 个元素。</p><ul><li><p><strong>Traditional</strong>：</p><ol><li><code>load A[0]</code></li><li><code>load B[0]</code></li><li><code>add</code> -> <code>store C[0]</code></li><li><code>load A[1]</code></li><li><code>load B[1]</code></li><li><code>add</code> -> <code>store C[1]</code></li><li>&mldr; 重复 4 次，需要执行 4 轮独立的“load-compute-store”指令</li></ol></li><li><p><strong>SIMD</strong>：</p><ol><li><strong><code>LOAD</code></strong>：将数组 <code>A</code> 的 4 个元素一次性加载到一个 128 位的 XMM 寄存器中</li><li><strong><code>LOAD</code></strong>：将数组 <code>B</code> 的 4 个元素加载到另一个 XMM 寄存器中</li><li><strong><code>VADDPS</code></strong>：CPU 的向量处理单元对这两个寄存器中的 4 对元素 <strong>同时</strong> 进行加法运算</li><li><strong><code>STORE</code></strong>：将计算结果寄存器中的 4 个和值一次性存回内存中的数组 <code>C</code></li></ol></li></ul><p>通过这种方式，原来需要循环多次的计算被压缩成了几条高效的向量指令，极大地提升了吞吐率，尤其是在图像处理、视频编解码、科学计算和人工智能等需要大量重复性计算的领域，效果非常显著</p><h2 id=gpu-和-gpgpu>GPU 和 GPGPU<a hidden class=anchor aria-hidden=true href=#gpu-和-gpgpu>#</a></h2><p>第二种克服“功耗墙”的思路——使用更多、更简单的处理器——直接催生了 <strong>GPU (Graphics Processing Unit)</strong> 的发展，它最初为图形渲染这种高度并行的任务而设计，其架构被证明非常有效，最终演变成了一个通用计算的强大引擎</p><h4 id=从-ppu-到-gpu>从 PPU 到 GPU<a hidden class=anchor aria-hidden=true href=#从-ppu-到-gpu>#</a></h4><p>对专用图形硬件的需求在早期游戏机中就很明显：CPU 在渲染方面效率极低，计算屏幕上每个像素的颜色，每秒重复 60 次，这种“大规模并行”任务会完全压垮为串行任务设计的 CPU</p><ul><li><p><strong>早期方案 - PPU</strong>：早期系统将图形任务交给 <strong>PPU (Picture Processing Unit)</strong> 处理，这是一种<strong>领域专用硬件</strong>，它操作的是高级图形对象，如 <strong>tiles</strong> (8x8 像素块) 和 <strong>sprites</strong> (可移动的前景角色)，而非单个像素，CPU 的工作被简化为告诉 PPU 该画 <em>哪个</em> 图块以及画在 <em>哪里</em></p></li><li><p><strong>固定功能 Pipeline</strong>：随着 3D 图形的出现，简单的 PPU 模型演变为更复杂但仍然固化的 <strong>“固定功能管线” (Fixed-Function Pipeline)</strong>，它有一系列硬件实现的固定阶段，虽然功能强大，但除了调整预设参数外，几乎没有创造性空间</p></li></ul><p>随后开发者为了自定义视觉效果，把图形管线中的关键部分被替换为可编程单元，发展出了<strong>可编程</strong>的特性</p><p><img loading=lazy src=/images/19-%E7%9C%9F%E5%AE%9E%E4%B8%96%E7%95%8C%E7%9A%84%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B-2/pasted-image-20250802235311-png></p><p>这种可编程性赋予了开发者前所未有的控制力，也标志着现代 GPU 的诞生</p><h3 id=gpgpu>GPGPU<a hidden class=anchor aria-hidden=true href=#gpgpu>#</a></h3><p>人们很快意识到，一个为像素并行执行数百万个简单程序的芯片，用途远不止于图形</p><ul><li><strong>早期的 hack</strong> ：最初的 <strong>GPGPU (General-Purpose computing on GPU)</strong> 是开发者将一个科学问题（如矩阵乘法）伪装成一个图形任务，例如将矩阵作为“纹理”加载，然后编写一个“片元着色器”来进行乘法计算，最后将结果“颜色”写出</li><li><strong>演变为计算平台</strong>：这种强大但繁琐的方法证明了其可行性，硬件厂商（比如 Nvidia）随即推出了专用的编程框架（<strong>CUDA</strong>）和开放标准（<strong>OpenCL</strong>），这些平台彻底剥离了图形接口，将 GPU 强大的并行计算能力直接暴露给开发者</li></ul><h2 id=ai-时代的并行编程>AI 时代的并行编程<a hidden class=anchor aria-hidden=true href=#ai-时代的并行编程>#</a></h2><p>随着 GPGPU 平台的成熟，可编程的 Shader 模型也演变成了更通用的线程模型，最终在 AI 时代大放异彩</p><h3 id=simt单指令多线程>SIMT：单指令，多线程<a hidden class=anchor aria-hidden=true href=#simt单指令多线程>#</a></h3><p>CUDA 编程模型的核心是 <strong>SIMT (Single Instruction, Multiple Threads)</strong>，这是对 SIMD 思想的扩展</p><p>GPU 程序中每个像素执行一次的“着色器”，在 CUDA 被看作是一个 <strong>Kernel 函数</strong>，会被成千上万甚至数百万个 <strong>线程</strong> 并行执行</p><p>SIMT 的魔法在于，GPU 会将线程分组（通常 32 个线程为一个 <strong>Warp</strong>），一个 Warp 内的所有线程<strong>共享同一个程序计数器 (PC)</strong>，在硬件层面，它们在同一时刻执行完全相同的指令</p><p>这实际上创造了一种<strong>类似巨型 SIMD</strong> 的效果，每个线程虽然有自己独立的寄存器和数据（通过 <code>threadIdx</code> 等内置变量区分），但它们的执行流被捆绑在一起，这使得控制单元的设计可以极其简化，从而在芯片上集成海量的计算核心</p><h3 id=challenges>Challenges<a hidden class=anchor aria-hidden=true href=#challenges>#</a></h3><p>SIMT 架构在带来巨大并行优势的同时，也给带来了挑战：</p><ul><li><p><strong>内存合并 (Memory Coalescing)</strong>：当一个 Warp 中的多个线程<strong>连续访问</strong>内存时，GPU 硬件能将这 32 个独立的访问请求<strong>合并</strong>成一笔或几笔大的内存事务，这是 CUDA 性能优化的关键</p></li><li><p><strong>分支发散 (Branch Divergence)</strong>：SIMT 最大的难点在于处理分支，如果一个 Warp 内的线程在 <code>if-else</code> 语句上做出不同选择，由于它们共享同一个 PC，硬件必须<strong>串行</strong>地执行 <code>if</code> 路径和 <code>else</code> 路径，并在执行每个路径时，将另一部分线程暂时屏蔽，这会使 Warp 的执行速度取决于内部执行最慢的线程</p></li><li><p><strong>共享内存 (Shared Memory)</strong>：虽然 CUDA 线程可以访问共享内存，但如何避免<strong>访问冲突 (Bank Conflict)</strong>，如何组织数据以最大化并行加载，都会增加 CUDA 程序的编写难度</p></li></ul><p>尽管编写高效的 CUDA 程序充满挑战，但其回报是巨大的，尤其对于那些计算密集、模式固定的任务，例如深度学习中的<strong>矩阵乘法</strong>和<strong>卷积</strong>运算，GPU 能提供比 CPU 高出数个数量级的性能和能效比</p></div><footer class=post-footer><ul class=post-tags><li><a href=https://diefish1024.github.io/tags/learning/>Learning</a></li><li><a href=https://diefish1024.github.io/tags/cs/>CS</a></li><li><a href=https://diefish1024.github.io/tags/nju-os/>Nju-Os</a></li></ul><nav class=paginav><a class=prev href=https://diefish1024.github.io/posts/nju-os-2025/18-%E7%9C%9F%E5%AE%9E%E4%B8%96%E7%95%8C%E7%9A%84%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B-1/><span class=title>« Prev</span><br><span>18. 真实世界的并发编程 (1)</span>
</a><a class=next href=https://diefish1024.github.io/posts/nju-os-2025/20-%E8%AE%BE%E5%A4%87%E5%92%8C%E9%A9%B1%E5%8A%A8%E7%A8%8B%E5%BA%8F/><span class=title>Next »</span><br><span>20. 设备和驱动程序</span></a></nav><ul class=share-buttons><li><a target=_blank rel="noopener noreferrer" aria-label="share 19. 真实世界的并发编程 (2) on x" href="https://x.com/intent/tweet/?text=19.%20%e7%9c%9f%e5%ae%9e%e4%b8%96%e7%95%8c%e7%9a%84%e5%b9%b6%e5%8f%91%e7%bc%96%e7%a8%8b%20%282%29&amp;url=https%3a%2f%2fdiefish1024.github.io%2fposts%2fnju-os-2025%2f19-%25E7%259C%259F%25E5%25AE%259E%25E4%25B8%2596%25E7%2595%258C%25E7%259A%2584%25E5%25B9%25B6%25E5%258F%2591%25E7%25BC%2596%25E7%25A8%258B-2%2f&amp;hashtags=learning%2cCS%2cnju-os"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446C483.971.0 512 28.03 512 62.554zM269.951 190.75 182.567 75.216H56L207.216 272.95 63.9 436.783h61.366L235.9 310.383l96.667 126.4H456L298.367 228.367l134-153.151H371.033zM127.633 110h36.468l219.38 290.065H349.5z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share 19. 真实世界的并发编程 (2) on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fdiefish1024.github.io%2fposts%2fnju-os-2025%2f19-%25E7%259C%259F%25E5%25AE%259E%25E4%25B8%2596%25E7%2595%258C%25E7%259A%2584%25E5%25B9%25B6%25E5%258F%2591%25E7%25BC%2596%25E7%25A8%258B-2%2f&amp;title=19.%20%e7%9c%9f%e5%ae%9e%e4%b8%96%e7%95%8c%e7%9a%84%e5%b9%b6%e5%8f%91%e7%bc%96%e7%a8%8b%20%282%29&amp;summary=19.%20%e7%9c%9f%e5%ae%9e%e4%b8%96%e7%95%8c%e7%9a%84%e5%b9%b6%e5%8f%91%e7%bc%96%e7%a8%8b%20%282%29&amp;source=https%3a%2f%2fdiefish1024.github.io%2fposts%2fnju-os-2025%2f19-%25E7%259C%259F%25E5%25AE%259E%25E4%25B8%2596%25E7%2595%258C%25E7%259A%2584%25E5%25B9%25B6%25E5%258F%2591%25E7%25BC%2596%25E7%25A8%258B-2%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share 19. 真实世界的并发编程 (2) on reddit" href="https://reddit.com/submit?url=https%3a%2f%2fdiefish1024.github.io%2fposts%2fnju-os-2025%2f19-%25E7%259C%259F%25E5%25AE%259E%25E4%25B8%2596%25E7%2595%258C%25E7%259A%2584%25E5%25B9%25B6%25E5%258F%2591%25E7%25BC%2596%25E7%25A8%258B-2%2f&title=19.%20%e7%9c%9f%e5%ae%9e%e4%b8%96%e7%95%8c%e7%9a%84%e5%b9%b6%e5%8f%91%e7%bc%96%e7%a8%8b%20%282%29"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share 19. 真实世界的并发编程 (2) on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fdiefish1024.github.io%2fposts%2fnju-os-2025%2f19-%25E7%259C%259F%25E5%25AE%259E%25E4%25B8%2596%25E7%2595%258C%25E7%259A%2584%25E5%25B9%25B6%25E5%258F%2591%25E7%25BC%2596%25E7%25A8%258B-2%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share 19. 真实世界的并发编程 (2) on whatsapp" href="https://api.whatsapp.com/send?text=19.%20%e7%9c%9f%e5%ae%9e%e4%b8%96%e7%95%8c%e7%9a%84%e5%b9%b6%e5%8f%91%e7%bc%96%e7%a8%8b%20%282%29%20-%20https%3a%2f%2fdiefish1024.github.io%2fposts%2fnju-os-2025%2f19-%25E7%259C%259F%25E5%25AE%259E%25E4%25B8%2596%25E7%2595%258C%25E7%259A%2584%25E5%25B9%25B6%25E5%258F%2591%25E7%25BC%2596%25E7%25A8%258B-2%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share 19. 真实世界的并发编程 (2) on telegram" href="https://telegram.me/share/url?text=19.%20%e7%9c%9f%e5%ae%9e%e4%b8%96%e7%95%8c%e7%9a%84%e5%b9%b6%e5%8f%91%e7%bc%96%e7%a8%8b%20%282%29&amp;url=https%3a%2f%2fdiefish1024.github.io%2fposts%2fnju-os-2025%2f19-%25E7%259C%259F%25E5%25AE%259E%25E4%25B8%2596%25E7%2595%258C%25E7%259A%2584%25E5%25B9%25B6%25E5%258F%2591%25E7%25BC%2596%25E7%25A8%258B-2%2f"><svg viewBox="2 2 28 28" height="30" width="30" fill="currentColor"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share 19. 真实世界的并发编程 (2) on ycombinator" href="https://news.ycombinator.com/submitlink?t=19.%20%e7%9c%9f%e5%ae%9e%e4%b8%96%e7%95%8c%e7%9a%84%e5%b9%b6%e5%8f%91%e7%bc%96%e7%a8%8b%20%282%29&u=https%3a%2f%2fdiefish1024.github.io%2fposts%2fnju-os-2025%2f19-%25E7%259C%259F%25E5%25AE%259E%25E4%25B8%2596%25E7%2595%258C%25E7%259A%2584%25E5%25B9%25B6%25E5%258F%2591%25E7%25BC%2596%25E7%25A8%258B-2%2f"><svg width="30" height="30" viewBox="0 0 512 512" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446zM183.8767 87.9921h-62.034L230.6673 292.4508V424.0079h50.6655V292.4508L390.1575 87.9921H328.1233L256 238.2489z"/></svg></a></li></ul></footer></article></main><footer class=footer><span>&copy; 2025 <a href=https://diefish1024.github.io/>diefish's blog</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>