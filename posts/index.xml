<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Posts on diefish&#39;s blog</title>
    <link>https://diefish1024.github.io/posts/</link>
    <description>Recent content in Posts on diefish&#39;s blog</description>
    <image>
      <title>diefish&#39;s blog</title>
      <url>https://diefish1024.github.io/images/avatar.jpg</url>
      <link>https://diefish1024.github.io/images/avatar.jpg</link>
    </image>
    <generator>Hugo -- 0.148.2</generator>
    <language>zh-cn</language>
    <atom:link href="https://diefish1024.github.io/posts/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>15. 并发控制：同步条件变量</title>
      <link>https://diefish1024.github.io/posts/nju-os-2025/15-%E5%B9%B6%E5%8F%91%E6%8E%A7%E5%88%B6%E5%90%8C%E6%AD%A5%E6%9D%A1%E4%BB%B6%E5%8F%98%E9%87%8F/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://diefish1024.github.io/posts/nju-os-2025/15-%E5%B9%B6%E5%8F%91%E6%8E%A7%E5%88%B6%E5%90%8C%E6%AD%A5%E6%9D%A1%E4%BB%B6%E5%8F%98%E9%87%8F/</guid>
      <description>&lt;h2 id=&#34;同步和条件变量&#34;&gt;同步和条件变量&lt;/h2&gt;
&lt;p&gt;互斥实现了&lt;strong&gt;原子性&lt;/strong&gt;，但是无法实现&lt;strong&gt;确定性&lt;/strong&gt;，也就是无法正确实现 &amp;ldquo;happens-before&amp;rdquo; 的关系&lt;/p&gt;
&lt;p&gt;因此需要引入条件变量来实现线程的同步，形成受控制的并发事件的&lt;strong&gt;发生顺序&lt;/strong&gt;（可以用乐团指挥来类比），把一系列不确定的状态在某一个时间点同步到了一个确定的状态，将发散的并发程序状态 “收束”&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;实现同步&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;实现 $ A\to B $：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;7
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-gdscript3&#34; data-lang=&#34;gdscript3&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;A&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;can_proceed&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;bp&#34;&gt;true&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;signal&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;while&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;!&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;can_proceed&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;B&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;//&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;B&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;wait&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;until&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;the&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;condition&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;is&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;satisfied&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;这样的思路大致正确，但是自选的循环有很大的性能问题，因此需要一个更加底层的机制来帮助实现这一点&lt;/p&gt;
&lt;p&gt;最理想的 API 是 &lt;code&gt;wait_until(cond)&lt;/code&gt; ，但是过去为了简化设计，变成了&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;条件不满足时等待：&lt;code&gt;wait&lt;/code&gt; - 直接睡眠等待&lt;/li&gt;
&lt;li&gt;条件满足时继续：&lt;code&gt;signal/broadcast&lt;/code&gt; - 唤醒所有线程&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;（小时候的 scratch 编程其实已经有了这样的思想😂）&lt;/p&gt;
&lt;p&gt;在 c++ 代码中我们可以把条件放到 $ \lambda $ 表达式中：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-c++&#34; data-lang=&#34;c++&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;std&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;mutex&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;mtx&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;std&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;condition_variable&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;cv&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kt&#34;&gt;void&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;T_player&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	&lt;span class=&#34;n&#34;&gt;std&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;unique_lock&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;lk&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;mtx&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	&lt;span class=&#34;n&#34;&gt;cv&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;wait&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;lk&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;		&lt;span class=&#34;p&#34;&gt;[]{&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;can_proceed&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	&lt;span class=&#34;n&#34;&gt;cv&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;notify_all&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;();&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	&lt;span class=&#34;n&#34;&gt;lk&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;unlock&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;();&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;注意条件变量在等待时需要带着一把锁（需要确保检查和等待是原子操作）&lt;/p&gt;</description>
    </item>
    <item>
      <title>16. 并发控制：同步信号量</title>
      <link>https://diefish1024.github.io/posts/nju-os-2025/16-%E5%B9%B6%E5%8F%91%E6%8E%A7%E5%88%B6%E5%90%8C%E6%AD%A5%E4%BF%A1%E5%8F%B7%E9%87%8F/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://diefish1024.github.io/posts/nju-os-2025/16-%E5%B9%B6%E5%8F%91%E6%8E%A7%E5%88%B6%E5%90%8C%E6%AD%A5%E4%BF%A1%E5%8F%B7%E9%87%8F/</guid>
      <description>&lt;h2 id=&#34;信号量&#34;&gt;信号量&lt;/h2&gt;
&lt;p&gt;互斥锁在某种意义上也可以认为实现了 &amp;ldquo;happens-before&amp;rdquo; 的依赖关系—— release 必然发生在 acquire 之前。我们可以试着利用这种依赖关系来实现计算图的调度：为每条边分配一个互斥锁，代表数据或前置任务的完成；一个节点必须获得所有入边对应的互斥锁才能开始计算，计算完成后，就释放所有出边对应的互斥锁，通知下游节点输出就绪（但是这种直接使用互斥锁作为边状态信号的方式是 undefined behavior，因为互斥锁主要用于保护临界区，其释放通常要求由持有它的线程完成，若释放未曾获取的锁，则行为未定义）&lt;/p&gt;
&lt;p&gt;我们可以从这种想法中抽象出其本质，也就是用一个“&lt;strong&gt;信号&lt;/strong&gt;”去获取资源的许可，类似餐厅的取号吃饭&lt;/p&gt;
&lt;p&gt;这种&lt;strong&gt;信号&lt;/strong&gt;的思想很适合用来管理&lt;strong&gt;计数类型的同类资源&lt;/strong&gt;，比如停车场的空位，为了实现这种 producer-customer 的问题，用 &lt;a href=&#34;15.%20%E5%B9%B6%E5%8F%91%E6%8E%A7%E5%88%B6%EF%BC%9A%E5%90%8C%E6%AD%A5%E6%9D%A1%E4%BB%B6%E5%8F%98%E9%87%8F.md&#34;&gt;条件变量&lt;/a&gt; 可以轻易解决，进入的条件就是存在空位 &lt;code&gt;count &amp;lt; capacity&lt;/code&gt; ，那我们从减少变量的角度出发，这实际上也就是剩余空位的数量大于零，我们停车相当于&lt;strong&gt;消耗&lt;/strong&gt;了一个车位，离开相当于&lt;strong&gt;创造&lt;/strong&gt;了一个车位，这也就得到了所谓“&lt;strong&gt;信号量&lt;/strong&gt;”的机制&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-c&#34; data-lang=&#34;c&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kt&#34;&gt;void&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;P&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;sem_t&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;sem&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c1&#34;&gt;// Prolaag - try + decrease/down/wait/acquire
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;    &lt;span class=&#34;nf&#34;&gt;mutex_lock&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;sem&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&amp;gt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;lk&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;while&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;!&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;sem&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&amp;gt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;count&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nf&#34;&gt;cond_wait&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;sem&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&amp;gt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;cv&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;sem&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&amp;gt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;lk&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;sem&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&amp;gt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;count&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;--&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;  &lt;span class=&#34;c1&#34;&gt;// 消耗一个信号 (车位)
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;    &lt;span class=&#34;nf&#34;&gt;mutex_unlock&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;sem&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&amp;gt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;lk&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kt&#34;&gt;void&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;V&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;sem_t&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;sem&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c1&#34;&gt;// Verhoog - increase/up/post/signal/release
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;    &lt;span class=&#34;nf&#34;&gt;mutex_lock&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;sem&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&amp;gt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;lk&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;sem&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&amp;gt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;count&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;++&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;  &lt;span class=&#34;c1&#34;&gt;// 创建一个信号 (车位)
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;    &lt;span class=&#34;nf&#34;&gt;cond_broadcast&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;sem&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&amp;gt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;cv&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nf&#34;&gt;mutex_unlock&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;sem&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&amp;gt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;lk&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;根据这个一路推出信号量的思路，或许可以认为这是互斥锁的扩展&lt;/p&gt;</description>
    </item>
    <item>
      <title>17. 并发 Bugs</title>
      <link>https://diefish1024.github.io/posts/nju-os-2025/17-%E5%B9%B6%E5%8F%91-bugs/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://diefish1024.github.io/posts/nju-os-2025/17-%E5%B9%B6%E5%8F%91-bugs/</guid>
      <description>&lt;h2 id=&#34;数据竞争&#34;&gt;数据竞争&lt;/h2&gt;
&lt;p&gt;大多并发 bug 最后都会体现为&lt;strong&gt;数据竞争 (Data Race)&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;对于顺序程序而言，函数 &lt;code&gt;f()&lt;/code&gt; 返回之后就已经完成了所有的状态修改，对于其他部分而言这个修改是立即生效的；如果对于并发程序而言模式的切换也在瞬间完成，那就不会导致并发的问题&lt;/p&gt;
&lt;p&gt;然而实际上模式的切换需要时间，执行的操作在未来一段时间之后才会就绪，但是我们在实际编程时总是容易有“立即生效”的肌肉记忆，这就导致了并发问题的可能性&lt;/p&gt;
&lt;p&gt;不过对于&lt;strong&gt;函数式编程&lt;/strong&gt;而言，操作不存在对外状态的修改，没有副作用（只会操作局部变量），这就不会导致并发问题&lt;/p&gt;
&lt;p&gt;Data Race 发生的实质是&lt;strong&gt;不同的线程&lt;/strong&gt;同时访问&lt;strong&gt;同一内存&lt;/strong&gt;，并且&lt;strong&gt;至少有一个是写&lt;/strong&gt;，形象的理解就是不同的内存访问在“赛跑”，跑赢的操作先执行&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Not that easy&lt;/strong&gt;: 虽然我们将数据竞争形象地比喻为“赛跑”，但实际上，哪一个操作能“跑赢”并没有想象中那么简单和确定，其复杂性主要体现在以下几个方面&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;弱内存模型 (Weak memory model)&lt;/strong&gt;：在现代处理器架构中，为了提升性能，处理器可能会对内存操作进行重排序。这意味着，不同的线程或“观察者”在不同时间点看到共享内存的状态可能是不一致的。一个线程对内存的写入操作，可能不会立即对所有其他线程可见，导致不同线程观察到不同的结果。这种&lt;strong&gt;内存模型的一致性问题&lt;/strong&gt;使得确定哪个操作“先发生”变得非常困难且不确定。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;未定义行为 (Undefined Behavior)&lt;/strong&gt;：从 C++11 标准开始，数据竞争被明确规定为&lt;strong&gt;未定义行为&lt;/strong&gt;。这意味着，如果你的程序发生了数据竞争，编译器可以自由地产生任何行为，无论是崩溃、产生错误结果，还是看似正常运行但结果不可预测。这使得数据竞争成为非常危险且难以调试的并发错误，因为它的表现可能是不确定、不稳定的。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;多线程与多内存的复杂交互&lt;/strong&gt;：在实际的并发程序中，通常会有多个线程同时访问多个共享内存位置。这些线程和内存之间存在复杂的读（R）写（W）交互。一个线程对一个内存位置的写入可能影响到其他多个线程对该位置的读取，同时，多个内存位置之间也可能存在复杂的依赖关系和缓存一致性问题。这种错综复杂的交互网络进一步加剧了数据竞争的不可预测性。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;为了消灭数据竞争，我们需要保证程序的 serializability ，&lt;strong&gt;可能竞争的内存访问要么互斥，要么同步&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;实际编程中遇到的数据竞争 bug 大多属于&lt;strong&gt;上错了锁&lt;/strong&gt;和&lt;strong&gt;忘记上锁&lt;/strong&gt;两种情况的变种&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Case 1: 上错了锁&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-c&#34; data-lang=&#34;c&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kt&#34;&gt;void&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;T_1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;spin_lock&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;A&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;sum&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;++&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;spin_unlock&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;A&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kt&#34;&gt;void&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;T_2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;spin_lock&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;B&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;sum&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;++&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;spin_unlock&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;B&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;&lt;strong&gt;Case 2: 忘记上锁&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-c&#34; data-lang=&#34;c&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kt&#34;&gt;void&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;T_1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;spin_lock&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;A&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;sum&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;++&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;spin_unlock&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;A&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kt&#34;&gt;void&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;T_2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;sum&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;++&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;但是实际系统面临的情况比这复杂的多，因为&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;内存可以是地址空间的任何内存，比如全局变量、堆内存分配的变量、程序的栈……&lt;/li&gt;
&lt;li&gt;访问可以发生在任何代码，比如自己的代码、框架代码、一行没读到的汇编指令、某条 ret 指令
&lt;ul&gt;
&lt;li&gt;“一行没读到的汇编指令”造成的访问的情况有编译器优化造成的指令重排、硬件层面弱内存模型的内存访问重排、还有一些高层语言操作的隐式内存访问&lt;/li&gt;
&lt;li&gt;实际系统中虽然难以避免，但是会尽可能保证底层的结构对上层尽可能封闭来防止这种错误&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;死锁&#34;&gt;死锁&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;死锁 (Deadlock)&lt;/strong&gt; 是指一个群体中的每个成员都在等待其他成员（包括自身）采取行动的状态&lt;/p&gt;
&lt;p&gt;死锁有两种：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;AA-Deadlock&lt;/strong&gt;: 自己等待自己&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;7
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-c&#34; data-lang=&#34;c&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nf&#34;&gt;lock&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;lk&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;// lk-&amp;gt;locked == ✅; proceed
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;...&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c1&#34;&gt;// Possibly in interrupt handler
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;    &lt;span class=&#34;nf&#34;&gt;lock&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;lk&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c1&#34;&gt;// while (lk-&amp;gt;locked == ❌) ;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;这样的错误虽然看起来很傻，但是在真实程序复杂的控制流中是可能出现的&lt;/p&gt;</description>
    </item>
    <item>
      <title>18. 真实世界的并发编程 (1)</title>
      <link>https://diefish1024.github.io/posts/nju-os-2025/18-%E7%9C%9F%E5%AE%9E%E4%B8%96%E7%95%8C%E7%9A%84%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B-1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://diefish1024.github.io/posts/nju-os-2025/18-%E7%9C%9F%E5%AE%9E%E4%B8%96%E7%95%8C%E7%9A%84%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B-1/</guid>
      <description>&lt;p&gt;并发编程的核心抽象是实现一个计算图，计算发生在节点上，边表示节点之间的依赖关系，同时计算图在运行时可能是动态变化的&lt;/p&gt;
&lt;p&gt;使用条件变量、锁、信号量等 api 去实现计算图并不是一个优雅的实现方式，因为这样会在代码中引入众多&lt;strong&gt;干扰代码&lt;/strong&gt;，也可能导致一些问题&lt;/p&gt;
&lt;p&gt;为此可以增加一些功能受限的&lt;strong&gt;语法&lt;/strong&gt;，可以在同样描述计算图的功能下减少了许多潜在的问题&lt;/p&gt;
&lt;h2 id=&#34;高性能计算中的并行编程&#34;&gt;高性能计算中的并行编程&lt;/h2&gt;
&lt;p&gt;在高性能计算中，计算图通常易于&lt;strong&gt;静态切分&lt;/strong&gt;，尤其适用于物理模拟的网格划分，为此 HPC 发展出多种高效的并行编程模型，具体学习可以参考 &lt;a href=&#34;https://xflops.sjtu.edu.cn/hpc-start-guide/parallel-computing/basic/&#34;&gt;SJTU HPC 学习手册&lt;/a&gt;&lt;/p&gt;
&lt;h4 id=&#34;mpi-分布式内存并行&#34;&gt;MPI: 分布式内存并行&lt;/h4&gt;
&lt;p&gt;每个 MPI 进程有独立的内存空间，进程间通过&lt;strong&gt;显式消息传递&lt;/strong&gt;（发送/接收）交换数据&lt;/p&gt;
&lt;h4 id=&#34;openmp-共享内存并行&#34;&gt;OpenMP: 共享内存并行&lt;/h4&gt;
&lt;p&gt;多个线程在同一地址空间中并行执行，所有线程可以直接访问相同的数据，使用 &lt;code&gt;#pragma omp&lt;/code&gt; 指令实现并行化&lt;/p&gt;
&lt;p&gt;对非计算机专业来说非常友好，只需要在正常的代码上面加上编译指令即可，能轻松实现高效的并行优化&lt;/p&gt;
&lt;h4 id=&#34;cuda-gpu-异构并行&#34;&gt;CUDA: GPU 异构并行&lt;/h4&gt;
&lt;p&gt;CPU 调度，GPU 执行大规模并行计算&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;概念&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;核函数 (Kernel)&lt;/strong&gt; ：在 GPU 上并行执行的函数&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;线程层次&lt;/strong&gt;：线程 (&lt;code&gt;threadIdx&lt;/code&gt;) 组成线程块 (&lt;code&gt;blockIdx&lt;/code&gt;)，线程块组成网格 (&lt;code&gt;gridDim&lt;/code&gt;)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;内存层次&lt;/strong&gt;：寄存器、共享内存（块内高速）、全局内存（所有线程可访问）&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;我们身边的并发编程&#34;&gt;我们身边的并发编程&lt;/h2&gt;
&lt;h4 id=&#34;从-web-10-到-web-20&#34;&gt;从 Web 1.0 到 Web 2.0&lt;/h4&gt;
&lt;p&gt;在 Web 时代用的最广泛的是 Javascript&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Asynchronous JavaScript and XML&lt;/strong&gt; (Ajax; ~1999)
&lt;ul&gt;
&lt;li&gt;允许网页实现“后台刷新”&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;jQuery $ (2006): A DOM Query Language&lt;/strong&gt; (编程抽象)&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;web-20-时代的并发编程&#34;&gt;Web 2.0 时代的并发编程&lt;/h4&gt;
&lt;p&gt;线程开销大，并且大多数 Web 开发者难以进行并发编程&lt;/p&gt;</description>
    </item>
    <item>
      <title>19. 真实世界的并发编程 (2)</title>
      <link>https://diefish1024.github.io/posts/nju-os-2025/19-%E7%9C%9F%E5%AE%9E%E4%B8%96%E7%95%8C%E7%9A%84%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B-2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://diefish1024.github.io/posts/nju-os-2025/19-%E7%9C%9F%E5%AE%9E%E4%B8%96%E7%95%8C%E7%9A%84%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B-2/</guid>
      <description>&lt;h2 id=&#34;cpu-内的并行编程&#34;&gt;CPU 内的并行编程&lt;/h2&gt;
&lt;p&gt;CPU 的功耗 $ P=C\cdot V^{2}\cdot f $ 导致纵使有更大的电路，热功耗限制了性能上限，从而有一堵“功耗墙”限制了 CPU 的性能，为此需要考虑如何在降低 $ V $ 和 $ f $ 的同时用面积换性能&lt;/p&gt;
&lt;p&gt;有两个思路：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;让一条指令能处理更多的数据&lt;/strong&gt;：SIMD (Single Instruction, Multiple Data)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;“一条指令” 浪费的能量大致是定数&lt;/li&gt;
&lt;li&gt;处理的数据越多，浪费越少&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;用更多更简单的处理器&lt;/strong&gt;：多处理器系统、异构多处理器&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;同等面积，处理器越简单，数量越多&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;异构计算&lt;/strong&gt;：最经典的例子是&lt;strong&gt;大小核架构&lt;/strong&gt;（如 Apple M1）&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;simd&#34;&gt;SIMD&lt;/h3&gt;
&lt;p&gt;SIMD 的核心思想是在硬件层面实现数据级并行，它通过引入专门的硬件单元来达成这个目标：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;宽位寄存器 (Wide Registers)&lt;/strong&gt;：CPU 内部增加了比通用寄存器宽很多的专用寄存器&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Intel 的 SSE 指令集引入了 128 位的 XMM 寄存器，而最新的 AVX-512 拥有 512 位的 ZMM 寄存器&lt;/li&gt;
&lt;li&gt;这些宽位寄存器可以一次性装入多个数据元素，比如一个 128 位的寄存器可以同时容纳 4 个 32 位的浮点数，或者 16 个 8 位的整数&lt;/li&gt;
&lt;li&gt;这些被打包在一起的数据被称为 Vector&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;向量处理单元 (Vector ALU)&lt;/strong&gt;：CPU 内部也配备了能够对整个向量进行并行计算的 ALU&lt;/p&gt;</description>
    </item>
    <item>
      <title>20. 设备和驱动程序</title>
      <link>https://diefish1024.github.io/posts/nju-os-2025/20-%E8%AE%BE%E5%A4%87%E5%92%8C%E9%A9%B1%E5%8A%A8%E7%A8%8B%E5%BA%8F/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://diefish1024.github.io/posts/nju-os-2025/20-%E8%AE%BE%E5%A4%87%E5%92%8C%E9%A9%B1%E5%8A%A8%E7%A8%8B%E5%BA%8F/</guid>
      <description>&lt;h2 id=&#34;输入输出设备&#34;&gt;输入输出设备&lt;/h2&gt;
&lt;h3 id=&#34;everything-is-a-file&#34;&gt;Everything is a File&lt;/h3&gt;
&lt;p&gt;在 Unix-like 系统中，与外部设备交互的核心思想是 &lt;strong&gt;Everything is a File&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;文件描述符 (File Descriptor)&lt;/strong&gt;：操作系统为上层软件提供了一个统一的抽象，即文件描述符，它是一个指向内核中任何 I/O 对象的“指针”或句柄&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;统一接口&lt;/strong&gt;：无论是普通文件、硬件设备（如终端、磁盘）、还是网络连接，都可以通过 &lt;code&gt;open&lt;/code&gt; 获得一个文件描述符，然后使用相同的 &lt;code&gt;read&lt;/code&gt;/&lt;code&gt;write&lt;/code&gt; 等系统调用来进行操作，这极大地简化了应用程序的编写&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;设备控制器与-mmio&#34;&gt;设备控制器与 MMIO&lt;/h3&gt;
&lt;p&gt;“文件”这个美好的抽象背后，是具体的硬件工作原理&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;设备控制器 (Device Controller)&lt;/strong&gt;：每个 I/O 设备都有一个控制器，它是一个包含 CPU、内存和寄存器的微型计算机，作为 CPU 和物理设备之间的桥梁&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;设备寄存器&lt;/strong&gt;：控制器通过一组&lt;strong&gt;寄存器&lt;/strong&gt;与 CPU 通信，通常包括：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;状态寄存器&lt;/strong&gt;：用于表示设备当前是否繁忙、是否准备好等&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;指令寄存器&lt;/strong&gt;：CPU 写入指令，告诉设备要做什么&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;数据寄存器&lt;/strong&gt;：用于在 CPU 和设备之间传输数据&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;内存映射 I/O (MMIO)&lt;/strong&gt;：为了让 CPU 能访问这些寄存器，现代系统普遍采用 &lt;strong&gt;MMIO (Memory-Mapped I/O)&lt;/strong&gt;，操作系统会将设备的寄存器映射到物理内存地址空间中的特定区域，这样一来，CPU 就可以像访问普通内存一样，使用标准的 &lt;code&gt;load&lt;/code&gt;/&lt;code&gt;store&lt;/code&gt; 指令来读写设备寄存器，从而实现对设备的控制&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;gpio&#34;&gt;GPIO&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;GPIO (General-Purpose Input/Output)&lt;/strong&gt; 是理解 I/O 设备原理最直观的例子，GPIO 就是一个物理引脚，可以通过编程设置为输入或输出模式&lt;/p&gt;
&lt;p&gt;通过 MMIO，一个 GPIO 引脚的电平状态被映射到一个特定的内存地址，当 CPU 向这个地址写入 &lt;code&gt;1&lt;/code&gt; 时，引脚就变为高电平；写入 &lt;code&gt;0&lt;/code&gt; 时，则变为低电平，这个过程将一条内存写指令直接转化为了一个物理世界的动作（比如点亮一个 LED）&lt;/p&gt;</description>
    </item>
    <item>
      <title>21. 存储设备原理</title>
      <link>https://diefish1024.github.io/posts/nju-os-2025/21-%E5%AD%98%E5%82%A8%E8%AE%BE%E5%A4%87%E5%8E%9F%E7%90%86/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://diefish1024.github.io/posts/nju-os-2025/21-%E5%AD%98%E5%82%A8%E8%AE%BE%E5%A4%87%E5%8E%9F%E7%90%86/</guid>
      <description>&lt;p&gt;科普性质，简单记录一下&lt;/p&gt;
&lt;h2 id=&#34;1-bit-的存储磁铁&#34;&gt;1-Bit 的存储：磁铁&lt;/h2&gt;
&lt;p&gt;要实现“持久化”存储，核心是要找到一个能反复改写的状态，很容易想到能够利用磁的特性，这就有了磁带的初步想法：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;一个长条的带子上面均匀有磁性物质&lt;/li&gt;
&lt;li&gt;定位到特定位置之后通过放大感应电流读取&lt;/li&gt;
&lt;li&gt;用电磁铁改变磁化方向来写入数据&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;为了提高存储密度，可以把这样的带子给卷起来，于是就得到了磁带&lt;/p&gt;
&lt;p&gt;这样的存储方式主要缺点是&lt;strong&gt;几乎不能随机读写&lt;/strong&gt;（比如磁带收音机需要倒带），一般用于冷数据的存档和备份&lt;/p&gt;
&lt;p&gt;为了解决这个缺点，可以想到用旋转的二维平面来替代卷起来的带子，这样读写延迟就不会超过旋转的周期，这就得到了&lt;strong&gt;磁鼓&lt;/strong&gt;：&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://diefish1024.github.io/images/21-%E5%AD%98%E5%82%A8%E8%AE%BE%E5%A4%87%E5%8E%9F%E7%90%86/pasted-image-20250805012735-png&#34;&gt;&lt;/p&gt;
&lt;p&gt;再在磁鼓的基础上进一步内卷，把用圆盘代替柱面，从而可以堆叠起来，进一步提高了存储密度，这就得到了&lt;strong&gt;磁盘&lt;/strong&gt;：&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://diefish1024.github.io/images/21-%E5%AD%98%E5%82%A8%E8%AE%BE%E5%A4%87%E5%8E%9F%E7%90%86/pasted-image-20250805012958-png&#34;&gt;&lt;/p&gt;
&lt;p&gt;磁盘作为存储设备的随机读写性能虽然相比磁带有了很大的改善，但是还是需要等待定位到正确的位置，性能仍然不够优秀，为了读写定位到一个扇区通常需要花费几个毫秒的时间，这一点可以通过缓存和调度算法来缓解，让数据尽可能连续存储&lt;/p&gt;
&lt;p&gt;当我们在磁盘的基础上把读写头和盘片本体分开，我们就实现了数据的移动，这也就得到了&lt;strong&gt;软盘&lt;/strong&gt;，这是上个数据数据发行的主要方式，虽然性能和可靠性都比较低，但是胜在了便捷、可移动&lt;/p&gt;
&lt;h2 id=&#34;1-bit-的存储挖坑&#34;&gt;1-Bit 的存储：挖坑&lt;/h2&gt;
&lt;p&gt;古人实现持久化存储的方式是在石头上刻字，也就是通过挖坑来存储信息，这种方式可以跨越非常长的时间&lt;/p&gt;
&lt;p&gt;而现代工业使我们可以挖出更加精细的坑，从而可以存储更高密度的信息&lt;/p&gt;
&lt;p&gt;为了读取这样的信息，我们可以从光学的角度考虑：在反射平面上挖粗糙坑，激光扫过表面，在平面会反射回来，在坑里会发生漫反射，于是我们只要检测是否收到反射光就可以识别是坑还是表面，这也就是&lt;strong&gt;光盘&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;光盘最有趣的特性是容易复制，我们要制造光盘可以先仔细地制造一张反转的盘片，坑的位置对应其表面的突起，之后只需要直接用这个盘片压制加热的塑料再镀上反射膜就可以得到一张光盘，这种方式可以达到极高的写入速度&lt;/p&gt;
&lt;p&gt;当然这种挖坑方式的一个重要特性就是不能修改已经写入的内容的，很难填上一个已经挖了的坑（当然通过特殊的制造材料和工艺也是可以做到的），这也就是说里面存储的数据是 append only 的，想要修改之前的内容可以采用可持久化二叉树的结构&lt;/p&gt;
&lt;p&gt;光盘作为存储设备，价格低的同时容量和可靠性都比较高，同时顺序读性能一般，随机读性能低并且很难写入，一个重要的应用常见就是数字时代的内容分发&lt;/p&gt;
&lt;p&gt;现代这种挖坑的存储方式还有一种应用方式是回归古人石碑的形式，把信息刻在很稳定的材料上来做到永久存储&lt;/p&gt;
&lt;h2 id=&#34;1-bit-的存储电荷&#34;&gt;1-Bit 的存储：电荷&lt;/h2&gt;
&lt;p&gt;前两种存储介质都存在比较大的缺陷：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;磁：依赖机械部件，从而无法避免 ms 级别的延迟&lt;/li&gt;
&lt;li&gt;坑（光）：挖坑效率低，同时填坑很困难&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;而电荷则是一种非常理想的存储介质：电子的密度极高，并且电路的速度极快（还天然并行）&lt;/p&gt;
&lt;p&gt;在电路中实现 1-bit 的持久存储，一个想法是我们可以挖一个坑，两种状态分别是：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;在坑里填入电子&lt;/li&gt;
&lt;li&gt;从坑里放跑电子&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;而这就得到了&lt;strong&gt;闪存 (Flash Memory)&lt;/strong&gt; ：
&lt;img loading=&#34;lazy&#34; src=&#34;https://diefish1024.github.io/images/21-%E5%AD%98%E5%82%A8%E8%AE%BE%E5%A4%87%E5%8E%9F%E7%90%86/pasted-image-20250805112704-png&#34;&gt;
其作为存储设备，价格低，容量和可靠性高，而且读写性能极高（由于电路天然并行，所以容量越大，速度越快）&lt;/p&gt;
&lt;p&gt;然而，闪存的物理原理也带来了其固有的缺陷，即&lt;strong&gt;会磨损 (wear out)&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;每次放电 (erase) 操作都无法 100% 将电子放干净，这会对存储单元造成微小的、不可逆的损伤&lt;/li&gt;
&lt;li&gt;在经历数千或数万次擦写循环后，一些存储单元会因为累积的损伤而失效，无法再可靠地存储数据，这被称为 “&lt;strong&gt;死单元 (Dead Cell)&lt;/strong&gt;”&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;为了解决闪存的磨损问题，并将其更好地呈现给操作系统，现代固态存储设备（如 SSD、U 盘、SD 卡）内部实际上都集成了一个微型计算机系统&lt;/p&gt;
&lt;p&gt;这个系统运行着一层被称为 &lt;strong&gt;FTL (Flash Translation Layer)&lt;/strong&gt; 的固件，它的核心功能之一是 &lt;strong&gt;磨损均衡 (Wear Leveling)&lt;/strong&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Benchmarking TTA</title>
      <link>https://diefish1024.github.io/posts/literature-notes/benchmarking-tta/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://diefish1024.github.io/posts/literature-notes/benchmarking-tta/</guid>
      <description>&lt;h3 id=&#34;a-general-paradigm-of-test-time-adaptation&#34;&gt;A General Paradigm of Test-Time Adaptation&lt;/h3&gt;
&lt;p&gt;根据测试数据接收方式和适应过程，TTA 分为三种主要范式：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Test-Time Batch Adaptation (TTBA) 测试时间批次适应：&lt;/strong&gt; 数据以小批次形式到达。模型会针对每个到来的小批次进行适应，并立即提供预测。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Online Test-Time Adaptation (OTTA) 在线测试时间适应：&lt;/strong&gt; 数据以序列化的方式（小批次）到达。模型进行增量更新，并且过去的适应经验会影响未来的预测。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Test-Time Domain Adaptation (TTDA) 测试时间域适应：&lt;/strong&gt; 整个目标域的数据（所有测试数据）可在预测前一次性用于适应。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;datasets-for-evaluation&#34;&gt;Datasets for Evaluation&lt;/h3&gt;
&lt;p&gt;论文使用了两种不同类型的分布偏移数据集进行评估：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Corruption Datasets 损坏数据集：&lt;/strong&gt; 原始数据集（CIFAR-10，ImageNet）经过&lt;strong&gt;人为损坏处理&lt;/strong&gt;后得到的，通过添加不同类型的噪声、模糊等，模拟不同严重程度的分布偏移。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Natural-shift Datasets 自然偏移数据集：&lt;/strong&gt; 这些数据集代表数据分布中&lt;strong&gt;自然发生的变化&lt;/strong&gt;，收集自不同的真实世界来源或条件（Office-Home，DomainNet，其中图像可能是不同风格的艺术作品、剪贴画、真实世界照片或草图）。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;results-on-natural-shift-datasets&#34;&gt;Results on Natural Shift Datasets&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;TTA 方法在自然偏移数据集上的表现与在损坏数据集上的表现有所不同。&lt;/li&gt;
&lt;li&gt;PredBN 在损坏数据集上有效，但在自然偏移数据集上表现不佳，有时甚至比源模型更差。这可能是因为自然偏移对数据分布的影响与人工损坏不同。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;T3A&lt;/strong&gt; 在 OTTA 范式下的自然偏移数据集上表现优于其他 OTTA 算法。这归因于其特征生成方式及其分类器优化能力。&lt;/li&gt;
&lt;li&gt;对于自然偏移数据集，&lt;strong&gt;TTDA 算法&lt;/strong&gt; 持续取得了最高的性能。一些 OTTA 方法的多轮次也能达到可比的成果。&lt;/li&gt;
&lt;/ul&gt;</description>
    </item>
    <item>
      <title>CoTTA</title>
      <link>https://diefish1024.github.io/posts/literature-notes/cotta/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://diefish1024.github.io/posts/literature-notes/cotta/</guid>
      <description>&lt;h1 id=&#34;setting&#34;&gt;Setting&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;Continual Test-Time Domain Adaptation&lt;/strong&gt; 是一种更具挑战性的模型适应设定。在此设定下，一个在源数据上预训练好的模型，在测试时会遇到一个&lt;strong&gt;非平稳&lt;/strong&gt;且&lt;strong&gt;持续变化&lt;/strong&gt;的目标环境 。&lt;/p&gt;
&lt;p&gt;CoTTA 与以下方法不同：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Standard Domain Adaptation&lt;/strong&gt;：需要同时访问源数据和（静态的）目标数据进行训练。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Standard Test-Time Adaptation / Fully Test-Time Adaptation&lt;/strong&gt;：通常假设目标域是固定的或静态的，而 CoTTA 关注的是持续变化的目标域。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Test-Time Training (TTT)&lt;/strong&gt;：需要修改源模型的训练过程以加入辅助任务，因此无法使用任意的“开箱即用”预训练模型。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;相比之下，CoTTA 专门解决在&lt;strong&gt;无源数据&lt;/strong&gt;的条件下，模型如何在线适应一个&lt;strong&gt;持续变化的&lt;/strong&gt;数据流，同时克服现有方法中常见的&lt;strong&gt;错误累积&lt;/strong&gt;和&lt;strong&gt;灾难性遗忘&lt;/strong&gt;问题。&lt;/p&gt;
&lt;h2 id=&#34;method&#34;&gt;Method&lt;/h2&gt;
&lt;p&gt;论文的核心贡献是提出了&lt;strong&gt;CoTTA (Continual Test-Time Adaptation)&lt;/strong&gt; 方法，旨在通过&lt;strong&gt;减少错误累积&lt;/strong&gt;和&lt;strong&gt;避免灾难性遗忘&lt;/strong&gt;，实现模型在非平稳环境下的长期稳定适应，主要有两个关键部分。&lt;/p&gt;
&lt;h3 id=&#34;1-减少错误累积-reducing-error-accumulation&#34;&gt;1. 减少错误累积 (Reducing Error Accumulation)&lt;/h3&gt;
&lt;p&gt;为了生成更可靠的自训练信号，CoTTA 采用了平均化的伪标签策略，该策略结合了权重平均和数据增强平均。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;权重平均伪标签 (Weight-Averaged Pseudo-Labels)&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;该方法采用一个&lt;strong&gt;教师 - 学生 (teacher-student)&lt;/strong&gt; 框架。学生模型 (student model) 在线进行学习和更新。&lt;/li&gt;
&lt;li&gt;教师模型 (teacher model) 的权重是学生模型权重的&lt;strong&gt;指数移动平均 (Exponential Moving Average, EMA)&lt;/strong&gt;。&lt;/li&gt;
&lt;li&gt;由于教师模型的更新更平滑，其预测结果通常比学生模型更准确，因此用它来生成伪标签，可以有效减少错误累积。学生模型通过最小化与教师伪标签的&lt;strong&gt;一致性损失&lt;/strong&gt; (consistency loss) 来进行更新。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;数据增强平均伪标签 (Augmentation-Averaged Pseudo-Labels)&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;为了进一步提升伪标签在遇到较大域偏移时的质量，CoTTA 会有条件地使用数据增强。&lt;/li&gt;
&lt;li&gt;它首先使用&lt;strong&gt;原始预训练模型&lt;/strong&gt;评估当前测试数据的&lt;strong&gt;预测置信度&lt;/strong&gt;，以此来近似域差异的大小。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;条件性应用&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;如果置信度&lt;strong&gt;高&lt;/strong&gt;（域差异小），则直接使用教师模型的预测作为伪标签 16。&lt;/li&gt;
&lt;li&gt;如果置信度&lt;strong&gt;低&lt;/strong&gt;（域差异大），则对输入数据进行 N 次随机增强，并将教师模型对这些增强样本的平均预测结果作为伪标签 17171717。这可以进一步提高伪标签的鲁棒性。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;2-避免灾难性遗忘-avoiding-catastrophic-forgetting&#34;&gt;2. 避免灾难性遗忘 (Avoiding Catastrophic Forgetting)&lt;/h3&gt;
&lt;p&gt;为了在长期适应过程中保留从源域学到的知识，CoTTA 引入了&lt;strong&gt;随机恢复 (Stochastic Restoration)&lt;/strong&gt; 机制。&lt;/p&gt;</description>
    </item>
    <item>
      <title>DANN</title>
      <link>https://diefish1024.github.io/posts/literature-notes/dann/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://diefish1024.github.io/posts/literature-notes/dann/</guid>
      <description>&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;类似 GAN 的对抗训练思想&lt;/p&gt;
&lt;h2 id=&#34;domain-adaptation&#34;&gt;Domain Adaptation&lt;/h2&gt;
&lt;p&gt;给定源域 $ D_{S} $ （有标签）和目标域 $ D_{T} $ （无标签），目标是训练一个分类器 $ \eta: X\to Y $ 使其在目标域上的目标风险
$$ 

R_{D_{T}}(\eta) = \underset{(\mathbf{x},y)\sim D_{T}}{\mathrm{Pr}}(\eta(\mathbf{x}) \neq y)

 $$
最小&lt;/p&gt;
&lt;h4 id=&#34;domain-divergence&#34;&gt;Domain Divergence&lt;/h4&gt;
&lt;p&gt;需要量化两个领域的“相似度”，从而引出了 &lt;strong&gt;H- 散度&lt;/strong&gt; 的概念：
$$ 

d_{\mathcal{H}}(D_S, D_T) = 2 \sup_{\eta \in \mathcal{H}} \left| \Pr_{x \sim D_S}[\eta(x) = 1] - \Pr_{x \sim D_T}[\eta(x) = 1] \right|

 $$
含义是最优的分类器将目标域和源域判定为 1 的可能性之差，当 H- 散度非常小时，说明两个领域很难被区分，也就说明学习的特征实现了领域不变性的效果&lt;/p&gt;
&lt;p&gt;由于理论 H 散度是理想数据分布上的定义，实际中只有有限的样本集 $ S $ 和 $ T $ ，因此需要一定的近似，于是需要经验 H- 散度
$$ 

\hat{d}_{\mathcal{H}}(S, T) = 2 \left(1 - \min_{\eta \in \mathcal{H}} \left[ \dfrac{1}{n}\sum_{i=1}^n \mathcal{I}[\eta(x_i) = 0] + \dfrac{1}{n&#39;}\sum_{i=n+1}^N \mathcal{I}[\eta(x_i) = 1] \right] \right)

 $$
其中 $ \mathcal{I}[\cdot] $ 表示条件为真时为 1，否则为 0&lt;/p&gt;</description>
    </item>
    <item>
      <title>EmT</title>
      <link>https://diefish1024.github.io/posts/literature-notes/emt/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://diefish1024.github.io/posts/literature-notes/emt/</guid>
      <description>&lt;h2 id=&#34;abstract&#34;&gt;Abstract&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;问题&lt;/strong&gt;：现有 EEG 情绪识别方法对长期上下文信息关注不足，导致跨被试泛化能力减弱&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;方案&lt;/strong&gt;：提出 &lt;strong&gt;Emotion Transformer (EmT)&lt;/strong&gt; ，为 Graph-Transformer 混和架构&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;核心模块&lt;/strong&gt;：
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;TGC&lt;/strong&gt;：将 EEG 信号转换为时序图序列&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;RMPG&lt;/strong&gt;：使用残差多视图金字塔 GCN，学习动态、多尺度的空间连接模式，生成 token（核心）&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;TCT&lt;/strong&gt;：使用任务自适应的 Transformer，学习 token 序列上下文（核心）&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;TSO&lt;/strong&gt;：输出分类/回归结果&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;成果&lt;/strong&gt;：在多个公开数据集的广义跨被试任务上面超过了 baseline&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;introduction--related-work&#34;&gt;Introduction &amp;amp; Related Work&lt;/h2&gt;
&lt;p&gt;为什么 EEG 难以使用跨被试 (cross-subject) 的场景？&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;个体差异&lt;/strong&gt;：不同被试生理结构和认知策略差异，导致 EEG 模式不同&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;低信噪比&lt;/strong&gt;：EEG 信号容易受到外源噪声干扰（肌电、眼电……）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;目标是学习一种&lt;strong&gt;跨被试共享&lt;/strong&gt;、具有&lt;strong&gt;泛化能力&lt;/strong&gt;的情绪表征&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;gpaph-neural-networks&#34;&gt;Gpaph Neural Networks&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;核心思想&lt;/strong&gt;：EEG 数据具有非欧图结构，适合使用 GNN 来处理&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;代表工作&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;ChebyNet&lt;/strong&gt;：使用切比雪夫多项式近似光谱滤波，EmT 模型中采用其作为 GCN 层&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;GCN&lt;/strong&gt;：通过局部一阶聚合近似光谱滤波&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;DGCNN / RGNN&lt;/strong&gt;：使用 GNNs 提取 EEG 空间信息；依赖单一的邻接矩阵，忽略时序上下文，具有&lt;strong&gt;局限性&lt;/strong&gt;；而 EmT 通过&lt;strong&gt;多视图可学习邻接矩阵&lt;/strong&gt;和&lt;strong&gt;时序图&lt;/strong&gt;来弥补&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id=&#34;temporal-context-learning&#34;&gt;Temporal Context Learning&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;核心理念&lt;/strong&gt;: 情绪是连续认知过程，EEG 信号中嵌入时序上下文信息&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;代表工作&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;LSTM / TCN / TESANet / Conformer / AMDET&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;局限性&lt;/strong&gt;：这些方法通常从扁平化的 EEG 特征向量学习，可能&lt;strong&gt;未能有效学习空间关系&lt;/strong&gt;；EmT 则通过并行 GCN 和 STA 层更有效地捕捉时空信息&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id=&#34;eeg-emotion-recognition&#34;&gt;EEG Emotion Recognition&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;核心理念&lt;/strong&gt;：EEG 情绪识别面临个体差异大、信噪比低等挑战，需提取光谱、空间、时序特征&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;代表工作&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;GCB-Net / TSception&lt;/li&gt;
&lt;li&gt;局限性：没有关注长时序上下文信息&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;method&#34;&gt;Method&lt;/h2&gt;
&lt;p&gt;EmT 是一个端到端的框架，包含四大模块：&lt;/p&gt;</description>
    </item>
    <item>
      <title>KV Cache 入门</title>
      <link>https://diefish1024.github.io/posts/ai-infra/kv-cache-%E5%85%A5%E9%97%A8/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://diefish1024.github.io/posts/ai-infra/kv-cache-%E5%85%A5%E9%97%A8/</guid>
      <description>&lt;p&gt;推理效率对于 llm 是一个至关重要的问题。当模型生成文本时，尤其是以自回归方式逐词生成时，效率瓶颈会变得非常明显。KV Cache 就是为了解决这一问题而诞生的技术。&lt;/p&gt;
&lt;h3 id=&#34;1-what-is-kv-cache&#34;&gt;1. What is KV Cache?&lt;/h3&gt;
&lt;p&gt;KV Cache，全称 &lt;strong&gt;Key-Value Cache&lt;/strong&gt;，是一种优化技术，用于加速 Transformer 架构在自回归生成过程中的推理速度。它的核心思想是&lt;strong&gt;缓存&lt;/strong&gt;并&lt;strong&gt;重用&lt;/strong&gt;在注意力机制中计算得到的 &lt;strong&gt;Key (K)&lt;/strong&gt; 和 &lt;strong&gt;Value (V)&lt;/strong&gt; 向量。&lt;/p&gt;
&lt;h3 id=&#34;2-transformer-attention-mechanism-review&#34;&gt;2. Transformer Attention Mechanism Review&lt;/h3&gt;
&lt;p&gt;要理解 KV Cache，首先需要对 Transformer 架构中的自注意力机制有一个基本认识。自注意力机制允许模型在处理序列中的某个词时，考虑序列中所有其他词的重要性。&lt;/p&gt;
&lt;p&gt;每个输入 token（词或子词）在进入注意力层时，都会被转换成三个不同的向量：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Q 向量：代表当前 token 的“查询”信息&lt;/li&gt;
&lt;li&gt;K 向量：代表所有 token 的“键”信息，用于与 Query 进行匹配&lt;/li&gt;
&lt;li&gt;V 向量：代表所有 token 的“值”信息，用于加权求和，得到最终的输出&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;自注意力机制的计算过程为以下步骤：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;计算 Query 与所有 Key 的点积，得到&lt;strong&gt;注意力分数&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;将注意力分数进行缩放，除以 $ \sqrt{d_k} $（$ d_k $ 是 Key 向量的维度)&lt;/li&gt;
&lt;li&gt;对缩放后的分数进行 Softmax，将其转换为&lt;strong&gt;注意力权重&lt;/strong&gt;，表示每个 token 对当前 token 的重要性&lt;/li&gt;
&lt;li&gt;将注意力权重与 Value 向量进行加权求和，得到当前 token 的注意力输出&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;公式为：
$$ 

\text{Attention}(Q, K, V) = \text{softmax}\left(\frac{QK^T}{\sqrt{d_k}}\right)V

 $$
其中矩阵 $ Q,K,V \in \mathbb{R}^{L \times d} $ ，$ L $ 为当前上下文长度&lt;/p&gt;</description>
    </item>
    <item>
      <title>SSA</title>
      <link>https://diefish1024.github.io/posts/literature-notes/ssa/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://diefish1024.github.io/posts/literature-notes/ssa/</guid>
      <description>&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;TTA 在回归任务上的局限：为分类任务设计，一般基于熵最小化和特征对齐；熵最小化不适用，回归模型产生单一值，不产生概率分布；简单特征对齐对回归模型效果不佳，可能反而会稀释需要学习的特征&lt;/p&gt;
&lt;h2 id=&#34;problem-setting&#34;&gt;Problem Setting&lt;/h2&gt;
&lt;p&gt;考虑一个回归模型 $ f_\theta: \mathcal{X} \to \mathbb{R} $，可以进一步分解为&lt;strong&gt;特征提取器&lt;/strong&gt; $ g_\phi: \mathcal{X} \to \mathbb{R}^D $（从输入 $ \mathcal{X} $ 提取 $ D $ 维特征 $ z $）和&lt;strong&gt;线性回归器&lt;/strong&gt; $ h_\psi(z) = w^T z + b $（或者 $ h_{\psi}(z)=Wz+b $）&lt;/p&gt;
&lt;p&gt;$ f_\theta $ 首先在一个有标签的&lt;strong&gt;源数据集&lt;/strong&gt; $ S = \{(x_i, y_i)\}_{i=1}^{N_s} $ 上进行预训练，数据从源域分布 $ p_s $ 中采样&lt;/p&gt;
&lt;p&gt;目标是使用一个&lt;strong&gt;无标签的&lt;/strong&gt;目标数据集 $ T = \{x_j\}_{j=1}^{N_t} $ 来适应预训练好的模型 $ f_\theta $ 到目标域&lt;/p&gt;
&lt;p&gt;我们假设存在 &lt;strong&gt;covariate shift&lt;/strong&gt; ，这意味着：&lt;/p&gt;</description>
    </item>
    <item>
      <title>T-TIME</title>
      <link>https://diefish1024.github.io/posts/literature-notes/t-time/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://diefish1024.github.io/posts/literature-notes/t-time/</guid>
      <description>&lt;h1 id=&#34;method&#34;&gt;Method&lt;/h1&gt;
&lt;h3 id=&#34;problem-set&#34;&gt;Problem Set&lt;/h3&gt;
&lt;p&gt;EEG 数据 $ \{ X_{s,l}^{i},y_{s,l}^{i} \}_{i=1}^{n_{s,l}} $ ，进行无监督在线 K 分类&lt;/p&gt;
&lt;h3 id=&#34;source-model-training&#34;&gt;Source Model Training&lt;/h3&gt;
&lt;p&gt;对源数据做 Euclidean alignment (EA) 数据对齐，减少不同个体 EEG 信号差异&lt;/p&gt;
&lt;p&gt;EA 计算每个个体所有 EEG 试次协方差矩阵的算术平均值
$$ 

R_{s,l} = \dfrac{1}{n}\sum_{i=1}^{n} X_{i}(X_{i})^{T} \implies \bar{X}_{i} = R_{s,l}^{-1/2}X_{i}

 $$
之后再整合经过对齐的受试者数据，形成“源域”&lt;/p&gt;
&lt;p&gt;在整合后的数据上独立训练 $ M $ 个模型&lt;/p&gt;
&lt;h3 id=&#34;incremental-ea-on-target-data&#34;&gt;Incremental EA on Target Data&lt;/h3&gt;
&lt;p&gt;对新数据增量式更新协方差矩阵，再用新的矩阵更新所有测试数据&lt;/p&gt;
&lt;h3 id=&#34;target-label-prediction&#34;&gt;Target Label Prediction&lt;/h3&gt;
&lt;p&gt;用训练好的 $ M $ 模型初始化用于适应目标域的 $ M $ 个 TTA 模型 $ f_{m} $&lt;/p&gt;
&lt;p&gt;新的 $ X_{a} $ 经过 IEA 被变换为 $ X_{a}&#39; $ 后被输入到每个模型 $ f_{m} $ 中进行分类，输出概率向量 $ f_{m}(X_{a}&#39;) $&lt;/p&gt;</description>
    </item>
    <item>
      <title>Tent</title>
      <link>https://diefish1024.github.io/posts/literature-notes/tent/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://diefish1024.github.io/posts/literature-notes/tent/</guid>
      <description>&lt;h1 id=&#34;setting&#34;&gt;Setting&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;Fully Test-Time Adaptation&lt;/strong&gt; 是一种独特的模型适应设定。在此设定下，模型 $ f_\theta(x) $ 在训练阶段已通过源数据 $ x^s $ 和标签 $ y^s $ 完成训练，获得参数 $ \theta $。但在测试阶段，模型将遇到与源数据分布不同的无标签目标数据 $ x^t $。&lt;/p&gt;
&lt;p&gt;FTT-Adaptation 与以下方法不同：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Fine-tuning&lt;/strong&gt;：需要目标标签进行重新训练。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Domain Adaptation&lt;/strong&gt;：需要源数据和目标数据进行联合训练。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Test-Time Training (TTT)&lt;/strong&gt;：需要修改训练过程并共同优化有监督及自监督损失。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;相比之下，FTT-Adaptation 仅能利用预训练模型 $ f_\theta $ 和无标签目标数据 $ x^t $ 进行适应，不依赖源数据或额外的监督信息。&lt;/p&gt;
&lt;h2 id=&#34;method&#34;&gt;Method&lt;/h2&gt;
&lt;p&gt;论文的核心贡献是提出了 &lt;strong&gt;Tent&lt;/strong&gt; 方法，其核心思想是通过&lt;strong&gt;最小化测试熵&lt;/strong&gt;（&lt;strong&gt;Test Entropy Minimization&lt;/strong&gt;）来适应模型预测，旨在使模型对测试数据的预测结果更“有信心”。&lt;/p&gt;
&lt;h3 id=&#34;entropy-objective&#34;&gt;Entropy Objective&lt;/h3&gt;
&lt;p&gt;Tent 的测试时目标函数是最小化模型预测 $ \hat{y} = f_\theta(x^t) $ 的&lt;strong&gt;熵 $ H(\hat{y}) $&lt;/strong&gt;。论文中使用的&lt;strong&gt;香农熵&lt;/strong&gt;计算公式如下：&lt;/p&gt;
$$ 

H(\hat{y}) = - \sum_c p(\hat{y}_c) \log p(\hat{y}_c)

 $$
&lt;p&gt;其中， $ p(\hat{y}_c) $ 表示模型预测目标数据 $ x^t $ 属于类别 $ c $ 的概率。&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
