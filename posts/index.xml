<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Posts on diefish&#39;s blog</title>
    <link>https://diefish1024.github.io/posts/</link>
    <description>Recent content in Posts on diefish&#39;s blog</description>
    <image>
      <title>diefish&#39;s blog</title>
      <url>https://diefish1024.github.io/images/avatar.jpg</url>
      <link>https://diefish1024.github.io/images/avatar.jpg</link>
    </image>
    <generator>Hugo -- 0.148.2</generator>
    <language>zh-cn</language>
    <atom:link href="https://diefish1024.github.io/posts/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>15. 并发控制：同步条件变量</title>
      <link>https://diefish1024.github.io/posts/nju-os-2025/15-%E5%B9%B6%E5%8F%91%E6%8E%A7%E5%88%B6%E5%90%8C%E6%AD%A5%E6%9D%A1%E4%BB%B6%E5%8F%98%E9%87%8F/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://diefish1024.github.io/posts/nju-os-2025/15-%E5%B9%B6%E5%8F%91%E6%8E%A7%E5%88%B6%E5%90%8C%E6%AD%A5%E6%9D%A1%E4%BB%B6%E5%8F%98%E9%87%8F/</guid>
      <description>&lt;h2 id=&#34;同步和条件变量&#34;&gt;同步和条件变量&lt;/h2&gt;
&lt;p&gt;互斥实现了&lt;strong&gt;原子性&lt;/strong&gt;，但是无法实现&lt;strong&gt;确定性&lt;/strong&gt;，也就是无法正确实现 &amp;ldquo;happens-before&amp;rdquo; 的关系&lt;/p&gt;
&lt;p&gt;因此需要引入条件变量来实现线程的同步，形成受控制的并发事件的&lt;strong&gt;发生顺序&lt;/strong&gt;（可以用乐团指挥来类比），把一系列不确定的状态在某一个时间点同步到了一个确定的状态，将发散的并发程序状态 “收束”&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;实现同步&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;实现 $A\to B$：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;7
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-gdscript3&#34; data-lang=&#34;gdscript3&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;A&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;can_proceed&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;bp&#34;&gt;true&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;signal&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;while&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;!&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;can_proceed&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;B&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;//&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;B&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;wait&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;until&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;the&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;condition&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;is&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;satisfied&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;这样的思路大致正确，但是自选的循环有很大的性能问题，因此需要一个更加底层的机制来帮助实现这一点&lt;/p&gt;
&lt;p&gt;最理想的 API 是 &lt;code&gt;wait_until(cond)&lt;/code&gt; ，但是过去为了简化设计，变成了&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;条件不满足时等待：&lt;code&gt;wait&lt;/code&gt; - 直接睡眠等待&lt;/li&gt;
&lt;li&gt;条件满足时继续：&lt;code&gt;signal/broadcast&lt;/code&gt; - 唤醒所有线程&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;（小时候的 scratch 编程其实已经有了这样的思想😂）&lt;/p&gt;
&lt;p&gt;在 c++ 代码中我们可以把条件放到 $\lambda$ 表达式中：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-c++&#34; data-lang=&#34;c++&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;std&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;mutex&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;mtx&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;std&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;condition_variable&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;cv&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kt&#34;&gt;void&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;T_player&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	&lt;span class=&#34;n&#34;&gt;std&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;unique_lock&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;lk&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;mtx&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	&lt;span class=&#34;n&#34;&gt;cv&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;wait&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;lk&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;		&lt;span class=&#34;p&#34;&gt;[]{&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;can_proceed&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	&lt;span class=&#34;n&#34;&gt;cv&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;notify_all&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;();&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	&lt;span class=&#34;n&#34;&gt;lk&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;unlock&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;();&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;注意条件变量在等待时需要带着一把锁（需要确保检查和等待是原子操作）&lt;/p&gt;</description>
    </item>
    <item>
      <title>DANN</title>
      <link>https://diefish1024.github.io/posts/literature-notes/dann/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://diefish1024.github.io/posts/literature-notes/dann/</guid>
      <description>&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;类似 GAN 的对抗训练思想&lt;/p&gt;
&lt;h2 id=&#34;domain-adaptation&#34;&gt;Domain Adaptation&lt;/h2&gt;
&lt;p&gt;给定源域 $D\&lt;em&gt;{S}$ （有标签）和目标域 $D\&lt;/em&gt;{T}$ （无标签），目标是训练一个分类器 $\eta: X\to Y$ 使其在目标域上的目标风险
$$
R\&lt;em&gt;{D\&lt;/em&gt;{T}}(\eta) = \underset{(\mathbf{x},y)\sim D\_{T}}{\mathrm{Pr}}(\eta(\mathbf{x}) \neq y)
$$
最小&lt;/p&gt;
&lt;h4 id=&#34;domain-divergence&#34;&gt;Domain Divergence&lt;/h4&gt;
&lt;p&gt;需要量化两个领域的“相似度”，从而引出了 &lt;strong&gt;H- 散度&lt;/strong&gt; 的概念：
$$
d\_{\mathcal{H}}(D\&lt;em&gt;S, D\&lt;em&gt;T) = 2 \sup\&lt;/em&gt;{\eta \in \mathcal{H}} \left| \Pr\&lt;/em&gt;{x \sim D\&lt;em&gt;S}[\eta(x) = 1] - \Pr\&lt;/em&gt;{x \sim D\_T}[\eta(x) = 1] \right|
$$
含义是最优的分类器将目标域和源域判定为 1 的可能性之差，当 H- 散度非常小时，说明两个领域很难被区分，也就说明学习的特征实现了领域不变性的效果&lt;/p&gt;
&lt;p&gt;由于理论 H 散度是理想数据分布上的定义，实际中只有有限的样本集 $S$ 和 $T$ ，因此需要一定的近似，于是需要经验 H- 散度
$$
\hat{d}\&lt;em&gt;{\mathcal{H}}(S, T) = 2 \left(1 - \min\&lt;/em&gt;{\eta \in \mathcal{H}} \left[ \dfrac{1}{n}\sum\_{i=1}^n \mathcal{I}[\eta(x\&lt;em&gt;i) = 0] + \dfrac{1}{n&amp;rsquo;}\sum\&lt;/em&gt;{i=n+1}^N \mathcal{I}[\eta(x\_i) = 1] \right] \right)
$$
其中 $\mathcal{I}[\cdot]$ 表示条件为真时为 1，否则为 0&lt;/p&gt;</description>
    </item>
    <item>
      <title>KV Cache 入门</title>
      <link>https://diefish1024.github.io/posts/ai-infra/kv-cache-%E5%85%A5%E9%97%A8/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://diefish1024.github.io/posts/ai-infra/kv-cache-%E5%85%A5%E9%97%A8/</guid>
      <description>&lt;p&gt;推理效率对于 llm 是一个至关重要的问题。当模型生成文本时，尤其是以自回归方式逐词生成时，效率瓶颈会变得非常明显。KV Cache 就是为了解决这一问题而诞生的技术。&lt;/p&gt;
&lt;h3 id=&#34;1-what-is-kv-cache&#34;&gt;1. What is KV Cache?&lt;/h3&gt;
&lt;p&gt;KV Cache，全称 &lt;strong&gt;Key-Value Cache&lt;/strong&gt;，是一种优化技术，用于加速 Transformer 架构在自回归生成过程中的推理速度。它的核心思想是&lt;strong&gt;缓存&lt;/strong&gt;并&lt;strong&gt;重用&lt;/strong&gt;在注意力机制中计算得到的 &lt;strong&gt;Key (K)&lt;/strong&gt; 和 &lt;strong&gt;Value (V)&lt;/strong&gt; 向量。&lt;/p&gt;
&lt;h3 id=&#34;2-transformer-attention-mechanism-review&#34;&gt;2. Transformer Attention Mechanism Review&lt;/h3&gt;
&lt;p&gt;要理解 KV Cache，首先需要对 Transformer 架构中的自注意力机制有一个基本认识。自注意力机制允许模型在处理序列中的某个词时，考虑序列中所有其他词的重要性。&lt;/p&gt;
&lt;p&gt;每个输入 token（词或子词）在进入注意力层时，都会被转换成三个不同的向量：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Q 向量：代表当前 token 的“查询”信息&lt;/li&gt;
&lt;li&gt;K 向量：代表所有 token 的“键”信息，用于与 Query 进行匹配&lt;/li&gt;
&lt;li&gt;V 向量：代表所有 token 的“值”信息，用于加权求和，得到最终的输出&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;自注意力机制的计算过程为以下步骤：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;计算 Query 与所有 Key 的点积，得到&lt;strong&gt;注意力分数&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;将注意力分数进行缩放，除以 $\sqrt{d\_k}$（$d\_k$ 是 Key 向量的维度)&lt;/li&gt;
&lt;li&gt;对缩放后的分数进行 Softmax，将其转换为&lt;strong&gt;注意力权重&lt;/strong&gt;，表示每个 token 对当前 token 的重要性&lt;/li&gt;
&lt;li&gt;将注意力权重与 Value 向量进行加权求和，得到当前 token 的注意力输出&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;公式为：
$$
\text{Attention}(Q, K, V) = \text{softmax}\left(\frac{QK^T}{\sqrt{d\_k}}\right)V
$$
其中矩阵 $Q,K,V \in \mathbb{R}^{L \times d}$ ，$L$ 为当前上下文长度&lt;/p&gt;</description>
    </item>
    <item>
      <title>SSA</title>
      <link>https://diefish1024.github.io/posts/literature-notes/ssa/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://diefish1024.github.io/posts/literature-notes/ssa/</guid>
      <description>&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;TTA 在回归任务上的局限：为分类任务设计，一般基于熵最小化和特征对齐；熵最小化不适用，回归模型产生单一值，不产生概率分布；简单特征对齐对回归模型效果不佳，可能反而会稀释需要学习的特征&lt;/p&gt;
&lt;h2 id=&#34;problem-setting&#34;&gt;Problem Setting&lt;/h2&gt;
&lt;p&gt;考虑一个回归模型 $f\&lt;em&gt;\theta: \mathcal{X} \to \mathbb{R}$，可以进一步分解为&lt;strong&gt;特征提取器&lt;/strong&gt; $g\&lt;/em&gt;\phi: \mathcal{X} \to \mathbb{R}^D$（从输入 $\mathcal{X}$ 提取 $D$ 维特征 $z$）和&lt;strong&gt;线性回归器&lt;/strong&gt; $h\&lt;em&gt;\psi(z) = w^T z + b$（或者 $h\&lt;/em&gt;{\psi}(z)=Wz+b$）&lt;/p&gt;
&lt;p&gt;$f\_\theta$ 首先在一个有标签的&lt;strong&gt;源数据集&lt;/strong&gt; $S = {(x\_i, y\&lt;em&gt;i)}\&lt;/em&gt;{i=1}^{N\_s}$ 上进行预训练，数据从源域分布 $p\_s$ 中采样&lt;/p&gt;
&lt;p&gt;目标是使用一个&lt;strong&gt;无标签的&lt;/strong&gt;目标数据集 $T = {x\&lt;em&gt;j}\&lt;/em&gt;{j=1}^{N\&lt;em&gt;t}$ 来适应预训练好的模型 $f\&lt;/em&gt;\theta$ 到目标域&lt;/p&gt;
&lt;p&gt;我们假设存在 &lt;strong&gt;covariate shift&lt;/strong&gt; ，这意味着：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;输入数据的分布在源域和目标域之间是不同的：$p\_s(x) \neq p\_t(x)$&lt;/li&gt;
&lt;li&gt;但给定输入后，输出的条件分布是相同的：$p\_s(y|x) = p\_t(y|x)$&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;test-time-adaptation-for-regression&#34;&gt;Test-time Adaptation for Regression&lt;/h2&gt;
&lt;h3 id=&#34;basic-idea-feature-alignment&#34;&gt;Basic Idea: Feature Alignment&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;朴素实现&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;计算源域特征统计量&lt;/strong&gt;：在源域训练后，计算源域特征的&lt;strong&gt;均值&lt;/strong&gt; $\mu^s$ 和&lt;strong&gt;元素级方差&lt;/strong&gt; $\sigma^{s2}$
$$ \mu^s = \frac{1}{N\&lt;em&gt;s} \sum\&lt;/em&gt;{i=1}^{N\_s} z\_i^s, \quad \sigma^{s2} = \frac{1}{N\&lt;em&gt;s} \sum\&lt;/em&gt;{i=1}^{N\_s} (z\_i^s - \mu^s) \odot (z\_i^s - \mu^s) \quad \text{(1)} $$
其中 $z\&lt;em&gt;i^s = g\&lt;/em&gt;\phi(x\_i)$ 是源特征，$N\_s$ 是源数据样本数，$\odot$ 表示元素级乘积&lt;/p&gt;</description>
    </item>
    <item>
      <title>T-TIME</title>
      <link>https://diefish1024.github.io/posts/literature-notes/t-time/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://diefish1024.github.io/posts/literature-notes/t-time/</guid>
      <description>&lt;h1 id=&#34;method&#34;&gt;Method&lt;/h1&gt;
&lt;h3 id=&#34;problem-set&#34;&gt;Problem Set&lt;/h3&gt;
&lt;p&gt;EEG 数据 ${ X\&lt;em&gt;{s,l}^{i},y\&lt;/em&gt;{s,l}^{i} }\&lt;em&gt;{i=1}^{n\&lt;/em&gt;{s,l}}$ ，进行无监督在线 K 分类&lt;/p&gt;
&lt;h3 id=&#34;source-model-training&#34;&gt;Source Model Training&lt;/h3&gt;
&lt;p&gt;对源数据做 Euclidean alignment (EA) 数据对齐，减少不同个体 EEG 信号差异&lt;/p&gt;
&lt;p&gt;EA 计算每个个体所有 EEG 试次协方差矩阵的算术平均值
$$
R\&lt;em&gt;{s,l} = \dfrac{1}{n}\sum\&lt;/em&gt;{i=1}^{n} X\&lt;em&gt;{i}(X\&lt;/em&gt;{i})^{T} \implies \bar{X}\&lt;em&gt;{i} = R\&lt;/em&gt;{s,l}^{-1/2}X\_{i}
$$
之后再整合经过对齐的受试者数据，形成“源域”&lt;/p&gt;
&lt;p&gt;在整合后的数据上独立训练 $M$ 个模型&lt;/p&gt;
&lt;h3 id=&#34;incremental-ea-on-target-data&#34;&gt;Incremental EA on Target Data&lt;/h3&gt;
&lt;p&gt;对新数据增量式更新协方差矩阵，再用新的矩阵更新所有测试数据&lt;/p&gt;
&lt;h3 id=&#34;target-label-prediction&#34;&gt;Target Label Prediction&lt;/h3&gt;
&lt;p&gt;用训练好的 $M$ 模型初始化用于适应目标域的 $M$ 个 TTA 模型 $f\_{m}$&lt;/p&gt;
&lt;p&gt;新的 $X\&lt;em&gt;{a}$ 经过 IEA 被变换为 $X\&lt;/em&gt;{a}&amp;rsquo;$ 后被输入到每个模型 $f\&lt;em&gt;{m}$ 中进行分类，输出概率向量 $f\&lt;/em&gt;{m}(X\_{a}&amp;rsquo;)$&lt;/p&gt;
&lt;p&gt;之后结合这 $M$ 个概率向量来获得最终的预测标签 $\hat{y}\_{a}$&lt;/p&gt;</description>
    </item>
    <item>
      <title>Tent</title>
      <link>https://diefish1024.github.io/posts/literature-notes/tent/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://diefish1024.github.io/posts/literature-notes/tent/</guid>
      <description>&lt;h1 id=&#34;setting&#34;&gt;Setting&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;Fully Test-Time Adaptation&lt;/strong&gt; 是一种独特的模型适应设定。在此设定下，模型 $f\_\theta(x)$ 在训练阶段已通过源数据 $x^s$ 和标签 $y^s$ 完成训练，获得参数 $\theta$。但在测试阶段，模型将遇到与源数据分布不同的无标签目标数据 $x^t$。&lt;/p&gt;
&lt;p&gt;FTT-Adaptation 与以下方法不同：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Fine-tuning&lt;/strong&gt;：需要目标标签进行重新训练。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Domain Adaptation&lt;/strong&gt;：需要源数据和目标数据进行联合训练。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Test-Time Training (TTT)&lt;/strong&gt;：需要修改训练过程并共同优化有监督及自监督损失。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;相比之下，FTT-Adaptation 仅能利用预训练模型 $f\_\theta$ 和无标签目标数据 $x^t$ 进行适应，不依赖源数据或额外的监督信息。&lt;/p&gt;
&lt;h2 id=&#34;method&#34;&gt;Method&lt;/h2&gt;
&lt;p&gt;论文的核心贡献是提出了 &lt;strong&gt;Tent&lt;/strong&gt; 方法，其核心思想是通过&lt;strong&gt;最小化测试熵&lt;/strong&gt;（&lt;strong&gt;Test Entropy Minimization&lt;/strong&gt;）来适应模型预测，旨在使模型对测试数据的预测结果更“有信心”。&lt;/p&gt;
&lt;h3 id=&#34;entropy-objective&#34;&gt;Entropy Objective&lt;/h3&gt;
&lt;p&gt;Tent 的测试时目标函数是最小化模型预测 $\hat{y} = f\_\theta(x^t)$ 的&lt;strong&gt;熵 $H(\hat{y})$&lt;/strong&gt;。论文中使用的&lt;strong&gt;香农熵&lt;/strong&gt;计算公式如下：&lt;/p&gt;
&lt;p&gt;$$
H(\hat{y}) = - \sum\_c p(\hat{y}\_c) \log p(\hat{y}\_c)
$$&lt;/p&gt;
&lt;p&gt;其中， $p(\hat{y}\_c)$ 表示模型预测目标数据 $x^t$ 属于类别 $c$ 的概率。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;最小化熵促使模型输出更“尖锐”或更“确定”的预测分布。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;优势&lt;/strong&gt;：熵是一种&lt;strong&gt;无监督目标&lt;/strong&gt;，仅依赖于模型预测，不需要真实标签。最小化熵与减少预测误差和数据漂移之间存在内在联系，因为更确定的预测通常意味着更正确的预测。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;modulation-parameters&#34;&gt;Modulation Parameters&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Tent&lt;/strong&gt; 不直接修改原始模型的全部参数 $\theta$。相反，它仅更新模型内部归一化层（如&lt;strong&gt;Batch Normalization layers&lt;/strong&gt;）中的线性且低维度的&lt;strong&gt;仿射变换&lt;/strong&gt;参数：尺度参数 $\gamma$ 和偏移参数 $\beta$。&lt;/p&gt;</description>
    </item>
    <item>
      <title>并发控制：同步 (1)</title>
      <link>https://diefish1024.github.io/posts/nju-os-2025/15.-%E5%B9%B6%E5%8F%91%E6%8E%A7%E5%88%B6%E5%90%8C%E6%AD%A5-1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://diefish1024.github.io/posts/nju-os-2025/15.-%E5%B9%B6%E5%8F%91%E6%8E%A7%E5%88%B6%E5%90%8C%E6%AD%A5-1/</guid>
      <description>&lt;h2 id=&#34;同步和条件变量&#34;&gt;同步和条件变量&lt;/h2&gt;
&lt;p&gt;互斥实现了&lt;strong&gt;原子性&lt;/strong&gt;，但是无法实现&lt;strong&gt;确定性&lt;/strong&gt;，也就是无法正确实现 &amp;ldquo;happens-before&amp;rdquo; 的关系&lt;/p&gt;
&lt;p&gt;因此需要引入条件变量来实现线程的同步，形成受控制的并发事件的&lt;strong&gt;发生顺序&lt;/strong&gt;（可以用乐团指挥来类比），把一系列不确定的状态在某一个时间点同步到了一个确定的状态，将发散的并发程序状态 “收束”&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;实现同步&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;实现 $A\to B$:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;7
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-gdscript3&#34; data-lang=&#34;gdscript3&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;A&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;can_proceed&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;bp&#34;&gt;true&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;signal&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;while&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;!&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;can_proceed&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;B&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;//&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;B&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;wait&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;until&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;the&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;condition&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;is&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;satisfied&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;这样的思路大致正确，但是自选的循环有很大的性能问题，因此需要一个更加底层的机制来帮助实现这一点&lt;/p&gt;
&lt;p&gt;最理想的 API 是 &lt;code&gt;wait_until(cond)&lt;/code&gt; ，但是过去为了简化设计，变成了&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;条件不满足时等待：&lt;code&gt;wait&lt;/code&gt; - 直接睡眠等待&lt;/li&gt;
&lt;li&gt;条件满足时继续：&lt;code&gt;signal/broadcast&lt;/code&gt; - 唤醒所有线程&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;（小时候的 scratch 编程其实已经有了这样的思想😂）&lt;/p&gt;
&lt;p&gt;在 c++ 代码中我们可以把条件放到 $\lambda$ 表达式中：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-c++&#34; data-lang=&#34;c++&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;std&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;mutex&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;mtx&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;std&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;condition_variable&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;cv&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kt&#34;&gt;void&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;T_player&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	&lt;span class=&#34;n&#34;&gt;std&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;unique_lock&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;lk&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;mtx&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	&lt;span class=&#34;n&#34;&gt;cv&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;wait&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;lk&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;		&lt;span class=&#34;p&#34;&gt;[]{&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;can_proceed&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	&lt;span class=&#34;n&#34;&gt;cv&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;notify_all&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;();&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	&lt;span class=&#34;n&#34;&gt;lk&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;unlock&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;();&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;注意条件变量在等待时需要带着一把锁（需要确保检查和等待是原子操作）&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
