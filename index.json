[{"content":"Exercise 1 注意到 $$ \\begin{aligned} \\left\\| \\sum_{i=1}^k c_i w_i \\right\\|^2 \u0026= \\left\\langle \\sum_{i=1}^k c_i w_i, \\sum_{j=1}^k c_j w_j \\right\\rangle \\\\ \u0026= \\sum_{i=1}^k \\sum_{j=1}^k c_i c_j \\langle w_i, w_j \\rangle \\end{aligned} $$ 根据题设，我们知道当 $ i \\neq j $ 时 $ \\langle w_i, w_j \\rangle = 0 $，当 $ i = j $ 时 $ \\langle w_i, w_j \\rangle = 1 $。因此，上述双重求和中仅保留 $ i=j $ 的项 $$ \\sum_{i=1}^k c_i^2 \\cdot 1 = \\sum_{i=1}^k c_i^2 $$ 得证。\nExercise 2 根据定义，我们有 $$ \\sum_{i=1}^{m} \\| a_{i} \\| ^{2} = \\mathrm{tr}(AA^{T}) = \\mathrm{tr}(A^{T}A) $$ 由于 $ A^T A $ 是对称半正定矩阵，其非零特征值恰好是 $ A $ 的奇异值的平方，即 $ \\lambda_j(A^T A) = \\sigma_j^2 $，那么 $$ \\text{tr}(A^T A) = \\sum_{j=1}^r \\lambda_j(A^T A) = \\sum_{j=1}^r \\sigma_j^2 $$ 证毕。\nExercise 3 设 $ A $ 的 SVD 分解为 $ A=U\\Sigma V^{T} $，其中 $ \\Sigma=\\text{diag}(\\sigma_{1},\\dots,\\sigma_{n}) $ 且 $ \\sigma_{i}\u003e0 $。那么 $ A $ 的逆矩阵为 $$ A^{-1} = (U\\Sigma V^{T})^{-1} = (V^{T})^{-1}\\Sigma ^{-1}U^{-1} = V\\Sigma ^{-1}U^{T} $$ 其中根据对角矩阵的性质 $ A^{-1}=\\text{diag}(1 / \\sigma_{1},\\dots,1 / \\sigma_{n}) $。从而 $ A^{-1} $ 的奇异值是 $ A $ 的奇异值的倒数。\nExercise 4 由于 $ R $ 是 $ \\mathbb{R}^m $ 的基矩阵，它是可逆的。我们有 $$ A = R (R^{-1} A) $$ 由于 $ A $ 的每个列向量都属于 $ \\text{Col}(A)=\\text{span}\\{ r_{1},\\dots,r_{r} \\} $，在基地 $ R $ 的坐标中只有前 $ r $ 个分量非零，因此 $ R^{-1}A $ 必然是 $ \\left[ B\\atop 0 \\right] $ 的形式，其中 $ B $ 为 $ r \\times n $ 的矩阵。\n因为 $ \\text{rank}(A)=r $ 且 $ R $ 可逆，所以 $ \\text{rank}(B)=r $。我们可以将 $ B $ 的 $ r $ 个行向量扩充为 $ \\mathbb{R}^n $ 的一组基，从而构造一个 $ n \\times n $ 的可逆矩阵 $$ C = \\begin{bmatrix} B \\\\ Y \\end{bmatrix} $$ 我们计算 $ R\\Sigma C $ 为 $$ R \\Sigma C = R \\begin{bmatrix} I_r \u0026 0 \\\\ 0 \u0026 0 \\end{bmatrix} \\begin{bmatrix} B \\\\ Y \\end{bmatrix} = R \\begin{bmatrix} B \\\\ 0 \\end{bmatrix} = R (R^{-1} A) = A $$ 设 $ c_k^T $ 为矩阵 $ C $ 的第 $ k $ 行。利用矩阵乘法的行列展开 $$ A = R \\begin{bmatrix} c_1^T \\\\ \\vdots \\\\ c_r^T \\\\ 0 \\end{bmatrix} = \\sum_{k=1}^r r_k c_k^T $$ 由于 $ C $ 是满秩矩阵，其行向量 $ c_1, \\dots, c_r $ 必然线性无关。证毕。\n","permalink":"https://diefish1024.github.io/posts/class-notes/math1205h-linear-algebra/math1205h-hw24/","summary":"\u003ch2 id=\"exercise-1\"\u003eExercise 1\u003c/h2\u003e\n\u003cp\u003e注意到\n$$ \n\\begin{aligned} \\left\\| \\sum_{i=1}^k c_i w_i \\right\\|^2 \u0026= \\left\\langle \\sum_{i=1}^k c_i w_i, \\sum_{j=1}^k c_j w_j \\right\\rangle \\\\ \u0026= \\sum_{i=1}^k \\sum_{j=1}^k c_i c_j \\langle w_i, w_j \\rangle \\end{aligned}\n $$\n根据题设，我们知道当 $ i \\neq j $ 时 $ \\langle w_i, w_j \\rangle = 0 $，当 $ i = j $ 时 $ \\langle w_i, w_j \\rangle = 1 $。因此，上述双重求和中仅保留 $ i=j $ 的项\n$$ \n\\sum_{i=1}^k c_i^2 \\cdot 1 = \\sum_{i=1}^k c_i^2\n $$\n得证。\u003c/p\u003e","title":"MATH1205H HW24"},{"content":"Exercise 1 不唯一。只有奇异值 $ \\Sigma $ 是唯一的，而 $ U,V $ 通常不唯一。首先我们改变 $ U,V $ 中对应列的符号不会产生影响；其次相同的奇异值对应的奇异向量可以在保持正交的情况下任意变换，也不会对 SVD 分解产生影响；并且如果存在零奇异值，也可以任意选择。\nExercise 2 我们需要证明对于所有 $ k\\in \\{ r+1,\\dots, m\\} $ 满足 $ AA^{T}u_{k}=\\mathbf{0} $。\n首先根据正交矩阵，因此对于任意 $ j\\in [r] $ 和 $ k\\in \\{ r+1,\\dots,m \\} $，有 $ u_{j}^{T}u_{k}=0 $。我们考虑 $ A $ 的列空间，显然 $ \\{ u_{j} \\}_{j=1}^{r} $ 是 $ AA^{T} $ 的非零特征值对应的特征向量，构成了 $ \\text{Col}(A) $ 的一组正交基，从而 $ \\{ u_{k} \\}_{k=r+1}^{m} $ 属于 $ \\text{Col}(A) $ 的正交补空间，也就属于 $ A^{T} $ 的零空间，因此 $$ A^{T}u_{k} = \\mathbf{0},\\quad k=r+1,\\dots,m $$ 带入就有 $ AA^{T}u_{k}=\\mathbf{0} $，证毕。\nExercise 3 由于一般情况下的 SVD 分解满足 $ Av_{j}=\\sigma_{j}u_{j} $，因此和题设对比，得到 $ \\sigma_{j}=1 $。从而 $ \\Sigma=I $。带入就得到了 $$ A = UV^{T} $$ 验证有 $$ Av_{j}=(UV^{T})v_{j}=U(V^{T}v_{j})=Ue_{j} = u_{j} $$\nExercise 4 设 $ v_1, \\dots, v_n $ 是 $ A^TA $ 的特征向量，它们构成 $ \\mathbb{R}^n $ 的一组标准正交基。 任意向量 $ x $ 可以表示为 $ x = c_1 v_1 + \\dots + c_n v_n $。 那么 $ ||x||^2 = \\sum_{i=1}^n c_i^2 $。\n那么根据 SVD 的性质，有 $$ \\begin{align*} Ax \u0026 =\\sum_{i=1}^{n} c_i A v_i \\\\ \u0026 = \\sum_{i=1}^{n} c_{i}\\sigma_{i}u_{i} \\\\ \\implies \\| Ax \\| ^{2} \u0026 = \\sum_{i=1}^{n} c_{i}^{2}\\sigma_{i}^{2} \\end{align*} $$ 带入就有 $$ \\dfrac{\\| Ax \\| ^{2}}{\\| x \\| ^{2}} = \\dfrac{\\sum_{i=1}^{n} c_{i}^{2}\\sigma_{i}^{2}}{\\sum_{i=1}^{n} c_{i}^{2}} \\leq \\sigma_{1}^{2}\\cdot \\dfrac{\\sum_{i=1}^{n} c_{i}^{2}}{\\sum_{i=1}^{n} c_{i}^{2}} = \\sigma_{1}^{2} $$ 并且当 $ x=v_{1} $ 时就有 $$ \\dfrac{\\| Av_{1} \\| }{\\| v_{1} \\| } = \\dfrac{\\| \\sigma_{1} v_{1} \\| }{1} = \\sigma_{1} $$ 所以最大值可以取到 $ \\sigma_{1} $，从而 $ \\| A \\|=\\sigma_{1} $，得证。\nExercise 5 (1)\n根据定义，对于任意 $ x $，有 $$ \\| Mx \\| \\leq \\| M \\| \\cdot \\| x \\| $$ 因此对于任意 $ x \\in \\mathbb{R}^{n} $，有 $$ \\begin{align*} \\| (A+B)x \\| \u0026 = \\| Ax+Bx \\| \\\\ \u0026 \\leq \\| Ax \\| + \\| Bx \\| \\\\ \u0026 \\leq (\\| A \\| +\\| B \\| )\\cdot \\| x \\| \\end{align*} $$ 这等价于 $$ \\dfrac{\\| (A+B)x \\| }{\\| x \\| } \\leq \\| A \\| + \\| B \\| $$ 从而 $$ \\| A+B \\| = \\max_{x \\in \\mathbb{R}^{n}} \\dfrac{\\| (A+B)x \\| }{\\| x \\| } \\leq \\| A \\| + \\| B \\| $$ (2)\n因此对于任意 $ x \\in \\mathbb{R}^{n} $，有 $$ \\begin{align*} \\| ABx \\| \u0026 = \\| A(Bx) \\| \\\\ \u0026 \\leq \\| A \\| \\cdot \\| Bx \\| \\quad (y=Bx \\in \\mathbb{R}^{n}) \\\\ \u0026 \\leq \\| A \\| \\cdot \\| B \\| \\cdot \\| x \\| \\end{align*} $$ 这等价于 $$ \\dfrac{\\| ABx \\| }{\\| x \\| } \\leq \\| A \\| \\cdot \\| B \\| $$ 从而 $$ \\| AB \\| = \\max_{x \\in \\mathbb{R}^{n}} \\dfrac{\\| ABx \\| }{\\| x \\| } \\leq \\| A \\| \\cdot \\| B \\| $$\n","permalink":"https://diefish1024.github.io/posts/class-notes/math1205h-linear-algebra/math1205h-hw23/","summary":"\u003ch2 id=\"exercise-1\"\u003eExercise 1\u003c/h2\u003e\n\u003cp\u003e不唯一。只有奇异值 $ \\Sigma $ 是唯一的，而 $ U,V $ 通常不唯一。首先我们改变 $ U,V $ 中对应列的符号不会产生影响；其次相同的奇异值对应的奇异向量可以在保持正交的情况下任意变换，也不会对 SVD 分解产生影响；并且如果存在零奇异值，也可以任意选择。\u003c/p\u003e\n\u003ch2 id=\"exercise-2\"\u003eExercise 2\u003c/h2\u003e\n\u003cp\u003e我们需要证明对于所有 $ k\\in \\{ r+1,\\dots, m\\} $ 满足 $ AA^{T}u_{k}=\\mathbf{0} $。\u003c/p\u003e\n\u003cp\u003e首先根据正交矩阵，因此对于任意 $ j\\in [r] $ 和 $ k\\in \\{ r+1,\\dots,m \\} $，有 $ u_{j}^{T}u_{k}=0 $。我们考虑 $ A $ 的列空间，显然 $ \\{ u_{j} \\}_{j=1}^{r} $ 是 $ AA^{T} $ 的非零特征值对应的特征向量，构成了 $ \\text{Col}(A) $ 的一组正交基，从而 $ \\{ u_{k} \\}_{k=r+1}^{m} $ 属于 $ \\text{Col}(A) $ 的正交补空间，也就属于 $ A^{T} $ 的零空间，因此\n$$ \n\nA^{T}u_{k} = \\mathbf{0},\\quad k=r+1,\\dots,m\n\n $$\n带入就有 $ AA^{T}u_{k}=\\mathbf{0} $，证毕。\u003c/p\u003e","title":"MATH1205H HW23"},{"content":"Problem 1 图 $ G=(V,E) $ 有 $ n $ 个顶点和 $ m $ 条边，图 $ H $ 是较小的图，且 $ G $ 不包含 $ H $ 作为子图。证明当 $ k \u003e n^2 \\ln n / m $ 时，完全图 $ K_n $ 存在一种边 $ k $-染色方案，使得 $ K_n $ 中不存在单色的 $ H $。\n证\n令 $ V $ 为 $ K_{n} $ 的顶点集。随机选取 $ k $ 个 $ V $ 上的随机排列，将 $ G $ 映射到 $ V $，得到与 $ G $ 同构的 $ k $ 个图 $ G_{1},\\dots,G_{k} $。\n考虑 $ K_{n} $ 中的任意一条边 $ e $ 未被覆盖的概率。对于任意一个图，$ e $ 在这个图中的概率为 $$ p = \\mathbb{P}[e\\in E(G_{i})] = \\frac{m}{\\binom{ n }{ 2 } } $$ 从而 $$ \\mathbb{P}\\left[ e\\not\\in \\bigcup_{i=1}^{k}E(G_{i}) \\right] = (1-p)^{k} = \\left( 1-\\frac{m}{\\binom{ n }{ 2 } } \\right)^{k} $$ 我们证明存在一种方案使得 $ K_{n} $ 的所有边都被覆盖，等价于证明至少有一条边未被覆盖的概率小于 $ 1 $。设事件 $ A $ 表示至少有一条边未被覆盖，那么根据 Union Bound，有 $$ \\mathbb{P}[A] \\leq \\sum_{e\\in E(K_{n})}\\mathbb{P}\\left[ e\\not\\in \\bigcup_{i=1}^{k}E(G_{i}) \\right] = \\binom{ n }{ 2 } \\left( 1-\\frac{m}{\\binom{ n }{ 2 } } \\right)^{k} $$ 带入不等式 $ 1-x\u003c e^{ -x } $，我们尝试证明 $$ \\binom{ n }{ 2 } \\exp\\left( -\\frac{mk}{\\binom{ n }{ 2 } } \\right) \u003c 1 $$ 化简就得到了在 $$ k \u003e \\frac{\\binom{ n }{ 2 }}{m}\\ln \\binom{ n }{ 2 } $$ 时不等式成立。\n由于 $$ k \u003e \\frac{n^{2}}{m}\\ln n = \\frac{n^{2} / 2}{m}\\ln n^{2} \u003e \\frac{\\binom{ n }{ 2 } }{m}\\ln \\binom{ n }{ 2 } $$ 因此必有 $ \\mathbb{P}[A] \u003c 1 $，从而一定存在一组副本 $ G_1, \\dots, G_k $，它们的并集覆盖了 $ K_n $ 的所有边。于是我们定义我们定义边染色如下：对于 $ K_n $ 中的每条边 $ e $，定义其颜色 $ c(e) $ 为覆盖它的最小的副本索引 $$ c(e) = \\min \\{i \\mid e \\in E(G_i)\\} $$ 在这种染色方案下，对于任意颜色 $ i $，所有颜色为 $ i $ 的边组成的集合 $ E_i $ 都是 $ E(G_i) $ 的子集，即 $ E_i \\subseteq E(G_i) $。因为 $ G_i \\cong G $，而已知 $ G $ 不包含 $ H $ 作为子图，所以 $ G_i $ 也不包含 $ H $，因此，它的子集 $ E_i $ 也不可能包含 $ H $。\n综上所述，$ K_n $ 的这种 $ k $-边染色中不包含单色的 $ H $。得证。\nProblem 2 证明对于任意 $ r $ 和 $ n $（为简化假设 $ n $ 能被 $ r $ 整除），存在一个定义在 $ [n] $ 上的 $ r $-一致超图 $ \\mathcal{H} $，至少有 $ \\binom{n}{r}/e^r $ 条超边，其独立数满足 $$ \\alpha(\\mathcal{H}) \\geq n(1 - \\frac{1}{r}) $$ 超图的独立集是指不包含任何完整超边的顶点子集。\n证\n我们将 $ n $ 个顶点均分成 $ r $ 个组，每组大小均为 $ \\frac{n}{r} $。定义 $ \\mathcal{H} $ 的边集 $ E $ 满足一个 $ r $ 元组 $ \\{ v_{1},v_{2},\\dots,v_{n} \\} $ 为一条边当且仅当每个 $ v_{i} $ 来自不同的组。这样我们任意删掉一组边，剩下的顶点数为 $$ n - \\left| V_{1} \\right| = n\\left( 1-\\frac{1}{r} \\right) $$ 构成了一个独立集。从而这个构造的独立数满足要求。\n下面我们验证这个构造的边数符合要求。由于每组可以任取一个点形成边，因此 $$ \\left| E \\right| = \\left| V_{1} \\right| ^{r} = \\left( \\frac{n}{r} \\right)^{r} $$ 因此我们只需要证明 $$ \\left( \\frac{n}{r} \\right)^{r} \u003e \\dfrac{\\binom{ n }{ r } }{e^{ r }} $$ 变形后等价于证明 $$ \\binom{ n }{ r } \u003c \\left( \\frac{ne}{r} \\right)^{r} $$ 由于 $$ e^{ r } = 1 + r + \\dots + \\frac{r^{r}}{r!} + \\dots \u003e \\frac{r^{r}}{r!} \\implies \\frac{1}{r!} \u003c \\frac{e^{r}}{r^{r}} $$ 那么 $$ \\binom{ n }{ r } = \\frac{n^{\\underline{r}}}{r!} \u003c \\frac{n^{r}}{r!} \u003c \\frac{e^{r}}{r^{r}}\\cdot n^{r} = \\left( \\frac{ne}{r} \\right)^{r} $$ 证毕。\nProblem 3 证明对于任意常数 $ c_1 \u003e 0 $，都存在另一个常数 $ c_2 \u003e 0 $，使得对于任意包含 $ n $ 个顶点、$ m $ 条超边的 $ 3 $-一致超图 $ \\mathcal{H} $，只要满足 $ m \\geq c_1 n $，就有 $$ \\alpha(\\mathcal{H}) \\geq \\frac{c_2 n \\sqrt{n}}{\\sqrt{m}} $$ 证\n设 $ \\mathcal{H} = (V, E) $ 是一个 $ 3 $-一致超图，顶点数 $ |V|=n $，边数 $ |E|=m $。 构造一个随机顶点子集 $ S \\subseteq V $，其中每一个顶点 $ v \\in V $ 被选入 $ S $ 的概率都是 $ p $，且各顶点是否被选是相互独立的。\n令随机变量 $ X = |S| $ 表示 $ S $ 中的顶点数量，随机变量 $ Y $ 表示 $ S $ 中包含的完整超边的数量。计算它们的期望 $$ \\mathbf{E}[X] = \\sum_{v\\in V}\\mathbb{P}[v\\in S] = n\\cdot p $$ 由于一条超边包含三个独立选择的顶点，因此 $ \\mathbb{P}[e\\subseteq S]=p^{3} $，从而 $$ \\mathbf{E}[Y] = \\sum_{e\\in E}\\mathbb{P}[e\\subseteq S] =m\\cdot p^{3} $$ 我们现在考虑将随机选择的 $ S $ “修剪”成一个独立集。对于 $ S $ 中的每一条边，从 $ S $ 中移除这条边中的任意一个顶点，剩下的集合记为 $ S' $。最坏情况每条边都要删掉一个不同的点，所以 $$ \\left| S' \\right| \\geq X-Y $$ 从而 $$ \\mathbf{E}[\\left| S' \\right| ]\\geq \\mathbf{E}[X]-\\mathbf{E}[Y] = np-mp^{3} = f(p) $$ 我们需要选出一个合适的 $ p $ 来最大化下界 $ f(p) $，经过简单的求导计算可知在 $$ p^{*}=\\sqrt{ \\frac{n}{3m} } $$ 时 $ \\dfrac{\\mathrm{d} f}{\\mathrm{d}p}=0 $，带入题设条件 $ m\\geq c_{1}n $，有 $$ p^{*} \\leq \\sqrt{ \\frac{1}{3c_{1}} } $$ 如果 $ c_{1}\\geq \\frac{1}{3} $，那么 $ p^{*}\\leq 1 $。从而直接取 $ p=p^{*} $，带入得到了 $$ \\alpha(\\mathcal{H}) \\geq f(p^{*}) = \\frac{2}{3\\sqrt{ 3 }} \\frac{n\\sqrt{ n }}{\\sqrt{ m }} $$ 这是取常数 $ c_{2}= \\frac{2}{3\\sqrt{ 3 }} $ 即可。\n如果 $ c_{1}\u003c \\frac{1}{3} $，那么利用 $$ m\\geq c_{1}n \\implies \\sqrt{ \\frac{c_{1}n}{m} } \\leq 1 $$ 带入 $ p=\\sqrt{ \\frac{c_{1}n}{m} } $，得到 $$ \\begin{align*} \\alpha(\\mathcal{H}) \u0026 \\geq f(p) \\\\ \u0026 = n\\left( \\sqrt{ c_{1} }\\sqrt{ \\frac{n}{m} } \\right) - m\\left( \\sqrt{ c_{1} }\\sqrt{ \\frac{n}{m} } \\right)^{3} \\\\ \u0026 = (\\sqrt{ c_{1} }-c_{1}\\sqrt{ c_{1} }) \\frac{n\\sqrt{ n }}{\\sqrt{ m }} \\end{align*} $$ 由于 $ c_{1}\u003c \\frac{1}{3}\u003c 1 $，因此 $ \\sqrt{ c_{1} }-c_{1}\\sqrt{ c_{1} }\u003e0 $，从而取 $ c_{2}=\\sqrt{ c_{1} }-c_{1}\\sqrt{ c_{1} } $ 即可。\n","permalink":"https://diefish1024.github.io/posts/class-notes/cs0901-combinatorics/cs0901-hw11/","summary":"\u003ch2 id=\"problem-1\"\u003eProblem 1\u003c/h2\u003e\n\u003cp\u003e图 $ G=(V,E) $ 有 $ n $ 个顶点和 $ m $ 条边，图 $ H $ 是较小的图，且 $ G $ 不包含 $ H $ 作为子图。证明当 $ k \u003e n^2 \\ln n / m $ 时，完全图 $ K_n $ 存在一种边 $ k $-染色方案，使得 $ K_n $ 中不存在单色的 $ H $。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e证\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e令 $ V $ 为 $ K_{n} $ 的顶点集。随机选取 $ k $ 个 $ V $ 上的随机排列，将 $ G $ 映射到 $ V $，得到与 $ G $ 同构的 $ k $ 个图 $ G_{1},\\dots,G_{k} $。\u003c/p\u003e","title":"CS0901 HW11"},{"content":"Exercise 2 根据定义，对于任意 $ \\phi \\in V' $，有 $$ T_{\\text{incl}}'(\\phi) = \\phi \\circ T_{\\text{incl}} $$ 由于 $ T_{\\text{incl}} $ 是包含映射，因此 $ T_{\\text{incl}}' $ 实际上将 $ \\phi $ 的定义域限制在了 $ U $ 上，也就是 $ T_{\\text{incl}}'(\\phi)=\\phi|_{U} $，因此 $ \\mathrm{Im}(T_{\\text{incl}}') $ 由所有形式为 $ \\phi|_{U} $ 的线性泛函组成，从而 $ \\mathrm{Im}(T_{\\text{incl}}')\\subseteq U' $。\n证明满射。即证对于任意 $ \\psi \\in U' $，都存在 $ \\phi \\in V' $ 使得 $ T_{\\text{incl}}'(\\phi)=\\psi $。设 $ \\{ u_{1},\\dots,u_{m} \\} $ 是 $ U $ 的一组基，将它扩充为 $ V $ 的一组基 $ \\{ u_{1},\\dots,u_{m},v_{m+1},\\dots,v_{n} \\} $。那么对于给定的 $ \\psi \\in U' $，在 $ V $ 的基上定义 $ \\phi \\in V' $ 满足 $$ \\begin{cases} \\phi(u_{i}) = \\psi(u_{i}), \\\\ \\phi(v_{j}) = 0 \\end{cases} $$ 根据线性扩展定理，$ \\phi $ 在 $ V $ 上唯一确定。从而对于任意 $ u \\in U $，$ \\phi(u) = \\psi(u) $，即 $ \\phi|_U = \\psi $。因此就有 $ U'\\subseteq \\mathrm{Im}(T_{\\text{incl}}') $。\n综上就证明了 $$ \\mathrm{Im}(T_{\\text{incl}}') = U' $$\nExercise 3 首先验证 $ \\{ L_{m+1},\\dots,L_{n} \\}\\subseteq U^{0} $。对偶基满足定义 $ L_{i}(v_{j})=\\delta_{ij} $，对于任意 $ k\\in \\{ m+1,\\dots,n \\} $ 和任意 $ u\\in U $，将 $ u $ 写成 $ u=\\sum_{j=1}^{m}c_{j}v_{j} $。那么 $$ L_{k}(u) = L_{k}\\left( \\sum_{j=1}^{m} c_{j}v_{j} \\right) = \\sum_{j=1}^{m} c_{j}L_{k}(v_{j}) $$ 由于 $ k\u003em $ 并且 $ j\u003c m $，因此 $ L_{k}(u)=0 $，从而 $ L_{k}\\in U^{0} $。\n由于 $ \\{ L_{m+1},\\dots,L_{n} \\} $ 是对偶基 $ \\{ L_{1},\\dots,L_{n} \\} $ 的子集，所以线性无关。\n同时任取 $ \\phi \\in U^{0} $，由于 $ \\{ L_{1},\\dots,L_{n} \\} $ 是 $ V' $ 的基，因此 $ \\phi $ 可以唯一地表示为 $ \\phi=\\sum_{i=1}^{n}a_{i}L_{i} $。利用对偶基的性质，$ a_{i}=\\phi(v_{i}) $。由于 $ \\phi \\in U^{0} $，所以对于 $ i\\in[m] $，都有 $ a_{i}=0 $。因此 $ \\phi=\\sum_{i=m+1}^{n}a_{i}L_{i} $，这说明 $ U^{0} $ 中任意元素都可以由 $ \\{ L_{m+1},\\dots,L_{n} \\} $ 线性表示。\n综上，$ \\{ L_{m+1},\\dots,L_{n} \\} $ 是 $ U^{0} $ 的一组基，这也给出了 Lemma 1 的证明。\nExercise 4 假设 $ A = uv^T $，其中 $ u \\neq 0, v \\neq 0 $。\n必要性：矩阵 $ A $ 的第 $ j $ 列可以表示为 $ A_j = u v_j $（其中 $ v_j $ 是 $ v $ 的第 $ j $ 个分量）。这意味着 $ A $ 的每一列都是向量 $ u $ 的标量倍数。因为 $ v \\neq 0 $，至少存在一个 $ j $ 使得 $ v_j \\neq 0 $，故 $ A $ 至少有一列非零，即 $ A \\neq 0 $。列空间 $ \\text{Col}(A) = \\text{span}(\\{v_1 u, \\dots, v_n u\\}) = \\text{span}(\\{u\\}) $。由于 $ u \\neq 0 $，故 $ \\text{dim}(\\text{Col}(A)) = 1 $。即 $ \\text{rank}(A) = 1 $。\n充分性：假设 $ \\text{rank}(A) = 1 $，这意味着列空间 $ \\text{Col}(A) $ 的维数为 $ 1 $。取 $ \\text{Col}(A) $ 的一组基，记为向量 $ u \\in \\mathbb{R}^m $，显然 $ u \\neq 0 $。$ A $ 的每一列 $ C_1, \\dots, C_n $ 都在 $ \\text{Col}(A) $ 中，因此每一列都是 $ u $ 的倍数。 即存在标量 $ k_1, \\dots, k_n $ 使得 $ C_j = k_j u $。定义向量 $ v = [k_1, k_2, \\dots, k_n]^T \\in \\mathbb{R}^n $，由于 $ \\text{rank}(A) \\neq 0 $，至少有一列不为零向量，因此至少有一个 $ k_j \\neq 0 $，即 $ v \\neq 0 $。由矩阵乘法定义，$ A $ 的第 $ j $ 列为 $ u v_j $，即 $ A = uv^T $。\n","permalink":"https://diefish1024.github.io/posts/class-notes/math1205h-linear-algebra/math1205h-hw21/","summary":"\u003ch2 id=\"exercise-2\"\u003eExercise 2\u003c/h2\u003e\n\u003cp\u003e根据定义，对于任意 $ \\phi \\in V' $，有\n$$ \nT_{\\text{incl}}'(\\phi) = \\phi \\circ T_{\\text{incl}}\n $$\n由于 $ T_{\\text{incl}} $ 是包含映射，因此 $ T_{\\text{incl}}' $ 实际上将 $ \\phi $ 的定义域限制在了 $ U $ 上，也就是 $ T_{\\text{incl}}'(\\phi)=\\phi|_{U} $，因此 $ \\mathrm{Im}(T_{\\text{incl}}') $ 由所有形式为 $ \\phi|_{U} $ 的线性泛函组成，从而 $ \\mathrm{Im}(T_{\\text{incl}}')\\subseteq U' $。\u003c/p\u003e\n\u003cp\u003e证明满射。即证对于任意 $ \\psi \\in U' $，都存在 $ \\phi \\in V' $ 使得 $ T_{\\text{incl}}'(\\phi)=\\psi $。设 $ \\{ u_{1},\\dots,u_{m} \\} $ 是 $ U $ 的一组基，将它扩充为 $ V $ 的一组基 $ \\{ u_{1},\\dots,u_{m},v_{m+1},\\dots,v_{n} \\} $。那么对于给定的 $ \\psi \\in U' $，在 $ V $ 的基上定义 $ \\phi \\in V' $ 满足\n$$ \n\n\\begin{cases}\n\\phi(u_{i}) = \\psi(u_{i}), \\\\\n\\phi(v_{j}) = 0\n\\end{cases}\n\n $$\n根据线性扩展定理，$ \\phi $ 在 $ V $ 上唯一确定。从而对于任意 $ u \\in U $，$ \\phi(u) = \\psi(u) $，即 $ \\phi|_U = \\psi $。因此就有 $ U'\\subseteq \\mathrm{Im}(T_{\\text{incl}}') $。\u003c/p\u003e","title":"MATH1205H HW21"},{"content":"Problem 1 设 $ H = (V, \\mathcal{F}) $ 是一个没有孤立点的超图，满足每条超边至少包含 3 个顶点，且任意两条超边恰好共享一个顶点。假设 $ H $ 不是 2-可着色的（即不能用两种颜色对顶点染色使得每条超边内都有不同颜色的点）。\n(1)\n证明每个顶点 $ v $ 至少属于 $ \\mathcal{F} $ 中的两条超边。\n证\n假设存在一个顶点 $ v $ 满足 $ d(v)\u003c 2 $。由于没有孤立顶点，因此 $ d(v)=1 $，恰好属于一条超边，记为 $ E $。\n我们将顶点 $ v $ 染成红色，将 $ E $ 中的其他点染成蓝色，再将图中除了 $ E $ 之外的所有点染成红色。由于任意两条超边恰好共享一个顶点，并且 $ v $ 只在 $ E $ 中，所以任意一条超边必然和 $ E $ 存在蓝色交点，存在颜色不同的点。因此我们就构造出了一个合法的 2-着色方案，与题设矛盾。\n因此每个顶点至少属于两条超边。证毕。\n(2)\n证明任意两个顶点 $ u, v $ 恰好共同属于 $ \\mathcal{F} $ 中的一条超边。\n证\n假设存在两个顶点 $ u,v $，它们不共同属于任何一条超边。定义 $ N_{u} $ 为与 $ u $ 在同一条超边上的邻居，那么 $ v\\not\\in N_{u} $。\n我们构造染色方案，首先将 $ u $ 染为红色，$ N_u $ 中的所有点染为蓝色，其余顶点（包括 $ v $）染为红色。\n首先检查是否存在全红边。经过 $ u $ 的边包含 $ u $（红）和 $ N_u $ 中的点（蓝），非单色和边。对于不经过 $ u $ 的任意边 $ E $，根据 $ (1) $ 有 $ d(u)\u003e1 $，$ u $ 至少被两条边经过，设为 $ L_1, L_2 $，则 $ E $ 必与 $ L_1, L_2 $ 分别交于 $ x, y $。由于 $ u \\notin E $，交点 $ x, y $ 必然都在 $ N_u $ 中且 $ x \\neq y $。因此，任何不经过 $ u $ 的边起初至少包含两个蓝色点，不可能为全红。\n其次检查是否存在全蓝边。若存在全蓝边 $ F \\subseteq N_u $，则 $ u $ 的度数 $ d(u)=|F| \\ge 3 $，这使得任意不经过 $ u $ 的边在 $ N_u $ 中初始至少拥有 3 个蓝色顶点（即 $ u $ 的每个分支各贡献一个）。由于全蓝边集两两相交，根据几何性质，至多只需将 2 个公共顶点改染红色即可破坏所有全蓝边。因为 $ 3 \u003e 2 $，任何不经过 $ u $ 的边在染色修正后仍保留至少一个蓝点；而经过 $ u $ 的边因包含 $ u $ 且未翻转其所有邻居，也绝非全红，故矛盾成立。\n同时检查这时是否新产生了全红边：任何包含 $ w $ 的新红边，若经过 $ u $，则除 $ u, w $ 外必有第三点属于 $ N_u $（仍为蓝）；若不经过 $ u $，该边原先至少有两个蓝点，翻转 $ w $ 后仍剩至少一个蓝点。\n综上，我们总能构造出合法的 2-染色，这与题目条件矛盾，故假设不成立，任意两点必须共边。\nProblem 2 证明每一个拥有 $ m $ 条边的图，都包含一个至少拥有 $ (1 - 1/k)m $ 条边的 $ k $-可着色子图。\n证\n我们对图中每个点独立均匀随机地染成 $ k $ 种颜色中的一种，记这 $ k $ 种颜色为 $ \\{ 1,2,\\dots,k \\} $，顶点 $ v $ 的颜色为 $ X_{v} $，那么 $$ \\mathbb{P}(X_{v}=u)=\\frac{1}{k} $$ 再对每条边 $ e=(u,v) $ 定义指示变量 $ Y_{e}=\\mathbb{I}[X_{u}\\neq X_{v}] $。从而 $$ \\mathbb{P}(Y_{e}=0)= \\sum_{i=1}^{k} \\frac{1}{k^{2}} = \\frac{1}{k} $$ 从而 $$ \\mathbf{E}[Y_{e}] = 1\\cdot \\mathbb{P}(Y_{e}=1) + 0 \\cdot \\mathbb{P}(Y_{e}=0) = 1- \\frac{1}{k} $$ 当 $ Y_{e}=1 $ 说明一条边两端点颜色不同，可以被保留进需要的 $ k $-可着色子图。我们计算最终保留的总边数 $ Y $，为所有指示变量之和 $$ Y=\\sum_{e\\in E}Y_{e} $$ 那么 $$ \\mathbf{E}[Y] = \\sum_{e\\in E}\\mathbf{E}[Y_{e}] = m\\left( 1-\\frac{1}{k} \\right) $$ 由于 $ Y $ 的取值不可能总是小于 $ \\mathbf{E}[Y] $，因此必然存在一种方案使得保留下的边数满足 $$ Y \\geq \\mathbf{E}[Y]=m\\left( 1-\\frac{1}{k} \\right) $$ 由于留下的每一条边端点颜色都不同，因此这是一个 $ k $-着色子图。\nProblem 3 设 $ n \\ge 4 $ 且 $ t \\ge 3\\sqrt{n} $。证明：对于任意元素互不相同的 $ n \\times n $ 实数矩阵 $ A $，我们可以通过重排其列得到一个新矩阵 $ B $，使得在 $ B $ 中没有任何一行包含长度为 $ t $ 的单调子序列。\n证\n设矩阵 $ A $ 的列下标集合为 $ \\{1, 2, \\dots, n\\} $。我们在所有可能的列排列（共 $ n! $ 种）中，均匀随机地选取一种排列 $ \\sigma $，按照该排列重排 $ A $ 的列得到新矩阵 $ B $。\n记事件 $ E $ 为“矩阵 $ B $ 中至少有一行包含长度为 $ t $ 的单调子序列”。如果能证明 $ \\mathbb{P}(E) \u003c 1 $，则根据概率法的原理，满足条件的排列必然存在。\n题目条件为 $ n \\ge 4 $ 且 $ t \\ge 3\\sqrt{n} $。我们首先考察 $ n $ 较小的情况。当 $ 4 \\le n \u003c 9 $ 时 $$ \\sqrt{n} \u003c 3 \\implies 3\\sqrt{n} \u003e n $$ 由于 $ t \\ge 3\\sqrt{n} $，此时有 $ t \u003e n $。 在一个仅有 $ n $ 个元素的行中，显然不可能存在长度为 $ t $（且 $ t \u003e n $）的子序列。 因此，当 $ n \u003c 9 $ 时，事件 $ E $ 发生的概率为 $ \\mathbf{0} $。结论显然成立。\n当 $ n\\geq 9 $ 时，考虑利用 Union Bound 估计上界。设 $ E_{i} $ 为第 $ i $ 行包含长度为 $ t $ 的单调子序列的事件。那么 $$ \\mathbb{P}(E) = \\mathbb{P}\\left( \\bigcup_{i=1}^{n}E_{i} \\right) \\leq \\sum_{i=1}^{n} \\mathbb{P}(E_{i}) = n\\cdot \\mathbb{P}(E_{1}) $$ 对于 $ E_{1} $，我们考虑从 $ n $ 个元素选择 $ t $ 个位置，共 $ \\binom{ n }{ t } $ 中选法。对于选定 $ t $ 个元素，在 $ t! $ 种可能的排列中，只有 $ 2 $ 种是单调的，从而有上界 $$ \\mathbb{P}(E_{1}) \\leq \\binom{ n }{ t } \\frac{2}{t!} $$ 带入就有 $$ \\mathbb{P}(E) \\leq n\\cdot \\binom{ n }{ t } \\frac{2}{t!} $$ 利用不等式 $ \\binom{n}{t} \\le \\frac{n^t}{t!} $ 对上界进行放缩，可得 $$ \\mathbb{P}(E) \\leq n \\cdot \\frac{n^t}{t!} \\cdot \\frac{2}{t!} = \\frac{2n^{t+1}}{(t!)^2} $$ 由条件 $ t \\ge 3\\sqrt{n} $ 可知 $ n \\le \\frac{t^2}{9} $。将此不等式代入上式，我们将变量统一为 $ t $。记该上界函数为 $ f(t) $，则 $$ \\mathbb{P}(E) \\leq \\frac{2(t^2/9)^{t+1}}{(t!)^2} = f(t) $$\n由于 $ n \\ge 9 $，故 $ t \\ge 3\\sqrt{9} = 9 $。我们首先验证 $ t $ 取最小值 $ 9 $ 时的情况： $$ f(9) = \\frac{2 \\cdot (9^2/9)^{10}}{(9!)^2} = \\frac{2 \\cdot 9^{10}}{(362880)^2} \\approx \\frac{6.97 \\times 10^9}{1.31 \\times 10^{11}} \\approx 0.053 \u003c 1 $$\n接下来考察 $ f(t) $ 随 $ t $ 增大的变化趋势。利用 Stirling 公式 $ t! \\approx \\sqrt{2\\pi t}(t/e)^t $ 估算其量级，分母 $ (t!)^2 $ 的增长主要由 $ t^{2t} $ 主导，而分子的增长主要由 $ (t^2)^t = t^{2t} $ 以及常数底数因子主导。具体观察其底数比率 $$ \\frac{n^{t+1}}{(t!)^2} \\approx \\frac{(t^2/9)^t}{(t/e)^{2t}} = \\left( \\frac{t^2}{9} \\cdot \\frac{e^2}{t^2} \\right)^t = \\left( \\frac{e^2}{9} \\right)^t $$ 由于 $ e^2 \\approx 7.39 \u003c 9 $，该底数小于 $ 1 $，因此 $ f(t) $ 以指数级速度趋于 $ 0 $。\n综上所述，对于所有 $ n \\ge 9 $ 且 $ t \\ge 3\\sqrt{n} $，都有 $ \\mathbb{P}(E) \\le f(t) \\le f(9) \u003c 1 $。这表明在所有 $ n! $ 种排列中，必然存在一种排列，使得生成的矩阵 $ B $ 中没有任何一行包含长度为 $ t $ 的单调子序列。\n证毕。\nProblem 4 设 $ v_1, \\dots, v_n $ 是 $ \\mathbb{R}^n $ 中的 $ n $ 个单位向量。证明存在一组符号 $ \\epsilon_i = \\pm 1 $，使得 $ \\|\\epsilon_1 v_1 + \\dots + \\epsilon_n v_n\\| \\le \\sqrt{n} $，并且证明 $ \\sqrt{n} $ 这个界限是不可改进的。\n证\n首先证明存在性。明存在一组符号 $ \\epsilon_i \\in \\{+1, -1\\} $，使得 $ \\|\\sum \\epsilon_i v_i\\| \\le \\sqrt{n} $。假设 $ \\epsilon_1, \\epsilon_2, \\dots, \\epsilon_n $ 是独立同分布的随机变量，且取值概率满足 $$ \\mathbb{P}(\\epsilon_i = 1) = \\frac{1}{2}, \\quad \\mathbb{P}(\\epsilon_i = -1) = \\frac{1}{2} $$ 这意味每个 $ \\epsilon_i $ 的期望值为 $ E[\\epsilon_i] = 0 $，方差为 $ E[\\epsilon_i^2] = 1 $。\n考察向量和模长的平方。设随机变量 $ X $ 为 $$ X = \\left\\| \\sum_{i=1}^n \\epsilon_i v_i \\right\\|^2 $$ 展开得到 $$ \\begin{aligned} X \u0026= \\left\\langle \\sum_{i=1}^n \\epsilon_i v_i, \\sum_{j=1}^n \\epsilon_j v_j \\right\\rangle \\\\ \u0026= \\sum_{i=1}^n \\sum_{j=1}^n \\epsilon_i \\epsilon_j \\langle v_i, v_j \\rangle \\end{aligned} $$ 根据期望的线性性，有 $$ \\mathbf{E}[X] = \\sum_{i=1}^n \\sum_{j=1}^n \\mathbf{E}[\\epsilon_i \\epsilon_j] \\langle v_i, v_j \\rangle $$ 我们需要计算 $ E[\\epsilon_i \\epsilon_j] $。分别考虑 $ i=j $ 和 $ i\\neq j $，有 $$ \\mathbf{E}[\\epsilon_{i}^{2}]=1,\\quad \\mathbf{E}[\\epsilon_i \\epsilon_j] = \\mathbf{E}[\\epsilon_i] \\cdot \\mathbf{E}[\\epsilon_j] = 0 \\cdot 0 = 0 $$ 从而 $$ \\mathbf{E}[X] = \\sum_{i=1}^n 1 \\cdot \\langle v_i, v_i \\rangle = \\sum_{i=1}^n \\|v_i\\|^2=n $$ 由于一个随机变量的取值不可能严格大于它的期望，因此执照存在一组特定的符号使得 $$ \\left\\| \\sum_{i=1}^n \\epsilon_i v_i \\right\\|^2 \\le n $$ 从而就证明了 $$ \\left\\| \\sum_{i=1}^n \\epsilon_i v_i \\right\\| \\le \\sqrt{n} $$ 接着我们证明 $ \\sqrt{ n } $ 是紧的。取 $ \\mathbb{R}^{n} $ 中的一组标准正交基，那么这时无论如何选择符号，模长都恒等于 $ \\sqrt{ n } $，从而不可能存在比 $ \\sqrt{ n } $ 更小的上界。\n","permalink":"https://diefish1024.github.io/posts/class-notes/cs0901-combinatorics/cs0901-hw10/","summary":"\u003ch2 id=\"problem-1\"\u003eProblem 1\u003c/h2\u003e\n\u003cp\u003e设 $ H = (V, \\mathcal{F}) $ 是一个没有孤立点的超图，满足每条超边至少包含 3 个顶点，且任意两条超边恰好共享一个顶点。假设 $ H $ 不是 2-可着色的（即不能用两种颜色对顶点染色使得每条超边内都有不同颜色的点）。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e(1)\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e证明每个顶点 $ v $ 至少属于 $ \\mathcal{F} $ 中的两条超边。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e证\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e假设存在一个顶点 $ v $ 满足 $ d(v)\u003c 2 $。由于没有孤立顶点，因此 $ d(v)=1 $，恰好属于一条超边，记为 $ E $。\u003c/p\u003e\n\u003cp\u003e我们将顶点 $ v $ 染成红色，将 $ E $ 中的其他点染成蓝色，再将图中除了 $ E $ 之外的所有点染成红色。由于任意两条超边恰好共享一个顶点，并且 $ v $ 只在 $ E $ 中，所以任意一条超边必然和 $ E $ 存在蓝色交点，存在颜色不同的点。因此我们就构造出了一个合法的 2-着色方案，与题设矛盾。\u003c/p\u003e\n\u003cp\u003e因此每个顶点至少属于两条超边。证毕。\u003c/p\u003e","title":"CS0901 HW10"},{"content":"Exercise 1 根据对偶变换的定义 $$ (T'(L))(v) = L(T(v)) $$ 带入 $ T(v)=v $，就有 $$ (T'(L))(v) = L(v) $$ 由于这对所有 $ v \\in V $ 均成立，从而 $ T'(L) $ 和 $ L $ 是一个函数，因为输入输出完全相同，因此 $ T'(L)=L $，是恒等变换。\nExercise 2 先证充分性，如果 $ T=\\mathbf{0} $，那么对于任意 $ v \\in V $，都有 $ T(v)=\\vec{0} $。根据定义 $$ (T'(L))(v) = L(T(v)) = 0 $$ 说明 $ T'(L) $ 是零泛函，从而 $ T'=\\mathbf{0} $。\n如果 $ T'=\\mathbf{0} $，那么对于任意 $ L\\in W' $，$ T'(L) $ 是 $ V $ 上的零泛函。带入定义就有 $$ L(T(v)) =(T'(L))(v) = 0 $$ 由于对所有的线性泛函均成立，那么可以证明 $ T(v)=\\vec{0} $。否则将 $ T(v)=w $ 扩充为 $ W $ 的一组基，定义 $ L $ 只在 $ w $ 上为 $ 1 $，否则为 $ 0 $，这样就构造出了一个不符合的 $ L $，因此矛盾。从而 $ T(v)=\\vec{0} $ 对所有 $ v $ 均成立，也就有 $ T=\\mathbf{0} $。\nExercise 3 (1)\n对于任意 $ L\\in W' $ 和 $ v\\in V $，有 $$ \\begin{align*} ((S+T)'(L))(v) \u0026 = L((S+T)(v)) \\\\ \u0026 = L(S(v) + T(v)) \\\\ \u0026 = L(S(v)) + L(T(v)) \\\\ \u0026 = (S'(L)(v)) + (T'(L))(v) \\\\ \u0026 = ((S'+T')(L))(v) \\end{align*} $$ (2) $$ \\begin{align*} ((cT)'(L))(v) \u0026 = L((cT)(v)) \\\\ \u0026 = L(c\\cdot T(v)) \\\\ \u0026 = c\\cdot L(T(v)) \\\\ \u0026 = c\\cdot(T'(L))(v) \\\\ \u0026 = (cT'(L))(v) \\end{align*} $$ (3)\n设 $ L\\in W' $ 和 $ u\\in U $，有 $$ \\begin{align*} ((S'T')(L))(u) \u0026 = (S'(T'(L)))(u) \\\\ \u0026 = (T'(L))(S(u)) \\\\ \u0026 = L(T(S(u))) \\\\ \u0026 = L((TS)(u)) \\\\ \u0026 = ((TS)'(L))(u) \\end{align*} $$\nExercise 4 考虑采用 $ (\\text{ii}) $ 中的思路。\n构造 $ V''=(V')' $ 为 $ V' $ 的对偶空间。定义映射 $ \\Phi:V\\to V'' $，对于任意 $ v\\in V $，$ \\Phi(v) $ 是 $ V' $ 上的一个泛函，定义为 $$ \\forall L\\in V',\\quad (\\Phi(v))(L) = L(v) $$ 由于对于任意 $ u,v\\in V $ 和标量 $ c\\in \\mathbb{F} $，以及任意 $ L\\in V' $，有 $$ \\begin{align*} \\Phi(cu+v)(L) \u0026 = L(cu+v) \\\\ \u0026 = cL(u)+L(v) \\\\ \u0026 = c[\\Phi(u)(L)] + \\Phi(v)(L) \\\\ \u0026 = (c\\Phi(u)+\\Phi(v))(L) \\end{align*} $$ 从而 $ \\Phi $ 是一个线性变换。\n接着证明 $ \\Phi $ 是一个双射。假设 $ \\Phi(v)=\\mathbf{0}_{V''} $，为 $ V' $ 上的零泛函，那么对于所有 $ L\\in V' $ 都有 $ L(v)=0 $，从而必然有 $ v=\\mathbf{0}_{V} $，否则取 $ V' $ 的一组基即可推出矛盾。因此 $ \\text{Ker}(\\Phi)=\\{ \\mathbf{0}_{V} \\} $，$ \\Phi $ 是一个单射。并且由于空间是有限维的，而且 $ \\text{dim}(V'')=\\text{dim}(V')=\\text{dim}(V)=n $，一个映射前后维数相同的单射必然是一个双射。\n综上证明了 $ \\Phi $ 是一个可逆线性变换。\n我们已知 $ \\{ L_{1},\\dots,L_{n} \\} $ 是 $ V' $ 的一组基。那么根据对偶基的存在性，$ V'' $ 中存在唯一的一组基 $ \\{ \\phi_{1},\\dots,\\phi_{n} \\} $ 满足 $$ \\phi_{i}(L_{j}) = \\mathbb{I}[i=j],\\quad (1\\leq i,j \\leq n) $$ 已知 $ \\Phi $ 的逆映射 $ \\Phi ^{-1} $ 存在，那么定义 $$ v_{i} = \\Phi ^{-1}(\\phi_{i}),\\quad i \\in[n] $$ 由于 $ \\Phi $ 是线性双射，从而保持了基的性质，也就有 $ \\{ v_{1},\\dots,v_{n} \\} $ 仍然是 $ V $ 的一组基。\n我们接着验证 $ L_{i}(v_{j})=\\mathbb{I}[i=j] $ 即可。根据定义 $$ \\Phi(v_{i})(L_{j}) = L_{j}(v_{i}) = \\phi_{i}(L_{j}) = \\mathbb{I}[i=j] $$ 证毕。\n","permalink":"https://diefish1024.github.io/posts/class-notes/math1205h-linear-algebra/math1205h-hw20/","summary":"\u003ch2 id=\"exercise-1\"\u003eExercise 1\u003c/h2\u003e\n\u003cp\u003e根据对偶变换的定义\n$$ \n\n(T'(L))(v) = L(T(v))\n\n $$\n带入 $ T(v)=v $，就有\n$$ \n\n(T'(L))(v) = L(v)\n\n $$\n由于这对所有 $ v \\in V $ 均成立，从而 $ T'(L) $ 和 $ L $ 是一个函数，因为输入输出完全相同，因此 $ T'(L)=L $，是恒等变换。\u003c/p\u003e\n\u003ch2 id=\"exercise-2\"\u003eExercise 2\u003c/h2\u003e\n\u003cp\u003e先证充分性，如果 $ T=\\mathbf{0} $，那么对于任意 $ v \\in V $，都有 $ T(v)=\\vec{0} $。根据定义\n$$ \n\n(T'(L))(v) = L(T(v)) = 0\n\n $$\n说明 $ T'(L) $ 是零泛函，从而 $ T'=\\mathbf{0} $。\u003c/p\u003e\n\u003cp\u003e如果 $ T'=\\mathbf{0} $，那么对于任意 $ L\\in W' $，$ T'(L) $ 是 $ V $ 上的零泛函。带入定义就有\n$$ \n\nL(T(v)) =(T'(L))(v) = 0\n\n $$\n由于对所有的线性泛函均成立，那么可以证明 $ T(v)=\\vec{0} $。否则将 $ T(v)=w $ 扩充为 $ W $ 的一组基，定义 $ L $ 只在 $ w $ 上为 $ 1 $，否则为 $ 0 $，这样就构造出了一个不符合的 $ L $，因此矛盾。从而 $ T(v)=\\vec{0} $ 对所有 $ v $ 均成立，也就有 $ T=\\mathbf{0} $。\u003c/p\u003e","title":"MATH1205H HW20"},{"content":"Problem 1 (1)\n总共有 $ N=\\binom{ n }{ 2 } $ 对点。设 $ X_{ij}=\\mathbb{I}[(i,j)\\in E_{n}] $。那么 $ \\mathbf{E}[X_{ij}]=p $。并且 $$ \\left| E_{n} \\right| = \\sum_{1\\leq i\u003c j\\leq n} X_{i} $$ 由于边与边之间独立，因此 $ X_{i} $ 是独立同分布，并且可积，那么根据强大数定律，就有 $$ \\dfrac{\\sum X_{i}}{N} = \\dfrac{\\left| E_{n} \\right| }{\\binom{ n }{ 2 } } \\xrightarrow{a.s.} \\mathbf{E}[X_{i}]=p $$ (2)\n设 $ \\mathcal{C}_n $ 为 $ V_n $ 中所有大小为 $ 3 $ 的子集的集合，也就是所有无序三元组 $ \\{i, j, k\\} $。集合大小 $ |\\mathcal{C}_n| = \\binom{n}{3} $。\n对于任意 $ \\alpha = \\{i, j, k\\} \\in \\mathcal{C}_n $，定义指示变量 $ Y_\\alpha $ $$ Y_\\alpha = X_{ij} X_{jk} X_{ki} $$ 由于 $ X $ 相互独立，因此 $$ \\mathbf{E}[Y_{\\alpha}] = \\mathbf{E}[X_{ij}]\\mathbf{E}[X_{jk}]\\mathbf{E}[X_{ki}]=p^{3} $$ 由于三角形总数满足 $ \\left| T_{n} \\right|=\\sum_{\\alpha \\in \\mathcal{C}_{n}}Y_{\\alpha} $，那么根据期望的线性性，有 $$ \\mathbf{E}[\\left| T_{n} \\right| ] = \\sum_{\\alpha \\in \\mathcal{C}_{n}} \\mathbf{E}[Y_{\\alpha}] = \\binom{ n }{ 3 } p^{3} $$ 接着考虑 $ \\left| T_{n} \\right| $ 的方差。分析两个不同三元组 $ \\alpha $ 和 $ \\beta $ 的协方差 $$ \\text{Conv}(Y_{\\alpha},Y_{\\beta}) = \\mathbf{E}[Y_{\\alpha}Y_{\\beta}] - \\mathbf{E}[Y_{\\alpha}]\\mathbf{E}[Y_{\\beta}] $$ 假如 $ \\alpha,\\beta $ 没有公共边，那么相互独立，协方差为零。如果 $ \\left| \\alpha \\cap\\beta\\right|=2 $，有公共边，那么一共涉及了五条不同的边，从而 $$ \\mathbf{E}[Y_{\\alpha}Y_{\\beta}]=p^{5} \\implies \\text{Conv}(Y_{\\alpha},Y_{\\beta}) = p^{5}-p^{6} $$ 并且存在公共边的 $ \\alpha,\\beta $ 的数量是 $ O(n^{4}) $ 级别的，因为一共涉及到了 $ 4 $ 个点的选择。\n因此 $$ \\text{Var}(\\left| T_{n} \\right| ) = \\binom{ n }{ 3 } \\text{Var}(Y_{\\alpha}) + O(n^{4})\\cdot(p^{5}-p^{6}) \\leq C\\cdot n^{4} $$ 考察随机变量 $ Z_{n}=\\left| T_{n} \\right| / \\binom{ n }{ 3 } $。我们有 $$ \\text{Var}(Z_{n}) = \\dfrac{1}{\\binom{ n }{ 3 }^{2}} \\text{Var}(\\left| T_{n} \\right| ) = \\dfrac{O(n^{4})}{O(n^{6})} = O(n^{-2}) $$ 从而对于任意 $ \\varepsilon\u003e0 $，都有 $$ \\mathbb{P}(\\left| Z_{n} - \\varepsilon\\right| \\geq \\varepsilon) \\leq \\dfrac{\\text{Var}(Z_{n})}{\\sigma^{2}} \\leq \\dfrac{K}{n^{2}\\varepsilon^{2}} $$ 从而 $$ \\lim_{n \\to \\infty} \\mathbb{P}\\left( \\left| \\frac{|T_n|}{\\binom{n}{3}} - p^3 \\right| \\ge \\varepsilon \\right) = 0 $$ 就证明了依概率收敛。\n(3)\n根据 $ (2) $ 我们得到了 $$ \\mathbb{P}\\left( \\left| \\frac{|T_n|}{\\binom{n}{3}} - p^3 \\right| \\ge \\varepsilon \\right) \\leq \\dfrac{K}{\\varepsilon^{2}n^{2}} $$ 其中 $ K $ 是一个和 $ n $ 无关的常数。\n我们将这个概率对所有的 $ n $ 求和，得到 $$ \\sum_{n=1}^{\\infty} \\mathbb{P}\\left( \\left| \\frac{|T_n|}{\\binom{n}{3}} - p^3 \\right| \\ge \\varepsilon \\right) \\leq \\dfrac{K}{\\varepsilon^{2}}\\sum_{n=1}^{\\infty} \\dfrac{1}{n^{2}} \u003c \\infty $$ 利用 Borel-Cantelli Lemma，设事件 $ A_{n}=\\left\\{ \\left| \\frac{|T_n|}{\\binom{n}{3}} - p^3 \\right| \\ge \\varepsilon \\right\\} $，就得到了 $$ \\mathbb{P}(A_{n}\\text{ i.o}) = 0 $$ 从而说明存在 $ N_{0} $ 使得当 $ n\u003eN_{0} $，必然有 $$ \\left| \\dfrac{\\left| T_{n} \\right| }{\\binom{ n }{ 3 } }-p^{3} \\right| \u003c \\varepsilon $$ 这正是几乎处处收敛的定义，因此 $$ \\dfrac{\\left| T_{n} \\right| }{\\binom{ n }{ 3 } } \\xrightarrow{a.s.} p^{3} $$\nProblem 2 (1)\n首先证明下界。由于 $ p(x)=\\mathbb{P}(X=x) $ 是一个概率，因此 $ p(x)\\in(0,1) $，从而 $ -p(x)\\log_{2}p(x)\\geq0 $，因此求和必定非负。\n接着证明上界。将 $ H(X) $ 理解为期望，有 $$ H(X) = \\sum_{x \\in A}p(x)\\log_{2}\\left( \\dfrac{1}{p(x)} \\right) = \\mathbf{E}\\left[ \\log_{2}\\left( \\dfrac{1}{p(X)} \\right) \\right] $$ 其中 $ \\dfrac{1}{p(X)} $ 是一个随机变量。考虑函数 $ f(t)=\\log_{2}t $，其二阶导 $ f''(t)=-\\dfrac{1}{t^{2}\\ln 2}\u003c 0 $，$ f(t) $ 是凹函数，从而根据琴生不等式，有 $$ \\mathbf{E}\\left[ \\log_{2}\\left( \\dfrac{1}{p(X)} \\right) \\right]\\leq \\log_{2}\\left( \\mathbf{E}\\left[ \\dfrac{1}{p(X)} \\right] \\right) $$ 其中 $$ \\mathbf{E}\\left[ \\dfrac{1}{p(X)} \\right] = \\sum_{x \\in A} \\mathbb{P}(X=x)\\cdot \\dfrac{1}{\\mathbb{P}(X=x)} = \\left| A \\right| $$ 带入就得到了 $$ H(X) \\leq \\log_{2}\\left| A \\right| $$ 在所有 $ p(x) $ 全都相等时取到等号。由于 $ \\sum p(x)=1 $，因此取等时 $ p(x)=\\frac{1}{\\left| A \\right|} $。也就是 $ X $ 服从均匀分布时熵最大。\n(2)\n根据定义，有 $$ \\log_{2}\\mathbb{P}(X) = \\log_{2}\\left( \\prod_{i=1}^{n} \\mathbb{P}(X_{i}) \\right) = \\sum_{i=1}^{n} \\log_{2}\\mathbb{P}(X_{i}) $$ 令 $ Z_{i}=-\\log_{2}\\mathbb{P}(X_{i}) $。由于 $ X_{i} $ 独立同分布，因此 $ Z_{i} $ 也独立同分布。\n注意到 $ Z_{i} $ 的期望正是 $ H(X_{i}) $ 的定义： $$ \\mathbf{E}[Z_{i}] = \\sum_{x \\in A}\\mathbb{P}(X_{i}=x)\\cdot (-\\log_{2}\\mathbb{P}(X_{i}=x)) = H(X_{i}) $$ 由于 $ A $ 是有限集，因此 $ \\mathbf{E}[Z_{i}] $ 存在上界，$ \\mathbf{E}[|Z_{i}|]\u003c \\infty $。从而根据弱大数定律，有 $$ \\dfrac{1}{n}\\sum_{i=1}^{n} Z_{i} \\xrightarrow{P} \\mathbf{E}[Z] $$ 带回就得到了 $$ -\\dfrac{1}{n}\\log_{2}\\mathbb{P}(\\vec{X})\\xrightarrow{P} H(X) $$ (3)\n如果 $ \\vec{x}\\in A_{\\varepsilon}^{(n)} $，那么带入定义，化简可得 $$ 2^{-n(H(X)+\\varepsilon)} \\leq \\mathbb{P}(\\vec{X}=\\vec{x}) \\leq 2^{-n(H(X)-\\varepsilon)} $$ 首先证明上界。考虑 $$ \\mathbb{P}(A_{\\varepsilon}^{(n)}) = \\sum_{\\vec{x}\\in A_{\\varepsilon}^{(n)}}\\mathbb{P}(\\vec{X}=\\vec{x}) \\geq \\sum_{\\vec{x}\\in A_{\\varepsilon}^{(n)}}2^{-n(H(X)+\\varepsilon)} = \\left| A_{\\varepsilon}^{(n)} \\right| \\cdot 2^{-n(H(X)+\\varepsilon)} $$ 由于 $ \\mathbb{P}(A_{\\varepsilon}^{(n)})\\leq 1 $，就得到了 $$ \\left| A_{\\varepsilon}^{(n)} \\right| \\cdot 2^{-n(H(X)+\\varepsilon)} \\leq 1 \\implies \\left| A_{\\varepsilon}^{(n)} \\right| \\leq 2^{n(H(X)+\\varepsilon)} $$ 接着证明下界。根据 $ (2) $，我们知道对于给定 $ \\varepsilon\u003e0 $，存在 $ N\\in \\mathbb{N} $ 使得当 $ n\u003eN $ 时 $$ \\mathbb{P}(A_{\\varepsilon}^{(n)}) \u003e 1-\\varepsilon $$ 从而 $$ \\left| A_{\\varepsilon}^{(n)} \\right| \\cdot 2^{-n(H(X)-\\varepsilon)} \u003e 1-\\varepsilon \\implies \\left| A_{\\varepsilon}^{(n)} \\right| \u003e (1-\\varepsilon)\\cdot 2^{n(H(X)-\\varepsilon)} $$ 综上，证明了 $$ (1-\\varepsilon)\\cdot 2^{n(H(X)-\\varepsilon)} \u003c \\left| A_{\\varepsilon}^{(n)} \\right| \\leq 2^{n(H(X)+\\varepsilon)} $$\nProblem 3 (1)\n根据提示，设 $ X_{n} $ 为从 $ (0,0) $ 出发，长度为 $ n $ 的开放路径个数。当 $ \\left| C_{0,0} \\right|=\\infty $ 说明至少存在一条经过远点的无限长的路径，从而 $$ \\mathbb{P}(\\left| C_{0,0} \\right| =\\infty) \\leq \\lim_{ n \\to \\infty } \\mathbb{P}(X_{n}\\geq 1) $$ 根据马尔可夫不等式，就得到了 $$ \\mathbb{P}(\\left| C_{0,0} \\right| =\\infty) \\leq \\lim_{ n \\to \\infty } \\mathbb{P}(X_{n}\\geq 1) \\leq \\lim_{ n \\to \\infty } \\mathbf{E}[X_{n}] $$ 我们目标是证明 $ \\lim_{ n \\to \\infty }\\mathbf{E}[X_{n}]=0 $。\n考虑计算长度为 $ n $ 的路径总数。除了第一步，剩下的每一步都不能走回头路，只有 $ 3 $ 个方向可选，因此至多只能有 $ 4\\times 3^{n-1} $ 条路径。由于每一段路相互独立，因此一条长度为 $ n $ 的路径开放的概率为 $ p^{n} $，因此 $$ \\mathbf{E}[X_{n}] \\leq (4 \\times 3^{n-1}) \\cdot p^{n} = \\dfrac{4}{3}(3p)^{n} $$ 由于 $ p \u003c \\frac{1}{3} $，从而 $$ \\lim_{ n \\to \\infty } \\mathbf{E}[X_{n}] \\leq \\lim_{ n \\to \\infty } \\dfrac{4}{3}(3p)^{n} = 0 $$\n(2)\n设一条路关闭的概率为 $ q=1-p $，那么根据题设，有 $ q\u003c \\frac{1}{10} $。\n设 $ N_{n} $ 为对偶网络中长度为 $ n $ 且包含原点的回路总数。对于任意一条长度为 $ n $ 的回路，其关闭的概率均为 $ q^{n} $。\n设事件 $ B=\\{ \\left| C_{0,0} \\right|\u003c\\infty \\} $。根据提示中的 Lemma，$ B $ 发生等价于 $ \\tilde{\\mathbb{Z}}^{2} $ 中存在一条闭合回路 $ \\gamma $ 满足 $ \\gamma $ 包围原点并且 $ \\gamma $ 上每一条边对应 $ \\mathbb{Z}^{2} $ 中的边均关闭。根据 Union Bound，事件 $ B $ 发生的概率存在上界 $$ \\mathbb{P}(B) \\leq \\sum_{n} N_{n}\\cdot q^{n} $$ 我们考虑估计一个 $ N_{n} $ 的上界。因为回路必然经过 $ x $ 轴（指 $ \\tilde{\\mathbb{Z}}^{2} $ 上的 $ x $ 轴），所以不妨在 $ x $ 轴上选择路径起点。因为总长度为 $ n $，所以到原点距离不能超过 $ n $，从而最多只有 $ 2n $ 种选择。同样第一步有 $ 4 $ 个方向，往后每一步只有 $ 3 $ 种方向，这样可以估计出 $ N_{n} $ 的一个粗略的上界 $$ N_{n} \\leq 2n \\cdot (4 \\times 3^{n-1}) $$ 从而由于一个环的长度至少为 $ 4 $，所以直接从 $ n=4 $ 开始求和即可 $$ \\begin{align*} \\mathbb{P}(B) \u0026 \\leq \\sum_{n=4}^{\\infty} 2n \\cdot(4 \\times 3^{n-1})\\cdot q^{n} \\\\ \u0026 \u003c \\frac{8}{3}\\sum_{n=4}^{\\infty} n\\cdot \\left( \\frac{3}{10} \\right)^{n} \u003c 1 \\end{align*} $$ 因此 $$ \\mathbb{P}(\\left| C_{0,0} \\right| \u003e \\infty) = 1-\\mathbb{P}(\\left| C_{0,0} \\right| \u003c \\infty) \u003e 0 $$ (3)\n首先当 $ p\u003c p^{*} $ 时，令事件 $ E=\\{ \\exists v\\in \\mathbb{Z}^{2},\\left| C_{v} \\right|=\\infty \\} $，那么 $ E=\\bigcup_{v\\in \\mathbb{Z}^{2}}\\{ \\left| C_{v} \\right|=\\infty \\} $。\n由于二维网格具有平移不变性，所以此时 $ \\mathbb{P}(\\left| C_{v} \\right|=\\infty)=\\mathbb{P}(\\left| C_{0,0} \\right|=\\infty)=0 $。那么根据 Union Bound，就有 $$ \\mathbb{P}(E) \\leq \\sum_{v \\in \\mathbb{Z}^{2}} \\mathbb{P}(\\left| C_{v} \\right| =\\infty) = \\sum_{v \\in \\mathbb{Z}^{2}} 0 = 0 $$ 当 $ p\u003ep^{*} $ 时，我们证明事件 $ E $ 是一个尾事件。$ E $ 等价于网格中存在无穷多的点联通，根据图的性质，改变有限条边的状态并不会改变 $ E $。\n形式化地描述，将 $ \\mathbb{Z}^2 $ 中的边集进行可数编号，记为序列 $ \\{X_n\\}_{n \\ge 1} $，其中 $ X_n $ 为第 $ n $ 条边的状态。$ \\{X_n\\} $ 为独立同分布序列。事件 $ E $ 的发生与否不依赖于任意有限条边的状态（修改有限条边不会改变是否存在无限连通分量这一性质）。因此对于任意 $ n $， $ E \\in \\sigma(X_{n+1}, X_{n+2}, \\dots) $，即 $ E $ 是尾事件。\n那么根据 Kolmogorov 0-1 律，有 $ \\mathbb{P}(E)\\in \\{ 0,1 \\} $。我们只需要验证 $ \\mathbb{P}(E)\\neq 0 $ 即可。显然 $ \\{ \\left| C_{0,0} \\right|=\\infty \\}\\subseteq E $，从而根据单调性 $$ \\mathbb{P}(E) \\geq \\mathbb{P}(\\left| C_{0,0} \\right| =\\infty) \u003e 0 $$ 从而 $ \\mathbb{P}(E)=1 $，证毕。\nProblem 4.1 (1)\n首先由于 $ \\mathbb{P}(\\left| Y \\right|\\geq t)=\\mathbb{P}(Y\\geq t) + \\mathbb{P}(Y \\leq -t) $，分别考虑这两个概率。\n对于任意 $ \\lambda \u003e0 $，根据单调性有 $$ \\{ Y\\geq t \\} \\iff \\{ e^{ \\lambda Y } \\geq e^{ \\lambda t } \\} $$ 利用马尔可夫不等式，有 $$ \\mathbb{P}(Y\\geq t) = \\mathbb{P}(e^{ \\lambda Y }\\geq e^{ \\lambda t } ) \\leq \\frac{\\mathbf{E}[e^{ \\lambda Y }]}{e^{ \\lambda t }} $$ 带入次高斯条件就有 $$ \\mathbb{P}(Y\\geq t) \\leq \\dfrac{\\mathbf{E}[e^{ \\lambda Y }]}{e^{ \\lambda t }} \\leq e^{ \\alpha^{2}\\lambda^{2}-\\lambda t } $$ 而指数中的二次函数存在最小值 $ \\alpha^{2}\\lambda^{2}-\\lambda t\\geq -\\frac{t^{2}}{4\\alpha^{2}} $，从而 $$ \\mathbb{P}(Y\\geq t) \\leq \\exp \\left\\{ -\\frac{t^{2}}{4\\alpha^{2}} \\right\\} $$ 对于 $ mk\\mathbb{P}Y\\leq-t $，考虑随机变量 $ -Y $，利用对称性同样有 $$ \\mathbb{P}(Y\\leq -t)=\\mathbb{P}(-Y\\geq t) \\leq \\exp \\left\\{ -\\frac{t^{2}}{4\\alpha^{2}} \\right\\} $$ 因此 $$ \\mathbb{P}(\\left| Y \\right| \\geq t) \\leq 2\\exp \\left\\{ -\\frac{t^{2}}{4\\alpha^{2}} \\right\\} $$ (2)\n由于直接带入积分只能得到 $ O(n) $ 量级的 $ \\alpha $ 的界，因此考虑使用截断法。\n将积分区间分成 $ [0,\\delta] $ 和 $ (\\delta,\\infty) $ 两段。在 $ t $ 比较大的时候再考虑使用 $ (2) $ 中给出的上界，$ t $ 比较小的时候直接使用概率不超过 $ 1 $ 的限制，那么就有 $$ \\begin{align*} \\mathbf{E}[\\max_{i\\in[n]}\\left| Y_{i} \\right|] \u0026 = \\int_{0}^{\\infty} \\mathbb{P}(\\max_{i\\in[n]}\\left| Y_{i} \\right| \u003et) \\mathrm{d}t \\\\ \u0026 = \\int_{0}^{\\delta} \\mathbb{P}(\\dots)\\mathrm{d}t + \\int_{\\delta}^{\\infty} \\mathbb{P}(\\dots)\\mathrm{d}t \\\\ \u0026 \\leq \\int_{0}^{\\delta} 1\\cdot \\mathrm{d}t + \\int_{\\delta}^{\\infty} \\left( \\sum_{i\\in[n]} \\mathbb{P}(\\left| Y_{i} \\right| \u003e t)\\right) \\mathrm{d}t \\\\ \u0026 \\leq \\delta + \\int_{\\delta}^{\\infty} \\left( \\sum_{i\\in[n]}2\\exp \\left\\{ -\\frac{t^{2}}{4\\alpha_{i}^{2}} \\right\\} \\right) \\mathrm{d}t \\\\ (\\alpha=\\max_{i\\in[n]}\\alpha_{i}) \u0026 \\leq \\delta + 2n\\int_{\\delta}^{\\infty} \\exp \\left\\{ -\\frac{t^{2}}{4\\alpha^{2}} \\right\\} \\mathrm{d}t \\end{align*} $$ 我们需要估算 $ \\int_{\\delta}^{\\infty} e^{ -t^{2}/4\\alpha^{2} } \\mathrm{d}t $。由于在积分区间上 $ t\u003e\\delta $，因此 $$ \\begin{align*} \\int_{\\delta}^{\\infty} \\exp \\left\\{ -\\frac{t^{2}}{4\\alpha^{2}} \\right\\} \\mathrm{d}t \u0026 \\leq \\frac{1}{\\delta} \\int_{\\delta}^{\\infty} t\\exp \\left\\{ -\\frac{t^{2}}{4\\alpha^{2}} \\right\\} \\mathrm{d}t \\\\ \u0026 = \\frac{1}{2\\delta}\\int_{\\delta}^{\\infty} \\exp \\left\\{ -\\frac{t^{2}}{4\\alpha^{2}} \\right\\} \\mathrm{d}t^{2} \\\\ \u0026 = \\frac{2\\alpha^{2}}{\\delta} \\exp \\left\\{ -\\frac{\\delta^{2}}{4\\alpha^{2}} \\right\\} \\end{align*} $$ 带回原式就有 $$ \\mathbf{E}[\\max\\left| Y_{i} \\right| ] \\leq \\delta + 2n\\cdot \\frac{2\\alpha^{2}}{\\delta}\\cdot \\exp \\left\\{ -\\frac{\\delta^{2}}{4\\alpha^{2}} \\right\\} $$ 我们选取 $ \\delta $ 使得 $ \\exp \\left\\{ -\\frac{\\delta^{2}}{4\\alpha^{2}} \\right\\} = \\frac{1}{2n} $，那么 $$ \\delta=\\alpha \\sqrt{ 4\\ln(2n) } = 2\\alpha \\sqrt{ \\ln(2n) } $$ 带入有 $$ \\mathbf{E}[\\max\\left| Y_{i} \\right| ] \\leq 2\\alpha \\sqrt{ \\ln(2n) } + \\frac{\\alpha}{\\sqrt{ \\ln(2n) }} = \\alpha \\sqrt{ \\ln(2n) } \\left( 2 + \\frac{1}{\\ln(2n)} \\right) $$ 由于 $ \\ln(2n)\u003e1 $，因此括号内是有界常数；并且 $ \\sqrt{ \\ln(2n) } \u003c2\\sqrt{ \\ln n } $。所以存在常数 $ C $ 使得 $$ \\mathbf{E}[\\max_{i \\in[n]}\\left| Y_{i} \\right| ] \\leq C\\sqrt{ \\ln n }\\cdot\\max_{i} \\alpha_{i} $$\nProblem 4.2 (1)\n根据定义，有 $$ F(x) = \\mathbb{P}(X\\leq x) = \\mathbf{E}[\\mathbb{I}_{X\\leq x}] $$ 引入 $ X_{1}',\\dots,X_{n}' $，这时 $ F(x) $ 也可以看成新样本的经验分布函数 $ F_{n}'(x) $ 的期望。 $$ F(x) = \\mathbf{E}{F_{n}'(x)} = \\mathbf{E}\\left[ \\frac{1}{n}\\sum_{i=1}^{n} \\mathbb{I}_{X'_{i}\\leq x} \\right] $$ 要处理的左式为 $$ \\begin{align*} \\text{LHS} \u0026 = \\mathbf{E}\\left[\\sup_{x \\in \\mathbb{R}}\\left| F_{n}(x)-F(x) \\right| \\right] \\\\ \u0026 = \\mathbf{E}\\left[\\sup_{x \\in \\mathbb{R}}\\left| F_{n}(x)-\\mathbf{E}[F'_{n}(x)] \\right| \\right] \\end{align*} $$ 由于对 $ X' $ 求期望时 $ X $ 可以看作常数，因此 $ F_{n}(x)-\\mathbf{E}[F'_{n}(x)]=\\mathbf{E}[F_{n}(x)-F_{n}'(x)]|_{X'} $。由于函数 $ g(X)=\\sup_{x}\\left| X(x) \\right| $ 是一个凸函数，因此根据琴生不等式，就有 $$ \\mathbf{E} \\left[ \\sup_{x} |\\mathbf{E}' [F_n(x) - F'_n(x)]| \\right] \\le \\mathbf{E} \\left[ \\mathbf{E}' \\left[ \\sup_{x} |F_n(x) - F'_n(x)| \\right] \\right] $$ 其中 $ \\mathbf{E}' $ 表示对 $ X' $ 求的期望。\n现在我们只需要分析 $ \\left| F_{n}(x)-F_{n}'(x) \\right| $，带入得到 $$ F_n(x) - F'_n(x) = \\frac{1}{n} \\sum_{i=1}^n \\mathbb{I}_{X_i \\le x} - \\frac{1}{n} \\sum_{i=1}^n \\mathbb{I}_{X'_i \\le x} = \\frac{1}{n} \\sum_{i=1}^n (\\mathbb{I}_{X_i \\le x} - \\mathbb{I}_{X'_i \\le x}) $$ 带回不等式就得到了 $$ \\text{LHS} \\leq \\mathbf{E}\\left[ \\sup_{x}\\left| \\frac{1}{n}\\sum_{i=1}^{n} (\\mathbb{I}_{X_{i}\\leq x} - \\mathbb{I}_{X_{i}'\\leq x}) \\right| \\right] = \\frac{1}{n} \\mathbf{E} \\left[ \\sup_{x\\in\\mathbb{R}} \\left| \\sum_{i=1}^n (\\mathbb{I}_{X_i \\le x} - \\mathbb{I}_{X'_i \\le x}) \\right| \\right] $$\n(2)\n设 $ Z_{i}=\\mathbb{I}_{X_{i}\\leq x}-\\mathbb{I}_{X'_{i}\\leq x},W_{i}=\\varepsilon_{i}Z_{i} $。由于 $ X $ 和 $ X' $ 独立同分布，因此根据对称性，如果交换 $ X $ 和 $ X' $，那么 $ Z_{i} $ 就会变成 $ -Z_{i} $，这意味着 $ Z_{i} $ 是一个关于 $ 0 $ 对称的随机变量。\n引入 $ \\varepsilon_{i} $ 后，若 $ \\varepsilon_{i}=1 $，那么 $ W_{i}=Z_{i} $；否则 $ W_{i}=-Z_{i} $，这时由于 $ Z_{i} $ 和 $ -Z_{i} $ 同分布，因此 $ Z_{i} $ 和 $ W_{i} $ 也同分布。所以乘以 $ \\varepsilon_{i} $ 不改变分布，因此 $ Z_{i} $ 和 $ W_{i} $ 具有相同的分布。\n接着我们目标证明 $ \\mathbf{E} \\left[ \\sup_{x} |F_n(x) - F(x)| \\right] \\le \\frac{2}{n} \\cdot \\mathbf{E} \\left[ \\sup_{x} \\left| \\sum_{i=1}^n \\varepsilon_i \\cdot \\mathbb{I}_{X_i \\le x} \\right| \\right] $，根据第一小问，已经有 $$ \\text{LHS} \\leq \\frac{1}{n} \\mathbf{E} \\left[ \\sup_{x\\in\\mathbb{R}} \\left| \\sum_{i=1}^n (\\mathbb{I}_{X_i \\le x} - \\mathbb{I}_{X'_i \\le x}) \\right| \\right] $$ 根据刚才的性质，我们可以将求和式中的 $ (\\mathbb{I}_{X_i \\le x} - \\mathbb{I}_{X'_i \\le x}) $ 替换为 $ \\varepsilon_{i}(\\mathbb{I}_{X_i \\le x} - \\mathbb{I}_{X'_i \\le x}) $，因为不仅同分布而且 $ i $ 之间也相互独立。于是右侧就变为了 $$ \\frac{1}{n} \\mathbf{E} \\left[ \\sup_{x\\in\\mathbb{R}} \\left| \\sum_{i=1}^n \\varepsilon_{i}(\\mathbb{I}_{X_i \\le x} - \\mathbb{I}_{X'_i \\le x}) \\right| \\right] $$ 将内侧求和展开，得到了 $$ \\sum_{i=1}^{n} \\varepsilon_{i}(\\mathbb{I}_{X_{i}\\leq x}-\\mathbb{I}_{X'_{i}\\leq x}) = \\sum_{i=1}^{n} \\varepsilon_{i}\\mathbb{I}_{X_{i}\\leq x} - \\sum_{i=1}^{n} \\varepsilon_{i}\\mathbb{I}_{X_{i}'\\leq x} $$ 从而 $$ \\begin{align*} \\sup_{x\\in\\mathbb{R}} \\left| \\sum_{i=1}^n (\\mathbb{I}_{X_i \\le x} - \\mathbb{I}_{X'_i \\le x}) \\right| \u0026 = \\sup_{x \\in \\mathbb{R}}\\left| \\sum_{i=1}^{n} \\varepsilon_{i}\\mathbb{I}_{X_{i}\\leq x} - \\sum_{i=1}^{n} \\varepsilon_{i}\\mathbb{I}_{X_{i}'\\leq x} \\right| \\\\ \u0026 \\leq \\sup_{x \\in \\mathbb{R}} \\left( \\left| \\sum_{i=1}^{n} \\varepsilon_{i}\\mathbb{I}_{X_{i}\\leq x} \\right| +\\left| \\sum_{i=1}^{n} \\varepsilon_{i}\\mathbb{I}_{X_{i}'\\leq x} \\right| \\right) \\\\ \u0026 \\leq \\sup_{x \\in \\mathbb{R}}\\left| \\sum_{i=1}^{n} \\varepsilon_{i}\\mathbb{I}_{X_{i}\\leq x} \\right| + \\sup_{x \\in \\mathbb{R}}\\left| \\sum_{i=1}^{n} \\varepsilon_{i}\\mathbb{I}_{X'_{i}\\leq x} \\right| \\end{align*} $$ 从而 $$ \\begin{align*} \\text{LHS} \u0026 \\leq \\frac{1}{n}\\mathbf{E}\\left[ \\sup_{x \\in \\mathbb{R}}\\left| \\sum_{i=1}^{n} \\varepsilon_{i}\\mathbb{I}_{X_{i}\\leq x} \\right| + \\sup_{x \\in \\mathbb{R}}\\left| \\sum_{i=1}^{n} \\varepsilon_{i}\\mathbb{I}_{X'_{i}\\leq x} \\right| \\right] \\\\ \u0026 = \\frac{1}{n}\\mathbf{E}\\left[ \\sup_{x \\in \\mathbb{R}}\\left| \\sum_{i=1}^{n} \\varepsilon_{i}\\mathbb{I}_{X_{i}\\leq x} \\right| \\right] + \\frac{1}{n}\\mathbf{E}\\left[ \\sup_{x \\in \\mathbb{R}}\\left| \\sum_{i=1}^{n} \\varepsilon_{i}\\mathbb{I}_{X'_{i}\\leq x} \\right| \\right] \\\\ \u0026 = \\frac{2}{n}\\mathbf{E}\\left[ \\sup_{x \\in \\mathbb{R}}\\left| \\sum_{i=1}^{n} \\varepsilon_{i}\\mathbb{I}_{X_{i}\\leq x} \\right| \\right] \\end{align*} $$ 证毕。\nProblem 4.3 设 $ a_{i}=\\mathbb{I}_{x_{i}\\leq x}-\\mathbb{I}_{x_{i}\\leq y} $，那么 $ Z_{x}-Z_{y}=\\sum_{i=1}^{n}\\varepsilon_{i}a_{i} $。再令 $ \\sigma=\\sqrt{ \\sum_{i=1}^{n}a_{i}^{2} } $，那么 $$ Z=\\dfrac{\\sum_{i=1}^{n} \\varepsilon_{i}a_{i}}{\\sigma} = \\sum_{i=1}^{n} \\varepsilon_{i}\\left( \\frac{a_{i}}{\\sigma} \\right),\\quad \\sum_{i=1}^{n} \\left( \\frac{a_{i}}{\\sigma} \\right)^{2}=1 $$ 计算 $ Z $ 的矩生成函数，有 $$ \\mathbf{E}[e^{\\lambda Z}] = \\mathbf{E}\\left[ \\exp\\left( \\lambda \\sum_{i=1}^n w_i \\varepsilon_i \\right) \\right] = \\mathbf{E}\\left[ \\prod_{i=1}^n \\exp( \\lambda w_i \\varepsilon_i ) \\right] $$ 其中 $ w_{i}=\\frac{a_{i}}{\\sigma} $。\n利用提示中的式子进行放缩，得到 $$ e^{ \\lambda w_{i}\\varepsilon_{i} } \\leq \\lambda w_{i}\\varepsilon_{i} + e^{ (\\lambda w_{i}\\varepsilon_{i})^{2} } \\implies \\mathbf{E}[e^{ \\lambda w_{i}\\varepsilon_{i} }] \\leq \\mathbf{E}[\\lambda w_{i}\\varepsilon_{i}] + \\mathbf{E}[e^{ (\\lambda w_{i}\\varepsilon_{i})^{2} }] $$ 其中 $ \\mathbf{E}[\\lambda w_{i}\\varepsilon_{i}]=0 $ 并且 $ \\mathbf{E}[e^{ (\\lambda w_{i}\\varepsilon_{i})^{2} }]=\\mathbf{E}[e^{ \\lambda^{2}w_{i}^{2} }]=e^{ \\lambda^{2}w_{i}^{2} } $。带入就有 $$ \\mathbf{E}[e^{\\lambda w_i \\varepsilon_i}] \\le e^{\\lambda^2 w_i^2} $$ 带回就有 $$ \\begin{align*} \\mathbf{E}[e^{ \\lambda Z }] \u0026 =\\prod_{i=1}^{n} \\mathbf{E}[e^{ \\lambda w_{i}\\varepsilon_{i} }] \\\\ \u0026 \\leq \\prod_{i=1}^{n} e^{ \\lambda^{2}w_{i}^{2} } \\\\ \u0026 = \\exp\\left( \\lambda^{2}\\sum_{i=1}^{n} w_{i}^{2} \\right) \\\\ \u0026 = \\exp(\\lambda^{2})\\quad \\left( \\sum_{i=1}^{n} w_{i}^{2}=1 \\right) \\end{align*} $$ 证毕。\nProblem 4.4 (1)\n定义映射 $ \\Phi:\\mathbb{R}\\to \\mathbb{R}^{n} $，对于任意 $ x \\in \\mathbb{R} $，有 $$ \\Phi(x) = \\left( \\frac{1}{\\sqrt{ n }}\\mathbb{I}_{x_{1}\\leq x},\\frac{1}{\\sqrt{ n }}\\mathbb{I}_{x_{2}\\leq x}, \\dots, \\frac{1}{\\sqrt{ n }}\\mathbb{I}_{x_{n}\\leq x}\\right) $$ 从而题目中给的距离可以重写为 $$ d(x,y) = \\| \\Phi(x)-\\Phi(y) \\|_{2} $$ 根据三角不等式，对于任意向量 $ u,v,w\\in \\mathbb{R}^{n} $，都有 $$ \\| u-v \\| \\leq \\| u-w \\| + \\| v-w \\| $$ 从而带入就有 $$ d(x,y) \\leq d(x,z) + d(z,y) $$ 证毕。\n(2)\n设经验分布函数 $ F_{n}(x)=\\frac{1}{n}\\sum_{i=1}^{n}\\mathbb{I}_{x_{i}\\leq x} $。我们化简距离公式，不妨先假设 $ x\\geq y $，那么 $ \\mathbb{I}_{x_{i}\\leq x}-\\mathbb{I}_{x_{i}\\leq y}=\\mathbb{I}_{y\u003c x_{i}\\leq x} $，从而 $$ [d(x,y)]^{2}=\\frac{1}{n}\\sum_{i=1}^{n} \\mathbb{I}_{y\u003c x_{i}\\leq x} = F_{n}(x) - F_{n}(y) $$ 对于 $ x\u003c y $ 也同理，就得到了 $$ d(x,y) = \\sqrt{ \\left| F_{n}(x)-F_{n}(y) \\right| } $$ 我们首先构造 $ n+1 $ 个点的集合 $ S_{0} $。由于 $ F_{n}(x) $ 是一个阶梯函数，只在 $ x_{1},\\dots,x_{n} $ 共 $ n $ 个点处发生跳跃，值域为 $ \\left\\{ 0,\\frac{1}{n},\\frac{2}{n},\\dots,1 \\right\\} $。我们构造 $ S_{0}=\\{ x_{1},\\dots,x_{n} \\}\\cup \\{ x_{\\min}-1 \\} $，大小为 $ n+1 $。这样对于任意 $ x \\in \\mathbb{R} $，其 $ F_{n} $ 值必然等于 $ S_{0} $ 中某一点的 $ F_{n} $ 值，也就是 $ \\exists y\\in S_{0} $，使得 $ F_{n}(x)=F_{n}(y)\\implies d(x,y)=0\u003c \\varepsilon $。从而用 $ n+1 $ 个点实现 $ 0 $ 误差覆盖。\n针对 $ \\frac{2}{\\varepsilon^{2}} $，我们考虑分割值域，将 $ [0,1] $ 分割成长度为 $ \\varepsilon^{2} $ 的小区间。令 $ m=\\left\\lceil \\frac{1}{\\varepsilon^{2}} \\right\\rceil $，构造区间 $ J_{k}=[(k-1)\\varepsilon^{2},k\\varepsilon^{2}],k\\in[m] $。设 $ F_{n}(x) $ 的值域为 $ U $，对于每一个区间 $ J_{K} $，如果和 $ U $ 存在交集，那么就从其中随机选择一个点加入 $ S_{\\varepsilon} $，这样一共选出了 $ m $ 个点。由于 $$ \\left| S_{\\varepsilon} \\right| \\leq \\left\\lceil \\frac{1}{\\varepsilon^{2}} \\right\\rceil \u003c \\frac{1}{\\varepsilon^{2}} + 1 \\leq \\frac{2}{\\varepsilon^{2}} $$ 因此这时集合大小不超过 $ \\frac{2}{\\varepsilon^{2}} $。\n这时对于任意 $ x \\in \\mathbb{R} $，$ F_n(x) $ 必然落在某个区间 $ J_k $ 中。因为 $ F_n(x) $ 存在，所以 $ J_k \\cap U $ 非空，我们在 $ S_\\varepsilon $ 中一定选了一个对应的代表 $ y_k $。 此时，$ F_n(x) $ 和 $ F_n(y_k) $ 都在长度为 $ \\varepsilon^2 $ 的区间 $ J_k $ 内，所以 $$ |F_n(x) - F_n(y_k)| \\le \\varepsilon^2 \\implies d(x,y_{k})=\\sqrt{ \\left| F_{n}(x)-F_{n}(y_{k}) \\right| }\\leq \\sqrt{ \\varepsilon^{2} }=\\varepsilon $$ 综上，取 $ n+1 $ 和 $ \\frac{2}{\\varepsilon^{2}} $ 无论哪个集合，均能满足条件，证毕。\n(3)\n根据定义，有 $ d(x,y_{k}(x))\\leq \\varepsilon_{k},d(x,y_{k-1}(x))\\leq\\varepsilon_{k-1} $。那么根据三角不等式，就有 $$ d(y_{k-1}(x),y_{k}(x)) \\leq d(y_{k-1}(x),x) + d(x,y_{k}(x)) \\leq \\varepsilon_{k-1}+\\varepsilon_{k} $$ 其中 $ \\varepsilon_{k-1}+\\varepsilon_{k}=3\\cdot 2^{-k} $。\n确界 $ \\sup_{x \\in \\mathbb{R}} $ 实际上只需要在覆盖集 $ S_{\\varepsilon_k} $ 和 $ S_{\\varepsilon_{k-1}} $ 的元素对中寻找。定义集合 $ A = \\{ (u, v) : u \\in S_{\\varepsilon_{k}}, v \\in S_{\\varepsilon_{k-1}}, d(u, v) \\le 3 \\cdot 2^{-k} \\} $，根据包含关系，原式中的 $ \\sup $ 肯定被 $ A $ 中的最大值控制，也就是 $$ \\sup_{x \\in \\mathbb{R}} \\left| Z_{y_{k-1}(x)}-Z_{y_{k}(x)} \\right| \\leq \\max_{(u,v)\\in A}\\left| Z_{u}-Z_{v} \\right| $$ 我们考虑 $ A $ 的集合大小。根据 $ 4.(2) $ 中的结论，有 $$ \\left| A \\right| \\leq \\left| S_{\\varepsilon_{k}} \\right| \\cdot \\left| S_{\\varepsilon_{k-1}} \\right| \\leq \\frac{2}{(2^{-k})^{2}}\\cdot \\frac{2}{(2^{-(k-1)})^{2}} = 2\\cdot 4^{k}\\cdot 2 \\cdot 4^{k-1} = 4^{2k} $$ 根据第 $ 3 $ 问的结论，化简得到 $ \\frac{Z_{u}-Z_{v}}{\\sqrt{ n }\\cdot d(u,v)} $ 是一个参数为 $ 1 $ 的次高斯变量，从而 $ Z_{u}-Z_{v} $ 是一个参数为 $ \\sigma_{u,v}=\\sqrt{ n }\\cdot d(u,v) $ 的次高斯变量。根据条件就有 $ \\sigma_{\\max}\\leq \\sqrt{ n }\\cdot 3 \\cdot 2^{-k} $。共有 $ \\left| A \\right| $ 个次高斯变量，那么根据 $ 21(2) $，就有 $$ \\begin{align*} \\mathbf{E}[\\max_{(u,v)\\in A}\\left| Z_{u}-Z_{v} \\right| ] \u0026 \\leq C\\cdot \\sqrt{ \\ln \\left| A \\right| }\\cdot \\sigma_{\\max} \\\\ \u0026 \\leq C\\cdot \\sqrt{ 2k\\cdot \\ln 4 } \\cdot (3\\sqrt{ n } \\cdot 2^{-k}) \\\\ \u0026 = (3\\sqrt{ 2 \\ln 4 }C)\\cdot \\sqrt{ n }\\cdot \\sqrt{ k }\\cdot 2^{-k} \\end{align*} $$ 令 $ C'=3\\sqrt{ 2 \\ln 4 }C $，也是一个和 $ n,k $ 无关的常数，从而就得到了 $$ \\mathbf{E} \\left[ \\frac{1}{\\sqrt{n}} \\sup_{x \\in \\mathbb{R}} |Z_{y_{k-1}(x)} - Z_{y_k(x)}| \\right] \\le \\frac{1}{\\sqrt{n}} \\cdot C' \\sqrt{n} \\sqrt{k} 2^{-k} = C' \\sqrt{k} 2^{-k} $$\n(4)\n#TODO\n(5)\n首先我们证明 $$ \\mathbf{E}\\left[ \\sup_{x \\in \\mathbb{R}}\\left| \\frac{1}{\\sqrt{ n }} Z_{x} \\right| \\right] \\leq 2 + 2C' $$ 根据 $ 4.(2) $，对于 $ \\varepsilon_{k}=2^{-k} $，存在集合 $ S_{\\varepsilon_{k}} $。对于任意 $ x $，设 $ y_{k}(x) $ 为 $ S_{\\varepsilon_{k}} $ 中距离 $ x $ 最近的点。\n考虑截断法。令 $ k^{*} $ 为满足 $ \\varepsilon_{k}\u003c \\frac{1}{n} $ 的最小的 $ k $。当 $ k \\ge k^* $ 时，由于 $ d(x, y_k(x)) \u003c \\frac{1}{n} \u003c \\frac{1}{\\sqrt{n}} $，这意味着对于当前的固定样本，$ \\mathbb{I}_{x_i \\le x} $ 与 $ \\mathbb{I}_{x_i \\le y_k(x)} $ 完全一致，因此 $ Z_x = Z_{y_{k^*}(x)} $。 利用裂项求和 $$ Z_{x} = Z_{y_{0}(x)} + \\sum_{k=1}^{k^{*}} (Z_{y_{k}(x)} - Z_{y_{k-1}(x)}) $$ 两边取绝对值，除以 $ \\sqrt{n} $、取上确界并求期望 $$ \\mathbf{E}\\left[ \\sup_{x} \\left| \\frac{Z_{x}}{\\sqrt{n}} \\right| \\right] \\le \\mathbf{E}\\left[ \\sup_{x} \\frac{|Z_{y_{0}(x)}|}{\\sqrt{n}} \\right] + \\sum_{k=1}^{\\infty} \\mathbf{E}\\left[ \\sup_{x} \\frac{|Z_{y_{k}(x)} - Z_{y_{k-1}(x)}|}{\\sqrt{n}} \\right] $$ 对于 $ k=0 $，根据 $ 4.(4) $ 的结论 $ \\mathbf{E}[|Z_x|] \\le 2\\sqrt{n} $。从而 $$ \\mathbf{E}\\left[ \\sup_{x} \\frac{|Z_{y_{0}(x)}|}{\\sqrt{n}} \\right] = \\frac{1}{\\sqrt{n}}\\mathbf{E}[|Z_{y_{0}}|] \\le \\frac{2\\sqrt{n}}{\\sqrt{n}} = 2 $$ 利用 $ 4.(3) $ 的结论 $ \\mathbf{E}[\\dots]\\leq C'\\sqrt{ k }2^{-k} $，有 $$ \\sum_{k=1}^{\\infty} \\mathbf{E}\\left[ \\sup_{x} \\frac{|Z_{y_{k}(x)} - Z_{y_{k-1}(x)}|}{\\sqrt{n}} \\right] \\le \\sum_{k=1}^{\\infty} C' \\sqrt{k} 2^{-k} = C' \\sum_{k=1}^{\\infty} \\sqrt{k} 2^{-k} $$ 由于级数 $ \\sum_{k=1}^{\\infty} \\sqrt{k} 2^{-k} $ 收敛且和小于 $ 2 $，故上式 $ \\le 2C' $。\n合并就得到了 $$ \\mathbf{E}\\left[ \\sup_{x \\in \\mathbb{R}}\\left| \\frac{1}{\\sqrt{ n }} Z_{x} \\right| \\right] \\le 2 + 2C' $$ 根据 $ 2.(2) $ 的结论，有 $$ \\begin{aligned} \\mathbf{E}\\left[ \\sup_{x}|F_{n}(x) - F(x)| \\right] \u0026 \\le \\frac{2}{n} \\mathbf{E}\\left[ \\sup_{x} \\left| \\sum_{i=1}^{n} \\varepsilon_{i} \\mathbb{I}_{X_{i} \\le x} \\right| \\right] \\\\ \u0026 = \\frac{2}{\\sqrt{n}} \\mathbf{E}\\left[ \\sup_{x} \\left| \\frac{1}{\\sqrt{n}} Z_{x} \\right| \\right] \\\\ \u0026 \\le \\frac{2}{\\sqrt{n}} (2 + 2C') = \\frac{4 + 4C'}{\\sqrt{n}} \\end{aligned} $$ 令 $ C''=4+4C' $，与 $ n $ 无关，即证 $$ \\mathbf{E}\\left[ \\sup_{x \\in \\mathbb{R}}|F_{n}(x) - F(x)| \\right] \\le \\frac{C''}{\\sqrt{n}} $$\n","permalink":"https://diefish1024.github.io/posts/class-notes/math2701-probability-theory/math2701-hw7/","summary":"\u003ch2 id=\"problem-1\"\u003eProblem 1\u003c/h2\u003e\n\u003cp\u003e\u003cstrong\u003e(1)\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e总共有 $ N=\\binom{ n }{ 2 } $ 对点。设 $ X_{ij}=\\mathbb{I}[(i,j)\\in E_{n}] $。那么 $ \\mathbf{E}[X_{ij}]=p $。并且\n$$ \n\n\\left| E_{n} \\right| = \\sum_{1\\leq i\u003c j\\leq n} X_{i}\n\n $$\n由于边与边之间独立，因此 $ X_{i} $ 是独立同分布，并且可积，那么根据强大数定律，就有\n$$ \n\n\\dfrac{\\sum X_{i}}{N} = \\dfrac{\\left| E_{n} \\right| }{\\binom{ n }{ 2 } } \\xrightarrow{a.s.} \\mathbf{E}[X_{i}]=p\n\n $$\n\u003cstrong\u003e(2)\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e设 $ \\mathcal{C}_n $ 为 $ V_n $ 中所有大小为 $ 3 $ 的子集的集合，也就是所有无序三元组 $ \\{i, j, k\\} $。集合大小 $ |\\mathcal{C}_n| = \\binom{n}{3} $。\u003c/p\u003e","title":"MATH2701 HW7"},{"content":"Exercise 1 根据分块对角矩阵的性质，秩等于对角线上各个子块的秩之和，因此 $$ \\text{rank}(AB)+n = \\text{rank}\\left(\\begin{bmatrix} AB \u0026 0 \\\\ 0 \u0026 I \\end{bmatrix}\\right) $$ 接着由于初等列变换不改变矩阵的秩，将第二列右乘 $ B $ 加到第一列得到 $$ \\text{rank}\\left(\\begin{bmatrix} AB \u0026 0 \\\\ 0 \u0026 I \\end{bmatrix}\\right) = \\text{rank}\\left(\\begin{bmatrix} AB \u0026 0 \\\\ B \u0026 I \\end{bmatrix}\\right) $$ 同样由于初等行变换也不改变矩阵的秩，将第二行左乘 $ A $ 再和第一行相减，得到 $$ \\text{rank}\\left(\\begin{bmatrix} AB \u0026 0 \\\\ B \u0026 I \\end{bmatrix}\\right) = \\text{rank}\\left(\\begin{bmatrix} 0 \u0026 -A \\\\ B \u0026 I \\end{bmatrix}\\right) $$ 交换上下两行，得到 $$ \\text{rank}\\left(\\begin{bmatrix} 0 \u0026 -A \\\\ B \u0026 I \\end{bmatrix}\\right) = \\text{rank}\\left(\\begin{bmatrix} B \u0026 I \\\\ 0 \u0026 -A \\end{bmatrix}\\right) $$ 第二行乘以 $ -1 $ 就得到了 $$ \\text{rank}\\left(\\begin{bmatrix} B \u0026 I \\\\ 0 \u0026 -A \\end{bmatrix}\\right) = \\text{rank}\\left(\\begin{bmatrix} B \u0026 -I \\\\ 0 \u0026 A \\end{bmatrix}\\right) $$ 再根据上三角分块矩阵的性质，就有 $$ \\text{rank}\\left(\\begin{bmatrix} B \u0026 -I \\\\ 0 \u0026 A \\end{bmatrix}\\right) \\geq \\text{rank}(A) + \\text{rank}(B) $$\nExercise 2 设 $ \\dim(U) = n $, $ \\dim(V) = m $, $ \\dim(W) = p $。 对应矩阵为 $ A $ (代表 $ T $) 和 $ B $ (代表 $ S $)。那么我们有 $$ \\text{rank}(AB) \\ge \\text{rank}(A) + \\text{rank}(B) - m $$ 对于 $ S $，有 $ \\text{rank}(B)=n-\\text{dim}(\\text{Ker}(S)) $。对于 $ T $，有 $ \\text{rank}(A)=m-\\text{dim}(\\text{Ker}(T)) $。对于 $ TS $，这是一个 $ U\\to W $ 的映射，对应矩阵为 $ AB $，那么 $ \\text{rank}(AB)=n-\\text{dim}(\\text{Ker}(TS)) $。带入就得到了 $$ n-\\text{dim}(\\text{Ker}(TS)) \\geq n - \\text{dim}(\\text{Ker}(S)) + m - \\text{dim}(\\text{Ker}(T)) - m $$ 化简就得到了 $$ \\text{dim}(\\text{Ker}(S)) + \\text{dim}(\\text{Ker}(T)) \\leq \\text{dim}(\\text{Ker}(TS)) $$\nExercise 3 (1)\n设线性变换 $ \\phi: W \\to \\mathbb{R}^m $ 为关于基 $ \\bar{w} $ 的双射。由线性变换的性质可知，像空间 $ \\text{Im}(T) $ 由 $ V $ 中基向量的像 $ \\{T(v_1), \\dots, T(v_n)\\} $ 生成；而根据矩阵表示的定义，$ A_T $ 的列空间 $ \\text{Col}(A_T) $ 正是由这些像对应的坐标向量 $ \\{\\phi(T(v_1)), \\dots, \\phi(T(v_n))\\} $ 生成。\n由于 $ \\phi $ 是线性同构，它将由一组向量张成的子空间 $ \\text{Im}(T) $ 双射地映射为由其坐标向量张成的子空间 $ \\text{Col}(A_T) $，且在此过程中保持维数不变，即 $$ \\dim(\\text{Im}(T)) = \\dim(\\phi(\\text{Im}(T))) = \\dim(\\text{Col}(A_T)) $$ 结合矩阵秩的定义 $ \\text{rank}(A_T) = \\dim(\\text{Col}(A_T)) $，即得 $ \\dim(\\text{Im}(T)) = \\text{rank}(A_T) $。\n(2)\n根据秩-零化度定理，有 $$ \\text{dim}(V) = \\text{dim}(\\text{Ker}(T)) + \\text{dim}(\\mathrm{Im}(T)) $$ 如果 $ T $ 是单射，那么 $ \\text{Ker}(T)=\\{ 0 \\} $，从而 $ \\text{dim}(\\text{Ker}(T))=0 $。带入就得到了 $$ \\text{dim(V)} = \\text{dim}(\\mathrm{Im}(T)) = \\text{rank}(A_{T}) $$ 如果 $ T $ 是满射，那么 $ \\mathrm{Im}(T)=W $，从而 $ \\text{dim}(\\mathrm{Im}(T))=\\text{dim}(W) $，带入 $ (1) $ 就得到了 $$ \\text{dim}(W) = \\text{rank}(A_{T}) $$\nExercise 4 设泛函 $ L\\in V' $ 为 $ L:V\\to \\mathbb{F} $，其中 $ \\mathbb{F} $ 是标量域。由于 $ \\text{dim}(\\mathbb{F})=1 $，并且 $ \\mathrm{Im}(L)\\leq\\text{dim}(\\mathbb{F}) $，那么就有 $ \\text{dim}(\\mathrm{Im}(L))=0 $ 或者 $ \\text{dim}(\\mathrm{Im}(L))=1 $。\n如果 $ \\text{dim}(\\mathrm{Im}(L))=0 $，那么也就是只有 $ \\{0\\} $。这时 $ \\text{Im}(L) = \\{0\\} $，意味着 $ L $ 是零映射。\n如果 $ \\text{dim}(\\mathrm{Im}(L))=1 $，也就是 $ \\mathbb{F} $ 本身。这时 $ \\text{Im}(L) = \\mathbb{F} $，意味着 $ L $ 是满射。\n","permalink":"https://diefish1024.github.io/posts/class-notes/math1205h-linear-algebra/math1205h-hw19/","summary":"\u003ch2 id=\"exercise-1\"\u003eExercise 1\u003c/h2\u003e\n\u003cp\u003e根据分块对角矩阵的性质，秩等于对角线上各个子块的秩之和，因此\n$$ \n\n\\text{rank}(AB)+n = \\text{rank}\\left(\\begin{bmatrix}\nAB \u0026 0 \\\\ 0 \u0026 I\n\\end{bmatrix}\\right)\n\n $$\n接着由于初等列变换不改变矩阵的秩，将第二列右乘 $ B $ 加到第一列得到\n$$ \n\n\\text{rank}\\left(\\begin{bmatrix}\nAB \u0026 0 \\\\ 0 \u0026 I\n\\end{bmatrix}\\right) = \\text{rank}\\left(\\begin{bmatrix}\nAB \u0026 0 \\\\ B \u0026 I\n\\end{bmatrix}\\right)\n\n $$\n同样由于初等行变换也不改变矩阵的秩，将第二行左乘 $ A $ 再和第一行相减，得到\n$$ \n\n\\text{rank}\\left(\\begin{bmatrix}\nAB \u0026 0 \\\\ B \u0026 I\n\\end{bmatrix}\\right) = \\text{rank}\\left(\\begin{bmatrix}\n0 \u0026 -A \\\\ B \u0026 I\n\\end{bmatrix}\\right)\n\n $$\n交换上下两行，得到\n$$ \n\n\\text{rank}\\left(\\begin{bmatrix}\n0 \u0026 -A \\\\ B \u0026 I\n\\end{bmatrix}\\right) = \\text{rank}\\left(\\begin{bmatrix}\nB \u0026 I \\\\ 0 \u0026 -A\n\\end{bmatrix}\\right)\n\n $$\n第二行乘以 $ -1 $ 就得到了\n$$ \n\n\\text{rank}\\left(\\begin{bmatrix}\nB \u0026 I \\\\ 0 \u0026 -A\n\\end{bmatrix}\\right) = \\text{rank}\\left(\\begin{bmatrix}\nB \u0026 -I \\\\ 0 \u0026 A\n\\end{bmatrix}\\right)\n\n $$\n再根据上三角分块矩阵的性质，就有\n$$ \n\n\\text{rank}\\left(\\begin{bmatrix}\nB \u0026 -I \\\\ 0 \u0026 A\n\\end{bmatrix}\\right) \\geq  \\text{rank}(A) + \\text{rank}(B)\n\n $$\u003c/p\u003e","title":"MATH1205H HW19"},{"content":"Exercise 1 (1)\n对于任意标量 $ c $ 和向量 $ x,y\\in U $，都有 $$ \\begin{align*} TS(cx+y) \u0026 = T(S(cx+y)) \\\\ \u0026 = T(cS(x)+S(y)) \\\\ \u0026 = cT(S(x)) + T(S(y)) \\\\ \u0026 = cTS(x) + TS(y) \\end{align*} $$ 从而证明了这是一个线性变换。\n(2)\n设 $ U,V,W $ 的基为 $$ \\bar{u} = \\{ u_{1},\\dots,u_{p} \\},\\bar{v}=\\{ v_{1},\\dots,v_{n} \\},\\bar{w}=\\{ w_{1},\\dots,w_{m} \\} $$ 根据线性变换矩阵的定义，有 $$ S(u_{i}) = \\sum_{k=1}^{n} (A_{S})_{k,i}v_{k},\\quad T(v_{i})=\\sum_{k=1}^{m} (A_{T})_{k,i}w_{k} $$ 计算 $ TS(u_{i}) $ 并观察系数 $$ \\begin{align*} TS(u_{j}) \u0026 = T(S(u_{j})) \\\\ \u0026 = T\\left( \\sum_{k=1}^{n} (A_{S})_{k,j}v_{k} \\right) \\\\ \u0026 = \\sum_{k=1}^{n} (A_{S})_{k,j}T(v_{k}) \\\\ \u0026 = \\sum_{k=1}^{n} (A_{S})_{k,j}\\left( \\sum_{i=1}^{m} (A_{T})_{i,k}w_{i} \\right) \\\\ \u0026 = \\sum_{i=1}^{m} \\left( \\sum_{k=1}^{n} (A_{T})_{i,k}(A_{S})_{k,j} \\right)w_{i} \\\\ \u0026 = \\sum_{i=1}^{m} (A_{T}A_{S})_{i,j}w_{i} \\end{align*} $$ 再结合 $ A_{TS} $ 的定义就证明了 $$ A_{TS}=A_{T}A_{S} $$\nExercise 2 (1)\n分别验证满足线性性 $$ \\begin{align*} (T+T')(cx+y) \u0026 =T(cx+y)+T'(cx+y) \\\\ \u0026 = T(cx)+T(y)+T'(cx)+T'(y) \\\\ \u0026 = cT(x)+T(y)+cT'(x)+T'(y) \\\\ \u0026 =c(T+T')(x)+(T+T')(y) \\end{align*} $$ 以及 $$ \\begin{align*} (cT)(dx+y) \u0026 = c(T(dx+y)) \\\\ \u0026 = c(T(dx)+T(y)) \\\\ \u0026 = c(dT(x)+T(y)) \\\\ \u0026 = d(cT)(x) + (cT)(y) \\end{align*} $$ 从而对线性运算封闭，都是线性变换。\n(2)\n要证明 $ T(V,W) $ 构成向量空间，需验证其满足封闭性（已在 (1) 中得证）及 8 条公理。由于运算是逐点定义在目标空间 $ W $ 上的，而 $ W $ 本身是向量空间，因此结合律、交换律、分配律等性质自然继承。\n我们需要证明零元和逆元的存在：\n零向量：存在 $ T_0 \\in T(V,W) $，定义为对于任意 $ v \\in V $，$ T_0(v) = \\vec{0}_W $。显然 $ T + T_0 = T $。\n加法逆元：对于任意 $ T $，定义 $ (-T)(v) = -(T(v)) $。显然 $ T + (-T) = T_0 $。\n综上，结合 (1) 中的封闭性，$ T(V,W) $ 构成向量空间。\n(3)\n由线性变换的基本定理，线性变换 $ T $ 由其在基向量上的作用唯一确定。 设 $ V $ 的基为 $ v_1, \\dots, v_n $， $ W $ 的基为 $ w_1, \\dots, w_m $。 对于每一个 $ v_j $，我们可以任意指定其像 $ T(v_j) \\in W $。 由于 $ W $ 是 $ m $ 维的，选择一个 $ T(v_j) $ 相当于选择了 $ m $ 个坐标标量。 共有 $ n $ 个基向量 $ v_j $ 需要确定，且它们的选择是独立的。 因此，总的自由度（即维数）为 $$ \\text{dim}(T(V,W))=m\\times n $$ (4)\n定义映射 $ \\Phi: T(V,W) \\rightarrow M_{m\\times n}(\\mathbb{R}) $ 为 $ \\Phi(T) = A_T $。设 $ T, S \\in T(V,W) $，$ c \\in \\mathbb{R} $。\n加法：考察矩阵 $ A_{T+S} $ 的第 $ j $ 列，其定义为 $ (T+S)(v_j) $ 在 $ W $ 基下的坐标 $$ [(T+S)(v_j)]_{\\overline{w}} = [T(v_j) + S(v_j)]_{\\overline{w}} = [T(v_j)]_{\\overline{w}} + [S(v_j)]_{\\overline{w}} $$ 这表明 $ A_{T+S} $ 的每一列都是 $ A_T $ 和 $ A_S $ 对应列的和。根据矩阵加法定义 $$ A_{T+S} = A_T + A_S \\implies \\Phi(T+S) = \\Phi(T) + \\Phi(S) $$\n数乘：考察矩阵 $ A_{cT} $ 的第 $ j $ 列： $$ [(cT)(v_j)]_{\\overline{w}} = [c \\cdot T(v_j)]_{\\overline{w}} = c \\cdot [T(v_j)]_{\\overline{w}} $$ 这表明 $ A_{cT} $ 的每一列都是 $ A_T $ 对应列的 $ c $ 倍。根据矩阵数乘定义： $$ A_{cT} = c A_T \\implies \\Phi(cT) = c \\Phi(T) $$ 故该映射为线性变换。\nExercise 3 根据过渡矩阵定义，新基 $ v' $ 是旧基 $ v $ 的线性组合：$ v'_j = \\sum_{i=1}^n M_{ij} v_i $。 对 $ v'_j $ 施加 $ T $，就有 $$ T(v'_j) = T(\\sum_{i} M_{ij} v_i) = \\sum_{i} M_{ij} T(v_i) $$ 这正是矩阵乘法 $ [T(v_1)\\dots T(v_n)] \\times M_{j} $。将所有结果合并即可，证毕。\nExercise 4 我们需要计算 $ T_{id} $ 作用在定义域基向量 $ v'_j $ 上，并表示为值域基 $ v $ 的坐标。 $$ T_{id}(v'_j) = v'_j $$ 因为 $ M $ 是 $ v \\to v' $ 的过渡矩阵，意味着 $ v'_j = \\sum_{i} M_{ij} v_i $。\n所以 $ v'_j $ 在基 $ v $ 下的坐标正是 $ M $ 的第 $ j $ 列。因此该矩阵就是 $ M $。\nExercise 5 定义矩阵 $ V = [v_1, v_2, v_3] $ 和 $ V' = [v'_1, v'_2, v'_3] $。\n过渡矩阵 $ M $ 满足 $ V' = VM $（即 $ v'_j $ 在 $ v $ 下的坐标），解得 $ M = V^{-1}V' $。\n经过高斯消元得到\n$$ M = \\begin{pmatrix} -2 \u0026 -1.5 \u0026 1.5 \\\\ 1 \u0026 1.5 \u0026 1.5 \\\\ 1 \u0026 0.5 \u0026 -2.5 \\end{pmatrix} $$ 计算各情形下的矩阵 $ A_T $。\nCase 1：基 $ \\overline{v} \\to \\overline{v} $\n第 $ j $ 列为 $ [T(v_j)]_{\\overline{v}} $。$ [T(v_j)]_{\\overline{v}} = [v'_j]_{\\overline{v}} $。这正是 $ M $ 的定义。\n$$ A_1 = M = \\begin{pmatrix} -2 \u0026 -1.5 \u0026 1.5 \\\\ 1 \u0026 1.5 \u0026 1.5 \\\\ 1 \u0026 0.5 \u0026 -2.5 \\end{pmatrix} $$ Case 2： 基 $ \\overline{v} \\to \\overline{v}' $\n第 $ j $ 列为 $ [T(v_j)]_{\\overline{v}'} $。$ [T(v_j)]_{\\overline{v}'} = [v'_j]_{\\overline{v}'} $。向量在自身基下的坐标为标准单位向量 $ e_j $。 $$ A_2 = I = \\begin{pmatrix} 1 \u0026 0 \u0026 0 \\\\ 0 \u0026 1 \u0026 0 \\\\ 0 \u0026 0 \u0026 1 \\end{pmatrix} $$\nCase 3： 基 $ \\overline{v}' \\to \\overline{v} $\n第 $ j $ 列为 $ [T(v'_j)]_{\\overline{v}} $。由于 $ T(v_k)=v'_k $，且 $ T $ 是线性的，则 $ T $ 将 $ v $ 空间的向量映射为 $ v' $ 空间中具有相同系数的向量。 $$ [T(v'_j)]_{\\overline{v}} = [T(\\sum_k M_{kj}v_k)]_{\\overline{v}} = [\\sum_k M_{kj}T(v_k)]_{\\overline{v}} = [\\sum_k M_{kj}v'_k]_{\\overline{v}} $$ 这相当于用 $ M $ 对 $ M $ 的列再做一次线性组合，即 $ A_3 = M \\cdot M = M^2 $。\n$$ A_3 = M^2 = \\begin{pmatrix} 4 \u0026 1.5 \u0026 -9 \\\\ 1 \u0026 1.5 \u0026 0 \\\\ -4 \u0026 -2 \u0026 8.5 \\end{pmatrix} $$ Case 4： 基 $ \\overline{v}' \\to \\overline{v}' $\n第 $ j $ 列为 $ [T(v'_j)]_{\\overline{v}'} $。$ [T(v'_j)]_{\\overline{v}'} = [\\sum_k M_{kj} v'_k]_{\\overline{v}'} $。其坐标即为 $ M $ 的第 $ j $ 列。\n$$ A_4 = M = \\begin{pmatrix} -2 \u0026 -1.5 \u0026 1.5 \\\\ 1 \u0026 1.5 \u0026 1.5 \\\\ 1 \u0026 0.5 \u0026 -2.5 \\end{pmatrix} $$ Exercise 6 设 $ x $ 为 $ V $ 中向量的坐标，$ y $ 为 $ W $ 中向量的坐标。\n对于 $ x $，变换后的坐标 $ x' $ 满足 $ x=Mx' $。对于 $ y $，变换后的坐标 $ y' $ 满足 $ y=Ny'\\implies y'=N^{-1}y $。根据线性变换关系，有 $$ y=A_{1}x,y'=A_{2}x' $$ 带入就得到了 $$ y'=N^{-1}y=N^{-1}(A_{1}x)=N^{-1}A_{1}Mx' $$ 从而证明了 $$ A_{2}=N^{-1}A_{1}M $$\n","permalink":"https://diefish1024.github.io/posts/class-notes/math1205h-linear-algebra/math1205h-hw18/","summary":"\u003ch2 id=\"exercise-1\"\u003eExercise 1\u003c/h2\u003e\n\u003cp\u003e\u003cstrong\u003e(1)\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e对于任意标量 $ c $ 和向量 $ x,y\\in U $，都有\n$$ \n\n\\begin{align*}\nTS(cx+y) \u0026 = T(S(cx+y)) \\\\\n \u0026 = T(cS(x)+S(y)) \\\\\n \u0026 = cT(S(x)) + T(S(y)) \\\\\n \u0026 = cTS(x) + TS(y)\n\\end{align*}\n\n $$\n从而证明了这是一个线性变换。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e(2)\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e设 $ U,V,W $ 的基为\n$$ \n\n\\bar{u} = \\{ u_{1},\\dots,u_{p} \\},\\bar{v}=\\{ v_{1},\\dots,v_{n} \\},\\bar{w}=\\{ w_{1},\\dots,w_{m} \\}\n\n $$\n根据线性变换矩阵的定义，有\n$$ \n\nS(u_{i}) = \\sum_{k=1}^{n} (A_{S})_{k,i}v_{k},\\quad T(v_{i})=\\sum_{k=1}^{m} (A_{T})_{k,i}w_{k}\n\n $$\n计算 $ TS(u_{i}) $ 并观察系数\n$$ \n\n\\begin{align*}\nTS(u_{j}) \u0026 = T(S(u_{j})) \\\\\n \u0026 = T\\left( \\sum_{k=1}^{n} (A_{S})_{k,j}v_{k} \\right) \\\\\n \u0026 = \\sum_{k=1}^{n} (A_{S})_{k,j}T(v_{k}) \\\\\n \u0026 = \\sum_{k=1}^{n} (A_{S})_{k,j}\\left( \\sum_{i=1}^{m} (A_{T})_{i,k}w_{i} \\right) \\\\\n \u0026 = \\sum_{i=1}^{m} \\left( \\sum_{k=1}^{n} (A_{T})_{i,k}(A_{S})_{k,j} \\right)w_{i} \\\\\n \u0026 = \\sum_{i=1}^{m} (A_{T}A_{S})_{i,j}w_{i}\n\\end{align*}\n\n $$\n再结合 $ A_{TS} $ 的定义就证明了\n$$ \n\nA_{TS}=A_{T}A_{S}\n\n $$\u003c/p\u003e","title":"MATH1205H HW18"},{"content":"Exercise 1 设 $ A $ 的特征多项式为 $ P(\\lambda) = \\det(A-\\lambda I) $。由于特征值 $ \\lambda_{1},\\lambda_{2},\\dots,\\lambda_{n} $ 是 $ P(\\lambda) $ 的根，因此 $$ P(\\lambda) = (-1)^{n}(\\lambda-\\lambda_{1})(\\lambda-\\lambda_{2})\\dots(\\lambda-\\lambda_{n}) $$ 我们首先证明 $ \\prod_{i=1}^{n}\\lambda_{i}=\\det(A) $。首先直接带入 $$ P(0)=\\det(A-0\\cdot I)=\\det A $$ 又有 $$ P(0) = (-1)^{n}(0-\\lambda_{1})(0-\\lambda_{2})\\dots(0-\\lambda_{n})=\\prod_{i=1}^{n} \\lambda_{i} $$ 这样就得到了 $ \\prod_{i=1}^{n}\\lambda_{i}=\\det(A) $。\n接着证明 $ \\sum_{i=1}^{n}\\lambda_{i}=\\mathrm{trace}(A) $。展开 $ P(\\lambda) $ 考察 $ \\lambda^{n-1} $ 的系数，为 $$ (-1)^{n}\\cdot \\sum_{i=1}^{n} (-\\lambda_{i}) = (-1)^{n+1}\\sum_{i=1}^{n} \\lambda_{i} $$ 同时对于矩阵 $ M=A-\\lambda I $，利用行列式定义，有 $$ \\det(A-\\lambda I)=\\sum_{\\sigma \\in S_{n}}\\text{sgn}(n)\\prod_{i=1}^{n} (A-\\lambda I)_{i,\\sigma(i)} $$ 其中 $ S_{n} $ 表示 $ [n] $ 中所有置换的集合。\n考虑其中 $ \\lambda^{n-1} $ 的系数。矩阵 $ A-\\lambda I $ 中包含 $ \\lambda $ 的元素都在对角线上。由于只要 $ \\sigma $ 不是恒等置换，那么乘积中至少包含两个非对角线元素，从而最多只包含 $ n-2 $ 个 $ \\lambda $，乘积不可能含有 $ \\lambda^{n-1} $。从而只有在 $ \\sigma $ 为恒等置换时乘积才有可能包含 $ \\lambda^{n-1} $ 的项。从而展开 $$ \\begin{align*} \\prod_{i=1}^{n} (A-\\lambda I)_{i,i} \u0026 = \\prod_{i=1}^{n} (a_{i,i}-\\lambda) \\\\ \u0026 = (-1)^{n}\\lambda^{n}+(-1)^{n-1}\\left( \\sum_{i=1}^{n} a_{i,i} \\right)\\lambda^{n-1}+\\dots \\\\ \\end{align*} $$ 得到其中 $ \\lambda^{n-1} $ 的系数为 $ \\sum_{i=1}^{n}a_{i,i} $ 也就是 $ (-1)^{n-1}\\mathrm{trace}(A) $。比较系数，就得到了 $$ (-1)^{n+1}\\sum_{i=1}^{n} \\lambda_{i} = (-1)^{n-1}\\sum_{i=1}^{n}\\mathrm{trace}(A)\\implies \\sum_{i=1}^{n} \\lambda_{i}=\\mathrm{trace}(A) $$ 证毕。\nExercise 2 设 $ \\{ e_{1},e_{2},\\dots,e_{n} \\} $ 是 $ \\mathbb{R}^{n} $ 的标准基。构造矩阵 $ A $，它的第 $ j $ 列为 $ T(e_{j}) $，也就是 $$ A = (T(e_{1}),T(e_{2}),\\dots,T(e_{n})) $$ 对于任意 $ x \\in \\mathbb{R}^{n} $，都有 $ x=\\sum_{j=1}^{n}x_{j}e_{j} $，从而 $$ T(x) = T\\left( \\sum_{j=1}^{n} x_{j}e_{j} \\right) = \\sum_{j=1}^{n} x_{j}T(e_{j}) $$ 其中 $ T(e_{j}) $ 也是矩阵 $ A $ 的第 $ j $ 列，从而就有 $$ T(x) = \\sum_{j=1}^{n} x_{j}a_{j} = Ax $$\nExercise 3 要证明这是一个线性变换，我们需要证明 $ T_{A}(M)=AM $ 满足加法和数乘的封闭性。设 $ M_{1},M_{2}\\in M_{m\\times n}(\\mathbb{R}) $ 为任意矩阵，$ c\\in \\mathbb{R} $ 为任意标量。\n加法：根据矩阵乘法的分配律 $$ T_{A}(M_{1}+M_{2}) = A(M_{1}+M_{2}) = AM_{1}+AM_{2} = T_{A}(M_{1}) + T_{A}(M_{2}) $$ 数乘：根据乘法结合律 $$ T_{A}(cM_{1}) = A(cM_{1}) = c(AM_{1}) = cT_{A}(M_{1}) $$ 从而 $ T_{A} $ 是 $ M_{m\\times n}(\\mathbb{R}) $ 到 $ M_{l\\times n}(\\mathbb{R}) $ 的线性变换。\nExercise 4 记行向量组 $ V = [v_1 \\dots v_n] $。\n加法：需证 $ [v_1 \\dots v_n](A+A') = [v_1 \\dots v_n]A + [v_1 \\dots v_n]A' $。考虑结果向量的第 $ j $ 个分量，左边第 $ j $ 项为 $$ = \\sum_{i=1}^n v_i (A+A')_{ij} = \\sum_{i=1}^n v_i (A_{ij} + A'_{ij}) = \\sum_{i=1}^n v_i A_{ij} + \\sum_{i=1}^n v_i A'_{ij} $$ 这正是右边 $ (VA)_j + (VA')_j $ 的定义。\n乘法：需证 $ [v_1 \\dots v_n](AB) = ([v_1 \\dots v_n]A)B $。考虑结果向量的第 $ k $ 个分量。 左边第 $ k $ 项为 $$ \\sum_{i=1}^n v_i (AB)_{ik} = \\sum_{i=1}^n v_i (\\sum_{j=1}^m A_{ij} B_{jk}) $$ 交换求和顺序得到 $$ \\sum_{j=1}^{m} \\left( \\sum_{i=1}^{n} v_{i}A_{ij} \\right)B_{jk} $$ 括号内是 $ VA $ 的第 $ j $ 个分量，从而就说明了上式等于 $ ((VA)B) $ 的第 $ k $ 项。\nExercise 5 设旧基矩阵 $ V = \\begin{bmatrix} 1 \u0026 2 \\\\ 1 \u0026 3 \\end{bmatrix} $，新基矩阵 $ U = \\begin{bmatrix} 4 \u0026 6 \\\\ 5 \u0026 7 \\end{bmatrix} $。\n(1)\n我们需要找到 $ c_1, c_2 $ 使得 $ c_1 \\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix} + c_2 \\begin{bmatrix} 2 \\\\ 3 \\end{bmatrix} = \\begin{bmatrix} x \\\\ y \\end{bmatrix} $。即求解 $ V \\mathbf{c} = \\mathbf{x} $，故 $ \\mathbf{c} = V^{-1} \\mathbf{x} $。 $$ V^{-1} = \\frac{1}{3-2} \\begin{bmatrix} 3 \u0026 -2 \\\\ -1 \u0026 1 \\end{bmatrix} = \\begin{bmatrix} 3 \u0026 -2 \\\\ -1 \u0026 1 \\end{bmatrix} $$ 因此坐标向量为 $$ [\\mathbf{x}]_{\\bar{v}} = \\begin{bmatrix} 3x - 2y \\\\ -x + y \\end{bmatrix} $$ (2)\n从基 $ V $ 变到基 $ U $ 的过渡矩阵 $ P $ 满足 $ UP=V $ ，从而 $ P = U^{-1}V $。\n首先求解 $ U^{-1} $ $$ U^{-1} = \\frac{1}{28-30} \\begin{bmatrix} 7 \u0026 -6 \\\\ -5 \u0026 4 \\end{bmatrix} = -\\frac{1}{2} \\begin{bmatrix} 7 \u0026 -6 \\\\ -5 \u0026 4 \\end{bmatrix} $$ 从而计算 $ P = U^{-1}V $ 得到 $$ P = -\\frac{1}{2} \\begin{bmatrix} 7 \u0026 -6 \\\\ -5 \u0026 4 \\end{bmatrix} \\begin{bmatrix} 1 \u0026 2 \\\\ 1 \u0026 3 \\end{bmatrix} = -\\frac{1}{2} \\begin{bmatrix} 1 \u0026 -4 \\\\ -1 \u0026 2 \\end{bmatrix} = \\begin{bmatrix} -0.5 \u0026 2 \\\\ 0.5 \u0026 -1 \\end{bmatrix} $$\n","permalink":"https://diefish1024.github.io/posts/class-notes/math1205h-linear-algebra/math1205h-hw17/","summary":"\u003ch2 id=\"exercise-1\"\u003eExercise 1\u003c/h2\u003e\n\u003cp\u003e设 $ A $ 的特征多项式为 $ P(\\lambda) = \\det(A-\\lambda I) $。由于特征值 $ \\lambda_{1},\\lambda_{2},\\dots,\\lambda_{n} $ 是 $ P(\\lambda) $ 的根，因此\n$$ \n\nP(\\lambda) = (-1)^{n}(\\lambda-\\lambda_{1})(\\lambda-\\lambda_{2})\\dots(\\lambda-\\lambda_{n})\n\n $$\n我们首先证明 $ \\prod_{i=1}^{n}\\lambda_{i}=\\det(A) $。首先直接带入\n$$ \n\nP(0)=\\det(A-0\\cdot I)=\\det A\n\n $$\n又有\n$$ \n\nP(0) = (-1)^{n}(0-\\lambda_{1})(0-\\lambda_{2})\\dots(0-\\lambda_{n})=\\prod_{i=1}^{n} \\lambda_{i}\n\n $$\n这样就得到了 $ \\prod_{i=1}^{n}\\lambda_{i}=\\det(A) $。\u003c/p\u003e\n\u003cp\u003e接着证明 $ \\sum_{i=1}^{n}\\lambda_{i}=\\mathrm{trace}(A) $。展开 $ P(\\lambda) $ 考察 $ \\lambda^{n-1} $ 的系数，为\n$$ \n\n(-1)^{n}\\cdot \\sum_{i=1}^{n} (-\\lambda_{i}) = (-1)^{n+1}\\sum_{i=1}^{n} \\lambda_{i}\n\n $$\n同时对于矩阵 $ M=A-\\lambda I $，利用行列式定义，有\n$$ \n\n\\det(A-\\lambda I)=\\sum_{\\sigma \\in S_{n}}\\text{sgn}(n)\\prod_{i=1}^{n} (A-\\lambda I)_{i,\\sigma(i)}\n\n $$\n其中 $ S_{n} $ 表示 $ [n] $ 中所有置换的集合。\u003c/p\u003e","title":"MATH1205H HW17"},{"content":"Problem 1 假设有 $ m $ 个俱乐部和 $ n $ 个人，满足以下条件： (i) 每个俱乐部的人数为偶数； (ii) 任意两个俱乐部之间共同拥有的人数为奇数。 证明：$ m \\le n $。\n证：\n我们在有限域 $ \\mathbb{F}_{2} $ 上考虑。设 $ v_{1},\\dots,v_{m}\\in \\mathbb{F}_{2}^{n} $ 为每个俱乐部对应向量。根据条件，我们知道\n人数为偶数：$ v_{i}\\cdot v_{i}=0 $ 交集为奇数：$ v_{i}\\cdot v_{j}=1(i\\neq j) $ 考察这 $ m $ 个向量的线性相关性。假设存在系数 $ c_{1},\\dots c_{m}\\in \\mathbb{F}_{2} $ 使得 $$ \\sum_{i=1}^{m} c_{i}v_{i}=\\mathbf{0} $$ 那么对于任意 $ j\\in [m] $，我们将上式与 $ v_{j} $ 做内积 $$ \\left( \\sum_{i=1}^{m} c_{i}v_{i} \\right)\\cdot v_{j} = c_{j}(v_{j}\\cdot v_{j}) + \\sum_{i\\neq j}c_{i}(v_{i}\\cdot v_{j}) = 0 $$ 带入得到 $$ \\sum_{i\\neq j}c_{i}=0 $$ 由于对于每个 $ j $ 这个条件都要成立，从而 $ c_{j}=\\sum_{i\\in[m]}c_{i} $，这意味着所有的 $ c_{i} $ 都相等，因此要么全为 $ 0 $，要么全为 $ 1 $。若全为 $ 0 $，则线性无关；若全为 $ 1 $，显然与 $ \\sum_{i\\neq j}c_{i}=0 $ 矛盾。\n所以说明 $ v_{1},\\dots,v_{m} $ 线性无关，从而 $ \\text{rank}(v_{1},\\dots,v_{m})= m\\leq n $（向量的维数为 $ n $，利用秩的基本性质）。\nProblem 2 假设有 $ m $ 个俱乐部和 $ n $ 个人，满足以下条件： (i) 每个俱乐部的人数为奇数； (ii) 任意两个俱乐部之间共同拥有的人数为奇数。 证明：$ m \\le 2^{\\lfloor(n-1)/2\\rfloor} $。\n证：\n同样取每个俱乐部对应的向量 $ v_{1},\\dots,v_{m}\\in \\mathbb{F}_{2}^{n} $。取第一个向量 $ v_{1} $，对于所有的 $ i\\in[m] $，构造 $$ u_{i} = (v_{i} + v_{1}) \\in\\mathbb{F}_{2} $$ 特别地，其中 $ u_{1}=v_{1}+v_{1}=\\mathbf{0} $。我们考察 $ U=\\{ u_{1},\\dots,u_{m} \\} $。\n$ U $ 中任意两个向量满足 $$ \\begin{align*} u_{i}\\cdot u_{j} \u0026 = (v_{i}+v_{1})(v_{j}+v_{1}) \\\\ \u0026 = v_{i}\\cdot v_{j} + v_{i}\\cdot v_{1} + v_{j}\\cdot v_{1} + v_{1}\\cdot v_{1} \\\\ \u0026 = 0\\pmod 2 \\end{align*} $$ 从而 $ U $ 中任意两个向量的内积都是 $ 0 $，包括自己和自己的内积。从而 $ U $ 张成的子空间 $ W=\\text{span}\\{ u_{2},\\dots,u_{m} \\} $ 满足 $ W\\subseteq W^{\\perp} $。\n除此之外，这些向量同样和 $ v_{1} $ 正交： $$ u_{i}\\cdot v_{1} = (v_{i}+v_{1})\\cdot v_{1} = 0 $$ 说明 $ W $ 是 $ n $ 维空间中与 $ v_{1} $ 的正交的子空间，其中 $ v_{1} $ 的正交补空间记为 $ V_{1} $，满足 $ \\text{dim}(V_{1})=n-1 $。\n利用秩-零度定理，我们知道 $$ \\text{dim}(W) + \\text{dim}(W^{\\perp}) = \\text{dim}(V_{1})=n-1 $$ 由于 $ W\\subseteq W^{\\perp} $，因此 $$ 2\\text{dim}(W) \\leq \\text{dim}(W) + \\text{dim}(W^{\\perp}) = n-1 $$ 从而 $$ \\text{dim}(W) \\leq \\left\\lfloor \\dfrac{n-1}{2} \\right\\rfloor $$ 由于这时 $ \\mathbb{F}_{2} $ 上的向量，每个自由维度只有个 $ 2 $ 种可能。所以最多只可能有 $$ m \\leq \\left| W \\right| \\leq 2^{\\lfloor (n-1)/2 \\rfloor } $$ 个向量。\nProblem 3 设 $ A, B \\subseteq \\mathbb{R}^3 $ 是三维空间中的两个点集。已知 $ A $ 中任意一点到 $ B $ 中任意一点的距离都相等。 证明：$ \\min\\{|A|, |B|\\} \\le 2 $ （即 $ A $ 和 $ B $ 中至少有一个集合的元素个数不超过 $ 2 $）。\n证：\n设 $ A $ 中的点为 $ \\{ a_{1},a_{2},\\dots, \\} $，$ B $ 中的点为 $ \\{ b_{1},b_{2},\\dots \\} $。根据题意，存在一个常数 $ d $ 使得对于任意 $ a\\in A,b\\in B $，满足 $ \\| a-b \\|^{2}=d^{2} $。\n任取 $ a_{i},a_{j}\\in A,b_{k},b_{l}\\in B $（两个点不相等），那么 $$ \\begin{align*} \\| a_{i}-b_{k} \\| ^{2} \u0026 = \\| a_{i} \\| ^{2} - 2a_{i}\\cdot b_{k} + \\| b_{k} \\| ^{2} = d^{2} \\\\ \\| a_{j}-b_{k} \\| ^{2} \u0026 = \\| a_{j} \\|^{2} - 2a_{j}\\cdot b_{k} + \\| b_{k} \\| ^{2} =d^{2} \\end{align*} $$ 两式相减，得到 $$ 2(a_{i}-a_{j})\\cdot b_{k} = \\| a_{i} \\| ^{2} - \\| a_{j} \\| ^{2} $$ 同理，对于 $ b_{l} $，也有 $$ 2(a_{i}-a_{j})\\cdot b_{l} = \\| a_{i} \\| ^{2} - \\| a_{j} \\| ^{2} $$ 再次相减，就得到了 $$ (a_{i}-a_{j})(b_{k}-b_{l})=0 $$\n这说明 $ A $ 中任意两点构成的向量垂直于 $ B $ 中任意两点构成的向量。不妨设 $ A $ 中任意两点构成的向量组成的空间为 $ V_{A} $，对应 $ B $ 中任意两点之间的向量组成的空间为 $ V_{B} $，那么这说明 $ V_{A}\\perp V_{B} $。\n由于 $ V_{A} $ 和 $ V_{B} $ 都是 $ \\mathbb{R}^{3} $ 的子空间，并且它们正交，说明 $$ \\text{dim}(V_{A}) + \\text{dim}(V_{B}) \\leq 3 $$ 如果 $ \\left| A \\right|\\geq 3 $ 且 $ \\left| B \\right| \\geq 3 $，我们分类讨论。若 $ A $ 中有三个点共线，此时根据简单几何知识，知道 $ B $ 中不可能存在点到这三个点距离相等。\n因此 $ A,B $ 中都满足任意三点不共线。此时 $ V_{A} $ 和 $ V_{B} $ 至少都构成了一个平面，从而 $$ \\text{dim}(V_{A}) + \\text{dim}(V_{B}) \\geq 2 + 2 = 4 $$ 矛盾！\n因此假设不成立，$ A,B $ 不可能同时拥有 $ 3 $ 个及以上的点，即 $$ \\min\\{ \\left| A \\right| ,\\left| B \\right| \\} \\leq 2 $$\n","permalink":"https://diefish1024.github.io/posts/class-notes/cs0901-combinatorics/cs0901-hw9/","summary":"\u003ch2 id=\"problem-1\"\u003eProblem 1\u003c/h2\u003e\n\u003cp\u003e假设有 $ m $ 个俱乐部和 $ n $ 个人，满足以下条件： (i) 每个俱乐部的人数为\u003cstrong\u003e偶数\u003c/strong\u003e； (ii) 任意两个俱乐部之间共同拥有的人数为\u003cstrong\u003e奇数\u003c/strong\u003e。 证明：$ m \\le n $。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e证\u003c/strong\u003e：\u003c/p\u003e\n\u003cp\u003e我们在有限域 $ \\mathbb{F}_{2} $ 上考虑。设 $ v_{1},\\dots,v_{m}\\in \\mathbb{F}_{2}^{n} $ 为每个俱乐部对应向量。根据条件，我们知道\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e人数为偶数：$ v_{i}\\cdot v_{i}=0 $\u003c/li\u003e\n\u003cli\u003e交集为奇数：$ v_{i}\\cdot v_{j}=1(i\\neq j) $\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e考察这 $ m $ 个向量的线性相关性。假设存在系数 $ c_{1},\\dots c_{m}\\in \\mathbb{F}_{2} $ 使得\n$$ \n\n\\sum_{i=1}^{m} c_{i}v_{i}=\\mathbf{0}\n\n $$\n那么对于任意 $ j\\in [m] $，我们将上式与 $ v_{j} $ 做内积\n$$ \n\n\\left( \\sum_{i=1}^{m} c_{i}v_{i} \\right)\\cdot v_{j} = c_{j}(v_{j}\\cdot v_{j}) + \\sum_{i\\neq j}c_{i}(v_{i}\\cdot v_{j}) = 0\n\n $$\n带入得到\n$$ \n\n\\sum_{i\\neq j}c_{i}=0\n\n $$\n由于对于每个 $ j $ 这个条件都要成立，从而 $ c_{j}=\\sum_{i\\in[m]}c_{i} $，这意味着所有的 $ c_{i} $ 都相等，因此要么全为 $ 0 $，要么全为 $ 1 $。若全为 $ 0 $，则线性无关；若全为 $ 1 $，显然与 $ \\sum_{i\\neq j}c_{i}=0 $ 矛盾。\u003c/p\u003e","title":"CS0901 HW9"},{"content":"Problem 1 (1)\n根据泊松分布的定义，我们有 $$ \\mathbb{P}[X=\\lambda+k] = \\dfrac{e^{ -\\lambda }\\lambda^{\\lambda+k}}{(\\lambda+k)!},\\quad \\mathbb{P}[X=\\lambda-k-1] = \\dfrac{e^{ -\\lambda }\\lambda^{\\lambda-k-1}}{(\\lambda-k-1)!} $$ 我们计算两者的比值，有 $$ \\dfrac{\\mathbb{P}[X=\\lambda+k]}{\\mathbb{P}[X=\\lambda-k-1]} = \\dfrac{\\lambda^{2k+1}\\cdot(\\lambda-k-1)!}{(\\lambda+k)!} = \\dfrac{\\lambda^{2k+1}}{(\\lambda+k)(\\lambda+k-1)\\dots(\\lambda-k)} $$ 将分母的乘积左右两两配对，得到 $$ (\\lambda+k)\\dots(\\lambda-k) = \\lambda \\cdot \\prod_{i=1}^{k} (\\lambda^{2}-k^{2}) \u003e \\lambda \\cdot \\prod_{i=1}^{k} \\lambda^{2} = \\lambda^{2k+1} $$ 从而就有 $$ \\dfrac{\\mathbb{P}[X=\\lambda+1]}{\\mathbb{P}[X=\\lambda-k-1]} \\geq 1 \\implies \\mathbb{P}[X=\\lambda+1]\\geq \\mathbb{P}[X=\\lambda-k-1] $$\n接着证明 $ \\mathbb{P}[X\\geq\\lambda]\\geq \\frac{1}{2} $，将事件展开并拆分可以得到 $$ \\begin{align*} \\mathbb{P}[X\\geq \\lambda] \u0026 =\\sum_{k=0}^{\\infty} \\mathbb{P}[X=\\lambda+k] \\\\ \u0026 = \\sum_{k=0}^{\\lambda-1} \\mathbb{P}[X=\\lambda+k] + \\mathbb{P}[X\\geq 2\\lambda] \\\\ \u0026 \\geq \\sum_{k=0}^{\\lambda-1} \\mathbb{P}[X=\\lambda+k] \\end{align*} $$ 我们再考虑 $ \\mathbb{P}[X\u003c \\lambda] $，也就是 $$ \\begin{align*} \\mathbb{P}[X\u003c \\lambda] \u0026 = \\sum_{k=0}^{\\lambda-1} \\mathbb{P}[X=\\lambda-k-1] \\\\ \u0026 \\leq \\sum_{k=0}^{\\lambda-1} \\mathbb{P}[X=\\lambda+k] \\end{align*} $$ 又因为 $ \\mathbb{P}[X\\geq\\lambda]+\\mathbb{P}[X\u003c \\lambda]=1 $，这样就得到了 $$ 1-\\mathbb{P}[X\\geq \\lambda] \\leq \\mathbb{P}[X\\geq \\lambda] \\implies \\mathbb{P}[X\\geq \\lambda] = \\dfrac{1}{2} $$ (2)\n对于 $ \\{ Y \\} $，我们直到所有球的总数 $ M $ 是随机的，并且 $ M\\sim\\text{Pois}(m) $。\n根据全期望公式，我们有 $$ \\mathbb{E}[f(Y_{1},\\dots,Y_{n})] = \\sum_{k=0}^{\\infty} \\mathbb{P}[M=k]\\cdot \\mathbb{E}[f(Y_{1},\\dots,Y_{n})\\mid M=k] $$ 其中在固定 $ M=k $ 时，由于球也是随机扔的，这和固定总数随机放球的情形相同，所以这时 $$ \\mathbb{E}[f(Y_{1},\\dots,Y_{n})\\mid M=k] = \\mathbb{E}[f(\\mathbf{X}^{(k)})] $$ 其中 $ \\mathbf{X}^{(k)} $ 表示固定总数为 $ k $ 个球时的方案。\n由于题设中可知 $ f $ 关于球数是单增的，因此若 $ k\\geq m $，我们就有 $ \\mathbb{E}[f(\\mathbf{X}^{(k)})]\\geq \\mathbb{E}[f(\\mathbf{X}^{(m)})] $。\n我们对 $ \\mathbb{E}[f(\\mathbf{Y})] $ 放缩，只考虑 $ k\\geq m $ 的情形（因为根据第一问知道泊松分布在后一半的概率大于 $ \\frac{1}{2} $），就有 $$ \\begin{align*} \\mathbb{E}[f(\\mathbf{Y})] \u0026 \\geq \\sum_{k=m}^{\\infty} \\mathbb{P}[M=k]\\cdot \\mathbb{E}[f(\\mathbf{Y})\\mid M=k] \\\\ \u0026 = \\sum_{k=m}^{\\infty} \\mathbb{P}[M=k] \\cdot \\mathbb{E}[f(\\mathbf{X}^{(k)})] \\\\ \u0026 \\geq \\mathbb{E}[f(\\mathbf{X}^{(m)})]\\cdot \\mathbb{P}[M\\geq m] \\\\ \u0026 \\geq \\dfrac{1}{2}\\mathbb{E}[f(\\mathbf{X}^{(m)})] \\end{align*} $$ 换回题设中的记号，移项后我们就证明了 $$ \\mathbb{E}[f(X_{1},X_{2},\\dots,X_{n})] \\leq 2\\cdot \\mathbb{E}[f(Y_{1},Y_{2},\\dots,Y_{n})] $$ (3)\n利用 $ (2) $ 的结论。我们定义函数 $$ f(\\mathbf{X}) = \\mathbb{I}(\\text{\\textbf{X} 中存在 5 个学生生日在同一天}) $$ 显然总人数越多，越容易达成这个条件，因此 $ \\mathbb{E}[f] $ 满足单调性。因此我们可以利用 $ (2) $ 的结论来估算概率。\n我们假设某一天生日的学生数量独立服从泊松分布，即 $ Y_{i}\\sim\\text{Pois}(\\lambda) $，其中 $$ \\lambda = \\dfrac{m}{n} = \\dfrac{96}{365} \\approx 0.263 $$ 此时某一天有 $ \\geq 5 $ 个人生日的概率为 $$ \\mathbb{P}[Y_{i}\\geq 5] = \\sum_{k=5}^{\\infty} \\dfrac{e^{ -\\lambda }\\lambda^{k}}{k!} $$ 采用等比级数放缩，就有 $$ \\begin{align*} \\mathbb{P}[Y_{i}\\geq 5] \u0026 = \\dfrac{e^{ -\\lambda }\\lambda^{5}}{5!}\\left( 1 + \\dfrac{\\lambda}{6} + \\dfrac{\\lambda^{2}}{6\\cdot 7} + \\dots \\right) \\\\ \u0026 \u003c \\dfrac{e^{ -\\lambda }\\lambda^{5}}{5!}\\left[ 1+\\dfrac{\\lambda}{6} + \\left( \\dfrac{\\lambda}{6} \\right)^{2} + \\left( \\dfrac{\\lambda}{6} \\right)^{3} + \\dots \\right] \\\\ \u0026 = \\dfrac{e^{ -\\lambda }\\lambda^{5}}{5!}\\cdot \\dfrac{1}{1-\\frac{\\lambda}{6}} \\\\ \u0026 = \\dfrac{e^{ -\\lambda }\\lambda^{5}}{20(6-\\lambda)} \\\\ \u0026 \\approx 8.43 \\times 10^{-6} \\end{align*} $$ 从而利用 Union Bound，得到至少有一天发生的概率的上界是 $$ \\mathbb{P}[\\exists i,Y_{i}\\geq 5] \\leq \\sum_{i=1}^{365} \\mathbb{P}[Y_{i}\\geq 5] \\approx 365\\times 8.43\\times 10^{-6}\\approx 3.08 \\times 10^{-3} $$ 利用 $ (2) $ 的结论，就有 $$ \\mathbb{P}[\\mathbf{X}] \\leq 2\\cdot \\mathbb{P}[\\mathbf{Y}] \\approx 0.616\\% \u003c 0.7\\% $$ 证毕。\nProblem 2 (1)\n令 $ Z=X^{3} $。由于 $ X\\geq 0 $，所以 $ Z\\geq 0 $。我们写出 $ Z $ 的 CDF， $$ \\begin{align*} F_{Z}(z) \u0026 = \\mathbb{P}[Z \\leq z] = \\mathbb{P}[X^{3} \\leq z] \\\\ \u0026 = \\mathbb{P}[X \\leq z^{1/3}] \\\\ \u0026 = 1 - \\exp( -\\alpha z^{1/3} ) \\end{align*} $$ 我们对 $ z $ 求导即可得到 PDF， $$ \\begin{align*} f_{Z}(z) \u0026 = \\dfrac{\\mathrm{d} }{\\mathrm{d}z} (1 - \\exp(-\\alpha z^{1/3})) \\\\ \u0026 = - \\exp(-\\alpha z^{1/3})\\cdot \\dfrac{\\mathrm{d} }{\\mathrm{d}z} (-\\alpha z^{1/3}) \\\\ \u0026 = \\dfrac{\\alpha}{3}z^{-2/3}\\exp(-\\alpha z^{1/3}),\\quad (z\\geq 0) \\end{align*} $$ (2)\n令 $ Z=2X+3 $。由于 $ X\\geq 0 $，因此 $ Z\\geq 3 $。写出 $ Z $ 的 CDF，有 $$ \\begin{align*} F_{Z}(z) \u0026 = \\mathbb{P}[Z\\leq z] = \\mathbb{P}[2X+3\\leq z] \\\\ \u0026 = \\mathbb{P}\\left[ X \\leq \\dfrac{z-3}{2} \\right] \\\\ \u0026 = 1-\\exp\\left( -\\alpha\\left( \\dfrac{z-3}{2} \\right) \\right) \\end{align*} $$ 求导得到 $$ \\begin{align*} f_{Z}(z) \u0026 = \\dfrac{\\mathrm{d} }{\\mathrm{d}z} \\left( 1-\\exp\\left( -\\alpha\\left( \\dfrac{z-3}{2} \\right) \\right) \\right) \\\\ \u0026 = \\dfrac{\\alpha}{2}\\exp\\left( -\\alpha\\left( \\dfrac{z-3}{2} \\right) \\right),\\quad (z\\geq 3) \\end{align*} $$ (3)\n令 $ Z=X-Y $。此时 $ Z $ 的范围是 $ \\mathbb{R} $。我们使用全概率公式，有 $$ f_{Z}(z) = \\int_{-\\infty}^{\\infty} f_{X}(x)f_{Y}(x-z) \\mathrm{d}x $$ 由于 $ x,y $ 均需要非负，因此积分的区间需要满足 $ x\\geq 0 $ 且 $ x\\geq z $。\n分类讨论。若 $ z\\geq 0 $，那么限制条件合并为 $ x\\geq z $，从而 $$ \\begin{align*} f_{Z}(z) \u0026 = \\int_{z}^{\\infty} (\\alpha e^{ -\\alpha x })(\\alpha e^{ -\\alpha(x-z) }) \\mathrm{d}x \\\\ \u0026 = \\alpha^{2}e^{ \\alpha z }\\int_{z}^{\\infty} e^{ -2\\alpha x } \\mathrm{d}x \\\\ \u0026 = \\alpha^{2}e^{ \\alpha z }\\left[ -\\dfrac{1}{2\\alpha}e^{ -2\\alpha x } \\right]_{z}^{\\infty} \\\\ \u0026 = \\dfrac{\\alpha}{2}e^{ -\\alpha z } \\end{align*} $$ 若 $ z\u003c 0 $，由于对称性，$ X-Y $ 和 $ Y-X $ 同分布，也就是 $ f(z)=f(-z) $，所以直接写出结果 $$ f_{Z}(z) = \\dfrac{\\alpha}{2}e^{ \\alpha z } $$ 合并就有 $$ f_{Z}(z) = \\dfrac{\\alpha}{2}e^{ -\\alpha \\left| z \\right| },\\quad z\\in \\mathbb{R} $$ (4)\n使用上一问的 $ Z $，令 $ W=\\left| Z \\right| $。我们有 $ W\\in [0,+\\infty) $。\n由于 $ \\left| Z \\right|=W $ 的情况有 $ Z=W $ 和 $ Z=-W $ 两种可能，所以 $$ f_{W}(w)=f_{Z}(w)+f_{Z}(-w) = \\alpha e^{ -\\alpha w },\\quad (w\\geq 0) $$ (5)\n令 $ W=Y^{3} $，利用第一问，我们有 $$ \\mathbb{P}[W\u003ew] = \\mathbb{P}[Y^{3}\u003ew] = e^{ -\\alpha w^{1/3} } $$ 令 $ Z=\\min(X,W) $，于是 $$ \\mathbb{P}(Z\u003ez) = \\mathbb{P}(\\min(X,W)\u003ez) $$ $ \\min(X,W)\u003ez $ 说明两者都同时大于 $ z $。因此利用独立性，就有 $$ \\begin{align*} \\mathbb{P}(Z\u003ez) \u0026 = \\mathbb{P}(X\u003ez)\\cdot \\mathbb{P}(W\u003ez) \\\\ \u0026 = e^{ -\\alpha z }\\cdot e^{ -\\alpha z^{1/3} } \\\\ \u0026 = e^{ -\\alpha(z+z^{1/3}) } \\end{align*} $$ 从而 $ Z $ 的 CDF 为 $ 1-e^{ -\\alpha(z+z^{1/3}) } $。\n接着我们求导得到 PDF，有 $$ \\begin{align*} f_{Z}(z) \u0026 = \\dfrac{\\mathrm{d} }{\\mathrm{d}z} (1-e^{ -\\alpha(z+z^{1/3}) }) \\\\ \u0026 = \\alpha\\left( 1+\\dfrac{1}{3}z^{-2/3} \\right)e^{ -\\alpha(z+z^{1/3}) },\\quad (z\\geq 0) \\end{align*} $$ (6)\n同理 $ (5) $，令 $ Z=\\max(X,Y^{3}) $，我们有 $$ F_{Z}(z) = \\mathbb{P}(Z\\leq z) = \\mathbb{P}(\\max(X,W)\\leq w) $$ 这说明两个数都同时小于等于 $ u $，于是 $$ \\begin{align*} F_{Z}(z) \u0026 = \\mathbb{P}(X\\leq z)\\cdot \\mathbb{P}(W\\leq z) \\\\ \u0026 = F_{X}(z)\\cdot F_{W}(w) \\\\ \u0026 = (1-e^{ -\\alpha z })(1-e^{ -\\alpha z^{1/3} }) \\end{align*} $$ 求导可得 $$ \\begin{align*} f_{Z}(z) \u0026 = (\\alpha e^{ -\\alpha z })(1-e^{ -\\alpha z^{1/3} })+(1-e^{ -\\alpha z })\\left( \\dfrac{\\alpha}{3}z^{-2/3}e^{ -\\alpha z^{1/3} } \\right),\\quad (z\\geq 0) \\end{align*} $$\nProblem 3 (1)\n由于 $ T_{1},T_{2} $ 独立，因此它们的联合概率密度函数为 $$ f(x,y) = g_{m}(x)\\cdot g_{n}(y) $$ 我们需要求在 $ y\u003c x $ 区域内的概率 $$ \\begin{align*} \\mathbb{P}(T_{2}\u003c T_{1}) \u0026 = \\underset{ 0\u003c y\u003c x }{ \\iint } g_{m}(x)g_{n}(y)\\mathrm{d}x\\mathrm{d}y \\\\ \u0026 = \\int_{0}^{\\infty} g_{m}(x)\\left( \\int_{0}^{x} g_{n}(y) \\mathrm{d}y \\right) \\mathrm{d}x \\end{align*} $$ (2)\n由于两个队列服从服从参数相同的指数分布 $ \\text{Exp}(\\lambda) $，根据指数分布的性质，任意时刻下一次服务完成发生在 $ 1 $ 或 $ 2 $ 的概率是相等的。我们将整个服务过程视为一系列独立的伯努利试验，也就是抛硬币。如果硬币为正面，代表队列 $ 2 $ 完成一次服务；如果硬币为反面，代表队列 $ 1 $ 完成一次服务。\n事件 $ T_{2}\u003c T_{1} $ 意味着队列 $ 2 $ 的 $ n $ 名顾客全部完成服务时，队列 $ 1 $ 的 $ m $ 个顾客还没有全部完成。对应到硬币模型，也就是累计出现 $ n $ 次正面的时刻，反面出现的次数还没到 $ m $ 次。因此 $ \\mathbb{P}(T_{2}\u003c T_{1}) $ 是在公平的抛硬币模型中，$ n $ 个正面比 $ m $ 个反面先出现的概率。\nProblem 4 (1)\n我们知道随机变量 $ X_{1},X_{2},\\dots,X_{n} $ 独立且均服从指数分布 $ \\text{Exp}(\\lambda) $，从而其 PDF 为 $$ f(x) = \\begin{cases} \\lambda e^{ -\\lambda x }, \u0026 x\\geq 0 \\\\ 0, \u0026 x \u003c 0 \\end{cases} $$ 以及其 CDF 为 $$ F(x) = \\begin{cases} 1-e^{ -\\lambda x }, \u0026 x\\geq 0 \\\\ 0, \u0026 x \u003c 0 \\end{cases} $$ 首先处理带证明公式中的组合系数，$ n\\binom{ n-1 }{ k-1 } $ 表示从 $ n $ 个随机变量中选定 $ X_{(k)} $ 后再从剩下 $ n-1 $ 个随机变量中选出前 $ k-1 $ 个发生的 $ X_{(1)},\\dots,X_{(k-1)} $ 的方案数。这样就表示所有可能发生的事件的组合数。\n对于 $ X_{(1)},\\dots,X_{(k-1)} $，它们在时刻 $ x $ 之前已经坏掉的概率为 $$ [F(x)]^{k-1} = (1-e^{ -\\lambda x })^{k-1} $$ 对于 $ X_{(k)} $，它在时刻 $ x $ 坏掉的概率密度为 $$ \\lambda e^{ -\\lambda x } $$ 对于 $ X_{(k+1)},\\dots,X_{(n)} $，它们再时刻 $ x $ 还没有发生过的概率为 $$ [1-F(x)]^{n-k} = e^{ -(n-k)\\lambda } $$ 从而相乘后就得到了 $$ f_{X_{(k)}}(x) = n\\binom{ n-1 }{ k-1 } (1-e^{ -\\lambda x })^{k-1}e^{ -(n-k)\\lambda x }\\cdot\\lambda e^{ -\\lambda x } $$ (2)\n首先考虑当 $ r=n $。由于所有 $ X_{1},\\dots,X_{n} $ 独立同分布，因此其概率联合密度为 $ \\prod_{i=1}^{n}f(x_{i}) $。我们要统计的 $ X_{(1)}\u003c X_{(2)}\u003c \\dots\u003c X_{(n)} $ 对应原始样本 $ (X_{1},\\dots,X_{n}) $ 的 $ n! $ 种排序中的特定一种。\n从而在定义域 $ 0\u003c x_{1}\u003c x_{2}\u003c \\dots\u003c x_{n} $ 中，根据每个 $ X $ 的对称性，联合概率密度函数为 $$ f_{X_{(1)},\\dots,X_{(n)}}(x_{1},\\dots,x_{n})=n!\\cdot \\prod_{i=1}^{n} f(x_{i}) $$ 带入就得到了 $$ \\begin{align*} f_{X_{(1)},\\dots,X_{(n)}}(x_{1},\\dots,x_{n}) \u0026 = n!\\prod_{i=1}^{n} (\\lambda e^{ -\\lambda x_{i} }) \\\\ \u0026 = n!\\lambda^{n}e^{ -\\lambda \\sum_{i=1}^{n} x_{i} } \\end{align*} $$ 在这个定义域之外，概率密度为 $ 0 $。从而引入指示函数作为定义域的限制，就得到了 $$ f_{X_{(1)},\\dots,X_{(n)}}(x_{1},\\dots,x_{n}) = n!\\lambda^{n}e^{ -\\lambda \\sum_{i=1}^{n} x_{i} }\\cdot \\mathbb{I}[x_{1}\u003c x_{2}\u003c \\dots\u003c x_{n}] $$\n对于一般情况，$ X_{(1)}\u003c X_{(2)}\u003c \\dots\u003c X_{(r)} $ 对应原始样本中 $ \\dfrac{n!}{(n-r)!} $ 种排列（后 $ n-r $ 个随机变量可以随意排列）。\n此时对于 $ 0\u003c x_{1}\u003c x_{2}\u003c \\dots\u003c x_{r} $，我们首先要确保选出的 $ X_{(k)} $ 在时刻 $ x_{k} $ 发生，概率密度为 $ \\prod_{i=1}^{r}f(x_{i})=\\lambda^{r}e^{ -\\lambda \\sum_{i=1}^{r}x_{i} } $。接着要确保后未选中的 $ (n-r) $ 个随机事件不会在时刻 $ x_{r} $ 之前发生，概率为 $ [1-F(x_{r})]^{n-r}=e^{ ^{-(n-r)}\\lambda x_{r} } $。\n带入就得到了 $$ f_{X_{(1)},\\dots,X_{(r)}}(x_{1},\\dots,x_{r}) = \\dfrac{n!}{(n-r)!}\\cdot\\lambda^{r}e^{ -\\lambda \\sum_{i=1}^{r} x_{i} }\\cdot e^{ -(n-r)\\lambda x_{r} } $$ (3)\n定义 $ Y_{1}=X_{(1)},Y_{k}=X_{(k)}-X_{(k-1)}\\quad (k\u003e1) $，那么可以得到 $$ X_{(k)}=\\sum_{i=1}^{k} Y_{i} $$ 我们求出这个变换的 Jacobian 行列式。对于 $ n $ 个变量，这个变换对应的矩阵是一个下三角矩阵，并且对角线元素全为 $ 1 $，因为 $ \\frac{ \\partial X_{(k)} }{ \\partial Y_{k} }=1 $，从而 $$ \\left| J \\right| = \\det\\left( \\dfrac{ \\partial (x_{(1)},x_{(2)},\\dots,x_{(n)}) }{ \\partial (y_{1},y_{2},\\dots,y_{n}) } \\right) = 1 $$ 利用 $ (2) $ 中 $ r=n $ 时的联合概率密度函数，再带入 $$ \\sum_{i=1}^{n} x_{i} = \\sum_{i=1}^{n} \\sum_{j=1}^{i} y_{j} = \\sum_{j=1}^{n} (n-j+1)y_{j} $$ 就得到了 $$ \\begin{align*} f_{Y}(y_{1},y_{2},\\dots,y_{n}) \u0026 = n!\\lambda^{n}e^{ -\\lambda \\sum_{j=1}^{n} (n-j+1)y_{j}}\\cdot \\left| J \\right| \\\\ \u0026 = \\prod_{j=1}^{n} [(n-j+1)\\lambda e^{ -(n-j+1)\\lambda y_{j} }] \\end{align*} $$ 从而联合概率密度函数分解成了 $ n $ 个独立的因子的乘积 $$ f_{Y_{k}}=(n-k+1)\\lambda e^{ -(n-k+1)\\lambda y_{k} },f_{Y}=\\prod_{k=1}^{n} f_{Y_{k}} $$ 其中 $ Y_{k} $ 正对应着 $ n-k+1 $ 个还存活的指数分布的密度。\n对应回题目中 $ Y_{k+1}=X_{(k+1)}-X_{(k)} $ 的系数为 $ n-k $，从而说明间隔 $ X_{(k+1)}-X_{(k)} $ 相互独立，并且服从 $ \\text{Exp}((n-k)\\lambda) $。\n(4)\n由于 $ X_{(i)} $ 之间不独立，难以计算，因此我们考虑将 $ U $ 改写为 $ (3) $ 中用到的独立变量 $ Y_{i}\\sim\\text{Exp}((n-i+1)\\lambda) $ 的线性组合。\n首先每个 $ Y_{i} $ 的期望与方差分别为 $$ \\mathbb{E}[Y_{i}]=\\dfrac{1}{(n-i+1)\\lambda},\\quad \\text{Var}[Y_{i}]= \\dfrac{1}{(n-j+1)^{2}\\lambda^{2}} $$\n将 $ U $ 重写为 $ Y_{i} $ 的线性组合 $$ \\begin{align*} U \u0026 = \\sum_{i=1}^{r} a_{i}X_{(i)} \\\\ \u0026 = \\sum_{i=1}^{r} a_{i}\\left( \\sum_{j=1}^{i} Y_{j} \\right) \\\\ \u0026 = \\sum_{j=1}^{r} Y_{j}\\sum_{i=j}^{r} a_{i} \\end{align*} $$ 令 $ b_{i}=\\sum_{k=i}^{r}a_{k} $，就有 $$ \\begin{align*} U = \\sum_{i=1}^{r} b_{i}Y_{i} \\end{align*} $$ 题目要求 $ \\mathbb{E}[U]=\\lambda ^{-1} $，带入就得到 $$ \\mathbb{E}[U] = \\mathbb{E}\\left[ \\sum_{i=1}^{r} b_{i}Y_{i} \\right] = \\sum_{i=1}^{r} b_{i}\\mathbb{E}[Y_{i}] =\\dfrac{1}{\\lambda} \\sum_{i=1}^{r} \\dfrac{b_{i}}{n-i+1} = \\dfrac{1}{\\lambda} $$ 从而有约束条件 $$ \\sum_{i=1}^{r} \\dfrac{b_{i}}{n-i+1}=1 $$ 在这个约束条件下我们需要最小化 $ U $ 的方差。利用 $ Y_{i} $ 的独立性，有 $$ \\text{Var}[U] = \\sum_{j=1}^{r} b_{i}^{2}\\text{Var}[Y_{i}] = \\dfrac{1}{\\lambda^{2}}\\sum_{i=1}^{r} \\dfrac{b_{i}^{2}}{(n-i+1)^{2}} $$ 利用 Cauchy 不等式，容易求出在 $$ \\dfrac{b_{1}}{n} = \\dfrac{b_{2}}{n-1}=\\dots=\\dfrac{b_{r}}{n-r+1}=\\dfrac{1}{r} $$ 时 $ \\text{Var}[U] $ 取到最小值，由此解出最优的 $ b_{i} $ 为 $$ b_{i} = \\dfrac{n-i+1}{r} $$ 对应系数 $ a_{i} $ 为 $$ a_{r} = b_{r} = \\dfrac{n-r+1}{r},\\quad a_{k} = b_{k}-b_{k+1} = \\dfrac{1}{r}\\quad (k\u003c r) $$ 与题设一致。\n带入最优的 $ b_{i} $ 到 $ \\text{Var}[U] $ 的表达式中，得到 $$ \\text{Var}[U] = \\dfrac{1}{\\lambda^{2}}\\sum_{i=1}^{r} \\left( \\dfrac{1}{r} \\right)^{2} = \\dfrac{1}{r\\lambda^{2}} $$\n","permalink":"https://diefish1024.github.io/posts/class-notes/math2701-probability-theory/math2701-hw6/","summary":"\u003ch2 id=\"problem-1\"\u003eProblem 1\u003c/h2\u003e\n\u003cp\u003e\u003cstrong\u003e(1)\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e根据泊松分布的定义，我们有\n$$ \n\n\\mathbb{P}[X=\\lambda+k] = \\dfrac{e^{ -\\lambda }\\lambda^{\\lambda+k}}{(\\lambda+k)!},\\quad \\mathbb{P}[X=\\lambda-k-1] = \\dfrac{e^{ -\\lambda }\\lambda^{\\lambda-k-1}}{(\\lambda-k-1)!}\n\n $$\n我们计算两者的比值，有\n$$ \n\n\\dfrac{\\mathbb{P}[X=\\lambda+k]}{\\mathbb{P}[X=\\lambda-k-1]} = \\dfrac{\\lambda^{2k+1}\\cdot(\\lambda-k-1)!}{(\\lambda+k)!} = \\dfrac{\\lambda^{2k+1}}{(\\lambda+k)(\\lambda+k-1)\\dots(\\lambda-k)}\n\n $$\n将分母的乘积左右两两配对，得到\n$$ \n\n(\\lambda+k)\\dots(\\lambda-k) = \\lambda \\cdot \\prod_{i=1}^{k} (\\lambda^{2}-k^{2}) \u003e \\lambda \\cdot \\prod_{i=1}^{k} \\lambda^{2} = \\lambda^{2k+1}\n\n $$\n从而就有\n$$ \n\n\\dfrac{\\mathbb{P}[X=\\lambda+1]}{\\mathbb{P}[X=\\lambda-k-1]} \\geq  1 \\implies \\mathbb{P}[X=\\lambda+1]\\geq  \\mathbb{P}[X=\\lambda-k-1]\n\n $$\u003c/p\u003e\n\u003cp\u003e接着证明 $ \\mathbb{P}[X\\geq\\lambda]\\geq \\frac{1}{2} $，将事件展开并拆分可以得到\n$$ \n\n\\begin{align*}\n\\mathbb{P}[X\\geq \\lambda] \u0026 =\\sum_{k=0}^{\\infty} \\mathbb{P}[X=\\lambda+k] \\\\\n \u0026 = \\sum_{k=0}^{\\lambda-1} \\mathbb{P}[X=\\lambda+k] + \\mathbb{P}[X\\geq  2\\lambda] \\\\\n \u0026 \\geq  \\sum_{k=0}^{\\lambda-1} \\mathbb{P}[X=\\lambda+k]\n\\end{align*}\n\n $$\n我们再考虑 $ \\mathbb{P}[X\u003c \\lambda] $，也就是\n$$ \n\n\\begin{align*}\n\\mathbb{P}[X\u003c \\lambda] \u0026 = \\sum_{k=0}^{\\lambda-1} \\mathbb{P}[X=\\lambda-k-1] \\\\\n \u0026 \\leq  \\sum_{k=0}^{\\lambda-1} \\mathbb{P}[X=\\lambda+k]\n\\end{align*}\n\n $$\n又因为 $ \\mathbb{P}[X\\geq\\lambda]+\\mathbb{P}[X\u003c \\lambda]=1 $，这样就得到了\n$$ \n\n1-\\mathbb{P}[X\\geq \\lambda] \\leq  \\mathbb{P}[X\\geq \\lambda] \\implies \\mathbb{P}[X\\geq  \\lambda] = \\dfrac{1}{2}\n\n $$\n\u003cstrong\u003e(2)\u003c/strong\u003e\u003c/p\u003e","title":"MATH2701 HW6"},{"content":"Problem 1 给定平面上 $ 2n $ 个点，任意将 $ n $ 个点染成红色，剩下 $ n $ 个点染成蓝色。证明存在一种红蓝点的 $ 1 $-$ 1 $ 配对，使得连接它们的 $ n $ 条线段相互不相交。\n证\n定义红点集 $ R=\\{ r_{1},r_{2},\\dots,r_{n} \\} $，蓝点集 $ B=\\{ b_{1},b_{2},\\dots,b_{n} \\} $。$ R\\to B $ 的映射，对应一种配对方案，总数为 $ n! $。\n对于任意一种配对方案 $ \\sigma $，我们定义它的总长度 $ L(\\sigma) $ 为该方案中所有线段的长度之和 $$ L(\\sigma) = \\sum_{(r,b)\\in\\sigma}\\text{dist}(r,b) $$ 由于总方案数有限，因此一定存在一种方案 $ \\sigma_{m} $ 使得总长度 $ L(\\sigma_{m}) $ 最小。我们下面证明这个最小方案中没有相交的线段。\n假设在 $ \\sigma_{m} $ 中存在两条线段相交，设为 $ (r_{1},b_{1}) $ 和 $ (r_{2},b_{2}) $，相交于点 $ P $。那么我们考虑交换配对变为 $ (r_{1},b_{2}) $ 和 $ (r_{2},b_{1}) $。根据三角不等式，有 $ \\left| r_{1}b_{2} \\right|\u003c\\left| r_{1}X \\right|+\\left| Xb_{2} \\right|,\\left| r_{2}b_{1} \\right|\u003c\\left| r_{2}X \\right|+\\left| Xb_{1} \\right| $，从而 $$ \\left| r_{1}b_{2} \\right| +\\left| r_{2}b_{1} \\right| \u003c \\left| r_{1}X \\right| +\\left| Xb_{1} \\right| +\\left| r_{2}X \\right| +\\left| Xb_{2} \\right| = \\left| r_{1}b_{1} \\right| +\\left| r_{2}b_{2} \\right| $$ 发现交换后得到了一个总长度更小的方案，从而与总长度最小矛盾。这样我们就证明了总长度最小的配对方案所有线段必然不相交，证毕。\nProblem 2 给定一个 $ n $ 个点的点集 $ V $，称一条线是好的当且仅当它恰好经过 $ V $ 中的 $ 3 $ 个点。\n(1)\n证明好的线段的数量至多为 $ n^{2} / 6 $。\n证\n由于任意两个点确定一条直线，因此任意两条不同的直线不可能共用一个点对。一条好的线段恰好包含 $ 3 $ 个点，从而恰好包含 $ 3 $ 个点对。我们设好的线段数量为 $ m $，那么一共包含了 $ 3m $ 个不同的点对。又因为点对总数为 $ \\binom{ n }{ 2 } $，因此 $$ 3m \\leq \\binom{ n }{ 2 } \\implies m \\leq \\dfrac{n(n-1)}{6} \u003c \\dfrac{n^{2}}{6} $$ (2)\n设 $ M_{n} $ 是 $ n $ 个点所有可能的排布中最大的好的直线的数量。给出尽可能精确的 $ M_{n} $ 的下界。\n解\n实际上 $ M_{n} $ 的下界也是 $ \\dfrac{n^{2}}{6}-O(n) $。但是由于难以构造，这里给出一个也是 $ O(n^{2}) $，为 $ \\dfrac{n^{2}}{8}-O(n) $ 的构造。\n我们利用三次函数来完成这个构造。构造函数 $ y=x^{3} $，取 $ x \\in\\{ -n, \\dots,-1,0,1,\\dots,n \\} $ 共 $ 2n+1 $ 个点，对于每一个 $ x $，构造 $ P_{x}=(x,x^{3}) $。下面我们证明这个点集满足条件。\n根据三次函数的性质，我们知道任意一条直线与它至多只有三个交点，因此不可能出现四点共线的情况。并且利用代数性质容易证明三点共线的充要条件是横坐标之和为零，也就是若 $ x,y,z\\in \\{ -n, \\dots, n \\} $ 满足 $ x+y+z=0 $，那么 $ P_{x},P_{y},P_{z} $ 共线。\n在集合 $ \\{ -n, \\dots,n \\} $ 中，不互相同的 $ x+y+z=0 $ 的组合的数量等价于满足 $ -n\\leq x+y\\leq n $ 的组数，从而求出总数为 $$ 3n^{2} + 3n - 6\\lfloor n / 2 \\rfloor $$ 由于 $ x,y,z $ 轮换，因此直线的总数为 $$ \\dfrac{1}{2}n^{2} + \\dfrac{1}{2}n - \\lfloor n / 2 \\rfloor = \\dfrac{(2n+1)^{2}}{8} - O(n) $$\nProblem 3 设 $ \\mathcal{F} $ 为 $ [n] $ 的一个相交子集族。证明存在一个包含 $ \\mathcal{F} $ 的相交子集族 $ \\mathcal{F}' $，使得 $ |\\mathcal{F}'| = 2^{n-1} $。\n证\n考虑 $ [n] $ 的所有子集，共有 $ 2^{n} $ 个。我们将这 $ 2^{n} $ 个子集分成 $ 2^{n-1} $ 对互补的集合。也就是对于任意 $ A\\subseteq[n] $，它和它的补集 $ A^{c} $ 组成了一个互补对 $ \\{ A,A^{c} \\} $，显然 $ A $ 和 $ A^{c} $ 不相交。这说明在一个交族 $ \\mathcal{F} $，它不可能同时包含 $ A $ 和 $ A^{c} $。从而说明了一个交族的大小不可能超过互补对的数量，即 $ \\left| \\mathcal{F} \\right|\\leq 2^{n}-1 $。\n现在对于任意一个交族 $ \\mathcal{F}\\subseteq[n] $，我们进行以下操作来构造 $ \\mathcal{F}' $：对于每一对互补对，如果 $ A\\in \\mathcal{F} $ 或者 $ A^{c}\\in \\mathcal{F} $，那么我们保留它们在 $ \\mathcal{F}' $，否则选择 $ A $ 和 $ A^{c} $ 中的一个加入 $ \\mathcal{F}' $，需要保证加入后仍然保持了交族的性质。我们证明一定可以完成构造，假设某一步中我们无论加入 $ A $ 还是 $ A^{c} $ 都会破坏交族的性质，那么\n不能加入 $ A $ 说明 $ \\mathcal{F} $ 中存在集合 $ B $ 使得 $ A\\cap B=\\emptyset $，从而 $ B\\subseteq A^{c} $。 不能加入 $ A^{c} $ 说明 $ \\mathcal{F} $ 中存在集合 $ C $ 使得 $ A^{c}\\cap C=\\emptyset $，从而 $ C\\subseteq A $。 如果两个情况同时发生，那么同时存在 $ B\\subseteq A^{c} $ 以及 $ C\\subseteq A $，可以得到 $ B\\cap C\\subseteq A\\cap A^{c}=\\emptyset $，与 $ \\mathcal{F} $ 是一个交族矛盾！ 因此对于每一个互补对，我们都可以选出一个集合加入 $ \\mathcal{F}' $，所以 $ \\left| \\mathcal{F}' \\right|=2^{n-1} $，与互补对的数量相等。\nProblem 4 假设我们可以将子图 $ K_{n} $ 分解为 $ m $ 个边不重叠的完全子图的并集，并且这些子图都和 $ K_{n} $ 不同，证明：$ m\\geq n $。\n证\n我们将图 $ K_n $ 的顶点集 $ V $ 视为几何中的点集，将分解出的 $ m $ 个完全子图视为线集。我们将这个问题转化为满足 De Bruijn-Erdős 定理的结构。\n对于任意两个顶点 $ u, v \\in V $，它们在 $ K_n $ 中由唯一的一条边连接。由于这些完全子图构成了边的划分，该边 $ (u, v) $ 必须恰好属于某一个唯一的完全子图。这对应了平面上两个点唯一确定一条直线。\n题目已知这些完全子图均不同于 $ K_n $，这意味着没有任何一个子图包含了 $ V $ 中的所有顶点，这对应了定理中要求的所有点不共线。\n因此根据 De Bruijn-Erdős 定理，在线性空间中线的数量至少等于点的数量，我们就直接证明了 $ m\\geq n $，证毕。\n","permalink":"https://diefish1024.github.io/posts/class-notes/cs0901-combinatorics/cs0901-hw8/","summary":"\u003ch2 id=\"problem-1\"\u003eProblem 1\u003c/h2\u003e\n\u003cp\u003e给定平面上 $ 2n $ 个点，任意将 $ n $ 个点染成红色，剩下 $ n $ 个点染成蓝色。证明存在一种红蓝点的 $ 1 $-$ 1 $ 配对，使得连接它们的 $ n $ 条线段相互不相交。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e证\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e定义红点集 $ R=\\{ r_{1},r_{2},\\dots,r_{n} \\} $，蓝点集 $ B=\\{ b_{1},b_{2},\\dots,b_{n} \\} $。$ R\\to B $ 的映射，对应一种配对方案，总数为 $ n! $。\u003c/p\u003e\n\u003cp\u003e对于任意一种配对方案 $ \\sigma $，我们定义它的总长度 $ L(\\sigma) $ 为该方案中所有线段的长度之和\n$$ \n\nL(\\sigma) = \\sum_{(r,b)\\in\\sigma}\\text{dist}(r,b)\n\n $$\n由于总方案数有限，因此一定存在一种方案 $ \\sigma_{m} $ 使得总长度 $ L(\\sigma_{m}) $ 最小。我们下面证明这个最小方案中没有相交的线段。\u003c/p\u003e\n\u003cp\u003e假设在 $ \\sigma_{m} $ 中存在两条线段相交，设为 $ (r_{1},b_{1}) $ 和 $ (r_{2},b_{2}) $，相交于点 $ P $。那么我们考虑交换配对变为 $ (r_{1},b_{2}) $ 和 $ (r_{2},b_{1}) $。根据三角不等式，有 $ \\left| r_{1}b_{2} \\right|\u003c\\left| r_{1}X \\right|+\\left| Xb_{2} \\right|,\\left| r_{2}b_{1} \\right|\u003c\\left| r_{2}X \\right|+\\left| Xb_{1} \\right| $，从而\n$$ \n\n\\left| r_{1}b_{2} \\right| +\\left| r_{2}b_{1} \\right| \u003c \\left| r_{1}X \\right| +\\left| Xb_{1} \\right| +\\left| r_{2}X \\right| +\\left| Xb_{2} \\right| = \\left| r_{1}b_{1} \\right| +\\left| r_{2}b_{2} \\right| \n\n $$\n发现交换后得到了一个总长度更小的方案，从而与总长度最小矛盾。这样我们就证明了总长度最小的配对方案所有线段必然不相交，证毕。\u003c/p\u003e","title":"CS0901 HW8"},{"content":"Problem 1 (1)\n根据题设条件，我们知道最多抽取 $ m $ 个黑球，最少抽取 $ 0 $ 个黑球。设随机变量 $ X $ 表示抽到黑球的个数，根据组合意义，我们得到 $ X $ 的概率质量函数为 $$ \\mathbb{P}(X=x) = \\dfrac{\\binom{ m }{ x } \\binom{ n-m }{ k-x } }{\\binom{ n }{ k } },\\quad x = 0,1,\\dots,m $$ (2)\n矩生成函数定义为 $ M_{X}(\\theta) = \\mathbb{E}[e^{ \\theta X }] $。我们带入得到 $$ \\begin{align*} M_{X}(\\theta) \u0026 = \\sum_{x}e^{ \\theta x }\\mathbb{P}(X=x) \\\\ \u0026 = \\sum_{x=0}^{m} e^{ \\theta x } \\dfrac{\\binom{ m }{ x } \\binom{ n-m }{ k-x } }{\\binom{ n }{ k } } \\\\ \u0026 = \\dfrac{1}{\\binom{ n }{ k } }\\sum_{x=0}^{m} e^{ \\theta x }\\binom{ m }{ x } \\binom{ n-m }{ k-x } \\end{align*} $$ (3)\n首先计算 $ \\mathbb{E}[X] $。 $$ \\begin{align*} \\mathbb{E}[X] \u0026 = M'_{X}(0) = \\dfrac{\\mathrm{d} }{\\mathrm{d}\\theta} \\left( \\sum_{x}e^{ \\theta x }\\mathbb{P}(X=x) \\right)\\bigg|_{\\theta=0} \\\\ \u0026 = \\sum_{x=0}^{m} x\\mathbb{P}(X=x) \\\\ \u0026 = \\dfrac{1}{\\binom{ n }{ k }} \\sum_{x=0}^{m} x\\binom{ m }{ x } \\binom{ n-m }{ k-x } \\\\ \u0026 = \\dfrac{1}{\\binom{ n }{ k } }\\sum_{x=0}^{m} m\\binom{ m-1 }{ x-1 } \\binom{ n-m }{ k-x } \\\\ \u0026 = \\dfrac{m}{\\binom{ n }{ k } } \\sum_{y=0}^{m-1} \\binom{ m-1 }{ y } \\binom{ n-m }{ k-y-1 } \\\\ \u0026 = \\dfrac{m}{\\binom{ n }{ k } }\\binom{ n-m+m-1 }{ k-1 } = \\dfrac{m}{\\binom{ n }{ k } }\\binom{ n-1 }{ k-1 } \\\\ \u0026 = \\dfrac{mk}{n} \\end{align*} $$ 接着计算 $ \\mathbb{E}[X^{2}] $。由于 $ \\mathbb{E}[X^{2}] $ 的表达式化简较为困难，我们考虑求解 $ \\mathbb{E}[X(X-1)] $。根据 LOTUS，我们有 $$ \\begin{align*} \\mathbb{E}[X(X-1)] \u0026 = \\sum_{x=0}^{m} x(x-1)\\mathbb{P}(X=x) \\\\ \u0026 = \\dfrac{1}{\\binom{ n }{ k } }\\sum_{x=0}^{m} x(x-1)\\binom{ m }{ x } \\binom{ n-m }{ k-x } \\\\ \u0026 = \\dfrac{m}{\\binom{ n }{ k } }\\sum_{x=0}^{m} (x-1)\\binom{ m-1 }{ x-1 } \\binom{ n-m }{ k-x } \\\\ \u0026 = \\dfrac{m(m-1)}{\\binom{ m }{ k } }\\sum_{x=0}^{m} \\binom{ m-2 }{ x-2 } \\binom{ n-m }{ k-x } \\\\ \u0026 = \\dfrac{m(m-1)}{\\binom{ m }{ k } }\\binom{ n-2 }{ k-2 } \\\\ \u0026 = \\dfrac{m(m-1)k(k-1)}{n(n-1)} \\end{align*} $$ 从而带入方差公式得到 $$ \\begin{align*} \\text{Var}[X] \u0026 = \\mathbb{E}[X^{2}]-(\\mathbb{E}[X])^{2} \\\\ \u0026 = \\mathbb{E}[X(X-1)] + \\mathbb{E}[X] - (\\mathbb{E}[X])^{2} \\\\ \u0026 = \\dfrac{m(m-1)k(k-1)}{n(n-1)} + \\dfrac{mk}{n} - \\left( \\dfrac{mk}{n} \\right)^{2} \\\\ \u0026 = \\dfrac{mk}{n}\\left[ \\dfrac{(m-1)(k-1)}{n-1}+1 - \\dfrac{mk}{n}\\right] \\\\ \u0026 = \\dfrac{mk}{n}\\cdot \\dfrac{n-m}{n}\\cdot \\dfrac{n-k}{n-1} \\end{align*} $$ 综上得到 $$ \\mathbb{E}[X] = \\dfrac{mk}{n},\\quad \\text{Var}[X] = \\dfrac{mk}{n}\\cdot \\dfrac{n-m}{n}\\cdot \\dfrac{n-k}{n-1} $$\nProblem 2 (1)\n首先我们计算 $ X $ 的 pdf，记为 $ f_{X}(x) $，那么 $$ f_{X}(x) = \\prod_{i=1}^{n} f_{X_{i}}(x_{i}) = \\prod_{i=1}^{n} \\dfrac{1}{\\sqrt{ 2\\pi }}e^{ -x_{i}^{2} / 2 } = \\dfrac{1}{(2\\pi)^{n / 2}}e^{ - \\frac{1}{2}\\sum_{i=1}^{n} x_{i}^{2} } $$ 由于 $ \\| x \\|^{2}=x^{T}x = \\sum_{i=1}^{n}x_{i}^{2} $，我们可以化简为 $$ f_{X}(x) = \\dfrac{1}{(2\\pi)^{n / 2}}e^{ - \\frac{1}{2} x^{T}x } $$\n根据题设，我们知道 $$ y = Qx \\implies x = Q^{T}y $$ 从而计算该变换雅可比行列式的绝对值，有 $$ J = \\left| \\det\\left( \\dfrac{ \\partial x }{ \\partial y } \\right) \\right| = \\left| \\det(Q^{T}) \\right| $$ 根据正定矩阵的性质，我们知道 $ \\det Q^{T}=\\det Q=\\pm 1 $，因此 $ J=1 $。\n于是根据变量代换公式，我们得到 $$ f_{Y}(y) = f_{X}(x(y))\\cdot J = f_{X}(Q^{T}y)\\cdot 1 $$ 带入 $ Q^{T}y $，其中 $ x^{T}x $ 变为 $ y^{T}Q Q^{T}y=y^{T}y $ 即可得到 $$ f_{Y}(y) = \\dfrac{1}{(2\\pi)^{n/2}}\\exp\\left( -\\dfrac{1}{2}y^{T} y\\right) $$ 从而 $ x $ 与 $ y $ 的分布一致。\n(2)\n对于单位球面上的两个向量 $ z_{1} $ 和 $ z_{2} $，利用线性代数可以证明存在正交矩阵 $ Q $ 使得 $$ z_{2}=Qz_{1} $$ 我们考虑变换后的随机变量 $ QZ $，得到 $$ QZ = Q\\left( \\dfrac{X}{\\| X \\| } \\right)= \\dfrac{QX}{\\| X \\| } \\xlongequal{\\| QX \\| = \\| X \\| } \\dfrac{QX}{\\| QX \\| } $$ 我们令 $ Y=QX $，就有 $ QZ=\\dfrac{Y}{\\| Y \\|} $。利用 $ (1) $ 的结论，我们知道 $ X $ 和 $ Y $ 是同分布的，从而 $ Z $ 和 $ QZ $ 是同分布的。这就说明了 $ Z $ 具有旋转不变性，也就有 $ Z $ 在球面上取 $ z_{1} $ 附近的概率密度，必须等于取 $ z_{2}=Qz_{1} $ 附近的概率密度，也就是 $$ f_{Z}(z) = f_{Z}(Qz) $$ 我们可以找到 $ Q $ 将球面上的任意点 $ z_{1} $ 映射到球面上的任意点 $ z_{2} $，从而说明了 $$ \\forall z_{1},z_{2}\\in S^{n-1},\\quad f_{Z}(z_{1})=f_{Z}(z_{2}) $$\nProblem 3 (1)\n根据题设我们有 $$ \\begin{cases} u = xy \\\\ v = \\dfrac{x}{y} \\end{cases} $$ 从而得到 $ x=\\sqrt{ uv },y=\\sqrt{ u / v } $。我们计算变换的 Jacobi 行列式 $$ J = \\det\\left( \\dfrac{ \\partial (x,y) }{ \\partial (u,v) } \\right) = \\det \\begin{pmatrix} \\dfrac{1}{2}\\sqrt{ \\dfrac{v}{u} } \u0026 \\dfrac{1}{2}\\sqrt{ \\dfrac{u}{v} } \\\\ \\dfrac{1}{2\\sqrt{ uv }} \u0026 -\\dfrac{1}{2v}\\sqrt{ \\dfrac{u}{v} } \\end{pmatrix} = - \\dfrac{1}{2v} $$ 从而 $ \\left| J \\right|= \\dfrac{1}{2v} $。\n于是我们就得到了联合密度函数为 $$ f_{UV}(u,v) = f_{XY}(\\sqrt{ uv },\\sqrt{ u / v }) \\cdot \\left| J \\right| = 1 \\cdot\\dfrac{1}{2v} = \\dfrac{1}{2v} $$ (2)\n我们需要分区域讨论。将区域 $ [0,1]^{2} $ 沿对角线分成两个区域 $$ D_{1} = \\{ (x,y)\\mid 0\\leq x \u003c y\\leq 1 \\},\\quad D_{2} = [0,1]^{2}\\setminus D_{1} $$ 我们知道在 $ D_{1} $ 上有 $ U=X,V=Y $，在 $ D_{2} $ 上有 $ U=Y,V=X $。\n对于目标区域 $ 0\\leq u\\leq v\\leq 1 $，我们分别考虑来着 $ D_{1} $ 和 $ D_{2} $ 的贡献。来自 $ D_{1} $ 的映射满足 $ (x,y)=(u,v) $，从而 Jacobi 行列式为 $ \\left| J_{1} \\right|=1 $，产生的贡献为 $ f_{XY}(u,v)\\cdot 1=1 $。来自 $ D_{2} $ 的映射满足 $ (x,y)=(v,u) $，对应的 Jacobi 行列式为 $ \\left| J_{2} \\right|=1 $，产生的贡献为 $ f_{XY}(u,v)\\cdot 1=1 $。\n我们将两部分贡献相加，就得到了 $$ f_{UV}(u,v)=1+1=2 $$ (3)\n我们需要证明 $ f_{UV}(u,v) $ 是各分支逆映射密度函数乘以 Jacobi 行列式后的叠加。\n设 $ A $ 是 $ UV $ 平面上任意的 Borel 可测集。我们需要计算 $ \\mathbb{P}((U,V)\\in A) $。根据全概率公式，将事件分解到两个不相交的区域 $ D_{g} $ 和 $ D_{h} $ 上，有 $$ \\begin{align*} \\mathbb{P}((U,V)\\in A) \u0026 = \\mathbb{P}((X,Y)\\in D_{g},g(X,Y)\\in A) +\\mathbb{P}((X,Y)\\in D_{h},h(X,Y)\\in A) \\\\ \u0026 = \\underset{ \\{ (x,y)\\in D_{g}\\mid g(x,y)\\in A \\} }{ \\iint } f_{XY}(x,y)\\mathrm{d}x\\mathrm{d}y + \\underset{ \\{ (x,y)\\in D_{h}\\mid h(x,y)\\in A \\} }{ \\iint } f_{XY}(x,y)\\mathrm{d}x\\mathrm{d}y \\end{align*} $$ 对于第一个积分进行变量代换，令 $ (u,v)=g(x,y) $，则 $ (x,y)=g^{-1}(u,v) $。此时积分区域变为 $ A\\cap I_{g} $，面积元变为 $ \\left| J_{g^{-1}} \\right|\\mathrm{d}u\\mathrm{d}v $。同理对于第二个积分，令 $ (u,v)=h(x,y) $，那么积分区域变为 $ A\\cap I_{h} $，面积元变为 $ \\left| J_{^{-1}h} \\right|\\mathrm{d}u\\mathrm{d}v $。带入就得到了 $$ \\underset{ A\\cap I_{g} }{ \\iint } f_{XY}(g^{-1}(u,v))\\left| J_{g^{-1}} \\right| \\mathrm{d}u\\mathrm{d}v + \\underset{ A\\cap I_{h} }{ \\iint } f_{XY}(h^{-1}(u,v))\\left| J_{h^{-1}} \\right| \\mathrm{d}u\\mathrm{d}v $$ 利用指示函数将积分区域统一为 $ A $，就有 $$ \\mathbb{P}((U,V)\\in A) = \\underset{ A }{ \\iint } [f_{XY}(g^{-1}(u,v))\\left| J_{g^{-1}} \\right|\\cdot \\mathbb{I}_{(u,v)\\in I_{g}} + f_{XY}(h^{-1}(u,v))\\left| J_{h^{-1}} \\right|\\cdot \\mathbb{I}_{(u,v)\\in I_{h}}] \\mathrm{d}u\\mathrm{d}v $$ 根据 pdf 的定义，被积函数即为 $ f_{UV}(u,v) $，从而得证。\n(4)\n由题设，$ X\\sim U[0,1],Y\\sim U[0,2] $，并且两者独立。我们知道 $ f_{XY}(x,y)=f_{X}\\cdot f_{Y}=\\frac{1}{2} $。\n将矩形区域 $ R=[0,2]\\times[0,1] $ 按照直线 $ y=x $ 切割成两部分，分别为 $ D_{g} $ 满足 $ X\u003c Y $，$ D_{h} $ 满足 $ X\u003eY $。\n其中 $ D_{g} $ 区域 $ \\left| J_{1} \\right|=1 $，满足 $ u=x,v=y $，贡献 $ f_{XY}(u,v)=\\frac{1}{2} $，需要 $ 0\\leq u\u003c v\\leq 1 $。$ D_{h} $ 区域 $ \\left| J_{2} \\right|=1 $，满足 $ u=y,v=x $，贡献 $ f_{XY}(v,u)= \\frac{1}{2} $,需要 $ 0\\leq u\u003c v\\leq 1 $ 或者 $ 0\\leq u\\leq 1 $ 并且 $ 1\u003c v\\leq 2 $。我们考虑叠加两个区域的贡献，需要分两种情况，在 $ 0\\leq u\\leq v\\leq 1 $ 时同时被 $ D_{g} $ 和 $ D_{h} $ 覆盖，在 $ 0\\leq u\\leq 1\u003c v\\leq 2 $ 时只被 $ D_{h} $ 覆盖，因此 $$ f_{UV}(u,v) = \\begin{cases} 1, \u0026 0\\leq u\\leq v\\leq 1 \\\\ 0.5, \u0026 0\\leq u\\leq 1\u003c v\\leq 2 \\\\ 0, \u0026 \\text{o.w.} \\end{cases} $$\nProblem 4 (1)\n由于 $ q\\in(0,1) $，因此事件 $ \\{ Y=t \\} $ 等价于 $ (0,1)\\times \\{ t \\} $，所以 $$ \\mathbb{P}(Y=t)=\\binom{ T }{ t } \\int_{0}^{1} q^{t}(1-q)^{T-t} \\mathrm{d}q = \\binom{ T }{ t } \\cdot \\dfrac{t!(T-t)!}{(T+1)!} = \\dfrac{1}{T+1} $$ 说明 $$ \\mathbb{P}(Y=t)=\\dfrac{1}{T+1},\\quad t\\in[T]\\cup \\{ 0 \\} $$ 这说明在先验分布均匀的情况下，正面次数也均匀分布。\n(2)\n为了计算 $ Q $ 的概率密度，我们考虑 $ \\mathbb{P}(Q\\in[a,b]) $。根据全概率公式，我们知道 $$ \\begin{align*} \\mathbb{P}(Q\\in[a,b]) \u0026 = \\sum_{t=0}^{T} \\mathbb{P}(Q\\in[a,b]\\mid Y=t) \\\\ \u0026 = \\sum_{t=0}^{T} \\int_{a}^{b} \\binom{ T }{ t } q^{t}(1-q)^{T-t} \\mathrm{d}q \\\\ \u0026 = \\int_{a}^{b} \\sum_{t=0}^{T} q^{t}(1-q)^{T-t} \\mathrm{d}q \\\\ \u0026 = \\int_{a}^{b} 1 \\mathrm{d}q \\\\ \u0026 = b-a \\end{align*} $$ 从而说明这是一个均匀分布。因此 $$ p_{Q} = \\begin{cases} 1, \u0026 q\\in(0,1) \\\\ 0, \u0026 \\text{o.w.} \\end{cases} $$ 也就是 $ Q\\sim U(0,1) $。\n下面我们计算条件概率密度函数。根据定义，我们先计算 $$ \\mathbb{P}(Q\\in[q,q+h],Y=t) = \\int_{q}^{q+h} \\binom{ T }{ t } u^{t}(1-u)^{T-t} \\mathrm{d}u $$ 根据微积分基本定理，我们知道 $$ \\lim_{ h \\to 0 } \\dfrac{1}{h}\\cdot \\mathbb{P}(Q\\in[q,q+h],Y=t) = \\binom{ T }{ t } q^{t}(1-q)^{T-t} $$ 再根据第一问 $ \\mathbb{P}(Y=t)= \\frac{1}{T+1} $，我们知道 $$ \\begin{align*} p_{Q|Y}(q|t) \u0026 = \\binom{ T }{ t } q^{t}(1-q)^{T-t}\\cdot \\dfrac{1}{1 / (T+1)} \\\\ \u0026 = \\dfrac{(T+1)!}{t!(T-t)!}q^{t}(1-q)^{T-t} \\end{align*} $$ (3)\n根据定义，有 $$ M_{X}(\\theta) = \\mathbb{E}\\left[ 1 + \\sum_{n=1}^{\\infty} \\dfrac{\\theta^{n}}{n!}X^{n} \\right] = 1+\\sum_{n=1}^{\\infty} \\dfrac{\\theta^{n}}{n!}\\mathbb{E}[X^{n}] $$ 我们考虑计算 $ \\mathbb{E}[X^{n}] $。\n根据 $ (1) $ 式，我们得到 $$ \\begin{align*} \\mathbb{E}[X^{n}] \u0026 = \\int_{0}^{1} x^{n}p_{X}(x) \\mathrm{d}x \\\\ \u0026 = \\int_{0}^{1} x^{n} \\dfrac{\\Gamma(\\alpha+\\beta)}{\\Gamma(\\alpha)\\Gamma(\\beta)}x^{\\alpha-1}(1-x)^{\\beta-1} \\mathrm{d}x \\\\ \u0026 = \\dfrac{\\Gamma(\\alpha+\\beta)}{\\Gamma(\\alpha)\\Gamma(\\beta)} \\int_{0}^{1} x^{(n+\\alpha)-1}(1-x)^{\\beta-1} \\mathrm{d}x \\\\ \u0026 = \\dfrac{\\Gamma(\\alpha+\\beta)}{\\Gamma(\\alpha)\\Gamma(\\beta)} \\cdot \\dfrac{\\Gamma(n+\\alpha)\\Gamma(\\beta)}{\\Gamma(n+\\alpha+\\beta)} \\\\ \u0026 = \\dfrac{\\Gamma(n+\\alpha)}{\\Gamma(\\alpha)}\\cdot \\dfrac{\\Gamma(\\alpha+\\beta)}{\\Gamma(n+\\alpha+\\beta)} \\\\ \u0026 = \\prod_{k=0}^{n-1} \\dfrac{\\alpha+k}{\\alpha+\\beta+k} \\end{align*} $$ 其中最后一行利用了 $ \\Gamma $ 函数递推的性质。\n带入就得到了 $$ M_{X}(\\theta) = 1 + \\sum_{n=1}^{\\infty} \\dfrac{\\theta^{n}}{n!}\\cdot \\left( \\prod_{k=0}^{n-1} \\dfrac{\\alpha+k}{\\alpha+\\beta+k} \\right) $$\nProblem 5 (1)\n设随机变量 $ X\\sim\\text{Exp}(\\lambda) $，它的 pdf 和 cdf 分别为 $$ f(x) = \\lambda e^{ -\\lambda x }(x\\geq 0),\\quad F(x) = \\int_{0}^{x} \\lambda e^{ -\\lambda x } \\mathrm{d}x =1 - e^{ -\\lambda x } $$ 若 $ Y $ 是一个随机变量， CDF 为 $ F_{Y} $。那么利用 CDF 的单调性与定义可知，变换后的变量小于 $ u $ 的概率 $ P(F_Y(Y) \\le u) $ 等价于 $ P(Y \\le F_Y^{-1}(u)) $，而这恰好等于 $ F_Y(F_Y^{-1}(u)) = u $，这完全符合均匀分布的定义，因此我们知道 $ F_{Y}(Y) $ 服从 $ [0,1] $ 上的均匀分布。\n因此我们有 $ F(X)\\sim U[0,1] $，设 $ F(X)=U\\sim U[0,1] $，我们就可以得到 $ X=F^{-1}(U) $，从而 $$ \\begin{align*} 1 - e^{ -\\lambda X } \u0026 = U \\\\ e^{ -\\lambda X } \u0026 = 1-U \\\\ \\implies X \u0026 = - \\dfrac{1}{\\lambda}\\ln(1-U) \\end{align*} $$ 由于 $ 1-U $ 也服从 $ U[0,1] $，因此我们就得到了采样公式为 $$ X = -\\dfrac{1}{\\lambda}\\ln U $$ (2)\n根据题设，有 $$ \\begin{align*} f_{X}(x) \u0026 = \\dfrac{1}{\\Gamma(\\alpha)}x^{\\alpha-1}e^{ -x },\\quad x\u003e0 \\\\ f_{Y}(y) \u0026 = \\dfrac{1}{\\Gamma(\\beta)}y^{\\beta-1}e^{ -y },\\quad y\u003e0 \\end{align*} $$ 我们用 $ S,T $ 表示 $ X,Y $，得到 $$ X = ST, \\quad Y = S(1-T) $$ 从而 Jacobi 行列式为 $$ J = \\begin{vmatrix} t \u0026 s \\\\ 1-t \u0026 -s \\end{vmatrix} = -s \\implies \\left| J \\right| = s\\quad (S\u003e0) $$ 于是得到 $$ f_{ST}(s,t) = f_{XY}(x(s,t),y(s,t))\\cdot \\left| J \\right| = f_{XY}(st,s-st)\\cdot s $$ 其中由于 $ X,Y $ 独立 $$ f_{XY}(x,y) = f_{X}(x)\\cdot f_{Y}(y) = \\dfrac{1}{\\Gamma(\\alpha)\\Gamma(\\beta)}x^{\\alpha-1}y^{\\beta-1}e^{ -(x+y) } $$\n带入就得到了 $$ f_{ST}(s,t) = \\dfrac{1}{\\Gamma(\\alpha)\\Gamma(\\beta)} s ^{\\alpha+\\beta - 1}e^{ -s }t ^{\\alpha-1}(1-t)^{\\beta-1} $$ 定义域为 $ s\u003e0,0\u003c t\u003c 1 $。\n(3)\n观察 $ f_{ST} $，发现可以拆分成关于 $ s $ 和关于 $ t $ 的函数的乘积： $$ \\begin{align*} f_{ST}(s,t) \u0026 = \\dfrac{1}{\\Gamma(\\alpha)\\Gamma(\\beta)}(s^{\\alpha+\\beta-1}e^{ -s })(t ^{\\alpha-1}(1-t)^{\\beta-1}) \\\\ \u0026 = \\underbrace{ \\left( \\dfrac{1}{\\Gamma(\\alpha+\\beta)}s ^{(\\alpha+\\beta)-1}e^{ -s } \\right) }_{ g(s) }\\underbrace{ \\left( \\dfrac{\\Gamma(\\alpha+\\beta)}{\\Gamma(\\alpha)\\Gamma(\\beta)}t ^{\\alpha-1}(1-t)^{\\beta-1} \\right) }_{ h(t) } \\end{align*} $$ 从而 $ f_{ST}(s,t)=g(s)h(t) $，并且 $ s $ 和 $ t $ 的范围相互不依赖，从而 $ S $ 和 $ T $ 相互独立。\n我们接着讨论 $ T $ 的分布。根据上面的拆分，我们知道 $$ f_{T}(t)=h(t) = \\dfrac{\\Gamma(\\alpha+\\beta)}{\\Gamma(\\alpha)\\Gamma(\\beta)}t ^{\\alpha-1}(1-t)^{\\beta-1} $$ 这正是 $ T\\sim\\text{Beta}(\\alpha,\\beta) $ 的定义。\nProblem 6 (1)\n令 $ Z=X_{0} / \\sigma $，于是 $$ \\mathbb{E}[Z] = \\mathbb{E}\\left[ \\dfrac{X_{0}}{\\sigma} \\right] = \\dfrac{\\mathbb{E}[X_{0}]}{\\sigma} = \\dfrac{1}{\\sigma}\\cdot 0 = 0 $$ 以及 $$ \\text{Var}[Z] = \\text{Var}\\left[ \\dfrac{X_{0}}{\\sigma} \\right] = \\dfrac{\\text{Var}[X_{0}]}{\\sigma^{2}} = 1 $$ 并且由于 $ X_{0} $ 符合正态分布，因此经过线性变换得到 $ Z $ 以后依旧符合正态分布。\n因此 $ Z $ 服从期望为 $ 0 $，方差为 $ 1 $ 的正态分布，即 $ Z\\sim \\mathcal{N}(0,1) $。\n(2)\n我们展开 $ \\sum_{i=1}^{n}(X_{i}-\\hat{X}_{n})^{2} $，得到 $$ \\begin{align*} \\sum_{i=1}^{n} (X_{i}-\\hat{X}_{n})^{2} \u0026 = \\sum_{i=1}^{n} X_{i}^{2} - 2\\hat{X}_{n}\\sum_{i=1}^{n} X_{i} + n\\hat{X}_{n}^{2} \\\\ \u0026 = \\sum_{i=1}^{n} X_{i}^{2} - n\\hat{X}_{n}^{2} \\end{align*} $$ 因此我们需要计算 $ \\mathbb{E}[\\sum_{i=1}^{n} X_{i}^{2} - n\\hat{X}_{n}^{2}] $。\n对于 $ \\mathbb{E}[X_{i}^{2}] $ 项，我们利用方差公式，得到 $$ \\mathbb{E}[X_{i}^{2}] = \\text{Var}[X_{i}] + (\\mathbb{E}[X_{i}])^{2} = \\sigma^{2} + 0 = \\sigma^{2} $$ 所以 $ \\mathbb{E}\\left[ \\sum_{i=1}^{n}X_{i}^{2} \\right]=\\sum_{i=1}^{n}\\mathbb{E}[X_{i}^{2}]=n\\sigma^{2} $。\n对于 $ \\mathbb{E}[\\hat{X}_{n}^{2}] $，我们先计算 $ \\mathbb{E}[\\hat{X}_{n}] $ 和 $ \\text{Var}[\\hat{X}_{n}] $，得到 $$ \\mathbb{E}[\\hat{X}_{n}]=0,\\quad \\text{Var}[\\hat{X}_{n}] = \\text{Var}\\left[ \\dfrac{1}{n}\\sum X_{i} \\right] = \\dfrac{\\sigma^{2}}{n} $$ 从而 $$ \\mathbb{E}[\\hat{X}_{n}^{2}] = \\mathbb{E}[\\hat{X}_{n}] + \\text{Var}[\\hat{X}_{n}] = \\dfrac{\\sigma^{2}}{n} $$ 于是 $$ \\mathbb{E}\\left[ \\sum_{i=1}^{n} (X_{i}-\\hat{X}_{n})^{2} \\right] = n\\sigma^{2} - n\\left( \\dfrac{\\sigma^{2}}{n} \\right) = (n-1)\\sigma^{2} $$ 这样就算出了 $$ \\mathbb{E}[S_{n}^{2}] = \\mathbb{E}\\left[ \\dfrac{\\sum_{i=1}^{n} (X_{i}-\\hat{X}_{n})^{2}}{n-1} \\right] = \\sigma^{2} $$ (3)\n按照定义， $$ \\hat{X}_{2} = \\dfrac{X_{1}+X_{2}}{2}\\implies S_{2}^{2}=\\dfrac{1}{2-1}\\sum_{i=1}^{2} (X_{i}-\\hat{X}_{2})^{2} = \\dfrac{(X_{1}-X_{2})^{2}}{2} $$ 从而得到 $$ S_{2} = \\dfrac{\\left| X_{1}-X_{2} \\right| }{\\sqrt{ 2 }} $$ 进而得到 $$ Y_{2} = \\dfrac{X_{0}}{S_{2}} = \\dfrac{\\sqrt{ 2 }X_{0}}{\\left| X_{1}-X_{2} \\right| } $$ 我们直到 $ X_{0}\\sim \\mathcal{N}(0,\\sigma^{2}) $。令 $ D=X_{1}-X_{2} $，由于 $ X_{1},X_{2} $ 独立且均服从 $ \\mathcal{N}(0,\\sigma^{2}) $ 分布，因此 $ D\\sim \\mathcal{N}(0,\\sigma^{2}+\\sigma^{2})=\\mathcal{N}(0,2\\sigma^{2}) $。我们将它们写成标准正态分布，就有 $ \\dfrac{X_{0}}{\\sigma}=U\\sim \\mathcal{N}(0,1) $ 以及 $ \\dfrac{D}{\\sqrt{ 2 }\\sigma}=V\\sim \\mathcal{N}(0,1) $。带入就有 $$ Y_{2} = \\dfrac{\\sqrt{ 2 }(\\sigma U)}{\\left| \\sqrt{ 2\\sigma V } \\right| } = \\dfrac{U}{\\left| V \\right| } $$ 我们设 $ W=\\left| V \\right| $，那么 $ W $ 服从分布 $$ p_{W}(w) = \\dfrac{2}{\\sqrt{ 2\\pi }}e^{ -w^{2} / 2 },\\quad w\u003e0 $$ 带入 $ Y=U / W $，计算 Jacobi 行列式并带入即可得到 $$ \\begin{align*} p_{Y_{2}}(y) \u0026 = \\int_{-\\infty}^{\\infty} p_{UW}(yw,w)\\cdot \\left| w \\right| \\mathrm{d}w \\\\ \u0026 = \\int_{0}^{\\infty} w\\cdot p_{U}(yw)\\cdot p_{W}(w) \\mathrm{d}w \\\\ \u0026 = \\int_{0}^{\\infty} w\\cdot\\left( \\dfrac{1}{\\sqrt{ 2\\pi }}e^{ -(yw)^{2}/2 } \\right)\\cdot\\left( \\dfrac{2}{\\sqrt{ 2\\pi }}e^{ -\\omega^{2}/2 } \\right) \\mathrm{d}w \\\\ \u0026 = \\dfrac{1}{\\pi}\\int_{0}^{\\infty} we^{ -w^{2}(y^{2}+1)/2 } \\mathrm{d}w \\\\ \u0026 = \\dfrac{1}{\\pi(1+y^{2})}[e^{ -(y^{2}+1)w^{2}/2 }]_{0}^{\\infty} \\\\ \u0026 = \\dfrac{1}{\\pi(1+y^{2})} \\end{align*} $$ 说明了 pdf 为 $ p_{Y_{2}}(y)=1 / \\pi(y^{2}+1) $，就是标准柯西分布的 pdf。\n(4)\n我们需要证明在 $ \\theta\\neq 0 $ 时 $ \\mathbb{E}[e^{ \\theta Y_{2} }] $ 发散。根据定义，我们有 $$ \\begin{align*} \\mathbb{E}[e^{ \\theta Y_{2} }] \u0026 = \\int_{-\\infty}^{\\infty} e^{ \\theta y }\\cdot p_{Y_{2}}(y) \\mathrm{d}y \\\\ \u0026 = \\dfrac{1}{\\pi}\\int_{-\\infty}^{\\infty} \\dfrac{e^{ \\theta y }}{1+y^{2}} \\mathrm{d}y \\\\ \u0026 \u003e \\dfrac{1}{\\pi}\\int_{0}^{\\infty} \\dfrac{e^{ \\theta y }}{1+y^{2}} \\mathrm{d}y \\end{align*} $$ 对于任意 $ \\theta\u003e0 $，显然存在 $ M\u003e0 $ 使得当 $ y\u003eM $ 时有 $$ e^{ \\theta y }\u003e1+y^{2} $$ 从而 $$ \\begin{align*} \\int_{0}^{\\infty} \\dfrac{e^{ \\theta y }}{1+y^{2}} \\mathrm{d}y \u0026 \u003e \\int_{M}^{\\infty} \\dfrac{e^{ \\theta y }}{1+y^{2}} \\mathrm{d}y \\\\ \u0026 \u003e \\int_{M}^{\\infty} 1\\cdot \\mathrm{d}y \\\\ \u0026 = \\infty \\end{align*} $$ 从而得到了 $ \\mathbb{E}[e^{ \\theta Y_{2} }] $ 发散。这意味着 $ Y_{2} $ 的矩生成函数对于任意 $ \\theta\\neq 0 $ 均不存在。\n","permalink":"https://diefish1024.github.io/posts/class-notes/math2701-probability-theory/math2701-hw5/","summary":"\u003ch2 id=\"problem-1\"\u003eProblem 1\u003c/h2\u003e\n\u003cp\u003e\u003cstrong\u003e(1)\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e根据题设条件，我们知道最多抽取 $ m $ 个黑球，最少抽取 $ 0 $ 个黑球。设随机变量 $ X $ 表示抽到黑球的个数，根据组合意义，我们得到 $ X $ 的概率质量函数为\n$$ \n\n\\mathbb{P}(X=x) = \\dfrac{\\binom{ m }{ x } \\binom{ n-m }{ k-x } }{\\binom{ n }{ k } },\\quad x = 0,1,\\dots,m\n\n $$\n\u003cstrong\u003e(2)\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e矩生成函数定义为 $ M_{X}(\\theta) = \\mathbb{E}[e^{ \\theta X }] $。我们带入得到\n$$ \n\n\\begin{align*}\nM_{X}(\\theta) \u0026 = \\sum_{x}e^{ \\theta x }\\mathbb{P}(X=x) \\\\\n \u0026 = \\sum_{x=0}^{m} e^{ \\theta x } \\dfrac{\\binom{ m }{ x } \\binom{ n-m }{ k-x } }{\\binom{ n }{ k } } \\\\\n \u0026 = \\dfrac{1}{\\binom{ n }{ k } }\\sum_{x=0}^{m} e^{ \\theta x }\\binom{ m }{ x } \\binom{ n-m }{ k-x } \n\\end{align*}\n\n $$\n\u003cstrong\u003e(3)\u003c/strong\u003e\u003c/p\u003e","title":"MATH2701 HW5"},{"content":"Exercise 1 设 $ A $ 是一个 $ n\\times n $ 的矩阵，记 $ A $ 的不同特征值为 $ \\lambda_{1},\\lambda_{2},\\dots,\\lambda_{k} $，代数重数分别为 $ a_{i} $，几何重数为 $ g_{i}=\\text{dim ker}(A-\\lambda_{i}I) $。\n(⇒) 若 $ A $ 可对角化，则存在可逆矩阵 $ P $ 使得 $ P^{-1}AP=D $ 为对角阵。由于 $$ \\begin{align*} \\det(A - \\lambda I) \u0026 = \\det(P^{-1}DP-\\lambda I) \\\\ \u0026 = \\det(P^{-1}(D-\\lambda I)P) \\\\ \u0026 = \\det(D-\\lambda I) \\end{align*} $$ 说 $ A $ 和 $ D $ 的特征多项式相同，从而有一样的特征值和代数重数。\n由于 $ A $ 可对角化，这意味着存在 $ n $ 个线性无关的特征向量构成的基 $ B=\\{ v_{1},v_{2},\\dots,v_{n} \\} $ 构成了矩阵 $ P $ 的列空间，每个特征向量都属于某个特征值 $ \\lambda $ 的特征空间 $ E_{\\lambda} $，并且该特征值的几何重数 $ g_{\\lambda}=\\text{dim }E_{\\lambda} $。由于 $ B $ 是一个 $ n $ 维线性空间，因此这些特征向量构成了一个 $ n $ 维线性空间的一个基，于是 $$ \\sum_{i=1}^{k} g_{i}=n $$ 我们又知道任何特征值的几何重数总是小于等于代数重数，也就是 $ g_{k}\\leq a_{k} $，但是我们又有 $$ \\sum_{i=1}^{k} a_{i}=n $$ 这就得到了 $ a_{i}=g_{i} $，每个特征值的代数重数等于几何重数。\n(⇐) 反过来，若对每个 $ i $ 有 $ g_i=a_i $。注意代数重数之和等于矩阵阶数： $$ \\sum_{i=1}^k a_i = n $$ 由假设得 $ \\sum_{i=1}^k g_i=\\sum_{i=1}^k a_i=n $。而不同特征值对应的特征向量属于不同的特征子空间，这些特征子空间两两交为 $ {0} $，所以可以从每个特征子空间中取一组基向量，合并得到 $ n $ 个线性无关的特征向量，从而构成 $ \\mathbb{C}^n $ 的基。于是存在由特征向量构成的可逆矩阵 $ P $，使得 $ P^{-1}AP $ 为对角矩阵——即 $ A $ 可对角化。\n综上，$ A $ 可对角化当且仅当对每个特征值 $ \\lambda $，代数重数等于几何重数。\nExercise 2 首先根据特征值的性质，我们得到方差 $$ \\lambda^{2}=\\lambda $$ 其中 $ \\lambda $ 是 $ A $ 的特征值。因此我们得到 $ \\lambda=0,1 $。从而证明了特征值只可能是 $ 0 $ 或 $ 1 $。\n(1)\n我们构造 $ A $ 为所有元素全为 $ 0 $ 的矩阵，显然满足 $ A^{2}=A $ 并且 $ A $ 的特征值均为 $ 0 $。\n(2)\n我们构造 $ A=I $，显然满足 $ A^{2}=A=I $，并且 $ A $ 的特征值均为 $ 1 $。\n(3)\n我们构造 $$ A = \\begin{pmatrix} I_{n} \u0026 \\mathbf{0} \\\\ \\mathbf{0} \u0026 \\mathbf{0} \\end{pmatrix} $$ 此时有 $$ A^{2} = \\begin{pmatrix} I_{n}+\\mathbf{0} \u0026 \\mathbf{0} \\\\ \\mathbf{0} \u0026 \\mathbf{0} \\end{pmatrix} = A $$ 并且 $ A $ 的特征值为 $ 0 $ 和 $ 1 $。\nExercise 3 我们首先计算 $ A $ 的特征值 $$ \\det(A-\\lambda I) = \\begin{vmatrix} -3-\\lambda \u0026 2 \\\\ -2 \u0026 2-\\lambda \\end{vmatrix} = \\lambda^{2}+\\lambda-2 = 0 $$ 解得 $ \\lambda = 1,-2 $。\n分别计算 $ \\lambda_{1}=1,\\lambda_{2}=-2 $ 时的特征值 $$ (A-\\lambda_{1}I)v_{1} = 0,(A-\\lambda_{2}I)v_{2} = 0 $$ 得到 $$ v_{1} = \\begin{pmatrix} 2 \\\\ 1 \\end{pmatrix},\\quad v_{2} = \\begin{pmatrix} 1 \\\\ 2 \\end{pmatrix} $$ 从而有 $$ P = \\begin{pmatrix} 2 \u0026 1 \\\\ 1 \u0026 2 \\end{pmatrix},\\quad P^{-1}AP = \\begin{pmatrix} 1 \u0026 \\\\ \u0026 -2 \\end{pmatrix} $$\nExercise 4 我们将 $ A $ 对角化即可。\n首先计算 $ A $ 的特征值，有 $$ \\det(A-\\lambda I) = \\begin{vmatrix} 1-\\lambda \u0026 2 \u0026 2 \\\\ 2 \u0026 1-\\lambda \u0026 2 \\\\ 2 \u0026 2 \u0026 1-\\lambda \\end{vmatrix} = -(\\lambda+1)^{2}(\\lambda-5) $$ 分别计算 $ \\lambda_{1}=-1,\\lambda_{2}=5 $ 时的特征向量。\n当 $ \\lambda=-1 $，我们计算 $$ (A+I)v = 0 $$ 得到 $$ v_{1} = \\begin{pmatrix} -1 \\\\ 1 \\\\ 0 \\end{pmatrix},\\quad v_{2} = \\begin{pmatrix} -1 \\\\ 0 \\\\ 1 \\end{pmatrix} $$ 当 $ \\lambda=5 $，计算 $$ (A-5I)v = 0 $$ 得到 $$ v_{3} = \\begin{pmatrix} 1 \\\\ 1 \\\\ 1 \\end{pmatrix} $$ 从而我们取 $$ P = \\begin{pmatrix} -1 \u0026 -1 \u0026 1 \\\\ 1 \u0026 0 \u0026 1 \\\\ 0 \u0026 1 \u0026 1 \\end{pmatrix} \\implies P^{-1}AP = D = \\begin{pmatrix} -1 \u0026 \u0026 \\\\ \u0026 -1 \u0026 \\\\ \u0026 \u0026 5 \\end{pmatrix} $$ 就有 $$ A = PDP^{-1} \\implies A^{100} = PD^{100}P^{-1} $$ 计算得到 $$ \\begin{align*} A^{100} \u0026 = \\begin{pmatrix} -1 \u0026 -1 \u0026 1 \\\\ 1 \u0026 0 \u0026 1 \\\\ 0 \u0026 1 \u0026 1 \\end{pmatrix}\\begin{pmatrix} 1 \u0026 \u0026 \\\\ \u0026 1 \u0026 \\\\ \u0026 \u0026 5^{100} \\end{pmatrix} \\dfrac{1}{3} \\begin{pmatrix} -1 \u0026 2 \u0026 -1 \\\\ -1 \u0026 -1 \u0026 2 \\\\ 1 \u0026 1 \u0026 1 \\end{pmatrix} \\\\ \u0026 = \\dfrac{1}{3} \\begin{pmatrix} 2+5^{100} \u0026 -1+5^{100} \u0026 -1+5^{100} \\\\ -1+5^{100} \u0026 2+5^{100} \u0026 -1+5^{100} \\\\ -1+5^{100} \u0026 -1+5^{100} \u0026 2+5^{100} \\end{pmatrix} \\end{align*} $$\nExercise 5 (1)\n根据系数可以直接得到 $$ S = \\begin{pmatrix} 2 \u0026 -2 \u0026 3 \\\\ -2 \u0026 -1 \u0026 0 \\\\ 3 \u0026 0 \u0026 3 \\end{pmatrix} $$ 由于 $$ \\det \\begin{pmatrix} 2 \u0026 -2 \\\\ -2 \u0026 -1 \\end{pmatrix} \u003c 0 $$ 我们知道 $ S $ 不是正定的。\n(2)\n根据系数得到 $$ S = \\begin{pmatrix} 2 \u0026 1 \u0026 1 \\\\ 1 \u0026 2 \u0026 -1 \\\\ 1 \u0026 -1 \u0026 2 \\end{pmatrix} $$ 由于 $$ x^{T}Sx \\geq 0 $$ 根据定义，我们知道 $ S $ 是正定的。\n","permalink":"https://diefish1024.github.io/posts/class-notes/math1205h-linear-algebra/math1205h-hw16/","summary":"\u003ch2 id=\"exercise-1\"\u003eExercise 1\u003c/h2\u003e\n\u003cp\u003e设 $ A $ 是一个 $ n\\times n $ 的矩阵，记 $ A $ 的不同特征值为 $ \\lambda_{1},\\lambda_{2},\\dots,\\lambda_{k} $，代数重数分别为 $ a_{i} $，几何重数为 $ g_{i}=\\text{dim ker}(A-\\lambda_{i}I) $。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e(⇒)\u003c/strong\u003e 若 $ A $ 可对角化，则存在可逆矩阵 $ P $ 使得 $ P^{-1}AP=D $ 为对角阵。由于\n$$ \n\n\\begin{align*}\n\\det(A - \\lambda I) \u0026 = \\det(P^{-1}DP-\\lambda I) \\\\\n \u0026 = \\det(P^{-1}(D-\\lambda I)P) \\\\\n \u0026 = \\det(D-\\lambda I)\n\\end{align*}\n\n $$\n说 $ A $ 和 $ D $ 的特征多项式相同，从而有一样的特征值和代数重数。\u003c/p\u003e","title":"MATH1205H HW16"},{"content":"Exercise 2 先证充分性。如果 $ G $ 是一个二分图，设两部分的点集分别为 $ L,R $，所有边均满足两端点分别在 $ L,R $ 中。反证法，加入存在奇环，设环中第一和最后一个点分别为 $ v_{1},v_{k} $，那么 $ k $ 为奇数。不妨设 $ v_{1}\\in L $，由于一条边必然在 $ L,R $ 两部分之间 ，所以环中的点在 $ L,R $ 交替出现，即 $ v_{2}\\in R,v_{3}\\in L,\\dots $，由于 $ k $ 是奇数，因此 $ v_{k}\\in L $。这说明 $ v_{1},v_{k} $ 两个 $ L $ 中的点存在连边，与二分图矛盾。因此二分图中没有奇环。\n再证必要性。如果 $ G $ 没有奇环，我们可以将 $ G $ 分成若干个连通块，每个连通块中任取一个点 $ u_{i} $，我们按照一下顺序将所有点分成 $ L,R $ 两组：首先令 $ u_{i}\\in L $，将所有与 $ u_{i} $ 最短距离为偶数的点加入 $ L $，其余的点，也就是到 $ u_{i} $ 最短距离为奇数的点加入 $ R $。\n下面我们证明这是一个二分图，也就是证明所有 $ L $ 中的点两两不连边，所有 $ R $ 中的点也两两不练边。设 $ v_{1},v_{2}\\in L $，如果这两个点不在一个连通块内，那么显然 $ v_{1},v_{2} $ 之间没有边；如果两个点在一个连通块内，设这个连通块中之前选取的代表点 $ u $，我们知道 $ d(u,v_{1}),d(u,v_{2}) $ 均为偶数，如果边 $ \\{ v_{1},v_{2} \\} $ 存在，那么我们就找到了一个长度为奇数的环 $ u\\dots v_{1}v_{2}\\dots u $，矛盾，因此此时 $ v_{1},v_{2} $ 之间也没有边。对于 $ R $ 中的两个点，同理，如果两个点在一个连通块，那么假设边存在，选取对应连通块的代表元素 $ u $，也找到了奇数环 $ u\\dots v_{1}v_{2}\\dots u $，矛盾。所以 $ L $ 和 $ R $ 中一个集合内的点两两都没有连边，这是一个二分图。证毕！\nExercise 3 (1)\n由于 $ G $ 是 $ d $-正则图，所以最大的特征值 $ \\lambda_{1}=d $。如果 $ G $ 不连通，那么至少可以被划分为两个连通块 $ G_{1},G_{2} $。我们为每个连通块都定义一个特征向量，对于 $ G_{1} $，我们构造向量 $ v_{1} $，其中对应在 $ G_{1} $ 中顶点的元素为 $ 1 $，其余为 $ 0 $。\n此时当邻接矩阵乘以 $ v_{1} $，由于 $ G_{1} $ 和其他连通块之间都没有边，因此对于 $ G_{1} $ 中的每个点，结果都是 $ d $，其余的点都是 $ 0 $，所以就有 $$ Av_{1} = dv_{1} $$ 对于 $ G_{2} $，同理也能构造出这样 $ v_{2} $。并且 $ v_{1},v_{2} $ 显然是线性无关的，这样我们就找到了两个特征值 $ d $ 对应的特征向量，说明 $ d $ 的几何重数至少是 $ 2 $，从而代数重数也至少是 $ 2 $，所以必然有 $$ \\lambda_{1}=\\lambda_{2}=d $$ (2)\n由于 $ d $-正则图的性质，我们知道 $ \\left| \\lambda \\right|\\leq d $，因此我们只需要证明 $ -d $ 是一个特征值即可说明最小的特征值 $ \\lambda_{n}=-d $。\n对于二分图 $ G $，我们可以将点集 $ V $ 分成不相交的 $ U,W $ 两个集合，使得每条边的两个端点分别属于 $ U,W $。我们构造向量 $ v $ 满足所有 $ U $ 中的点对应的元素为 $ 1 $，所有 $ W $ 中的点对应的元素为 $ -1 $。根据二分图和正则图的性质，我们就知道 $$ Av = -dv $$ 因为 $ U $ 中的点对应行中只有 $ W $ 中的点值为 $ 1 $，共有 $ d $ 个，乘以 $ v $ 以后就会得到 $ -d $。$ W $ 中的点同理。\n由于 $ v $ 是一个非零向量，那么根据特征值的定义，我们就得到了 $ -d $ 是一个特征值，从而 $$ \\lambda_{n}=-d $$\nExercise 6 由于每个顶点 $ v $ 和所有通过路径可以和 $ v $ 相连的顶点构成的集合是一个联通子图，因此 $ v $ 至少属于一个连通分量。\n假设 $ u $ 同时属于两个不同的连通分量 $ C_{1},C_{2} $，那么对于 $ v_{1}\\in C_{1},v_{2}\\in C_{2} $，我们知道存在从 $ u $ 到 $ v_{1} $ 和 $ u $ 到 $ v_{2} $ 的路径，从而说明存在 $ v_{1} $ 到 $ v_{2} $ 的路径，从而与定义矛盾。\n因此每个顶点唯一地属于一个连通分量。\n接着证明如果 $ G $ 不连通，当且仅当 $ G $ 包含至少两个连通分量。首先如果 $ G $ 不连通，那么存在 $ u,v $ 满足 $ u,v $ 之间不存在任何路径相连，如果 $ u,v $ 属于一个连通分量，那么则与定义矛盾，所以 $ u,v $ 一定分开属于两个连通分量，因此 $ G $ 至少包含两个连通分量。如果 $ G $ 至少包含两个连通分量，那么取两个属于不同连通分量的点 $ u,v $，我们可以知道 $ u,v $ 之间不存在路径，因此 $ G $ 不连通。\nExercise 7 ($ \\Rightarrow $) 假设 $ G $ 有一个连通分量 $ C $ 是二部图。我们可以将 $ C $ 的点集 $ V(C) $ 分成不相交的 $ U,W $ 两个集合，使得 $ C $ 中每条边的两个端点分别属于 $ U $ 和 $ W $。我们构造向量 $ x $ 满足所有 $ U $ 中的点对应的元素为 $ 1 $，所有 $ W $ 中的点对应的元素为 $ -1 $，而所有不在 $ C $ 中的点对应的元素为 $ 0 $。根据二部图和 $ d $-正则图的性质，对于任何 $ U $ 中的点，其 $ d $ 个邻居都在 $ W $ 中，因此 $ A $ 的对应行与 $ x $ 相乘得到 $ d \\times (-1) = -d $。同理，对于任何 $ W $ 中的点，其 $ d $ 个邻居都在 $ U $ 中，相乘得到 $ d \\times (1) = d = -d \\times (-1) $。对于不在 $ C $ 中的点，其邻居也不在 $ C $ 中，相乘结果为 $ 0 $。因此，我们就知道 $ Ax = -dx $。由于 $ x $ 是一个非零向量，那么根据特征值的定义，$ -d $ 是一个特征值。又因为对于 $ d $-正则图的所有特征值 $ \\lambda $ 均满足 $ |\\lambda| \\leq d $，我们从而得到最小特征值 $ \\lambda_{n}=-d $。\n($ \\Leftarrow $) 假设 $ \\lambda_{n}=-d $。令 $ x $ 为其对应的非零特征向量，满足 $ Ax = -dx $。因为 $ x $ 非零，所以必定存在一个连通分量 $ C $ 使得 $ x $ 在 $ C $ 上的分量不全为零。在 $ C $ 中取一个顶点 $ v $ 使得其分量的绝对值 $ |x_v| $ 最大，令 $ M = |x_v| \u003e 0 $。不失一般性，设 $ x_v=M $。根据特征值方程有 $ \\sum_{u \\sim v} x_u = -d x_v = -dM $。由三角不等式可得 $ dM = |-dM| = |\\sum_{u \\sim v} x_u| \\le \\sum_{u \\sim v} |x_u| $。又因为 $ M $ 是最大绝对值，我们有 $ \\sum_{u \\sim v} |x_u| \\le \\sum_{u \\sim v} M = dM $。因此上述不等式必须取等，这意味着 $ v $ 的所有邻居 $ u $ 必须满足 $ |x_u|=M $ 且符号与 $ x_v $ 相反，即 $ x_u = -M $。此论证可以沿 $ C $ 中的路径传递，说明 $ C $ 中所有顶点的分量绝对值均为 $ M $。于是我们可以将 $ C $ 的点集划分为 $ U=\\{u \\in V(C) \\mid x_u=M\\} $ 和 $ W=\\{w \\in V(C) \\mid x_w=-M\\} $。根据构造， $ C $ 中的任意一条边都连接着 $ U $ 和 $ W $ 中的顶点，因此连通分量 $ C $ 是一个二部图。\n","permalink":"https://diefish1024.github.io/posts/class-notes/math1205h-linear-algebra/math1205h-hw15/","summary":"\u003ch2 id=\"exercise-2\"\u003eExercise 2\u003c/h2\u003e\n\u003cp\u003e先证充分性。如果 $ G $ 是一个二分图，设两部分的点集分别为 $ L,R $，所有边均满足两端点分别在 $ L,R $ 中。反证法，加入存在奇环，设环中第一和最后一个点分别为 $ v_{1},v_{k} $，那么 $ k $ 为奇数。不妨设 $ v_{1}\\in L $，由于一条边必然在 $ L,R $ 两部分之间 ，所以环中的点在 $ L,R $ 交替出现，即 $ v_{2}\\in R,v_{3}\\in L,\\dots $，由于 $ k $ 是奇数，因此 $ v_{k}\\in L $。这说明 $ v_{1},v_{k} $ 两个 $ L $ 中的点存在连边，与二分图矛盾。因此二分图中没有奇环。\u003c/p\u003e\n\u003cp\u003e再证必要性。如果 $ G $ 没有奇环，我们可以将 $ G $ 分成若干个连通块，每个连通块中任取一个点 $ u_{i} $，我们按照一下顺序将所有点分成 $ L,R $ 两组：首先令 $ u_{i}\\in L $，将所有与 $ u_{i} $ 最短距离为偶数的点加入 $ L $，其余的点，也就是到 $ u_{i} $ 最短距离为奇数的点加入 $ R $。\u003c/p\u003e","title":"MATH1205H HW15"},{"content":"Exercise 1 首先计算 $ A $ 的特征值和特征向量。 $$ \\det(A-\\lambda I) = (-1-\\lambda)(-\\lambda)-6 = 0 \\implies \\lambda^{2}+\\lambda-6 = 0 $$ 解得 $ \\lambda_{1}=2,\\lambda_{2}=-3 $。\n对于 $ \\lambda_{1}=2 $，我们求解 $ (A-2I)x=0 $，特征向量为 $$ x_{1} = k\\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix} $$ 对于 $ \\lambda_{2}=-3 $，我们求解 $ (A+3I)x=0 $，可以取特征向量为 $$ x_{2} = k\\begin{pmatrix} 3 \\\\ -2 \\end{pmatrix} $$\n对于 $ A^{2} $，我们计算得到 $ \\mu_{1}=4,\\mu_{2}=9 $。对于每个特征值，带入解出 $$ x_{1} = k\\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix},x_{2} = k\\begin{pmatrix} 3 \\\\ -2 \\end{pmatrix} $$\nExercise 2 根据定义，对于特征值 $ \\lambda $ 和特征向量 $ x_{0} $，我们有 $$ Ax_{0}=\\lambda x_{0} $$ 两边同时左乘 $ A $，得到 $$ A^{2}x_{0} = A(\\lambda x_{0}) = \\lambda(Ax_{0}) = \\lambda^{2}x_{0} $$ 从而说明 $ \\lambda^{2} $ 是 $ A^{2} $ 的一个特征值，并且对应的特征向量还是 $ x_{0} $。\n但是逆命题不一定成立。反例：考虑矩阵 $$ A = \\begin{pmatrix} 0 \u0026 1 \\\\ 0 \u0026 0 \\end{pmatrix} $$ 存在特征值 $ \\lambda=0 $，对应的特征向量为 $$ x =k\\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} $$ 但是矩阵 $$ A^{2} = \\begin{pmatrix} 0 \u0026 0 \\\\ 0 \u0026 0 \\end{pmatrix} $$ 显然任何非零向量都是 $ A^{2} $ 的特征向量。所以 $ A $ 和 $ A^{2} $ 的特征向量并不相等。\nExercise 3 由于转置不改变一个矩阵的行列式，并且 $ (A-\\lambda I)^{T}=A^{T}-\\lambda I $，因此 $$ \\det(A-\\lambda I) = \\det(A^{T}-\\lambda I) $$ 说明 $ A $ 和 $ A^{T} $ 的特征多项式完全相同，拥有一样的特征值。\n但是特征向量则通常不相同。\nExercise 4 首先证明 $ \\lambda_{0}\\neq 0 $。如果 $ \\lambda_{0} = 0 $，那么 $ \\det(A-0\\cdot I)=\\det A=0 $，这与 $ A $ 是可逆矩阵矛盾，说明 $ \\lambda_{0} $ 是非零特征值。\n根据定义，我们有 $$ Ax = \\lambda_{0}x $$ 由于 $ A $ 可逆，因此两侧同乘 $ A^{-1} $，得到 $$ A^{-1}(Ax) = A^{-1}(\\lambda_{0}x) \\underset{\\lambda_{0}\\neq 0}{\\implies} \\dfrac{1}{\\lambda_{0}}x = A^{-1}x $$ 从而得到 $ 1 / \\lambda_{0} $ 是 $ A^{-1} $ 的一个特征值，并且特征向量相同。\nExercise 6 加法：设 $ u,v\\in \\mathbb{C}^{n} $，其中 $ u=(u_{1},u_{2},\\dots,u_{n}),v=(v_{1},v_{2},\\dots,v_{n}) $，那么我们有 $$ u+v=(u_{1}+v_{1},u_{2}+v_{2},\\dots,u_{n}+v_{n}) $$ 每个分量 $ u_{i}+c_{i} $ 都是复数，从而 $ u+v\\in \\mathbb{C}^{n} $\n标量乘法：$ cv=(cv_{1},cv_{2},\\dots,cv_{n}) $，每个分量 $ cv_{i}\\in \\mathbb{C} $，从而 $ cv\\in \\mathbb{C}^{n} $。\n接着根据复数运算的性质，可以验证由于所有八个向量空间的公理都得到满足，因此 $ \\mathbb{C}^n $ 在通常的加法和数乘定义下是一个向量空间。\nExercise 8 为了证明 $ \\text{dim}(\\mathbb{C}^n) = n $，我们需要找到一个由 $ n $ 个向量组成的基。\n考虑 $ \\mathbb{C}^n $ 中的标准基向量集合 $ B = \\{e_1, e_2, ..., e_n\\} $，我们来证明它是一个基。\n首先我们需要证明 $ \\mathbb{C}^n $ 中的任意向量 $ v $ 都可以表示为 $ B $ 中向量的线性组合，也就是 $ B $ 可以张成 $ \\mathbb{C}^{n} $。设 $ v = (v_1, v_2, ..., v_n) $ 是 $ \\mathbb{C}^n $ 中的任意一个向量，其中 $ v_i \\in \\mathbb{C} $。我们可以将 $ v $ 写成 $$ \\begin{align*} v \u0026 = (v_1, v_2, ..., v_n) \\\\ \u0026 = v_1(1, 0, ..., 0) + v_2(0, 1, ..., 0) + ... + v_n(0, 0, ..., 1) \\\\ \u0026 = v_1e_1 + v_2e_2 + ... + v_ne_n \\end{align*} $$ 由于标量 $ v_1, v_2, ..., v_n $ 都是复数，这表明任意向量 $ v $ 都可以表示为 $ B $ 中向量的线性组合。因此，$ B $ 张成 $ \\mathbb{C}^n $。\n接着我们证明 $ B $ 中的向量线性无关。也就需要证明方程 $ c_1e_1 + c_2e_2 + ... + c_ne_n = 0 $（其中 $ c_i \\in \\mathbb{C} $，$ 0 $ 是零向量）的唯一解是 $ c_1=c_2=...=c_n=0 $。这个方程可以写成 $$ \\begin{align*} \u0026 c_1(1, 0, ..., 0) + c_2(0, 1, ..., 0) + ... + c_n(0, 0, ..., 1) = (0, 0, ..., 0) \\\\ \u0026 \\implies (c_1, c_2, ..., c_n) = (0, 0, ..., 0) \\end{align*} $$ 这直接意味着 $ c_1=0, c_2=0, ..., c_n=0 $。因此，$ V $ 中的向量是线性无关的。\n因为集合 $ B $ 既能张成 $ \\mathbb{C}^n $ 又是线性无关的，所以 $ B $ 是 $ \\mathbb{C}^n $ 的一个基。由于其中包含 $ n $ 个基向量，所以根据维数的定义，$ \\text{dim}(\\mathbb{C}^n) = n $。\nExercise 9 要成为 $ \\mathbb{C}^n $ 的一个子空间，$ \\mathbb{R}^n $ 必须满足对向量加法封闭，并且对标量乘法封闭（其中标量来自域 $ \\mathbb{C} $）。\n对于第二个性质，我们需要检验对于任意 $ v \\in \\mathbb{R}^n $ 和任意标量 $ c \\in \\mathbb{C} $，$ cv $ 是否总是在 $ \\mathbb{R}^n $ 中。答案是否定的。我们只需举一个反例。\n我们取一个非零向量 $ v \\in \\mathbb{R}^n $，例如 $ v = (1, 0, ..., 0) $，显然 $ v \\in \\mathbb{R}^n $。我们再取 $ c = i $，那么 $$ cv = i \\cdot (1, 0, ..., 0) = (i \\cdot 1, i \\cdot 0, ..., i \\cdot 0) = (i, 0, ..., 0) $$ 由于它的第一个分量 $ i $ 不是一个实数，所以这个向量不属于 $ \\mathbb{R}^n $。\n所以由于 $ \\mathbb{R}^n $ 对与复数标量的乘法不是封闭的，它不满足子空间的定义，$ \\mathbb{R}^n $ 不是 $ \\mathbb{C}^n $ 的子空间。\nExercise 10 ($ \\implies $) 假设 $ v_1, ..., v_m $ 在 $ \\mathbb{R}^n $ 中线性无关，证明它们在 $ \\mathbb{C}^n $ 中也线性无关。\n在 $ \\mathbb{R}^n $ 中线性无关意味着，对于方程 $$ c_1v_1 + c_2v_2 + ... + c_mv_m = 0 $$ 唯一的实数解是 $ c_1=c_2=...=c_m=0 $。\n现在，我们考虑在 $ \\mathbb{C}^n $ 中的情况，即对于方程 $$ z_1v_1 + z_2v_2 + ... + z_mv_m = 0 $$ 其中 $ z_i \\in \\mathbb{C} $ 是复数标量。\n我们可以将每个复数 $ z_i $ 写成实部和虚部的形式：$ z_i = a_i + i b_i $，其中 $ a_i, b_i \\in \\mathbb{R} $。代入方程中得到 $$ (a_1+ib_1)v_1 + (a_2+ib_2)v_2 + ... + (a_m+ib_m)v_m = 0 $$ 由于 $ v_i $ 是实向量，我们可以将方程的实部和虚部分开 $$ (a_1v_1 + a_2v_2 + ... + a_mv_m) + i(b_1v_1 + b_2v_2 + ... + b_mv_m) = 0 $$ 一个复向量等于零向量，当且仅当它的实部向量和虚部向量都为零向量。因此我们得到两个独立的方程 $$ \\begin{cases} a_1v_1 + a_2v_2 + ... + a_mv_m = 0 \\\\ b_1v_1 + b_2v_2 + ... + b_mv_m = 0 \\end{cases} $$ 因为 $ v_1, ..., v_m $ 在 $ \\mathbb{R}^n $ 中是线性无关的，且 $ a_i $ 和 $ b_i $ 都是实数，所以上述两个方程的唯一解是 $$ a_1=a_2=...=a_m=0,\\quad b_1=b_2=...=b_m=0 $$ 这意味着 $ z_i = a_i + ib_i = 0 $ 对所有的 $ i $ 都成立。\n因此，复数方程的唯一解是 $ z_1=z_2=...=z_m=0 $。这证明了 $ v_1, ..., v_m $ 在 $ \\mathbb{C}^n $ 中是线性无关的。\n($ \\impliedby $) 假设 $ v_1, ..., v_m $ 在 $ \\mathbb{C}^n $ 中线性无关，证明它们在 $ \\mathbb{R}^n $ 中也线性无关。\n在 $ \\mathbb{C}^n $ 中线性无关意味着，对于方程 $$ z_1v_1 + z_2v_2 + ... + z_mv_m = 0 $$ 唯一的复数解是 $ z_1=z_2=...=z_m=0 $。\n现在，我们考虑在 $ \\mathbb{R}^n $ 中的情况，即对于方程 $$ c_1v_1 + c_2v_2 + ... + c_mv_m = 0 $$ 其中 $ c_i \\in \\mathbb{R} $ 是实数标量。\n由于任何实数都是一个复数，这个方程可以看作是复数标量方程的一个特例，因此其唯一解也必然是所有标量都为零。因此 $ c_1=c_2=...=c_m=0 $。这证明了 $ v_1, ..., v_m $ 在 $ \\mathbb{R}^n $ 中是线性无关的。\n推论\n我们接着证明在 $ \\mathbb{R} $ 和 $ \\mathbb{C} $ 上的秩是相同的。\n设 $ A $ 是一个 $ m \\times n $ 的实矩阵。它的列向量 $ v_1, ..., v_n $ 都是 $ \\mathbb{R}^m $ 中的向量。\n$ A $ 在域 $ \\mathbb{R} $ 上的秩，$ \\text{rank}_{\\mathbb{R}}(A) $，是这组列向量在 $ \\mathbb{R}^m $ 中（使用实数标量）的最大线性无关子集的数量。 $ A $ 在域 $ \\mathbb{C} $ 上的秩，$ \\text{rank}_{\\mathbb{C}}(A) $，是这组列向量在 $ \\mathbb{C}^m $ 中（使用复数标量）的最大线性无关子集的数量。 根据我们刚刚的证明，一个实向量的集合在 $ \\mathbb{R} $ 上是线性无关的，当且仅当它在 $ \\mathbb{C} $ 上是线性无关的。这意味着，如果我们从 $ A $ 的列向量中选取一个子集，这个子集在 $ \\mathbb{R} $ 上是线性无关的，那么它在 $ \\mathbb{C} $ 上也一定是线性无关的，反之亦然。\n因此，能够选出的最大线性无关子集的大小，无论我们是在 $ \\mathbb{R} $ 上还是在 $ \\mathbb{C} $ 上考虑，都是完全相同的。所以$ \\text{rank}_{\\mathbb{R}}(A) = \\text{rank}_{\\mathbb{C}}(A) $。\n","permalink":"https://diefish1024.github.io/posts/class-notes/math1205h-linear-algebra/math1205h-hw14/","summary":"\u003ch2 id=\"exercise-1\"\u003eExercise 1\u003c/h2\u003e\n\u003cp\u003e首先计算 $ A $ 的特征值和特征向量。\n$$ \n\n\\det(A-\\lambda I) = (-1-\\lambda)(-\\lambda)-6 = 0 \\implies \\lambda^{2}+\\lambda-6 = 0\n\n $$\n解得 $ \\lambda_{1}=2,\\lambda_{2}=-3 $。\u003c/p\u003e\n\u003cp\u003e对于 $ \\lambda_{1}=2 $，我们求解 $ (A-2I)x=0 $，特征向量为\n$$ \n\nx_{1} = k\\begin{pmatrix}\n1 \\\\ 1\n\\end{pmatrix}\n\n $$\n对于 $ \\lambda_{2}=-3 $，我们求解 $ (A+3I)x=0 $，可以取特征向量为\n$$ \n\nx_{2} = k\\begin{pmatrix}\n3 \\\\ -2\n\\end{pmatrix}\n\n $$\u003c/p\u003e\n\u003cp\u003e对于 $ A^{2} $，我们计算得到 $ \\mu_{1}=4,\\mu_{2}=9 $。对于每个特征值，带入解出\n$$ \n\nx_{1} = k\\begin{pmatrix}\n1 \\\\ 1\n\\end{pmatrix},x_{2} = k\\begin{pmatrix}\n3 \\\\ -2\n\\end{pmatrix}\n\n $$\u003c/p\u003e","title":"MATH1205H HW14"},{"content":"Exercise 1 证\n我们有 $ \\det(A^{T})=\\det(-A) $，同时又有 $ \\det(A^{T})=\\det A $ 以及 $ \\det(-A)=(-1)^{n}\\det A $。\n如果 $ n $ 是奇数，那么 $ (-1)^{n}=-1 $，从而得到 $ \\det A=-\\det A\\implies \\det A=0 $。如果 $ n $ 是偶数，则无法说明，这个结论必然成立。\nExercise 2 解\n我们直接展开计算，就可以得到 $$ \\begin{align*} \\det \u0026 = \\begin{vmatrix} b \u0026 b^{2} \\\\ c \u0026 c^{2} \\end{vmatrix} - a\\begin{vmatrix} 1 \u0026 b^{2} \\\\ 1 \u0026 c^{2} \\end{vmatrix} + a^{2}\\begin{vmatrix} 1 \u0026 b \\\\ 1 \u0026 c \\end{vmatrix} \\\\ \u0026 = (bc^{2}-b^{2}c) - a(c^{2}-b^{2}) + a^{2}(c-b) \\\\ \u0026 = (b-a)(c-a)(c-b) \\end{align*} $$\nExercise 3 设矩阵 $ A $ 为 $$ A = \\begin{pmatrix} 1 \u0026 1 \u0026 \\dots \u0026 1 \\\\ 1 \u0026 1 \u0026 \\dots \u0026 1 \\\\ \\vdots \u0026 \\vdots \u0026 \\ddots \u0026 \\vdots \\\\ 1 \u0026 1 \u0026 \\dots \u0026 1 \\end{pmatrix} $$\n首先矩阵 $ A $ 是一个全为 $ 1 $ 的矩阵，其行列式为 $ 0 $。\n我们记所有的奇置换的集合为 $ S_{1} $，所有偶置换的集合为 $ S_{0} $。带入行列式的定义，由于所有元素都是 $ 1 $，因此我们可以得到 $$ \\det A = \\sum_{\\sigma \\in S_{0}}1 - \\sum_{\\sigma \\in S_{1}}1 = \\left| S_{0} \\right| -\\left| S_{1} \\right| = 0 $$ 从而证明了奇偶置换的数量相同。\nExercise 4 (1)\n首先计算 $ \\det A = -2 $。接着计算 $ \\text{adj}(A) $，根据定义，我们有 $$ \\text{adj}(A) = \\begin{bmatrix} 4 \u0026 -2 \\\\ -3 \u0026 1 \\end{bmatrix} $$ 从而 $$ A^{-1} = \\dfrac{1}{\\det A}\\text{adj}(A) = \\begin{bmatrix} -2 \u0026 1 \\\\ \\dfrac{3}{2} \u0026 - \\dfrac{1}{2} \\end{bmatrix} $$ (2)\n行列式 $ \\det A=13 $。\n伴随矩阵 $$ \\text{adj}(A) = \\begin{bmatrix} -2 \u0026 17 \\\\ -3 \u0026 19 \\end{bmatrix} $$ 从而得到 $$ A^{-1} = \\begin{bmatrix} -\\dfrac{2}{13} \u0026 \\dfrac{17}{13} \\\\ -\\dfrac{3}{13} \u0026 \\dfrac{19}{13} \\end{bmatrix} $$ (3)\n行列式 $ \\det A=5 $.\n伴随矩阵 $$ \\text{adj}(A) = \\begin{bmatrix} 5 \u0026 0 \\\\ -3 \u0026 1 \\end{bmatrix} $$ 从而 $$ A^{-1} = \\begin{bmatrix} 1 \u0026 0 \\\\ -\\dfrac{3}{5} \u0026 \\dfrac{1}{5} \\end{bmatrix} $$ (4)\n行列式 $ \\det A=-1-2=-3 $。\n伴随矩阵 $$ \\text{adj}(A) = \\begin{bmatrix} -1 \u0026 -1 \u0026 2 \\\\ -2 \u0026 1 \u0026 -2 \\\\ 2 \u0026 -1 \u0026 -1 \\end{bmatrix} $$ 从而 $$ A^{-1} = \\begin{bmatrix} \\dfrac{1}{3} \u0026 \\dfrac{1}{3} \u0026 -\\dfrac{2}{3} \\\\ \\dfrac{2}{3} \u0026 -\\dfrac{1}{3} \u0026 \\dfrac{2}{3} \\\\ -\\dfrac{2}{3} \u0026 \\dfrac{1}{3} \u0026 \\dfrac{1}{3} \\end{bmatrix} $$\nExercise 5 根据行列式的定义，我们得到 $$ \\det(A-\\lambda I) = \\sum_{\\sigma \\in\\text{Perm}(n)}\\text{sgn}(\\sigma)\\prod_{i=1}^{n} (a_{i,\\sigma(i)}-\\lambda[i=\\sigma(i)]) $$ 从而得到这是一个最高次项为 $ \\lambda^{n} $，最高次项系数为 $ (-1)^{n} $ 的关于 $ \\lambda $ 的多项式。\nExercise 6 (1)\n如果 $ A $ 满秩，那么有 $ \\det A\\neq 0 $。如果存在特征值 $ \\lambda=0 $，说明存在非零向量 $ x $ 满足 $ Ax=0 $，与 $ A $ 满秩矛盾。\n(2)\n取 $$ A = \\begin{bmatrix} 1 \u0026 1 \\\\ 0 \u0026 1 \\end{bmatrix} $$ 此时 $ A $ 满秩但是不可对角化。\n","permalink":"https://diefish1024.github.io/posts/class-notes/math1205h-linear-algebra/math1205h-hw13/","summary":"\u003ch2 id=\"exercise-1\"\u003eExercise 1\u003c/h2\u003e\n\u003cp\u003e\u003cstrong\u003e证\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e我们有 $ \\det(A^{T})=\\det(-A) $，同时又有 $ \\det(A^{T})=\\det A $ 以及 $ \\det(-A)=(-1)^{n}\\det A $。\u003c/p\u003e\n\u003cp\u003e如果 $ n $ 是奇数，那么 $ (-1)^{n}=-1 $，从而得到 $ \\det A=-\\det A\\implies \\det A=0 $。如果 $ n $ 是偶数，则无法说明，这个结论必然成立。\u003c/p\u003e\n\u003ch2 id=\"exercise-2\"\u003eExercise 2\u003c/h2\u003e\n\u003cp\u003e\u003cstrong\u003e解\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e我们直接展开计算，就可以得到\n$$ \n\n\\begin{align*}\n\\det \u0026 = \\begin{vmatrix}\nb \u0026 b^{2} \\\\\nc \u0026 c^{2}\n\\end{vmatrix} - a\\begin{vmatrix}\n1 \u0026 b^{2} \\\\\n1 \u0026 c^{2}\n\\end{vmatrix} + a^{2}\\begin{vmatrix}\n1 \u0026 b \\\\\n1 \u0026 c\n\\end{vmatrix} \\\\\n \u0026 = (bc^{2}-b^{2}c) - a(c^{2}-b^{2}) + a^{2}(c-b) \\\\\n \u0026 = (b-a)(c-a)(c-b)\n\\end{align*}\n\n $$\u003c/p\u003e","title":"MATH1205H HW13"},{"content":"Problem 1 设 $ n\u003erst $。证明 $ n $ 个数的实数列一定至少含有长度为 $ r $ 的严格上升子序列、长度为 $ s $ 的严格下降子序列、长度为 $ t $ 的常数列中的一个。\n证\n反证法，假设结论不成立。\n我们为第 $ i $ 个元素 $ x_{i} $ 记下标签 $ (a_{i},b_{i}) $，其中 $ a_{i} $ 表示以 $ x_{i} $ 结尾的最长上升子序列长度，$ b_{i} $ 表示以 $ x_{i} $ 结尾的最长下降子序列长度。那么我们有 $ a_{i}\\in[r-1],b_{i}\\in[s-1] $。因此总共只有 $ (r-1)(s-1) $ 种标签，此时又有 $ n\u003et\\cdot(r-1)(s-1) $，所以至少有 $ t $ 个元素的标签完全相同。\n我们假设 $ a_{i}=a_{j},b_{i}=b_{j} $，可以证明 $ x_{i}=x_{j} $。如果不相等，不妨设 $ i\u003c j $。若 $ x_{i}\u003c x_{j} $，那么我们将 $ x_{j} $ 加到以 $ x_{i} $ 结尾的最长上升子序列之后，就得到了一个长度为 $ a_{i}+1 $ 的上升子序列，所以 $ a_{j}\\geq a_{i}+1 $，与 $ a_{i}=a_{j} $ 矛盾；若 $ x_{i}\u003ex_{j} $，同理可以得到 $ b_{j}\\geq b_{i}+1 $，与 $ b_{i}=b_{j} $ 矛盾。所以一定有 $ x_{i}=x_{j} $。\n所以这 $ t $ 个标签完全相同的元素本身也相同，我们就得到了一个长度为 $ t $ 的常数列，从而和我们的假设矛盾。证毕！\nProblem 2 证明对于任意正整数 $ c $，存在 $ N=N(c) $ 满足对于 $ [N] $ 所有子集的任意的 $ c $-染色，存在不相交的非空集合 $ X,Y $ 满足 $ X,Y $ 和 $ X\\cup Y $ 具有相同的颜色。\n证\n我们取 $ N(c)=R_{c}(3;2) $。对 $ [N] $ 是所有子集任意 $ c $-染色后，对于 $ K_{N} $ 中的任意一条边 $ (i,j) $，不妨设 $ i\u003c j $，我们将它的颜色定义为集合 $ \\{ i, i+1,\\dots,j-1\\} $ 的颜色。根据 Ramsey 定理，我们知道其中必然存在一个同色三角形，不妨设三个顶点为 $ u,v,w $，满足 $ u\u003c v\u003c w $，我们就知道了 $$ \\{ u, \\dots,v-1 \\},\\{ v, \\dots,w-1 \\}, \\{ u, \\dots, w-1 \\} $$ 三个集合颜色相同，于是直接取 $$ \\begin{align*} X \u0026 = \\{ u, \\dots,v-1 \\} \\\\ Y \u0026 = \\{ v, \\dots,w-1 \\} \\\\ X \\cup Y \u0026 = \\{ u, \\dots, w-1 \\} \\end{align*} $$ 满足 $ X,Y,X\\cup Y $ 具有相同的颜色。\nProblem 3 对于任何正整数 $ c $ 和 $ l $，存在一个数 $ w = w(c, l) $，使得对集合 $ [w] = \\{1, 2, ..., w\\} $ 的任意 $ c $-着色，都存在一个单色的集合，其形式为 $ \\{a, a + d, a + 2d, ..., a + ld\\} \\cup \\{d\\} $，其中 $ a $ 和 $ d $ 为某个正整数。\n证\n我们将对颜色数 $ c $ 使用数学归纳法来证明。\n当 $ c=1 $，只有一种颜色，集合 $ [w] $ 中的所有整数都是同色的。我们需要找到一个单色的集合 $ \\{a, a+d, ..., a+ld\\} \\cup \\{d\\} $。我们可以简单地取 $ d=1 $ 和 $ a=1 $。这样我们得到的集合是 $ \\{1, 1, 1+1, 1+2, ..., 1+l\\} = \\{1, 2, ..., l+1\\} $。为了确保这个集合包含在 $ [w] $ 中，我们只需令 $ w(1, l) = l+1 $。此时集合 $ \\{1, 2, ..., l+1\\} $ 中的所有元素都在 $ [l+1] $ 中，并且都是单色的。因此定理在 $ c=1 $ 时成立。\n假设定理对于 $ c-1 $ 种颜色成立，即我们假设 $ w(c-1, l) $ 存在。现在我们需要证明定理对于 $ c $ 种颜色也成立。\n令 $ w' = w(c-1, l) $。根据归纳假设，这个数是存在的。令 $ W = W(c, l \\cdot w' + 1) $，其中 $ W(c, k) $ 保证了任何对 $ [W] $ 的 $ c $-着色都包含一个长度为 $ k $ 的单色等差数列。我们将证明 $ w(c, l) \\le W $。考虑对集合 $ [W] $ 的任意一个 $ c $-着色 $ \\chi $。根据定义，在 $ [W] $ 中必定存在一个长度为 $ l \\cdot w' + 1 $ 的单色等差数列，我们设为 $ A = \\{b, b+d', b+2d', ..., b+(l \\cdot w')d'\\} $，并假设它的颜色为 $ C_1 $。\n现在我们考虑公差 $ d' $ 的颜色 $ \\chi(d') $。分以下几种情况讨论\n若 $ \\chi(d') = C_1 $，在这种情况下，我们令 $ a = b $ 且 $ d = d' $。那么集合 $ \\{d, a, a+d, ..., a+ld\\} $ 就等于 $ \\{d', b, b+d', ..., b+ld'\\} $。因为 $ \\{b, b+d', ..., b+ld'\\} $ 是等差数列 $ A $ 的一个子集，它们的颜色都是 $ C_1 $。同时我们已知 $ \\chi(d') = C_1 $。因此，我们找到了一个颜色为 $ C_1 $ 的目标单色集合。\n若 $ \\chi(d') \\ne C_1 $ ，虑集合 $ S = \\{d', 2d', 3d', ..., w'd'\\} $。\n如果在集合 $ S $ 中，存在某个元素 $ kd' $ 的颜色为 $ C_1 $，即 $ \\chi(kd')=C_1 $。那么我们令 $ d = kd' $ 且 $ a = b $。考虑集合 $ \\{d, a, a+d, ..., a+ld\\} = \\{kd', b, b+kd', ..., b+lkd'\\} $。由于 $ k \\le w' $，数列 $ \\{b, b+kd', ..., b+lkd'\\} $ 是原始等差数列 $ A $ 的一个子数列（因为 $ lk \\le lw' $），因此它的所有元素颜色都是 $ C_1 $。又因为 $ \\chi(d)=\\chi(kd')=C_1 $，我们再次找到了一个颜色为 $ C_1 $ 的目标单色集合。\n如果对于所有的 $ k \\in \\{1, 2, ..., w'\\} $，颜色 $ \\chi(kd') $ 都不是 $ C_1 $。这意味着对集合 $ S=\\{d', 2d', ..., w'd'\\} $ 的着色 $ \\chi $ 只使用了 $ c-1 $ 种颜色（颜色 $ C_1 $ 被排除了）。现在我们在集合 $ [w']=\\{1, 2, ..., w'\\} $ 上定义一个新的着色 $ \\chi' $，规则为 $ \\chi'(k) = \\chi(k \\cdot d') $。这个新的着色 $ \\chi' $ 最多只使用 $ c-1 $ 种颜色。根据我们的归纳假设，在 $ [w'] $ 上进行 $ \\chi' $ 着色，必定存在一个单色的集合 $ \\{d^*, a^*, a^*+d^*, ..., a^*+ld^*\\} $。假设这个集合在 $ \\chi' $ 着色下的颜色为 $ C_2 $ (其中 $ C_2 \\ne C_1 $)。根据 $ \\chi' $ 的定义，这意味着 $$ \\begin{align*} \\chi(d^{*}\\cdot d') \u0026 = C_{2} \\\\ \\chi(a^{*}\\cdot d') \u0026 = C_{2} \\\\ \\chi((a^{*}+d^{*})\\cdot d') \u0026 = \\chi(a^{*}d' + d^{*}d') = C_{2} \\\\ \u0026 \\dots \\\\ \\chi((a^*+ld^*) \\cdot d') \u0026 = \\chi(a^*d' + l(d^*d')) = C_2 \\end{align*} $$ 现在，我们令 $ d = d^*d' $ 且 $ a = a^*d' $。那么我们就找到了一个在原始着色 $ \\chi $ 下的单色集合 $ \\{d, a, a+d, ..., a+ld\\} $，其颜色为 $ C_2 $。\n在所有可能的情况下，我们都能够找到所要求的单色结构。因此，归纳步骤完成，定理得证。\nProblem 4 证明任何图 $ G $ 至少有 $ \\binom{\\chi(G)}{2} $ 条边。\n证\n设 $ k=\\chi(G) $，我们使用 $ k $ 中颜色 $ \\{ c_{1},c_{2},\\dots,c_{k} \\} $ 对 $ G $ 进行染色。每种颜色的点都形成了一个非空独立集，对于颜色 $ i $，我们称所有颜色为 $ c_{i} $ 的点的集合为颜色类 $ V_{i} $。对于两个不同的颜色类 $ V_{i},V_{j} $，我们证明 $ V_{i},V_{j} $ 之间至少有一条边，否则合并 $ V_{i},V_{j} $ 可以得到一个更大的独立集，从而可以只用 $ k-1 $ 中颜色染色，与最小染色矛盾。从而一共 $ k=\\chi(G) $ 个颜色类，至少需要 $ \\binom{ \\chi(G) }{ 2 } $ 条边，因为两两之间都需要有边相连。\nProblem 5 假设 $ G = (V, E) $ 是一个包含 $ n $ 个顶点和 $ m $ 条边的图。对于一条边 $ e = \\{u, v\\} $，令 $ t(e) $ 为包含 $ e $ 的三角形数量，并令 $ t(G) $ 为图 $ G $ 中的三角形总数。\n证明对于每一对相邻顶点 $ (u, v) $ ，$ \\deg(u) + \\deg(v) - t(\\{u, v\\}) \\leq n $ 。 证明 $ t(G) \\geq \\frac{m}{3n}(4m - n^2) $ 。 证\n(1)\n设 $ N(u) $ 表示与 $ u $ 相邻的点的集合，$ t(\\{ u,v \\}) $ 即为同时与 $ u,v $ 相邻的点的个数，为 $ \\left| N(u)\\cap N(v) \\right| $，因此我们有 $$ \\left| N(u)\\cup N(v) \\right| = \\left| N(u) \\right| + \\left| N(v) \\right| - \\left| N(u)\\cap N(v) \\right| = \\text{deg}(u) + \\text{deg}(v) - t(\\{ u,v \\}) $$ 显然 $ \\left| N(u)\\cup N(v) \\right|\\leq \\left| V \\right|=n $，于是就得到了 $$ \\deg(u) + \\deg(v) - t(\\{u, v\\}) \\leq n $$ (2)\n根据 $ (1) $，我们得到 $$ t(\\{ u,v \\}) \\geq \\text{deg}(u) + \\text{deg}(v) - n $$ 我们考虑 $ \\sum_{e\\in E}t(e) $，每个三角形包含 $ 3 $ 条边，会被统计 $ 3 $ 次，因此 $$ \\sum_{e\\in E}t(e) = 3t(G) $$ 同时左侧我们有 $$ \\begin{align*} \\sum_{e\\in E}t(e) \u0026 = \\sum_{\\{ u,v \\}\\in E}t(\\{ u,v \\}) \\\\ \u0026 \\geq \\sum_{\\{ u,v \\}\\in E}(\\text{deg}(u)+\\text{deg}(v) - n) \\\\ \u0026 = \\sum_{u\\in V}\\text{deg}^{2}(u) - mn \\end{align*} $$ 其中利用 Cauchy 不等式， $$ \\begin{align*} \\left( \\sum_{u\\in V}1^{2} \\right)\\left( \\sum_{u\\in V}\\text{deg}^{2}(u) \\right) \u0026 \\leq \\left( \\sum_{u\\in V}\\text{deg}(u) \\right)^{2} \\\\ \u0026 = 4m^{2} \\\\ \\implies \\sum_{u\\in V}\\text{deg}^{2}(u) \u0026 \\leq \\dfrac{4m^{2}}{\\sum_{u\\in V}1} = \\dfrac{4m^{2}}{n} \\end{align*} $$ 带入得到 $$ t(G) \\leq \\dfrac{1}{3}\\left( \\dfrac{4m^{2}}{n} - mn \\right) = \\dfrac{m}{3n}(4m - n^{2}) $$\n","permalink":"https://diefish1024.github.io/posts/class-notes/cs0901-combinatorics/cs0901-hw7/","summary":"\u003ch2 id=\"problem-1\"\u003eProblem 1\u003c/h2\u003e\n\u003cp\u003e设 $ n\u003erst $。证明 $ n $ 个数的实数列一定至少含有长度为 $ r $ 的严格上升子序列、长度为 $ s $ 的严格下降子序列、长度为 $ t $ 的常数列中的一个。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e证\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e反证法，假设结论不成立。\u003c/p\u003e\n\u003cp\u003e我们为第 $ i $ 个元素 $ x_{i} $ 记下标签 $ (a_{i},b_{i}) $，其中 $ a_{i} $ 表示以 $ x_{i} $ 结尾的最长上升子序列长度，$ b_{i} $ 表示以 $ x_{i} $ 结尾的最长下降子序列长度。那么我们有 $ a_{i}\\in[r-1],b_{i}\\in[s-1] $。因此总共只有 $ (r-1)(s-1) $ 种标签，此时又有 $ n\u003et\\cdot(r-1)(s-1) $，所以至少有 $ t $ 个元素的标签完全相同。\u003c/p\u003e\n\u003cp\u003e我们假设 $ a_{i}=a_{j},b_{i}=b_{j} $，可以证明 $ x_{i}=x_{j} $。如果不相等，不妨设 $ i\u003c j $。若 $ x_{i}\u003c x_{j} $，那么我们将 $ x_{j} $ 加到以 $ x_{i} $ 结尾的最长上升子序列之后，就得到了一个长度为 $ a_{i}+1 $ 的上升子序列，所以 $ a_{j}\\geq a_{i}+1 $，与 $ a_{i}=a_{j} $ 矛盾；若 $ x_{i}\u003ex_{j} $，同理可以得到 $ b_{j}\\geq b_{i}+1 $，与 $ b_{i}=b_{j} $ 矛盾。所以一定有 $ x_{i}=x_{j} $。\u003c/p\u003e","title":"CS0901 HW7"},{"content":"Exercise 1 解\n根据题设，平面法向量为 $ \\mathbf{n}=(1,1,2) $。我们观察出一组解 $ v_{1}=(1,-1,0) $，再取 $$ v_{2} = \\mathbf{n}\\times v_{1} = (2,2,-2) $$ 单位化得到 $$ e_{1} = \\dfrac{1}{\\sqrt{ 2 }}(1,-1,0),\\quad e_{2} = \\dfrac{1}{\\sqrt{ 3 }}(1,1,-1) $$\nExercise 2 (1)\n我们取 $ q_{1}=(1,3,4,5,7) $，利用 G-S 正交化，得到 $$ q_{2} = \\mathbf{b} - \\dfrac{q_{1}\\cdot \\mathbf{b}}{\\| q_{1} \\| ^{2}}q_{1} = (-7,3,4,-5,1) $$ 再单位化得到 $$ \\mathbf{e}_{1} = \\dfrac{1}{10}(1,3,4,5,7),\\quad \\mathbf{e}_{2} = \\dfrac{1}{10}(-7,3,4,-5,1) $$\n(2)\n实际上只需要求 $ y $ 到平面的投影。根据 $ (1) $ 我们得到的一组标准正交基，我们就有投影为 $$ p = (y\\cdot e_{1})e_{1} + (y\\cdot e_{2})e_{2} = \\dfrac{1}{10}e_{1} - \\dfrac{7}{10}e_{2} = \\left( \\dfrac{1}{2},-\\dfrac{9}{50},-\\dfrac{6}{25},\\dfrac{2}{5},0 \\right) $$\nExercise 3 证\n对于第一个式子，根据性质 1，有 $$ \\Delta(a_{1},\\dots,a_{i}+ca_{j},\\dots,a_{n}) = \\Delta(a_{1},\\dots,a_{i},\\dots,a_{n}) + c\\Delta(a_{1},\\dots,a_{j},\\dots,a_{j},\\dots,a_{n}) $$ 根据性质 2，其中 $$ \\Delta(a_{1},\\dots,a_{j},\\dots,a_{j},\\dots,a_{n}) = 0 $$ 这样就得到了 $$ \\Delta(a_{1},\\dots,a_{i}+ca_{j},\\dots,a_{n}) = \\Delta(a_{1},\\dots,a_{i},\\dots,a_{n}) $$\n对于第二个式子，我们构造 $$ \\begin{align*} S = \u0026 \\Delta(a_{1},\\dots,a_{i},\\dots,a_{j},\\dots,a_{n}) \\\\ \u0026 + \\Delta(a_{1},\\dots,a_{i},\\dots,a_{i},\\dots,a_{n}) \\quad (= 0) \\\\ \u0026 + \\Delta(a_{1},\\dots,a_{j},\\dots,a_{j},\\dots,a_{n}) \\quad (= 0) \\\\ \u0026 + \\Delta(a_{1},\\dots,a_{j},\\dots,a_{i},\\dots,a_{n}) \\\\ = \u0026 \\Delta(a_{1},\\dots,a_{i},\\dots,a_{j},\\dots,a_{n}) \\\\ \u0026 + \\Delta(a_{1},\\dots,a_{j},\\dots,a_{i},\\dots,a_{n}) \\end{align*} $$ 我们只需要证明 $ S=0 $ 即可。\n注意到 $$ \\Delta(a_{1},\\dots,a_{i},\\dots,a_{i}+a_{j},\\dots,a_{n}) = \\Delta(a_{1},\\dots,a_{i},\\dots,a_{j},\\dots,a_{n}) + \\Delta(a_{1},\\dots,a_{i},\\dots,a_{i},\\dots,a_{n}) $$ 以及 $$ \\Delta(a_{1},\\dots,a_{j},\\dots,a_{i}+a_{j},\\dots,a_{n}) = \\Delta(a_{1},\\dots,a_{j},\\dots,a_{i},\\dots,a_{n}) + \\Delta(a_{1},\\dots,a_{j},\\dots,a_{j},\\dots,a_{n}) $$ 这样就得到了 $$ \\begin{align*} S = \u0026 [\\Delta(a_{1},\\dots,a_{i},\\dots,a_{j},\\dots,a_{n}) \\\\ \u0026 + \\Delta(a_{1},\\dots,a_{i},\\dots,a_{i},\\dots,a_{n})] \\\\ \u0026 + [\\Delta(a_{1},\\dots,a_{j},\\dots,a_{j},\\dots,a_{n}) \\\\ \u0026 + \\Delta(a_{1},\\dots,a_{j},\\dots,a_{i},\\dots,a_{n})] \\\\ = \u0026 \\Delta(a_{1},\\dots,a_{i},\\dots,a_{i}+a_{j},\\dots,a_{n})\\\\ \u0026 + \\Delta(a_{1},\\dots,a_{j},\\dots,a_{i}+a_{j},\\dots,a_{n}) \\end{align*} $$\n同时还有 $$ \\begin{align*} \u0026 \\Delta(a_{1},\\dots,a_{i},\\dots,a_{i}+a_{j},\\dots,a_{n}) + \\Delta(a_{1},\\dots,a_{j},\\dots,a_{i}+a_{j},\\dots,a_{n}) \\\\ = \u0026 \\Delta(a_{1},\\dots,a_{i}+a_{j},\\dots,a_{i}+a_{j},\\dots,a_{n}) \\\\ = \u0026 0 \\end{align*} $$ 于是就得到 $ S=0 $。\nExercise 4 证\n首先我们证明任意一个 $ n $ 的排列 $ \\sigma $，如果满足 $ \\tau(\\sigma)\u003e0 $，那么必然存在一对两个数相邻的逆序对。否则反证法，任意相邻的两个数都递增，那么就推出这是一个递增序列，与 $ \\tau(\\sigma)\u003e0 $ 矛盾，因此必然存在两个数相邻的逆序对。\n因此假设当前序列存在 $ \\sigma(i)\u003e\\sigma(i+1) $，那么我们就交换 $ i,i+1 $ 两列，这样就减少了一个逆序对（由于两个数相邻，因此对除此之外的逆序对没有影响）。我们重复这样的操作 $ \\tau(\\sigma) $ 次，每次减少一个逆序对，最终逆序对数量为零，就得到了序列 $ 1,2,\\dots,n $。\n把这个过程应用在矩阵 $ [e_{\\sigma(1)},\\dots,e_{\\sigma(n)}] $ 上，最终就得到了 $ I $。\nExercise 5 (1)\n我们令 $$ S = \\{ i\\in[n]\\mid \\sigma_{1}(i)\\neq\\sigma_{2}(i) \\} $$ 根据题设有 $ \\left| S \\right|=2 $，于是我们设 $ S=\\{ i_{1},i_{2} \\} $。\n由于 $ \\{ \\sigma_{1}(i)\\mid i\\in[n] \\}=\\{ \\sigma_{2}(i)\\mid i\\in[n] \\}=[n] $，我们从中去掉所有的 $ i\\not\\in S $，就得到了 $$ \\{ \\sigma_{1}(i_{1}),\\sigma_{1}(i_{2}) \\}=\\{ \\sigma_{2}(i_{1}),\\sigma_{2}(i_{2}) \\} $$ 再根据 $ S $ 的定义，我们又有 $ \\sigma_{1}(i_{1})\\neq\\sigma_{2}(i_{1}),\\sigma_{1}(i_{2})\\neq\\sigma_{2}(i_{2}) $，这就得到了 $$ \\sigma_{1}(i_{1})=\\sigma_{2}(i_{2}),\\sigma_{1}(i_{2})=\\sigma_{2}(i_{1}) $$ 其余的 $ i $ 均有 $ \\sigma_{1}(i)=\\sigma_{2}(i) $。这就是要证明的式子。\n(2)\n根据 $ (1) $，不妨设 $ i_{1}\u003c i_{2} $。我们只需要证明交换 $ i_{1},i_{2} $ 下标，会改变的逆序对数量是奇数即可。\n我们不妨设 $ \\sigma_{1}(i_{1})\u003c \\sigma_{1}(i_{2}) $，否则交换 $ \\sigma_{1},\\sigma_{2} $ 即可。此时设满足 $ k\\in(i_{1},i_{2})\\land\\sigma_{1}(k)\\in(\\sigma_{1}(i_{1}),\\sigma_{1}(i_{2})) $ 的 $ k $ 有 $ m $ 个。那么交换 $ i_{1},i_{2} $ 得到 $ \\sigma_{2} $ 后改变的逆序对数量为 $ 1+2m $，其中 $ 1 $ 为 $ (i_{1},i_{2}) $，两个 $ m $ 分别表示 $ (i_{1},k) $ 和 $ (k,i_{2}) $。\n所以我们就得到了 $$ \\tau(\\sigma_{1})+1 \\equiv \\tau(\\sigma_{2})\\mod 2 $$ 从而 $$ (-1)^{\\tau(\\sigma_{2})} = (-1)^{\\tau(\\sigma_{1})+1} $$\nExercise 6 (1)\n如果 $ \\sigma_{1}\\neq\\sigma_{2} $，那么我们每次都取最小的满足 $ \\sigma_{1}(i)\\neq\\sigma_{2}(i) $ 的 $ i $，并且设 $ \\sigma_{1}(j)=\\sigma_{2}(i) $，那么我们交换 $ i,j $ 得到 $ \\sigma_{1}' $，此时 $ \\sigma_{1}' $ 和 $ \\sigma_{2} $ 满足在 $ k\\leq i $ 时都有 $ \\sigma_{1}'(k)=\\sigma_{2}(k) $，减少了一个不同的位置。\n我们经过有限次这样的 swap 操作，直到 $ \\sigma_{1}'=\\sigma_{2} $，这样就从 $ \\sigma_{1} $ 得到了 $ \\sigma_{2} $。\n(2)\n根据 Ex5 中 $ (2) $ 的结论，我们直到每次 swap 操作后都有 $ \\tau(\\sigma')\\equiv \\tau(\\sigma)+1\\pmod 2 $，因此假设经过了 $ k $ 次操作得到 $ \\sigma_{2} $，那么我们就有 $$ \\tau(\\sigma_{2})\\equiv \\tau(\\sigma_{1})+k\\mod 2 $$ 从而就得到了 $$ k\\equiv \\tau(\\sigma_{1})+\\tau(\\sigma_{2})\\mod 2 $$\nExercise 7 根据 Ex3，我们设 $ A=(a_{1},a_{2},\\dots,a_{n}) $，利用 $ \\det $ 的定义，我们有 $$ \\begin{align*} \\det(a_{1},\\dots,a_{i}+\\lambda a_{i}',\\dots,a_{n}) \u0026 = \\sum_{\\sigma \\in \\text{Perm}(n)}(-1)^{\\tau(\\sigma)}\\alpha_{\\sigma(1),1}\\dots(\\alpha_{\\sigma(i),i} + \\lambda\\alpha'_{\\sigma(i),i})\\dots\\alpha_{\\sigma(n),n} \\\\ \u0026 = \\sum_{\\sigma \\in \\text{Perm}(n)}(-1)^{\\tau(\\sigma)}\\alpha_{\\sigma(1),1}\\dots\\alpha_{\\sigma(n),n} + \\lambda\\sum_{\\sigma \\in \\text{Perm}(n)}(-1)^{\\tau(\\sigma)}\\alpha_{\\sigma(1),1}\\dots \\alpha'_{\\sigma(i),i}\\dots\\alpha_{\\sigma(n),n} \\\\ \u0026 = \\det(a_{1},\\dots,a_{n}) + \\lambda \\det(a_{1},\\dots,a_{i}',\\dots,a_{n}) \\end{align*} $$ 满足 Ex3 中的性质 $ 1 $。\n我们接着证明满足性质 $ 2 $，也就是如果 $ a_{i}=a_{j} $，那么 $ \\det A=0 $。对于任意一个 $ \\sigma \\in\\text{Perm}(n) $，我们考虑交换其 $ i,j $ 下标，得到 $ \\text{swap}(\\sigma)=\\sigma' $，也就是 $ \\sigma(i)=\\sigma'(j),\\sigma(j)=\\sigma'(i) $。根据 Ex5 的结论，我们有 $ (-1)^{\\tau(\\sigma)}+(-1)^{\\tau(\\sigma')}=0 $。又因为 $ a_{i}=a_{j} $，我们带入求和中 $ \\sigma $ 对应的这一项，就得到了 $$ \\begin{align*} \u0026 (-1)^{\\tau(\\sigma)}\\alpha_{\\sigma(1),1}\\dots \\alpha_{\\sigma(i),i}\\dots \\alpha_{\\sigma(j),j}\\dots\\alpha_{\\sigma(n),n} \\\\ \u0026 +(-1)^{\\tau(\\sigma')}\\alpha_{\\sigma'(1),1}\\dots \\alpha_{\\sigma'(i),i}\\dots \\alpha_{\\sigma'(j),j}\\dots\\alpha_{\\sigma'(n),n} \\\\ = \u0026 (-1)^{\\tau(\\sigma)}\\alpha_{\\sigma(1),1}\\dots \\alpha_{\\sigma(i),i}\\dots \\alpha_{\\sigma(j),j}\\dots\\alpha_{\\sigma(n),n} \\\\ \u0026 - (-1)^{\\tau(\\sigma)}\\alpha_{\\sigma(1),1}\\dots \\alpha_{\\sigma(j),i}\\dots \\alpha_{\\sigma(i),j}\\dots\\alpha_{\\sigma(n),n} \\\\ = \u0026 (-1)^{\\tau(\\sigma)}\\alpha_{\\sigma(1),1}\\dots \\alpha_{\\sigma(i),i}\\dots \\alpha_{\\sigma(j),j}\\dots\\alpha_{\\sigma(n),n} \\\\ \u0026 +(-1)^{\\tau(\\sigma)}\\alpha_{\\sigma(1),1}\\dots \\alpha_{\\sigma(j),j}\\dots \\alpha_{\\sigma(i),i}\\dots\\alpha_{\\sigma(n),n} \\\\ = \u0026 0 \\end{align*} $$ 也就是 $ \\prod_{\\sigma}+\\prod_{\\sigma'}=0 $。\n并且如果 $ \\sigma_{1}\\neq\\sigma_{2} $，那么显然有 $ \\text{swap}(\\sigma_{1})\\neq\\text{swap}(\\sigma_{2}) $。进一步可以证明 $ \\text{swap} $ 操作是一个双射。\n所以如果 $ a_{i}=a_{j} $，那么 $$ \\begin{align*} \\det A+\\det A \u0026 = \\sum_{\\sigma \\in\\text{Perm(n)}} + \\sum_{\\sigma'\\in\\text{Perm}(n)} \\\\ \u0026 = \\sum_{\\sigma \\in\\text{Perm}(n)}\\left( \\prod_{\\sigma} + \\prod_{\\text{swap}(\\sigma)} \\right) \\\\ \u0026 = 0 \\end{align*} $$ 从而证明了 $ \\det A=0 $。\n从而根据 Ex3，就证明了在列加法下保持不变性。\nExercise 8 证\n设 $ A=(a_{ij})\\in M_n $。记余子式 $ M_{jk} $ 为删去第 $ j $ 行第 $ k $ 列后的行列式，余因子 $$ C_{jk}=(-1)^{j+k}M_{jk},\\qquad A^*=\\operatorname{adj}(A)=(C_{jk})^{\\mathsf T}. $$ 我们证明 $ AA^*=\\det(A)I $。\n计算第 $ (i,j) $ 个元素 $$ (AA^*)_{ij}=\\sum_{k=1}^n a_{ik}\\,A^*_{kj} =\\sum_{k=1}^n a_{ik}\\,C_{jk}. $$ 当 $ i=j $ 时，这正是按第 $ i $ 行的拉普拉斯展开 $$ \\sum_{k=1}^n a_{ik}C_{ik}=\\det(A). $$\n当 $ i\\ne j $ 时，将 $ A $ 的第 $ j $ 行用第 $ i $ 行替换得矩阵 $ B $。此时 $ B $ 有两行相同，$ \\det(B)=0 $。但按第 $ j $ 行对 $ \\det(B) $ 做拉普拉斯展开， $$ 0=\\det(B)=\\sum_{k=1}^n a_{ik}\\,C_{jk}. $$ 因而 $ (AA^*)_{ij}=0 $。\n综上，$ (AA^*)_{ij}=\\det(A) $ 当 $ i=j $，否则为 $ 0 $，即 $$ AA^*=\\det(A)\\,I. $$ 证毕。\n","permalink":"https://diefish1024.github.io/posts/class-notes/math1205h-linear-algebra/math1205h-hw12/","summary":"\u003ch2 id=\"exercise-1\"\u003eExercise 1\u003c/h2\u003e\n\u003cp\u003e\u003cstrong\u003e解\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e根据题设，平面法向量为 $ \\mathbf{n}=(1,1,2) $。我们观察出一组解 $ v_{1}=(1,-1,0) $，再取\n$$ \n\nv_{2} = \\mathbf{n}\\times v_{1} = (2,2,-2)\n\n $$\n单位化得到\n$$ \n\ne_{1} = \\dfrac{1}{\\sqrt{ 2 }}(1,-1,0),\\quad e_{2} = \\dfrac{1}{\\sqrt{ 3 }}(1,1,-1)\n\n $$\u003c/p\u003e\n\u003ch2 id=\"exercise-2\"\u003eExercise 2\u003c/h2\u003e\n\u003cp\u003e\u003cstrong\u003e(1)\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e我们取 $ q_{1}=(1,3,4,5,7) $，利用 G-S 正交化，得到\n$$ \n\nq_{2} = \\mathbf{b} - \\dfrac{q_{1}\\cdot \\mathbf{b}}{\\| q_{1} \\| ^{2}}q_{1} = (-7,3,4,-5,1)\n\n $$\n再单位化得到\n$$ \n\n\\mathbf{e}_{1} = \\dfrac{1}{10}(1,3,4,5,7),\\quad \\mathbf{e}_{2} = \\dfrac{1}{10}(-7,3,4,-5,1)\n\n $$\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e(2)\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e实际上只需要求 $ y $ 到平面的投影。根据 $ (1) $ 我们得到的一组标准正交基，我们就有投影为\n$$ \n\np = (y\\cdot e_{1})e_{1} + (y\\cdot e_{2})e_{2} = \\dfrac{1}{10}e_{1} - \\dfrac{7}{10}e_{2} = \\left( \\dfrac{1}{2},-\\dfrac{9}{50},-\\dfrac{6}{25},\\dfrac{2}{5},0 \\right)\n\n $$\u003c/p\u003e","title":"MATH1205H HW12"},{"content":"Exercise 1 (1)\n如果 $ A=B $，那么 $ Ax=Bx $ 对于所有 $ x \\in \\mathbb{R}^{n\\times 1} $ 是显然的。\n如果 $ \\forall x \\in \\mathbb{R}^{n\\times 1} $，都有 $ Ax=Bx $，那么我们有 $ (A-B)x=0 $。由于 $ x $ 是 $ \\mathbb{R}^{n} $ 中的任意一个向量，说明 $ A-B $ 的零空间是 $ \\mathbb{R}^{n} $，因此 $ \\text{rank}(A-B)=0 $，也就有 $ A-B=0 $，从而 $ A=B $。\n(2)\n$ A(A^{T}A)^{-1}A^{T} $ 和 $ B(B^{T}B)^{-1}B^{T} $ 分别是 $ A $ 和 $ B $ 的投影矩阵，记为 $ P_{A},P_{B} $。\n如果 $ P_{A}=P_{B} $，那么对于任意 $ x \\in \\mathbb{R}^{m} $，我们都有 $ P_{A}x=P_{B}x $，从而 $ x $ 在 $ C(A),C(B) $ 上的投影相同。如果 $ C(A)\\neq C(B) $，就会存在一个向量使得它在 $ C(A),C(B) $ 上的投影结果不一致，矛盾。因此 $ C(A)=C(B) $。\n如果 $ C(A)=C(B) $，说明 $ B $ 可以经过线性变换得到 $ A $。从而存在可逆矩阵 $ P $ 使得 $ A=BP $，于是 $$ \\begin{align*} A(A^{T}A)^{-1}A^{T} \u0026 = (BP)[(BP)^{T}BP]^{-1}(BP)^{T} \\\\ \u0026 = BP[P^{T}B^{T}BP]^{-1}P^{T}B^{T} \\\\ \u0026 = BP P^{-1}(B^{T}B)^{-1}(P^{T})^{-1}P^{T}B^{T} \\\\ \u0026 = B(B^{T}B)^{-1}B^{T} \\end{align*} $$\nExercise 2 首先我们证明 $ (V^{\\perp})^{\\perp}\\subseteq V $。设 $ \\omega \\in(V^{\\perp})^{\\perp} $，那么 $ \\omega $ 和 $ V^{\\perp} $ 中的所有向量正交。由于 $ V^{\\perp} $ 中的所有向量都和 $ V $ 中的向量正交，因此 $ \\omega \\in V $，从而 $ (V^{\\perp})^{\\perp}\\subseteq V $。\n接着证明 $ V\\subseteq(V^{\\perp})^{\\perp} $。设 $ v\\in V $，那么 $ \\forall w\\in V^{\\perp} $，我们有 $ \\langle v,w \\rangle=0 $，这也意味着 $ v\\in(V^{\\perp})^{\\perp} $，从而 $ V\\subseteq(V^{\\perp})^{\\perp} $。\n综上，我们证明了 $ V=(V^{\\perp})^{\\perp} $。\nExercise 3 证\n根据命题 $ (1) $，我们知道存在矩阵 $ A $ 使得 $ V=C(A) $。我们将命题 $ (3) $ 应用于 $ A^{T} $，得到 $$ \\text{rank}(A^{T}) + \\text{dim}(N(A^{T})) = n $$ 由于 $ \\text{rank}(A)=\\text{dim}(C(A))=\\text{dim}(V) $ 并且 $ \\text{rank}(A)=\\text{rank}(A^{T}) $，我们得到 $$ \\text{dim}(V) + \\text{dim}(N(A^{T})) = n $$ 再利用命题 $ (2) $ 的结论，我们得到 $ C(A)^{\\perp}=N(A^{T}) $，从而 $ V^{\\perp}=N(A^{T}) $，带入即可得到 $$ \\text{dim}(V) + \\text{dim}(V^{\\perp}) = n $$ 根据命题 $ (4) $，我们得到 $ \\text{dim}(V+V^{\\perp})=\\text{dim}(V)+\\text{dim}(V^{\\perp})=n $。\n由于 $ V+V^{\\perp} $ 是 $ \\mathbb{R}^{n} $ 的一个子空间，并且维度为 $ n $。根据命题 $ (5) $，我们可以推出 $ V+V^{\\perp}=\\mathbb{R}^{n} $，否则必然有 $ \\text{dim}(V+V^{\\perp})\u003c \\text{dim}(\\mathbb{R}^{n})=n $。\n证毕。\nExercise 4 证\n我们用极坐标表示 $ v\\in \\mathbb{R}^{2} $，令 $ v=(r\\cos\\alpha,r\\sin\\alpha)^{T} $，那么 $$ Qv = (r\\cos\\theta \\cos\\alpha-r\\sin\\theta \\sin\\alpha,r\\sin\\theta \\cos\\alpha+r\\cos\\theta \\sin\\alpha)^{T} $$ 化简得到 $$ Qv = (r\\cos(\\theta+\\alpha),r\\sin(\\theta+\\alpha)) $$ 得到了一个单位圆旋转角为 $ \\theta+\\alpha $ 的单位向量，可以看成 $ v $ 逆时针旋转 $ \\theta $ 角度。证毕。\nExercise 5 解\n矩阵 $ A $ 的列向量分别为 $ a_{1}=(1,2,-2)^{T},a_{2}=(1,-1,4)^{T} $。我们进行 G-S 正交化，首先 $ v_{1}=a_{1}=(1,2,-2)^{T} $，再得到与 $ v_{1} $ 正交的向量 $$ v_{2} = a_{2} - \\dfrac{a_{2}\\cdot v_{1}}{\\| v_{1} \\| ^{2}}\\cdot v_{1} = \\begin{pmatrix} 2 \\\\ 1 \\\\ 2 \\end{pmatrix} $$ 标准化后得到 $$ q_{1} = \\begin{pmatrix} 1 / 3 \\\\ 2 / 3 \\\\ -2 / 3 \\end{pmatrix}, q_{2} = \\begin{pmatrix} 2 / 3 \\\\ 1 / 3 \\\\ 2 / 3 \\end{pmatrix} $$\n接着我们用最小二乘法求解 $ Ax=(1,2,7)^{T} $。最小二乘解满足 $$ A^{T}A\\hat{x} = A^{T}b $$ 带入得到 $$ A^{T}A = \\begin{pmatrix} 9 \u0026 -9 \\\\ -9 \u0026 18 \\end{pmatrix},A^{T}b = \\begin{pmatrix} -9 \\\\ 27 \\end{pmatrix} $$ 得到 $$ \\begin{pmatrix} 1 \u0026 -1 \\\\ -1 \u0026 2 \\end{pmatrix}\\hat{x} = \\begin{pmatrix} -1 \\\\ 3 \\end{pmatrix} \\implies \\hat{x} = \\begin{pmatrix} 1 \\\\ 2 \\end{pmatrix} $$\nExercise 6 对于给定向量，记 $$ a_{1} = \\begin{pmatrix} 1 \\\\ 1 \\\\ 2 \\end{pmatrix},a_{2} = \\begin{pmatrix} 1 \\\\ -1 \\\\ 0 \\end{pmatrix}, a_{3} = \\begin{pmatrix} 1 \\\\ 0 \\\\ 4 \\end{pmatrix} $$ 首先得到 $$ q_{1} = \\dfrac{a_{1}}{\\| a_{1} \\| } = \\begin{pmatrix} \\dfrac{1}{\\sqrt{ 6 }} \u0026 \\dfrac{1}{\\sqrt{ 6 }} \u0026 \\dfrac{2}{\\sqrt{ 6 }} \\end{pmatrix}^{T} $$ 进一步得到（$ a_{1},a_{2} $ 正交） $$ q_{2} = \\dfrac{a_{2}}{\\| a_{2} \\| } = \\begin{pmatrix} \\dfrac{1}{\\sqrt{ 2 }} \u0026 -\\dfrac{1}{\\sqrt{ 2 }} \u0026 0 \\end{pmatrix}^{T} $$ 接着计算 $ q_{1},q_{2} $ 的正交向量 $$ v_{3} = a_{3} - (a_{3}\\cdot q_{1})q_{1} - (a_{3}\\cdot q_{2})q_{2} = \\begin{pmatrix} -1 \\\\ -1 \\\\ 1 \\end{pmatrix} $$ 标准化得到 $$ q_{3} = \\begin{pmatrix} -\\dfrac{1}{\\sqrt{ 3 }} \u0026 -\\dfrac{1}{\\sqrt{ 3 }} \u0026 \\dfrac{1}{\\sqrt{ 3 }} \\end{pmatrix}^{T} $$\n","permalink":"https://diefish1024.github.io/posts/class-notes/math1205h-linear-algebra/math1205h-hw11/","summary":"\u003ch2 id=\"exercise-1\"\u003eExercise 1\u003c/h2\u003e\n\u003cp\u003e\u003cstrong\u003e(1)\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e如果 $ A=B $，那么 $ Ax=Bx $ 对于所有 $ x \\in \\mathbb{R}^{n\\times 1} $ 是显然的。\u003c/p\u003e\n\u003cp\u003e如果 $ \\forall x \\in \\mathbb{R}^{n\\times 1} $，都有 $ Ax=Bx $，那么我们有 $ (A-B)x=0 $。由于 $ x $ 是 $ \\mathbb{R}^{n} $ 中的任意一个向量，说明 $ A-B $ 的零空间是 $ \\mathbb{R}^{n} $，因此 $ \\text{rank}(A-B)=0 $，也就有 $ A-B=0 $，从而 $ A=B $。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e(2)\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e$ A(A^{T}A)^{-1}A^{T} $ 和 $ B(B^{T}B)^{-1}B^{T} $ 分别是 $ A $ 和 $ B $ 的投影矩阵，记为 $ P_{A},P_{B} $。\u003c/p\u003e","title":"MATH1205H HW11"},{"content":"题目\nProblem 1 (1)\n不正确。\n反例\n设离散概率空间 $ (\\Omega,\\mathcal{F},\\mathbb{P}) $，其中 $ \\Omega=\\mathbb{N}^{+} $，$ \\mathcal{F} $ 是 $ \\Omega $ 的幂集，概率测度定义为 $ \\mathbb{P}(\\{ k \\})=\\dfrac{1}{2^{k}} $。我们定义随机变量 $ X_{n}:\\Omega\\to \\mathbb{R} $ 为 $$ X_{n}(k) = \\begin{cases} 2^{n} \u0026 k = n \\\\ -2^{n+1} \u0026 k = n+1\\\\ 0 \u0026 \\text{o.w.} \\end{cases} $$ 此时显然每个 $ X_{n} $ 都可积，并且 $$ \\mathbb{E}[X_{n}] = X_{n}(n)\\mathbb{P}(\\{ n \\}) + X_{n}(n+1)\\mathbb{P}(\\{ n+1 \\}) = 0 \\implies \\sum_{n=1}^{\\infty} \\mathbb{E}[X_{n}] = 0 $$ 但是 $$ \\sum_{n=1}^{\\infty} X_{n}(k) = \\begin{cases} 2 \u0026 k=1 \\\\ 0 \u0026 \\text{o.w.} \\end{cases} $$ 从而 $$ \\mathbb{E}\\left[ \\sum_{n=1}^{\\infty} X_{n} \\right] = 2 \\times \\mathbb{P}(\\{ 1 \\}) + 0 \\times (1 - \\mathbb{P}(\\{ 1 \\})) = 1 $$ 所以此时 $$ \\sum_{n=1}^{\\infty} \\mathbb{E}[X_{n}] \\neq \\mathbb{E}\\left[ \\sum_{n=1}^{\\infty} X_{n} \\right] $$ 不成立的原因在于我们需要级数绝对可积才能交换求和和期望。\n(2)\n不正确。\n反例\n我们构造 $ X_{n} $ 序列不可积即可。\n定义概率空间 $ (\\Omega,\\mathcal{F},\\mathbb{P}) $，其中 $ \\Omega=(0,1],\\mathcal{F}=\\mathcal{B}(0,1],\\mathbb{P}=\\lambda $。定义随机变量序列 $ X_{n}:(0,1]\\to \\mathbb{R} $ 为 $$ X_{n}(\\omega) = -\\dfrac{1}{\\omega}\\mathbb{I}_{(0,1 / n]}(\\omega) $$ 显然此时 $ \\{ X_{n} \\} $ 满足递增并且 $$ \\lim_{ n \\to \\infty } X_{n} = X = 0 \\implies \\mathbb{E}[X] = 0 $$ 然而 $$ \\mathbb{E}[X_{n}] = \\int_{0}^{1} X_{n}(\\omega) \\mathrm{d}\\lambda(\\omega) = \\int_{0}^{1 / n} -\\dfrac{1}{\\omega} \\mathrm{d}\\omega = -\\infty $$ 从而 $$ \\lim_{ n \\to \\infty } \\mathbb{E}[X_{n}] = -\\infty \\neq \\mathbb{E}[X] = 0 $$\n(3)\n正确。\n证\n我们构造随机变量序列 $ Y_{n}=X_{n}-X_{1} $。显然 $ Y_{n} $ 满足单调并且非负。并且 $$ \\lim_{ n \\to \\infty } Y_{n} = \\lim_{ n \\to \\infty } (X_{n}-X_{1}) = X - X_{1} := Y $$ 根据 MCT，我们得到 $$ \\lim_{ n \\to \\infty } \\mathbb{E}[Y_{n}] = \\mathbb{E}[Y] $$ 也就是 $$ \\lim_{ n \\to \\infty } \\mathbb{E}[X_{n}-X_{1}] = \\mathbb{E}[X-X_{1}] $$ 由于可积，$ \\mathbb{E}[X_{n}] $ 有限，因此根据期望的可加性，得到 $$ (\\lim_{ n \\to \\infty } \\mathbb{E}[X_{n}]) - \\mathbb{E}[X_{1}] = \\mathbb{E}[X] - \\mathbb{E}[X_{1}] $$ 从而 $$ \\lim_{ n \\to \\infty } \\mathbb{E}[X_{n}] = \\mathbb{E}[X] $$ 证毕。\n(4)\n不正确。\n证\n取 $ \\text{sup} $ 的操作不同于 $ \\text{inf} $，可能会改变可积性。\n定义概率空间 $ (\\Omega,\\mathcal{F},\\mathbb{P}) $，其中 $ \\Omega=(0,1],\\mathcal{F}=\\mathcal{B}(0,1],\\mathbb{P}=\\lambda $。定义随机变量序列 $ X_{n}:(0,1]\\to \\mathbb{R} $ 为 $$ X_{n}(\\omega) = n\\cdot \\mathbb{I}_{(0, 1 / n]}(\\omega) $$ 满足 $ X_{n} $ 非负。\n我们计算每个 $ X_{n} $ 的期望 $$ \\mathbb{E}[X_{n}] = \\int_{0}^{1} X_{n}(\\omega) \\mathrm{d}\\lambda(x) = n\\int_{0}^{1 / n} \\mathrm{d}x = 1 $$ 从而 $$ \\underset{n\\to \\infty}{\\text{lim sup }} \\mathbb{E}[X_{n}] = 1 $$\n然而 $$ \\underset{n\\to \\infty}{\\text{lim sup }} X_{n} = \\lim_{ n \\to \\infty } X_{n} = 0 $$ 所以 $$ \\mathbb{E}[\\underset{n\\to \\infty}{\\text{lim sup }} X_{n}] = 0 $$ 结论不成立。\nProblem 2 根据题设，每个 $ f_{n} $ 都是在闭区间 $ [a,b] $ 上的连续函数，从而在 Borel Set 中可测。并且一致收敛的连续函数序列的极限也是连续的，从而 $ f $ 也是可测函数。符合 DCT 中对可测性的要求。\n并且 $ f_{n} $ 在 $ [a,b] $ 上一致收敛到 $ f $，这是一个强于几乎处处收敛的条件，因此这也满足 DCT 中 $ X_{n}\\to X $ 几乎处处收敛的条件。\n下面证明满足存在可积控制函数的条件。根据一致收敛的定义，对于任意 $ \\varepsilon\u003e0 $，存在 $ N\u003e0 $ 使得对于所有 $ x \\in[a,b] $ 有 $ \\left| f_{n}(x)-f(x) \\right|\u003c\\varepsilon $。\n由于 $ f $ 是闭区间上的连续函数，因此一定有 $ f $ 有界，从而存在常数 $ M_{f} $ 满足对于所有 $ x $ 都有 $ \\left| f(x) \\right|","permalink":"https://diefish1024.github.io/posts/class-notes/math2701-probability-theory/math2701-hw4/","summary":"\u003cp\u003e\u003ca href=\"https://notes.sjtu.edu.cn/s/pu3AkRu9g\"\u003e题目\u003c/a\u003e\u003c/p\u003e\n\u003ch2 id=\"problem-1\"\u003eProblem 1\u003c/h2\u003e\n\u003cp\u003e\u003cstrong\u003e(1)\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e不正确。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e反例\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e设离散概率空间 $ (\\Omega,\\mathcal{F},\\mathbb{P}) $，其中 $ \\Omega=\\mathbb{N}^{+} $，$ \\mathcal{F} $ 是 $ \\Omega $ 的幂集，概率测度定义为 $ \\mathbb{P}(\\{ k \\})=\\dfrac{1}{2^{k}} $。我们定义随机变量 $ X_{n}:\\Omega\\to \\mathbb{R} $ 为\n$$ \n\nX_{n}(k) = \\begin{cases}\n2^{n} \u0026 k = n \\\\\n-2^{n+1} \u0026 k = n+1\\\\\n0 \u0026 \\text{o.w.}\n\\end{cases}\n\n $$\n此时显然每个 $ X_{n} $ 都可积，并且\n$$ \n\n\\mathbb{E}[X_{n}] = X_{n}(n)\\mathbb{P}(\\{ n \\}) + X_{n}(n+1)\\mathbb{P}(\\{ n+1 \\}) = 0 \\implies \\sum_{n=1}^{\\infty} \\mathbb{E}[X_{n}] = 0\n\n $$\n但是\n$$ \n\n\\sum_{n=1}^{\\infty} X_{n}(k) = \\begin{cases}\n2 \u0026 k=1 \\\\\n0 \u0026 \\text{o.w.}\n\\end{cases}\n\n $$\n从而\n$$ \n\n\\mathbb{E}\\left[ \\sum_{n=1}^{\\infty} X_{n} \\right] = 2 \\times \\mathbb{P}(\\{ 1 \\}) + 0 \\times (1 - \\mathbb{P}(\\{ 1 \\})) = 1\n\n $$\n所以此时\n$$ \n\n\\sum_{n=1}^{\\infty} \\mathbb{E}[X_{n}] \\neq \\mathbb{E}\\left[ \\sum_{n=1}^{\\infty} X_{n} \\right]\n\n $$\n不成立的原因在于我们需要级数绝对可积才能交换求和和期望。\u003c/p\u003e","title":"MATH2701 HW4"},{"content":"Problem 1 在一个 $ m $ 条边的二分图中，存在一个匹配，其大小至少为 $ m / \\Delta $，其中 $ \\Delta $ 表示图中最大顶点的度数。\n证\n我们需要证明这个二分图最大匹配的大小大于等于 $ m / \\Delta $。根据柯尼希定理，只需要证明最小边覆盖的大小大于等于 $ m / \\Delta $。\n设最小边覆盖大小为 $ t $。若 $ t\u003c m / \\Delta $，对于一个被选中的顶点 $ v $，其至多覆盖 $ \\text{deg}(v)\\leq\\Delta $ 条边，因此最多只能覆盖 $$ t\\cdot\\Delta \u003c m $$ 显然不能覆盖所有的边，不可能是一个边覆盖，矛盾。\n因此至少存在一个匹配的大小至少为 $ m / \\Delta $。\nProblem 2 证明一名学生有 $ 20 $ 周的时间来准备 ICPC，他决定每周至少完成一次训练比赛，但他只有 $ 30 $ 套训练题。请证明，无论他如何安排训练，都会存在连续的几周，他完成的训练题集数正好是 $ 9 $ 套。\n证\n我们转化问题为 $ 20 $ 个数 $ a_{1},a_{2},\\dots,a_{20} $ 满足 $ \\sum a_{i}=30 $，需要证明存在一段区间 $ [i,j] $ 满足 $$ \\sum_{i\\leq k\\leq j} a_{i} = 9 $$ 我们考虑 $ \\{ a_{n} \\} $ 的前缀和 $ \\{ S_{n} \\} $，定义为 $ S_{n}=\\sum_{i=1}^{n}a_{i} $，并且我们定义 $ S_{0}=0 $。根据 $ \\sum a_{i}=30 $，我们同时也有 $ S_{20}=30 $。这样我们就得到了一个递增的序列 $ T_{1}=\\{ 0,S_{1},S_{2},\\dots,S_{19},30 \\} $。我们需要证明其中存在 $ i,j $ 满足 $ S_{j}-S_{i}=9 $，也就是 $ S_{j}=S_{i}+9 $。\n我们考虑集合 $ T_{2}=\\{ 9,S_{1}+9,S_{2}+9,\\dots,S_{19}+9, 39 \\} $。我们只需要证明 $ T_{1}\\cap T_{2}\\neq \\emptyset $。由于 $ T_{1}\\cup T_{2} $ 中只会有 $ 0\\sim 39 $ 最多 $ 40 $ 个元素，但是 $ \\left| T_{1} \\right|=\\left| T_{2} \\right|=21 $，合计 $ 42 $ 个元素。所以根据鸽巢原理，这些元素中肯定有两个相同，并且由于 $ T_{1} $ 是一个递增序列，其中元素不可能相同，所以一定是 $ T_{1},T_{2} $ 中存在元素相同。\n所以必然存在 $ S_{j}=S_{i}+9 $，也就是必然存在一段和为 $ 9 $ 的区间。\nProblem 3 用三种颜色为 $ K_{17} $ 上的边着色。证明：无论如何着色，必定存在一个单色三角形。\n证\n我们任取一个点，从这个点会连出 $ 16 $ 条边，根据鸽巢原理，必然有 $ 6 $ 条边的颜色相同，设为蓝色。我们现在考虑这 $ 6 $ 条边连到的这 $ 6 $ 个点。假如这些点之间存在蓝色的边，那么就会和连到这些点的蓝色边构成一个全为蓝色的单色三角形。\n否则如果这 $ 6 $ 个点之间的所有边的颜色都为黄色和红色。同理，我们继续考虑任取一个点，这个点会连出 $ 5 $ 条边，根据鸽巢原理，必然存在 $ 3 $ 条边颜色相同，设为红色。我们接着考虑这 $ 3 $ 条红色边连到的 $ 3 $ 个点，如果之间存在红色边，那么就会和连到这些点的红色边构成一个红色三角形；如果不存在红色边，那么这 $ 3 $ 个点本身就会构成一个黄色三角形。\n综上，必然会存在一个单色三角形。\nProblem 4 (1)\n从 $ [2n] $ 中选出 $ n+1 $ 个数。证明其中存在三个数 $ x,y,z $ 满足 $ x+y=z $。\n证\n我们设这 $ n+1 $ 个数的集合为 $ S_{1} $。我们设 $ S_{1} $ 中最小的元素为 $ m $，令 $$ S_{2} = \\{ s-m\\mid s \\in S_{1},s\\neq m \\} $$ 表示剩下的元素与 $ s_{1} $ 的差，一共有 $ n $ 个元素。\n注意到 $ S_{1},S_{2} $ 中元素的范围都在 $ 1\\sim 2n $ 之间，最多只可能有 $ 2n $ 个元素，但是 $ \\left| S_{1} \\right|+\\left| S_{2} \\right|=2n+1 $，并且 $ S_{1},S_{2} $ 的元素都互不相同，那么根据鸽巢原理，说明 $ S_{1} $ 和 $ S_{2} $ 中肯定有重合的元素。因此存在 $ p \\in S_{1},q\\in S_{2} $ 满足 $ p=q-m $，从而取 $ x=m,y=p,z=q $，就满足了 $$ x+y=z $$\n(2)\n证明只取 $ n $ 个数时结论不成立。\n证\n我们直接取 $ 1,3,5,\\dots,2n-1 $。根据奇偶性，这样的三元组显然不存在。\n","permalink":"https://diefish1024.github.io/posts/class-notes/cs0901-combinatorics/cs0901-hw6/","summary":"\u003ch2 id=\"problem-1\"\u003eProblem 1\u003c/h2\u003e\n\u003cp\u003e在一个 $ m $ 条边的二分图中，存在一个匹配，其大小至少为 $ m / \\Delta $，其中 $ \\Delta $ 表示图中最大顶点的度数。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e证\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e我们需要证明这个二分图最大匹配的大小大于等于 $ m / \\Delta $。根据柯尼希定理，只需要证明最小边覆盖的大小大于等于 $ m / \\Delta $。\u003c/p\u003e\n\u003cp\u003e设最小边覆盖大小为 $ t $。若 $ t\u003c  m / \\Delta $，对于一个被选中的顶点 $ v $，其至多覆盖 $ \\text{deg}(v)\\leq\\Delta $ 条边，因此最多只能覆盖\n$$ \n\nt\\cdot\\Delta \u003c m\n\n $$\n显然不能覆盖所有的边，不可能是一个边覆盖，矛盾。\u003c/p\u003e\n\u003cp\u003e因此至少存在一个匹配的大小至少为 $ m / \\Delta $。\u003c/p\u003e\n\u003ch2 id=\"problem-2\"\u003eProblem 2\u003c/h2\u003e\n\u003cp\u003e证明一名学生有 $ 20 $ 周的时间来准备 ICPC，他决定每周至少完成一次训练比赛，但他只有 $ 30 $ 套训练题。请证明，无论他如何安排训练，都会存在连续的几周，他完成的训练题集数正好是 $ 9 $ 套。\u003c/p\u003e","title":"CS0901 HW6"},{"content":"Exercise 1 (1) $$ u\\cdot v = v\\cdot u = \\sum_{i=1}^{m} v_{i}w_{i} $$ (2) $$ (u+v)\\cdot w = u\\cdot w + v\\cdot w = \\sum_{i=1}^{m} (v_{i}+u_{i})w_{i} $$ (3) $$ cu\\cdot v = c(u\\cdot v) = \\sum_{i=1}^{m} (c\\cdot u_{i}v_{i}) $$ (4) $$ u\\cdot u = \\sum_{i=1}^{m} u_{i}^{2} \\geq 0 $$ 若 $ u\\cdot u = 0 $，可以得到 $ u_{i}=0 $，从而 $ u=\\mathbf{0} $。\nExercise 2 $$ u\\perp v \\implies u\\cdot v = \\sum_{i=1}^{m} u_{i}v_{i} = 0 $$ 从而 $$ \\begin{align*} \\| u+v \\| ^{2} \u0026 = \\sum_{i=1}^{m} (u_{i}+v_{i})^{2} \\\\ \u0026 = \\sum_{i=1}^{m} u_{i}^{2} + \\sum_{i=1}^{m} v_{i}^{2} + 2\\sum_{i=1}^{m} u_{i}v_{i} \\\\ \u0026 = \\sum_{i=1}^{m} u_{i}^{2} + \\sum_{i=1}^{m} v_{i}^{2} \\\\ \u0026 = \\| u \\| ^{2} + \\| v \\| ^{2} \\end{align*} $$\nExercise 3 (1)\n我们取 $ V $ 的一组基向量（共有 $ \\text{dim}V=n $ 个）$ \\{ v_{n} \\} $。将这些向量拼起来，从而就得到了一个 $ m\\times n $ 的矩阵 $$ A = \\begin{pmatrix} v_{1} \u0026 v_{2} \u0026 v_{3} \u0026 \\dots \u0026 v_{n} \\end{pmatrix} $$ 由于 $ \\{ v_{n} \\} $ 是一组线性无关的基向量，因此满足 $ V=C(A) $。\n(2)\n$ e $ 垂直于 $ V $ 说明 $ e $ 和 $ V $ 中的每一个向量都垂直。我们取 $ (1) $ 中取出的基 $ \\{ v_{n} \\} $，从而 $ v_{i}^{T}e=0 $，带入所有的 $ v_{i} $，就有 $$ A^{T}e = \\mathbf{0} \\implies A^{T}(v-p) = \\mathbf{0} $$ 由于 $ p \\in V=C(A) $，就有 $ p=Ax $，从而 $$ A^{T}v = A^{T}Ax \\implies x = (A^{T}A)^{-1}A^{T}v $$ 其中由于 $ \\text{rank}(A)=n $，从而 $ \\text{rank}(A^{T}A)=n $，得到这是一定一个可逆矩阵。因此 $$ p = Ax = A(A^{T}A)^{-1}A^{T}v $$ 一定存在。\n(3)\n我们带入 $ v=p+e $，那么只需要证明 $$ \\| p+e-u \\| = \\| e + (p-u) \\| \\geq \\| e \\| $$ 由于 $ e\\perp V $，并且 $ p-u\\in V $，因此 $$ \\| e+(p-u) \\| ^{2} = \\| e \\| ^{2} + \\| p-u \\| ^{2} \\geq \\| e \\| ^{2} $$ 等号当且仅当 $ u=p $。两边再开平方即可得到目标式子，得证。\n(4)\n我们带入 $ \\text{dist} $ 的定义，有 $$ \\text{dist}(v,V) = \\min_{u\\in V}\\| u-v \\| \\geq \\| e \\| $$ 并且在 $ u=p $ 时就有 $ \\| u-v \\|=\\| e \\| $。因此 $$ \\text{dist}(v,V) = \\| e \\| $$\nExercise 4 (1) $$ e = b - \\dfrac{a\\cdot b}{\\| a \\|^{2} }\\cdot a = \\begin{bmatrix} 1 \\\\ 2 \\\\ 2 \\end{bmatrix} - \\dfrac{5}{3}\\cdot \\begin{bmatrix} 1 \\\\ 1 \\\\ 1 \\end{bmatrix} = \\begin{bmatrix} -2 / 3 \\\\ 1 / 3 \\\\ 1 / 3 \\end{bmatrix} $$ (2) $$ e = b - \\dfrac{a\\cdot b}{\\| a \\|^{2} }\\cdot a = \\begin{bmatrix} 1 \\\\ 3 \\\\ 1 \\end{bmatrix} - \\dfrac{-11}{11}\\cdot \\begin{bmatrix} -1 \\\\ -3 \\\\ -1 \\end{bmatrix} = \\mathbf{0} $$\nExercise 5 (1)\n首先计算 $ A^T A $ $$ A^T A = \\begin{pmatrix} 1 \u0026 1 \\\\ 1 \u0026 2 \\end{pmatrix} \\implies (A^T A)^{-1} = \\begin{pmatrix} 2 \u0026 -1 \\\\ -1 \u0026 1 \\end{pmatrix} $$ $$ $$ 得到 $$ A^T b = \\begin{pmatrix} 2 \\\\ 5 \\end{pmatrix} $$\n投影向量 $ p $ 为 $$ p = A (A^T A)^{-1} A^T b = \\begin{pmatrix} 2 \\\\ 3 \\\\ 0 \\end{pmatrix} $$\n误差向量 $ e $ 为 $$ e = b - p = \\begin{pmatrix} 0 \\\\ 0 \\\\ 4 \\end{pmatrix} $$\n(2)\n首先计算 $ A^T A $ $$ A^T A = \\begin{pmatrix} 2 \u0026 2 \\\\ 2 \u0026 3 \\end{pmatrix} \\implies (A^T A)^{-1} = \\begin{pmatrix} 3/2 \u0026 -1 \\\\ -1 \u0026 1 \\end{pmatrix} $$\n得到 $$ A^T b = \\begin{pmatrix} 8 \\\\ 14 \\end{pmatrix} $$\n投影向量 $ p $ 为 $$ p = A (A^T A)^{-1} A^T b = \\begin{pmatrix} 4 \\\\ 4 \\\\ 6 \\end{pmatrix} $$\n误差向量 $ e $ 为 $$ e = b - p = \\begin{pmatrix} 0 \\\\ 0 \\\\ 0 \\end{pmatrix} $$\n","permalink":"https://diefish1024.github.io/posts/class-notes/math1205h-linear-algebra/math1205h-hw10/","summary":"\u003ch2 id=\"exercise-1\"\u003eExercise 1\u003c/h2\u003e\n\u003cp\u003e\u003cstrong\u003e(1)\u003c/strong\u003e\n$$ \n\nu\\cdot v = v\\cdot u = \\sum_{i=1}^{m} v_{i}w_{i}\n\n $$\n\u003cstrong\u003e(2)\u003c/strong\u003e\n$$ \n\n(u+v)\\cdot w = u\\cdot w + v\\cdot w = \\sum_{i=1}^{m} (v_{i}+u_{i})w_{i}\n\n $$\n\u003cstrong\u003e(3)\u003c/strong\u003e\n$$ \n\ncu\\cdot v = c(u\\cdot v) = \\sum_{i=1}^{m} (c\\cdot u_{i}v_{i})\n\n $$\n\u003cstrong\u003e(4)\u003c/strong\u003e\n$$ \n\nu\\cdot u = \\sum_{i=1}^{m} u_{i}^{2} \\geq  0\n\n $$\n若 $ u\\cdot u = 0 $，可以得到 $ u_{i}=0 $，从而 $ u=\\mathbf{0} $。\u003c/p\u003e\n\u003ch2 id=\"exercise-2\"\u003eExercise 2\u003c/h2\u003e\n\u003cp\u003e$$ \n\nu\\perp v \\implies u\\cdot v = \\sum_{i=1}^{m} u_{i}v_{i} = 0\n\n $$\n从而\n$$ \n\n\\begin{align*}\n\\| u+v \\| ^{2} \u0026 = \\sum_{i=1}^{m} (u_{i}+v_{i})^{2} \\\\\n \u0026 = \\sum_{i=1}^{m} u_{i}^{2} + \\sum_{i=1}^{m} v_{i}^{2} + 2\\sum_{i=1}^{m} u_{i}v_{i} \\\\\n \u0026 = \\sum_{i=1}^{m} u_{i}^{2} + \\sum_{i=1}^{m} v_{i}^{2} \\\\\n \u0026 = \\| u \\| ^{2} + \\| v \\| ^{2}\n\\end{align*}\n\n $$\u003c/p\u003e","title":"MATH1205H HW10"},{"content":"Exercise 1 (1)\n若 $ x \\in \\mathcal{N}(A) $，说明 $ Ax=0 $，从而一定有 $ BAx=0 $，这就得到了 $ x \\in \\mathcal{N}(BA) $，因此 $$ \\mathcal{N}(A) \\subseteq \\mathcal{N}(BA) $$ (2)\n当 $ \\text{rank}(B)=n $，设 $ x \\in \\mathcal{N}(BA) $，此时有 $ BAx=0 $。由于 $ \\text{rank}(B)=n $，因此我们可以得到 $ Ax=0 $，从而 $$ x \\in \\mathcal{N}(A) $$ 于是必然有 $ \\mathcal{N}(A)=\\mathcal{N}(BA) $。\n如果 $ \\mathcal{N}(A)=\\mathcal{N}(BA) $，并不能推出 $ \\text{rank}(B)=n $。我们可以构造出反例 $$ A = \\begin{pmatrix} 0 \u0026 0 \\\\ 0 \u0026 0 \\end{pmatrix},\\quad B = \\begin{pmatrix} 1 \u0026 0 \\\\ 0 \u0026 0 \\end{pmatrix} $$ 显然这时 $ A=BA $，结论成立，但是 $ B $ 不满秩。\nExercise 2 需要求解 $$ \\begin{pmatrix} 2 \u0026 4 \u0026 6 \u0026 4 \\\\ 2 \u0026 5 \u0026 7 \u0026 6 \\\\ 2 \u0026 3 \u0026 5 \u0026 2 \\end{pmatrix}\\mathbf{x} = \\begin{pmatrix} 4 \\\\ 3 \\\\ 5 \\end{pmatrix} $$ 我们定义增广矩阵 $$ A = \\left( \\begin{array}{cccc|c} 2 \u0026 4 \u0026 6 \u0026 4 \u0026 4 \\\\ 2 \u0026 5 \u0026 7 \u0026 6 \u0026 3 \\\\ 2 \u0026 3 \u0026 5 \u0026 2 \u0026 5 \\end{array} \\right) $$ 化简得到 $$ A = \\left( \\begin{array}{cccc|c} 1 \u0026 0 \u0026 1 \u0026 -2 \u0026 4 \\\\ 0 \u0026 1 \u0026 1 \u0026 2 \u0026 -1 \\\\ 0 \u0026 0 \u0026 0 \u0026 0 \u0026 0 \\end{array} \\right) $$ 从而得到这个方程的解为 $$ \\mathbf{x} = \\begin{pmatrix} 4 \\\\ -1 \\\\ 0 \\\\ 0 \\end{pmatrix} + s\\begin{pmatrix} -1 \\\\ -1 \\\\ 1 \\\\ 0 \\end{pmatrix} + t\\begin{pmatrix} 2 \\\\ -2 \\\\ 0 \\\\ 1 \\end{pmatrix} $$ 也就是 $$ x_{1} = 4-s+2t,\\,x_{2}=-1-s-2t,\\,x_{3}=s,\\,x_{4}=t $$\nExercise 3 如果 $ \\{ v_{n} \\} $ 线性相关，那么不妨设 $$ v_{n} = \\begin{pmatrix} v_{1} \u0026 v_{2} \u0026 \\dots \u0026 v_{n-1} \\end{pmatrix} \\begin{pmatrix} a_{1} \\\\ a_{2} \\\\ \\vdots \\\\ a_{n-1} \\end{pmatrix} $$ 其中 $ a_{i}\\in \\mathbb{R} $。\n根据垂直，我们有 $ v_{1}\\cdot v_{n}=0 $，于是 $$ v_{1}\\cdot v_{n} = v_{1}^{T}\\begin{pmatrix} v_{1} \u0026 v_{2} \u0026 \\dots \u0026 v_{n-1} \\end{pmatrix} \\begin{pmatrix} a_{1} \\\\ a_{2} \\\\ \\vdots \\\\ a_{n-1} \\end{pmatrix} = \\begin{pmatrix} v_{1}^{T}v_{1} \u0026 0 \u0026 0 \u0026 \\dots \u0026 0 \\end{pmatrix} \\begin{pmatrix} a_{1} \\\\ a_{2} \\\\ \\vdots \\\\ a_{n-1} \\end{pmatrix} = a_{1}v_{1}^{T}v_{1} = 0 $$ 根据 $ v_{1}^{T}v_{1}\\neq 0 $，我们可以得到 $ a_{1}=0 $。同理取 $ i=1,2,3,\\dots,n-1 $，我们都能得到 $ a_{i}=0 $。那么这就推出了 $ v_{n}=0 $，与题目条件矛盾。所以 $ \\{ v_{n} \\} $ 线性无关。\nExercise 4 (1)\n若 $ v\\in V\\cap W $，我们有 $ v^{T}v=0 $，从而 $ v=\\mathbf{0} $。因此 $ V\\cap W=\\{ \\mathbf{0} \\} $。\n(2)\n两边同乘 $ v_{1}^{T} $，我们得到 $$ v_{1}^{T}(v_{1}+w_{1}) = v_{1}^{T}(v_{2}+w_{2}) \\implies v_{1}^{T}(v_{1} - v_{2}) = \\mathbf{0} $$ 同理也有 $ v_{2}^{T}(v_{1}-v_{2})=\\mathbf{0} $。因此我们有 $ (v_{1}-v_{2})^{T}(v_{1}-v_{2})=\\mathbf{0} $，即 $ \\left| v_{1}-v_{2} \\right|=0 $，从而 $$ v_{1}=v_{2} $$ 同理，一样能得到 $ w_{1}=w_{2} $。\n(3)\n我们验证 $ V+W $ 满足 $ \\mathbb{R}^{n} $ 子空间的三个性质即可。\n包含零向量：由于 $ \\{ \\mathbf{0} \\}\\in V\\cap W $，因此 $ \\{ \\mathbf{0} \\}\\in V+W $。\n对向量加法封闭：设 $ (v_{1}+w_{1}),(v_{2}+w_{2})\\in V+W $，由于 $ V $ 和 $ W $ 本身都是 $ \\mathbb{R}^{n} $ 的子空间，因此 $ (v_{1}+v_{2})\\in V,(w_{1}+w_{2})\\in W $，所以 $$ (v_{1}+w_{1})+(v_{2}+w_{2})=(v_{1}+v_{2})+(w_{1}+w_{2})\\in V+W $$ 对标量乘法封闭：设 $ v\\in V,w \\in W $，那么对于 $ c\\in \\mathbb{R} $，有 $ cv\\in V,cw\\in W $，从而 $ c(v+w)\\in V+W $。\n综上，我们证明了 $ V+W $ 是 $ \\mathbb{R}^{n} $ 的一个子空间。\n(4)\n我们设 $ v_{1},v_{2},\\dots,v_{r} $ 为 $ V $ 的基，$ w_{1},w_{2},\\dots,w_{s} $ 为 $ W $ 的基。我们证明 $ v_{1},\\dots,v_{r},w_{1},\\dots,w_{s} $ 是 $ V+W $ 的一个基。\n首先证明用 $ v_{1},\\dots,v_{r},w_{1},\\dots,w_{s} $ 可以线性表示 $ V+W $ 中的元素。对于 $ v+w\\in V+W $，我们可以用 $ v_{1},v_{2},\\dots,v_{r} $ 线性表示出 $ v $，用 $ w_{1},w_{2},\\dots,w_{s} $ 线性表示出 $ w $，所以用 $ v_{1},\\dots,v_{r},w_{1},\\dots,w_{s} $ 可以线性表示出 $ v+w $。\n接着证明 $ v_{1},\\dots,v_{r},w_{1},\\dots,w_{s} $ 中的元素线性无关。不妨只证明不能用 $ v_{1},\\dots,v_{r} $ 线性表示 $ w_{1} $，其余完全同理。假设可以线性表示，我们就有 $$ w_{1} = \\begin{pmatrix} v_{1} \u0026 v_{2} \u0026 \\dots \u0026 v_{n} \\end{pmatrix} \\begin{pmatrix} a_{1} \\\\ a_{2} \\\\ \\vdots \\\\ a_{n-1} \\end{pmatrix} $$ 于是我们考虑 $ v_{i}^{T}w_{1}=0 $，可以推出 $ a_{i}=0 $，从而得到 $ w_{1}=0 $，矛盾。因此 $ v_{1},\\dots,v_{r},w_{1},\\dots,w_{s} $ 线性无关。\n","permalink":"https://diefish1024.github.io/posts/class-notes/math1205h-linear-algebra/math1205h-hw9/","summary":"\u003ch2 id=\"exercise-1\"\u003eExercise 1\u003c/h2\u003e\n\u003cp\u003e\u003cstrong\u003e(1)\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e若 $ x \\in \\mathcal{N}(A) $，说明 $ Ax=0 $，从而一定有 $ BAx=0 $，这就得到了 $ x \\in \\mathcal{N}(BA) $，因此\n$$ \n\n\\mathcal{N}(A) \\subseteq \\mathcal{N}(BA)\n\n $$\n\u003cstrong\u003e(2)\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e当 $ \\text{rank}(B)=n $，设 $ x \\in \\mathcal{N}(BA) $，此时有 $ BAx=0 $。由于 $ \\text{rank}(B)=n $，因此我们可以得到 $ Ax=0 $，从而\n$$ \n\nx \\in \\mathcal{N}(A)\n\n $$\n于是必然有 $ \\mathcal{N}(A)=\\mathcal{N}(BA) $。\u003c/p\u003e\n\u003cp\u003e如果 $ \\mathcal{N}(A)=\\mathcal{N}(BA) $，并不能推出 $ \\text{rank}(B)=n $。我们可以构造出反例\n$$ \n\nA = \\begin{pmatrix}\n0 \u0026 0 \\\\\n0 \u0026 0\n\\end{pmatrix},\\quad B = \\begin{pmatrix}\n1 \u0026 0 \\\\\n0 \u0026 0\n\\end{pmatrix}\n\n $$\n显然这时 $ A=BA $，结论成立，但是 $ B $ 不满秩。\u003c/p\u003e","title":"MATH1205H HW9"},{"content":"题目\nProblem 1.1 (1)\n证：若 $ \\sigma $-代数包含所有 $ (a,b) $，则包含 $ [a,b] $。 $$ [a,b] = \\bigcap_{n=1}^{\\infty} \\left(a-\\frac{1}{n}, b+\\frac{1}{n}\\right) $$ 由 $ \\sigma $-代数对可数交封闭，故 $ [a,b] $ 在其中。\n证：若 $ \\sigma $-代数包含所有 $ [a,b] $，则包含 $ (a,b) $。 $$ （a,b) = \\bigcup_{n=1}^{\\infty} \\left[a+\\frac{1}{n}, b-\\frac{1}{n}\\right] $$ 由 $ \\sigma $-代数对可数并封闭，故 $ (a,b) $ 在其中。\n(2)\n证：若 σ-代数包含所有 $ (a,b) $，则包含 $ [x,\\infty) $。 $$ [x,\\infty) = \\bigcap_{n=1}^{\\infty} \\left(x-\\frac{1}{n}, \\infty\\right) = \\bigcap_{n=1}^{\\infty} \\bigcup_{m=1}^{\\infty} \\left(x-\\frac{1}{n}, m\\right) $$ 由 $ \\sigma $-代数对可数并、可数交封闭，故 $ [x,\\infty) $ 在其中。\n证：若 $ \\sigma $-代数包含所有 $ [x,\\infty) $，则包含 $ (a,b) $。 $$ (a,b) = [a,\\infty) \\cap (-\\infty,b] = [a,\\infty) \\cap \\mathbb{R}\\setminus[b,\\infty) $$ 由 $ \\sigma $-代数对补集和交运算封闭，故 $ (a,b) $ 在其中。\nProblem 1.2 由于 $ \\mathbb{Q} $ 是可数集，因此我们设 $ \\mathbb{Q}=\\{ q_{1},q_{2},\\dots, \\} $。\n对于任意 $ \\varepsilon\u003e0 $，我们构造 $ \\mathbb{Q} $ 的一个开覆盖 $$ I = \\bigcup_{n\\geq 1}\\left( q_{n}-\\dfrac{\\varepsilon}{2^{n+1}},q_{n}+ \\dfrac{\\varepsilon}{2^{n+1}} \\right) $$ 于是我们有 $ \\mathbb{Q}\\subset I_{n} $，从而 $$ \\lambda(\\mathbb{Q}) \\leq \\lambda(I) = \\sum_{n=1}^{\\infty} \\dfrac{\\varepsilon}{2^{n}} = \\varepsilon $$ 这样我们就得到了 $ \\lambda(\\mathbb{Q})=0 $。\nProblem 2 (1)\n注意到每个 $ \\omega = (\\omega_1, \\omega_2, \\ldots) \\in \\Omega $ 的前 $ n $ 位 $ (\\omega_1, \\ldots, \\omega_n) $ 唯一确定一个 $ s \\in {0,1}^n $，使得 $ \\omega \\in C_s $。\n因此满足\n互不相交：若 $ s \\neq t $，则 $ C_s \\cap C_t = \\emptyset $（否则存在 $ \\omega $ 前 $ n $ 位同时为 $ s $ 和 $ t $，矛盾） 覆盖全集：$ \\bigcup_{s\\in{0,1}^n} C_s = \\Omega $（每个 $ \\omega $ 的前 $ n $ 位必为某个 $ s $） 故 $ {C_s}_{s\\in{0,1}^n} $ 构成 $ \\Omega $ 的分划。\n(2)\n由于 $ \\sigma $-代数的性质，我们知道 $ \\mathcal{F} $ 中的集合可以唯一的表示为一些 $ C_{s} $ 的并。也就是对于 $ A\\in \\mathcal{F} $，必然有 $$ A=\\bigcup_{s \\in S}C_{s}, \\quad S = \\{ s \\in \\{ 0,1 \\}^{n}:C_{s}\\subseteq A \\} $$ 于是我们就可以构造映射 $$ f:\\mathcal{F}_{n} \\to 2^{\\{ 0,1 \\}^{n}} ,f(A) = \\{ s \\in \\{ 0,1 \\}^{n}:C_{s}\\subseteq A \\} $$ 以及逆映射 $$ f^{-1}: 2^{\\{ 0,1 \\}^{n}} \\to \\mathcal{F}_{n},f^{-1}(S) = \\bigcup_{s \\in S}C_{s} $$ 我们容易验证 $ f $ 是单射和满射的性质，可以利用在 $ (1) $ 中证明的分划的性质。\n(3)\n根据 $ (2) $ 的性质，我们证明 $ \\mathcal{F}_{i}\\subset \\mathcal{F}_{j} $ 等价于证明 $ 2^{\\{ 0,1 \\}^{i}}\\subset 2^{\\{ 0,1 \\}^{j}} $。\n我们设 $ T_{n}=\\{ 0,1,2,\\dots,2^{n-1} \\} $，显然如果把集合 $ \\{ 0,1 \\}^{n} $ 中的元素看成数的二进制，就能得到和 $ T_{n} $ 的双射。对于 $ i\u003c j $，显然 $ S_{i}\\subset S_{j} $ 成立，从而 $ 2^{S_{i}}\\subset 2^{S_{j}} $ 成立。我们再把数字重新变成二进制表示，就得到了 $$ 2^{\\{ 0,1 \\}^{i}}\\subset 2^{\\{ 0,1 \\}^{j}} $$ (4)\n我们依次验证 $ \\mathcal{F}_{\\infty} $ 符合代数的三个性质。首先由于每个 $ \\mathcal{F}_{i} $ 都是代数，因此它们的并显然也会包含 $ \\Omega $。\n接着证明关于补集封闭。设 $ A\\in \\mathcal{F}_{\\infty} $，那么存在 $ N $ 使得 $ A\\in \\mathcal{F}_{N} $。由于 $ \\mathcal{F}_{N} $ 是代数，所以 $ A^{c}\\in \\mathcal{F}_{N} $，从而 $ A^{c}\\in \\mathcal{F}_{\\infty} $。\n接着证明对于有限并运算封闭。对于任意 $ A,B\\in \\mathcal{F}_{\\infty} $，存在 $ N_{1},N_{2} $ 使得 $ A\\in \\mathcal{F}_{N_{1}},B\\in \\mathcal{F}_{N_{2}} $。那么就有 $ A\\cup B\\in \\mathcal{F}_{N_{1}}\\cup \\mathcal{F}_{N_{2}} $。从而就有 $$ A\\cup B \\in \\mathcal{F}_{\\infty} $$ (5)\n我们需要证明得到 $ \\omega $ 需要可数无限次交，这样就可以说明属于 $ \\sigma $-代数但是不属于代数。\n我们依次取 $ \\omega $ 的前 $ n $ 位 $ S_{n} $，那么所有 $ C_{S_{n}} $ 的交集就是 $ \\{ \\omega \\} $，也就是 $$ \\{ \\omega \\} = \\bigcap_{n \\geq 1} C_{S_{n}} $$ 由于 $ \\sigma $-代数对可数交封闭，因此 $ \\{ \\omega \\}\\in \\mathcal{B}(\\Omega) $。\n接着我们证明 $ \\{ \\omega \\} \\not\\in \\mathcal{F}_{\\infty} $。由于 $ \\mathcal{F}_{n} $ 的元素是 $ C_{s} $ 的有限并，而每个 $ C_{s} $ 都不可数，因此它们的非空有限并也是不可数的，这就可以说明 $ \\mathcal{F}_{\\infty} $ 中的非空元素也是不可数的。然而 $ \\{ \\omega \\} $ 中只有可数个元素，所以显然不属于 $ \\mathcal{F}_{\\infty} $。\n综上，我们得到了 $$ \\{ \\omega \\} \\in \\mathcal{B}(\\Omega)\\setminus \\mathcal{F}_{\\infty} $$ (6)\n我们先证明存在性。对于任何 $ A \\in \\mathcal{F}_{\\infty} $，根据其定义，存在某个 $ n \\ge 1 $ 使得 $ A \\in \\mathcal{F}_n $。由 $ (5) $ 可知， $ \\mathcal{F}_n $ 中的每个集合 $ A $ 都能唯一表示为 $ A = \\bigcup_{s \\in S} C_s $，其中 $ S \\subseteq \\{0,1\\}^n $。令 $ k = |S| $，则 $ A = C_{s_1} \\cup \\cdots \\cup C_{s_k} $，其中 $ s_i \\in \\{0,1\\}^n $。\n接着证明比值的唯一性。设 $ A $ 有两种表示：\n$ A=\\bigcup_{i=1}^{k} C_{s_i} $，其中 $ s_i \\in \\{0,1\\}^n $ 且互不相同。 $ A=\\bigcup_{j=1}^{m} C_{t_j} $，其中 $ t_j \\in \\{0,1\\}^p $ 且互不相同。 取 $ L=\\max(n,p) $。每个 $ C_s $ (其中 $ s \\in \\{0,1\\}^N $) 可被分解为 $ 2^{L-N} $ 个互不相交的 $ C_u $ (其中 $ u \\in \\{0,1\\}^L $) 的并。\n将两种表示都扩展到级别 $ L $：\n$ A $ 可表示为 $ k \\cdot 2^{L-n} $ 个互不相交的 $ C_u $ (其中 $ u \\in \\{0,1\\}^L $) 的并。 $ A $ 也可表示为 $ m \\cdot 2^{L-p} $ 个互不相交的 $ C_u $ (其中 $ u \\in \\{0,1\\}^L $) 的并。 由于这种在固定级别 $ L $ 下的分解是唯一的，这两个数量必须相等： $$ k \\cdot 2^{L-n} = m \\cdot 2^{L-p} \\implies \\dfrac{k}{2^{n}} = \\dfrac{m}{2^{p}} $$ 因此，比值 $ k/2^n $ 对于给定的集合 $ A $ 是唯一确定的。\nProblem 3 (1)\n证 1\n我们只需要对于任意的 $ a \\in \\mathbb{R} $，说明 $ [X_{1}X_{2}\u003ea]\\in \\mathcal{F} $ 即可，进而根据 $ \\sigma $-代数的性质即可用 $ (a,+\\infty) $ 拼出其他的集合。\n不妨设 $ a\u003e0 $，其余情况同理。于是我们有 $$ [X_{1}X_{2}\u003ea] = \\left( \\bigcup_{r\\in \\mathbb{Q}\\land r\u003e0}\\left( [X_{1}\u003er]\\cap\\left[ X_{2}\u003e \\dfrac{a}{r} \\right] \\right) \\right) \\cup \\left( \\bigcup_{r\\in \\mathbb{Q}\\land r\u003c 0}\\left( [X_{1}\u003c r]\\cap\\left[ X_{2} \u003c \\dfrac{a}{r} \\right] \\right) \\right) $$ 对于其他情况，我们改变不等号方向即可。\n从而 $ [X_{1}X_{2}\u003ea] $ 被分解成了一系列可数的 $ \\mathcal{F} $ 中的集合的交集，因此 $ [X_{1}X_{2}\u003ea]\\in \\mathcal{F} $，也就说明了 $ X_{1}X_{2} $ 是随机变量。\n证 2\n我们可以直接考虑 $$ X_{1}X_{2} = \\dfrac{1}{4}[(X_{1}+X_{2})^{2} - (X_{1}-X_{2})^{2}] $$ 并且平方和加减操作都不会改变可测性，因此 $ X_{1}X_{2} $ 可测。\n平方可测：令 $ Z=X^{2} $，那么 $ [Z\u003ea]=[X\u003e\\sqrt{ a }]\\in \\mathcal{F}\\quad(a\u003e0) $。\n(2)\n由于分解子集对于除法操作过于繁琐，所以我们考虑先证明倒数的可测性，再直接利用 $ (1) $ 的结论即可。\n我们下面证明对于 $ X\\neq 0 $，那么 $ Z = 1/X $ 是可测函数。\n对于任意 $ a\\in \\mathbb{R} $，我们考虑 $ [Z\u003ea] $。\n若 $ a=0 $，那么 $ [Z\u003e0]=[X\u003e0]\\in \\mathcal{F} $。\n若 $ a\u003e0 $，那么 $$ [Z\u003ea] = [X\u003e0]\\cap [X\u003c 1 / a] $$ 显然有 $ [Z\u003ea]\\in \\mathcal{F} $。\n若 $ a\u003c 0 $，那么 $$ [Z\u003c a] = ([X\u003c 0]\\cap [X\u003e 1 / a]) \\cup [X\u003e0] \\in \\mathcal{F} $$ 综上，我们有 $ [Z\u003ea]\\in \\mathcal{F} $，于是倒数可测。\n从而利用 $ (1) $，我们得到除法也是可测的。\n(3)\n对于任意的 $ a\\in \\mathbb{R} $： $$ [ Z\u003ea ] = [ \\mathrm{inf}_{n\\geq 1}X_{n}\u003ea ] = \\bigcap_{n=1}^{\\infty}[ X_{n}\u003ea ] $$ (4)\n我们有 $$ \\lim\\mathrm{inf}_{n\\to \\infty} X_{n} = \\mathrm{sup}_{m\\geq 1} \\mathrm{inf}_{n\\geq m}X_{n} $$ 令 $ Y_{m}:=\\mathrm{inf}_{n\\geq m}X_{n} $。由 $ (3) $ 我们知道 $ Y_{m} $ 是一个随机变量，因此 $$ [\\mathrm{sup}_{m}Y_{m}\u003ea] = \\bigcup_{m=1}^{\\infty}\\{ Y_{m}\u003ea \\} $$ 从而得证。\n","permalink":"https://diefish1024.github.io/posts/class-notes/math2701-probability-theory/math2701-hw3/","summary":"\u003cp\u003e\u003ca href=\"https://notes.sjtu.edu.cn/s/_-B0cVjkY\"\u003e题目\u003c/a\u003e\u003c/p\u003e\n\u003ch2 id=\"problem-11\"\u003eProblem 1.1\u003c/h2\u003e\n\u003cp\u003e\u003cstrong\u003e(1)\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e证\u003c/strong\u003e：若 $ \\sigma $-代数包含所有 $ (a,b) $，则包含 $ [a,b] $。\n$$ \n[a,b] = \\bigcap_{n=1}^{\\infty} \\left(a-\\frac{1}{n}, b+\\frac{1}{n}\\right)\n $$\n由 $ \\sigma $-代数对可数交封闭，故 $ [a,b] $ 在其中。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e证\u003c/strong\u003e：若 $ \\sigma $-代数包含所有 $ [a,b] $，则包含 $ (a,b) $。\n$$ \n（a,b) = \\bigcup_{n=1}^{\\infty} \\left[a+\\frac{1}{n}, b-\\frac{1}{n}\\right]\n $$\n由 $ \\sigma $-代数对可数并封闭，故 $ (a,b) $ 在其中。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e(2)\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e证\u003c/strong\u003e：若 σ-代数包含所有 $ (a,b) $，则包含 $ [x,\\infty) $。\n$$ \n[x,\\infty) = \\bigcap_{n=1}^{\\infty} \\left(x-\\frac{1}{n}, \\infty\\right) = \\bigcap_{n=1}^{\\infty} \\bigcup_{m=1}^{\\infty} \\left(x-\\frac{1}{n}, m\\right)\n $$\n由 $ \\sigma $-代数对可数并、可数交封闭，故 $ [x,\\infty) $ 在其中。\u003c/p\u003e","title":"MATH2701 HW3"},{"content":"Problem 1 (1)\n证明： $$ \\chi(G) + \\chi(\\overline{G}) \\leq v(G) + 1 $$ 证\n归纳证明。对于大小为 $ 1 $ 的图，结论显然成立，此时 $ \\chi(G)=\\chi(\\overline{G})=1 $。\n假设对于大小为 $ n-1 $ 的图这个结论都成立，那么对于一个大小为 $ n $ 的图 $ G $，我们考虑加入一个点 $ v $。此时我们有 $$ \\chi(G-v)+\\chi(\\overline{G}-v) \\leq n $$ 我们现在证明 $ \\chi(G) $ 和 $ \\chi(\\overline{G}) $ 中至多只有一个可能会增加 $ 1 $。设 $ G $ 中 $ v $ 的度数为 $ d(v) $，在 $ \\overline{G} $ 中为 $ \\overline{d}(v)=n-1-d(v) $。\n若 $ d(v)\u003c \\chi(G-v) $ 或 $ \\overline{d}(v)\u003c \\chi(\\overline{G}-v) $。那么在一个图中新加入的点可以直接使用原来的颜色，不会增加这个图的染色数，并且另一个图至多只会增加一种染色数。在这两种情况下，直接就能得到 $$ \\chi(G)+\\chi(\\overline{G}) = \\chi(G-v)+\\chi(\\overline{G}-v)+1 \\leq n+1 $$\n由于 $ d(v)+(n-1-d(v))=n-1 $，所以如果这两个不等式都不成立，我们就有 $$ d(v)+\\overline{d}(v)=n-1\\geq \\chi(G-v)+\\chi(\\overline{G}-v) $$ 从而 $$ \\chi(G)+\\chi(\\overline{G})\\leq (\\chi(G-v)+1) + (\\chi(\\overline{G}-v)+1) \\leq n-1+2=n+1 $$\n综上，我们就证明了 $$ \\chi(G)+\\chi(\\overline{G}) \\leq n+1 $$ (2)\n找到一个 $ n $ 阶的图满足 $ \\chi(G)\\cdot \\chi(\\overline{G})= \\frac{(n+1)^{2}}{4} $。\n解\n考虑 $ n $ 为奇数。\n用以下方式构造出 $ G $：在 $ n $ 个点中取出 $ \\dfrac{n+1}{2} $ 个点组成一个完全图，剩下 $ \\dfrac{n-1}{2} $ 个点构成一个独立集。这样 $ \\chi(G)=\\dfrac{n+1}{2} $，因为完全图子图中每个点颜色都要彼此不同。\n现在我们来考虑 $ \\chi(\\overline{G}) $。$ \\overline{G} $ 为一个 $ \\dfrac{n+1}{2} $ 部完全图，同样也有 $ \\chi(\\overline{G})=\\dfrac{n+1}{2} $。\n这是就有 $$ \\chi(G)\\cdot \\chi(\\overline{G}) = \\dfrac{(n+1)^{2}}{4} $$\nProblem 2 一个图 $ G $ 的最优着色是指一个仅使用 $ \\chi(G) $ 种颜色的正确着色 $ \\varphi $，其中 $ \\chi(G) $ 是图 $ G $ 的色数。\n证明或反驳：对于所有简单图 $ G $，存在一个最大独立集 $ W $ 和一个最优着色 $ \\varphi $，使得 $ W $ 中至少 $ |W|/4 $ 个顶点被 $ \\varphi $ 分配了相同的颜色。\n反例\n构造一下反例：\n其中最大独立集大小为 $ 5 $，取外圈的一层点，但是 $ \\chi(G)=5 $，最大独立集中每个点都被染上了不同的颜色，与题设矛盾。\n构造思路：先用中间的团来限制染色数为 $ 5 $，接着再向外拓展其他的点，保证这些点构成独立集，并且颜色被限定只能与对面的点相同。\n注：本题并非独立解决，经过了和同学的讨论后才作出。\nProblem 3 证明：如果一个二部图 $ G = (L, R, E) $ 满足 $ |L| = |R| = n $ 且没有完美匹配，则存在一个集合 $ S $ 使得：\n(i) $ |S| = |N(S)| + 1 $，其中 $ N(S) $ 是 $ S $ 的所有邻居集合；\n(ii) $ |S| \\leq \\lceil n/2 \\rceil $;\n(iii) $ N(S) $ 中的每个顶点在 $ S $ 中至少有两个邻居。\n证\n由于二部图 $ G = (L, R, E) $ 满足 $ |L| = |R| = n $ 且没有完美匹配，根据 Hall 婚姻定理，存在 $ S \\subseteq L $ 使得 $ |N(S)| \u003c |S| $，并且也同样存在 $ S\\subseteq R $ 使得 $ \\left| N(S) \\right|\u003c\\left| S \\right| $。\n我们设 $ S_{L} $ 为所有 $ L $ 满足条件的子集中顶点数最少的那个，$ S_{R} $ 为所有 $ R $ 满足条件的子集中顶点数最少的那个。\n我们证明 $ S_{L} $ 满足性质 $ (1) $，$ S_{R} $ 同理。显然此时 $ \\left| S_{L} \\right|\\geq \\left| N(S_{L}) \\right|+1 $，我们此时只需要证明 $$ \\left| S_{L} \\right| \\leq \\left| N(S_{L}) \\right| +1 $$ 从 $ S_{L} $ 中任意删掉一个顶点，此时会得到一个规模小于 $ S_{L} $ 的集合 $ S^{*} $。由于 $ S_{L} $ 是最小的满足条件的子集，因此对于 $ S^{*} $ 有 $$ \\left| S^{*} \\right| = \\left| S_{L} \\right| - 1 \\leq \\left| N(S^{*}) \\right| \\leq \\left| N(S_{L}) \\right| $$ 这样就得到了 $$ \\left| S_{L} \\right| \\leq \\left| N(S_{L}) \\right| +1 $$ 从而得到 $ S_{L} $ 满足性质 $ (1) $ $$ \\left| S_{L} \\right| =\\left| N(S_{L}) \\right| + 1 $$\n接着证明 $ S_{L} $ 满足性质 $ (3) $。在性质 $ (1) $ 的证明中我们还可以发现必然有 $ \\left| N(S^{*}) \\right|=\\left| N(S_{L}) \\right| $（将结论代回 $ S^{*} $ 的不等式即可），说明 $ S_{L} $ 中任意删掉一个顶点都不会减少它的邻居数量，显然这就得到了 $ N(S_{L}) $ 中的每个点都有至少两个邻居，也就是 $ S_{L} $ 中每个点不会独占一个邻居。\n因此 $ S_{L} $ 和 $ S_{R} $ 都满足性质 $ (1),(3) $。下面我们证明它们中至少有一个满足性质 $ (2) $。\n我们构造 $ T=R\\setminus N(S_{L}) $，显然有 $ N(T)\\subseteq L\\setminus S_{L} $。我们计算 $ \\left| T \\right| $ 和 $ \\left| N(T) \\right| $ 的大小，得到 $$ \\left| T \\right| = n - \\left| S_{L} \\right| +1, \\left| N(T) \\right| =n-\\left| S_{L} \\right| $$ 由于 $ N(T)\u003c \\left| T \\right| $，我们知道 $ T $ 也是一个不满足条件的子集，于是根据 $ S_{R} $ 的最小性，得到 $$ \\left| T \\right| =n - \\left| S_{L} \\right| +1 \\geq \\left| S_{R} \\right| $$ 从而 $$ \\left| S_{L} \\right| +\\left| S_{R} \\right| \\leq n+1 $$ 其中至少有一个会满足性质 $ (2) $ $$ \\left| S \\right| \\leq \\left\\lceil \\dfrac{n}{2} \\right\\rceil $$ 证毕。\nProblem 4 设 $ S $ 是集合 $ [m n] $。我们将 $ S $ 分割成 $ m $ 个大小为 $ n $ 的集合 $ A_1, \\dots, A_m $。假设存在另一个将 $ S $ 分割成 $ m $ 个大小为 $ n $ 的集合 $ B_1, \\dots, B_m $。证明 $ A_1, \\dots, A_m $ 可以重新编号，使得 $ A_i \\cap B_i \\neq \\emptyset $ 对于所有 $ i $。\n证\n我们可以很自然地把这个问题转化成一个二分图匹配问题。设有顶点集 $ L,R $，分别代表 $ A_{1},\\dots A_{m} $ 和 $ B_{1},\\dots,B_{m} $。我们定义 $ u_{i}\\in L $ 和 $ v_{j}\\in R $ 存在变当且仅当 $ A_{i}\\cap B_{j}\\neq \\emptyset $。这样原问题就等价于证明这样构建的二分图 $ G $ 存在一个完美匹配。\n我们考虑证明 $ G $ 满足 Hall 婚姻定理的条件。证明对于 $ L $ 的任意子集 $ S\\subseteq L $，其邻居集合 $ N(S)\\subseteq R $，需要满足 $$ \\left| S \\right| \\leq \\left| N(S) \\right| $$ 我们现在任取一个非空子集 $ S\\subseteq L $，假设 $ \\left| S \\right|=k $，对应集合 $ A_{i_{1}},A_{i_{2}},\\dots,A_{i_{k}} $。它们的并集 $ U $ 大小为 $ n\\times k $，设有 $$ U = \\bigcup_{s \\in S}A_{s} $$ 现在考虑 $ N(S) $ 集合。如果顶点 $ v_{j}\\in R $ 不属于 $ N(S) $，即 $ v_{j}\\not\\in N(S) $，这说明 $ \\forall u_{i}\\in S,A_{i}\\cap B_{j}=\\emptyset $，说明 $ B_{j} $ 与并集 $ U $ 没有交集。这说明了 $$ U\\subseteq \\bigcup_{s \\in N(S)}B_{s} $$ 设 $ \\left| N(S) \\right|=r $，那么 $ N(S) $ 中所有 $ B $ 集合的并大小为 $ n\\times r $，于是根据包含关系，我们得到了 $$ n\\times k \\leq n\\times r \\implies k \\leq r $$ 从而证明了 $ \\left| S \\right|\\leq \\left| N(S) \\right| $，Hall 条件成立，存在完美匹配。证毕。\n","permalink":"https://diefish1024.github.io/posts/class-notes/cs0901-combinatorics/cs0901-hw5/","summary":"\u003ch2 id=\"problem-1\"\u003eProblem 1\u003c/h2\u003e\n\u003cp\u003e\u003cstrong\u003e(1)\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e证明：\n$$ \n\n\\chi(G) + \\chi(\\overline{G}) \\leq  v(G) + 1\n\n $$\n\u003cstrong\u003e证\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e归纳证明。对于大小为 $ 1 $ 的图，结论显然成立，此时 $ \\chi(G)=\\chi(\\overline{G})=1 $。\u003c/p\u003e\n\u003cp\u003e假设对于大小为 $ n-1 $ 的图这个结论都成立，那么对于一个大小为 $ n $ 的图 $ G $，我们考虑加入一个点 $ v $。此时我们有\n$$ \n\n\\chi(G-v)+\\chi(\\overline{G}-v) \\leq  n\n\n $$\n我们现在证明 $ \\chi(G) $ 和 $ \\chi(\\overline{G}) $ 中至多只有一个可能会增加 $ 1 $。设 $ G $ 中 $ v $ 的度数为 $ d(v) $，在 $ \\overline{G} $ 中为 $ \\overline{d}(v)=n-1-d(v) $。\u003c/p\u003e","title":"CS0901 HW5"},{"content":"Exercise 1 先证明行阶梯矩阵中主元列的唯一性。由于初等行变换保持了列向量之间的线性关系，因此如果矩阵 $ A $ 的第 $ j $ 列是前 $ j-1 $ 列的线性组合，初等行变换之后也仍然成立。并且一个列为主元列，当且仅当它不能被前面的列线性表示，所以 $ A_{1} $ 和 $ A_{2} $ 中的主元列位置完全相同。\n接着证明简化行阶梯矩阵的唯一性。对于每个主元列 $ j_{k} $，必须化简成单位向量 $ e_{k} $，满足主元为 $ 1 $，其余元素为 $ 0 $，具有唯一性；对于非主元列，可以表示为前面的列的线性组合，所以为 $ 0 $，也具有唯一性。因此简化行阶梯矩阵具有唯一性。\nExercise 2 (1)\n我们通过选择 $ W=\\text{span}\\{ v_{1},v_{2},\\dots,v_{n} \\} $ 中的一个子集，可以构造出 $ W $ 的一个基。我们依次考虑 $ i=1,2,\\dots,n $，如果 $ i=1 $ 或者 $ v_{i} $ 不是前 $ i-1 $ 个向量的线性组合，就选择 $ v_{i} $，这样最终就得到了 $ B=\\{ v_{i_{1}},v_{i_{2}},\\dots,v_{i_{r}} \\} $。\n下面验证这时 $ W $ 的基：显然根据选择策略，$ B $ 中的向量显然是线性无关的；并且 $ W\\setminus B $ 中的向量都可以被 $ B $ 中的向量线性表示。这就说明了 $ B $ 是 $ W $ 的一个基。\n(2)\n显然根据定义，有 $$ \\text{dim}(\\text{span}\\{ v_{1},v_{2},\\dots,v_{n} \\}) = r $$ 其中 $ r $ 为 $ (1) $ 中构造出的 $ B $ 的大小，$ \\left| B \\right|=r $。\n我们只需要证明若 $ v_{1},v_{2},\\dots,v_{n} $ 线性无关，就有 $ \\left| B \\right|=n $。根据 $ B $ 的定义，这是显然的，不可能出现一个向量 $ v_{i} $ 被前 $ i-1 $ 个向量线性表示的情况，所以构造 $ B $ 过程会选择所有的向量，我们就得到了 $$ W=B\\implies \\left| B \\right| =r=n $$ 从而 $$ \\text{dim}(\\text{span}\\{ v_{1},v_{2},\\dots,v_{n} \\}) = n $$\nExercise 3 我们把 $ AB $ 看成将 $ A $ 中的列向量线性组合，于是 $ AB $ 的列空间 $ C(AB) $ 是 $ A $ 的列空间 $ C(A) $ 的子空间，即 $ C(AB)\\subseteq C(A) $，所以 $$ \\text{dim}(C(AB)) \\leq \\text{dim}(C(A)) \\implies \\text{rank}(AB) \\leq \\text{rank}(A) $$ 同理，考虑行空间，还可以得到 $ \\text{rank}(AB) \\leq\\text{rank}(B) $。\n综上，我们可以得到 $$ \\text{rank}(AB) \\leq \\min\\{ \\text{rank}(A),\\text{rank}(B) \\} $$\nExercise 4 (1)\n将 $ A $ 化为简化行阶梯形： $$ \\begin{pmatrix} -1 \u0026 3 \u0026 5 \\\\ -2 \u0026 6 \u0026 10 \\end{pmatrix} \\to \\begin{pmatrix} -1 \u0026 3 \u0026 5 \\\\ 0 \u0026 0 \u0026 0 \\end{pmatrix} $$ 从而得到方程 $ -x_{1}+3x_{2}+5x_{3}=0 $。于是得到两组特解为 $$ \\begin{pmatrix} 3 \\ \\\\ 1 \\ \\\\ 0 \\end{pmatrix}, \\begin{pmatrix} 5 \\ \\\\ 0 \\ \\\\ 1 \\end{pmatrix} $$ (2)\n将 $ A $ 化为简化行阶梯形： $$ \\begin{pmatrix} -1 \u0026 3 \u0026 5 \\\\ -2 \u0026 6 \u0026 7 \\end{pmatrix} \\to \\begin{pmatrix} -1 \u0026 3 \u0026 5 \\\\ 0 \u0026 0 \u0026 -3 \\end{pmatrix} \\to \\begin{pmatrix} -1 \u0026 3 \u0026 0 \\\\ 0 \u0026 0 \u0026 1 \\end{pmatrix} $$ 从而得到方程 $$ \\begin{cases} x_{1}-3x_{2}=0 \\\\ x_{3}=0 \\end{cases} $$ 得到特解为 $$ \\begin{pmatrix} 3 \\ \\\\ 1 \\ \\\\ 0 \\end{pmatrix} $$\nExercise 5 求以下 $ n \\times n $ 循环矩阵的逆矩阵：\n$$ A = \\begin{pmatrix} 1 \u0026 2 \u0026 3 \u0026 \\cdots \u0026 n-1 \u0026 n \\ \\\\ n \u0026 1 \u0026 2 \u0026 \\cdots \u0026 n-2 \u0026 n-1 \\ \\\\ n-1 \u0026 n \u0026 1 \u0026 \\cdots \u0026 n-3 \u0026 n-2 \\ \\\\ \\vdots \u0026 \\vdots \u0026 \\vdots \u0026 \\ddots \u0026 \\vdots \u0026 \\vdots \\ \\\\ 3 \u0026 4 \u0026 5 \u0026 \\cdots \u0026 1 \u0026 2 \\ \\\\ 2 \u0026 3 \u0026 4 \u0026 \\cdots \u0026 n \u0026 1 \\end{pmatrix} $$ 其中 $ A_{ij} = ((j-i) \\bmod n) + 1 $，即每一行都是上一行循环左移一位的结果。\n我们构造增广矩阵 $ [A \\mid I_n] $：\n$$ [A \\mid I_n] = \\left[\\begin{array}{cccccc|cccccc} 1 \u0026 2 \u0026 3 \u0026 \\cdots \u0026 n-1 \u0026 n \u0026 1 \u0026 0 \u0026 0 \u0026 \\cdots \u0026 0 \u0026 0 \\\\ n \u0026 1 \u0026 2 \u0026 \\cdots \u0026 n-2 \u0026 n-1 \u0026 0 \u0026 1 \u0026 0 \u0026 \\cdots \u0026 0 \u0026 0 \\\\ n-1 \u0026 n \u0026 1 \u0026 \\cdots \u0026 n-3 \u0026 n-2 \u0026 0 \u0026 0 \u0026 1 \u0026 \\cdots \u0026 0 \u0026 0 \\\\ \\vdots \u0026 \\vdots \u0026 \\vdots \u0026 \\ddots \u0026 \\vdots \u0026 \\vdots \u0026 \\vdots \u0026 \\vdots \u0026 \\vdots \u0026 \\ddots \u0026 \\vdots \u0026 \\vdots \\\\ 3 \u0026 4 \u0026 5 \u0026 \\cdots \u0026 1 \u0026 2 \u0026 0 \u0026 0 \u0026 0 \u0026 \\cdots \u0026 1 \u0026 0 \\\\ 2 \u0026 3 \u0026 4 \u0026 \\cdots \u0026 n \u0026 1 \u0026 0 \u0026 0 \u0026 0 \u0026 \\cdots \u0026 0 \u0026 1 \\end{array}\\right] $$ 接着对于 $ i = n, n-1, \\ldots, 3, 2 $（从下往上执行），进行 $ R_i \\leftarrow R_i - R_{i-1} $ 操作得到 $$ \\left[\\begin{array}{cccccc|cccccc} 1 \u0026 2 \u0026 3 \u0026 \\cdots \u0026 n-1 \u0026 n \u0026 1 \u0026 0 \u0026 0 \u0026 \\cdots \u0026 0 \u0026 0 \\\\ n-1 \u0026 -1 \u0026 -1 \u0026 \\cdots \u0026 -1 \u0026 -1 \u0026 -1 \u0026 1 \u0026 0 \u0026 \\cdots \u0026 0 \u0026 0 \\\\ -1 \u0026 n-1 \u0026 -1 \u0026 \\cdots \u0026 -1 \u0026 -1 \u0026 0 \u0026 -1 \u0026 1 \u0026 \\cdots \u0026 0 \u0026 0 \\\\ -1 \u0026 -1 \u0026 n-1 \u0026 \\cdots \u0026 -1 \u0026 -1 \u0026 0 \u0026 0 \u0026 -1 \u0026 \\cdots \u0026 0 \u0026 0 \\\\ \\vdots \u0026 \\vdots \u0026 \\vdots \u0026 \\ddots \u0026 \\vdots \u0026 \\vdots \u0026 \\vdots \u0026 \\vdots \u0026 \\vdots \u0026 \\ddots \u0026 \\vdots \u0026 \\vdots \\\\ -1 \u0026 -1 \u0026 -1 \u0026 \\cdots \u0026 -1 \u0026 n-1 \u0026 0 \u0026 0 \u0026 0 \u0026 \\cdots \u0026 -1 \u0026 1 \\end{array}\\right] $$ 观察到第 2 到第 $ n $ 行形成了一个特殊的模式，每行有一个 $ n-1 $ 和 $ (n-1) $ 个 $ -1 $。\n继续进行行化简操作，目标是将左侧矩阵化为单位矩阵 $ I_n $。具体流程为依次消去每一列的其余元素，再回代继续执行消元操作。由于具体的每一步会非常冗长，因此我们这里直接给出最终结果，\n经过消元，增广矩阵化为 $ [I_n \\mid A^{-1}] $，其中 $$ A^{-1} = \\frac{2}{n^2(n+1)} \\begin{pmatrix} a \u0026 b \u0026 1 \u0026 \\cdots \u0026 1 \\ \\\\ 1 \u0026 a \u0026 b \u0026 \\cdots \u0026 1 \\ \\\\ \\vdots \u0026 \\vdots \u0026 \\ddots \u0026 \\ddots \u0026 \\vdots \\ \\\\ b \u0026 1 \u0026 \\cdots \u0026 1 \u0026 a \\end{pmatrix} $$ 参数为 $$ a = -\\frac{n^2 + n - 2}{2}, \\quad b = \\frac{n^2 + n + 2}{2} $$\n","permalink":"https://diefish1024.github.io/posts/class-notes/math1205h-linear-algebra/math1205h-hw8/","summary":"\u003ch2 id=\"exercise-1\"\u003eExercise 1\u003c/h2\u003e\n\u003cp\u003e先证明行阶梯矩阵中主元列的唯一性。由于初等行变换保持了列向量之间的线性关系，因此如果矩阵 $ A $ 的第 $ j $ 列是前 $ j-1 $ 列的线性组合，初等行变换之后也仍然成立。并且一个列为主元列，当且仅当它不能被前面的列线性表示，所以 $ A_{1} $ 和 $ A_{2} $ 中的主元列位置完全相同。\u003c/p\u003e\n\u003cp\u003e接着证明简化行阶梯矩阵的唯一性。对于每个主元列 $ j_{k} $，必须化简成单位向量 $ e_{k} $，满足主元为 $ 1 $，其余元素为 $ 0 $，具有唯一性；对于非主元列，可以表示为前面的列的线性组合，所以为 $ 0 $，也具有唯一性。因此简化行阶梯矩阵具有唯一性。\u003c/p\u003e\n\u003ch2 id=\"exercise-2\"\u003eExercise 2\u003c/h2\u003e\n\u003cp\u003e\u003cstrong\u003e(1)\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e我们通过选择 $ W=\\text{span}\\{ v_{1},v_{2},\\dots,v_{n} \\} $ 中的一个子集，可以构造出 $ W $ 的一个基。我们依次考虑 $ i=1,2,\\dots,n $，如果 $ i=1 $ 或者 $ v_{i} $ 不是前 $ i-1 $ 个向量的线性组合，就选择 $ v_{i} $，这样最终就得到了 $ B=\\{ v_{i_{1}},v_{i_{2}},\\dots,v_{i_{r}} \\} $。\u003c/p\u003e","title":"MATH1205H HW8"},{"content":"Exercise 1 首先初等行变换保持了行向量之间的线性关系，因此保证了矩阵的行空间不会改变，从而它的行秩自然也不便。同时对于列秩，这等价于左乘一个一个初等矩阵，此时显然 $ Ax=0 $ 与 $ EAx=0 $ 等价，说明两者有相同的零空间，因此列秩也不边。\n对于列变换，和行变换完全同理，也可以证明行秩和列秩都不变。\n下面证明矩阵 $ A $ 可以通过初等操作化为 $ \\begin{pmatrix}I \u0026 0 \\\\ 0 \u0026 0\\end{pmatrix} $。设 $ \\mathrm{rank}(A)=r $，那么我们先通过初等行变换将 $ A $ 化成阶梯矩阵的形式，得到 $ \\begin{pmatrix}I_{r} \u0026 R \\\\ 0 \u0026 0\\end{pmatrix} $。再对这个结果进行初等列变换，可以直接消除掉 $ R $ 部分中的所有非零元素，并且不影响其他部分。最终就可以化简为 $ \\begin{pmatrix}I \u0026 0 \\\\ 0 \u0026 0\\end{pmatrix} $。\nExercise 2 我们需要证明通过任意执行步骤的高斯消元得到的行阶梯矩阵，其主元数量是相同的，从而说明矩阵的秩是一个唯一的值，和消元过程无关。\n由于高斯消元本质上就是一系列初等矩阵变换操作，根据第一问我们已经证明了这些操作不会改变矩阵的秩，因此最后得到的阶梯矩阵的秩也不变，最终主元数量就是秩的数量必然相同，等于原来的秩。\nExercise 3 若 $ c=0 $，那么显然有 $$ A\\cdot \\begin{pmatrix} 1 \\\\ 1 \\\\ \\vdots \\\\ 1 \\end{pmatrix} = \\mathbf{0} $$ 说明 $ \\text{rank}(A)\\neq n $，因此 $ A $ 不可逆，矛盾，所以 $ c\\neq 0 $。\n此时 $$ A\\cdot \\begin{pmatrix} 1 \\\\ 1 \\\\ \\vdots \\\\ 1 \\end{pmatrix} = \\begin{pmatrix} c \\\\ c \\\\ \\vdots \\\\ c \\end{pmatrix} $$ 左右同左乘 $ A^{-1} $，得到 $$ A^{-1}\\cdot\\begin{pmatrix} 1 \\\\ 1 \\\\ \\vdots \\\\ 1 \\end{pmatrix} = \\begin{pmatrix} \\frac{1}{c} \\\\ \\frac{1}{c} \\\\ \\vdots \\\\ \\frac{1}{c} \\end{pmatrix} $$ 等价于 $$ \\sum_{j\\in[n]}A^{-1}(i,j) = \\dfrac{1}{c} $$\nExercise 4 我们设 $ A $ 的列向量为 $ a_{1},a_{2},\\dots,a_{n} $，$ C(A)=\\text{span}\\{ a_{1},a_{2},\\dots,a_{n} \\} $ 表示 $ A $ 的列空间，同理 $ C(B)=\\text{span}\\{ b_{1},b_{2},\\dots,b_{n} \\} $ 表示 $ B $ 的列空间，那么 $ C(A+B)=\\text{span}\\{ a_{1}+b_{1},a_{2}+b_{2},\\dots,a_{n}+b_{n} \\} $。\n现在考虑 $ C(A)+C(B) $，定义为 $ C(A) $ 和 $ C(B) $ 中向量之和的集合 $$ C(A)+C(B) = \\{ u+v\\mid u\\in C(A),v\\in C(B) \\} $$ 显然我们可以取 $ u,v $ 为编号相同的列向量，就能得到 $ C(A+B) $，说明 $ C(A+B) $ 是 $ C(A)+C(B) $ 的一个子空间，所以它的维数小于 $ C(A)+C(B) $ 的维数，即 $$ \\text{dim}(C(A+B)) \\leq \\text{dim}(C(A)+C(B)) \u003c \\text{dim}(C(A)) + \\text{dim}(C(B)) $$ 这实际上也就是 $$ \\text{rank}(A+B) \u003c \\text{rank}(A) + \\text{rank}(B) $$\nExercise 5 (a)\n我们对矩阵 $ A $ 施行初等行变换：\n$$ \\begin{align*} \u0026 \\begin{pmatrix} 5 \u0026 2 \u0026 3 \\\\ -4 \u0026 5 \u0026 0 \\\\ 0 \u0026 1 \u0026 -5 \\\\ 3 \u0026 7 \u0026 6 \\end{pmatrix} \\to \\begin{pmatrix} 1 \u0026 2/5 \u0026 3/5 \\\\ -4 \u0026 5 \u0026 0 \\\\ 0 \u0026 1 \u0026 -5 \\\\ 3 \u0026 7 \u0026 6 \\end{pmatrix} \\to \\begin{pmatrix} 1 \u0026 2/5 \u0026 3/5 \\\\ 0 \u0026 33/5 \u0026 12/5 \\\\ 0 \u0026 1 \u0026 -5 \\\\ 0 \u0026 29/5 \u0026 21/5 \\end{pmatrix} \\\\ \\\\ \u0026 \\to \\begin{pmatrix} 1 \u0026 2/5 \u0026 3/5 \\\\ 0 \u0026 1 \u0026 -5 \\\\ 0 \u0026 33/5 \u0026 12/5 \\\\ 0 \u0026 29/5 \u0026 21/5 \\end{pmatrix} \\to \\begin{pmatrix} 1 \u0026 0 \u0026 3 \\\\ 0 \u0026 1 \u0026 -5 \\\\ 0 \u0026 0 \u0026 33 \\\\ 0 \u0026 0 \u0026 30 \\end{pmatrix} \\to \\begin{pmatrix} 1 \u0026 0 \u0026 3 \\\\ 0 \u0026 1 \u0026 -5 \\\\ 0 \u0026 0 \u0026 1 \\\\ 0 \u0026 0 \u0026 30 \\end{pmatrix} \\\\ \\\\ \u0026 \\to \\begin{pmatrix} 1 \u0026 0 \u0026 0 \\\\ 0 \u0026 1 \u0026 0 \\\\ 0 \u0026 0 \u0026 1 \\\\ 0 \u0026 0 \u0026 0 \\end{pmatrix} \\end{align*} $$ 简化行阶梯形矩阵 $ A' $ 有 3 个主元，因此 $$ \\text{rank}(A) = 3 $$ $ A $ 的简化行阶梯形 $ A' $ 为 $$ A' = \\begin{pmatrix} 1 \u0026 0 \u0026 0 \\\\ 0 \u0026 1 \u0026 0 \\\\ 0 \u0026 0 \u0026 1 \\\\ 0 \u0026 0 \u0026 0 \\end{pmatrix} $$\n要找到 $ N(A) $，我们要求解 $ Ax=0 $，这等价于求解 $ A'x=0 $。将 $ A' $ 写回方程组形式： $$ \\begin{cases} 1x_1 + 0x_2 + 0x_3 = 0 \u0026 \\implies x_1 = 0 \\\\ 0x_1 + 1x_2 + 0x_3 = 0 \u0026 \\implies x_2 = 0 \\\\ 0x_1 + 0x_2 + 1x_3 = 0 \u0026 \\implies x_3 = 0 \\\\ 0x_1 + 0x_2 + 0x_3 = 0 \u0026 \\implies 0 = 0 \\end{cases} $$ 解为 $ x_1=0, x_2=0, x_3=0 $。这意味着 $$ N(A) = \\left\\{ \\begin{pmatrix} 0 \\\\ 0 \\\\ 0 \\end{pmatrix} \\right\\} $$ (b)\n我们对矩阵 $ A $ 施行初等行变换：\n$$ \\begin{align*} \u0026 \\begin{pmatrix} 2 \u0026 2 \u0026 0 \u0026 1 \u0026 0 \\\\ 0 \u0026 5 \u0026 1 \u0026 -1 \u0026 1 \\\\ 11 \u0026 -2 \u0026 7 \u0026 1 \u0026 0 \\end{pmatrix} \\to \\begin{pmatrix} 1 \u0026 1 \u0026 0 \u0026 \\frac{1}{2} \u0026 0 \\\\ 0 \u0026 1 \u0026 \\frac{1}{5} \u0026 - \\frac{1}{5} \u0026 \\frac{1}{5} \\\\ 1 \u0026 -\\frac{2}{11} \u0026 \\frac{7}{11} \u0026 \\frac{1}{11} \u0026 0 \\\\ \\end{pmatrix} \\to \\begin{pmatrix} 1 \u0026 1 \u0026 0 \u0026 \\frac{1}{2} \u0026 0 \\\\ 0 \u0026 1 \u0026 \\frac{1}{5} \u0026 - \\frac{1}{5} \u0026 \\frac{1}{5} \\\\ 0 \u0026 -\\frac{13}{11} \u0026 \\frac{7}{11} \u0026 -\\frac{9}{22} \u0026 0 \\\\ \\end{pmatrix} \\\\ \u0026 \\to \\begin{pmatrix} 1 \u0026 1 \u0026 0 \u0026 \\frac{1}{2} \u0026 0 \\\\ 0 \u0026 1 \u0026 \\frac{1}{5} \u0026 - \\frac{1}{5} \u0026 \\frac{1}{5} \\\\ 0 \u0026 1 \u0026 -\\frac{7}{13} \u0026 \\frac{9}{26} \u0026 0 \\\\ \\end{pmatrix} \\to \\begin{pmatrix} 1 \u0026 1 \u0026 0 \u0026 \\frac{1}{2} \u0026 0 \\\\ 0 \u0026 1 \u0026 \\frac{1}{5} \u0026 - \\frac{1}{5} \u0026 \\frac{1}{5} \\\\ 0 \u0026 0 \u0026 -\\frac{48}{65} \u0026 \\frac{71}{130} \u0026 -\\frac{1}{5} \\\\ \\end{pmatrix} \\to \\begin{pmatrix} 1 \u0026 1 \u0026 0 \u0026 \\frac{1}{2} \u0026 0 \\\\ 0 \u0026 1 \u0026 \\frac{1}{5} \u0026 - \\frac{1}{5} \u0026 \\frac{1}{5} \\\\ 0 \u0026 0 \u0026 1 \u0026 -\\frac{71}{96} \u0026 \\frac{13}{48} \\\\ \\end{pmatrix} \\\\ \u0026 \\to \\begin{pmatrix} 1 \u0026 1 \u0026 0 \u0026 \\frac{1}{2} \u0026 0 \\\\ 0 \u0026 1 \u0026 0 \u0026 - \\frac{5}{96} \u0026 \\frac{7}{48} \\\\ 0 \u0026 0 \u0026 1 \u0026 -\\frac{71}{96} \u0026 \\frac{13}{48} \\\\ \\end{pmatrix} \\to \\begin{pmatrix} 1 \u0026 0 \u0026 0 \u0026 \\frac{53}{96} \u0026 -\\frac{7}{48} \\\\ 0 \u0026 1 \u0026 0 \u0026 - \\frac{5}{96} \u0026 \\frac{7}{48} \\\\ 0 \u0026 0 \u0026 1 \u0026 -\\frac{71}{96} \u0026 \\frac{13}{48} \\\\ \\end{pmatrix} \\end{align*} $$ 此为矩阵 $ A $ 的简化行阶梯形 $ A' $。\n简化行阶梯形矩阵 $ A' $ 有 3 个主元，因此 $ A $ 的秩是 $ 3 $。 $$ \\text{rank}(A) = 3 $$ 由上述步骤得到： $$ A' = \\begin{pmatrix} 1 \u0026 0 \u0026 0 \u0026 \\frac{53}{96} \u0026 -\\frac{7}{48} \\\\ 0 \u0026 1 \u0026 0 \u0026 - \\frac{5}{96} \u0026 \\frac{7}{48} \\\\ 0 \u0026 0 \u0026 1 \u0026 -\\frac{71}{96} \u0026 \\frac{13}{48} \\ \\end{pmatrix} $$ 我们要求解 $ Ax=0 $，这等价于求解 $ A'x=0 $。将 $ A' $ 写回方程组形式： $$ \\begin{cases} x_1 = -\\frac{53}{96}x_4 + \\frac{7}{48}x_5 \\\\ x_2 = \\frac{5}{96}x_4 - \\frac{7}{48}x_5 \\\\ x_3 = \\frac{71}{96}x_4 - \\frac{13}{48}x_5 \\end{cases} $$ 解向量 $ x $ 可以写为： $$ x = \\begin{pmatrix} x_1 \\\\ x_2 \\\\ x_3 \\\\ x_4 \\\\ x_5 \\end{pmatrix} = x_4 \\begin{pmatrix} -53/96 \\\\ 5/96 \\\\ 71/96 \\\\ 1 \\\\ 0 \\end{pmatrix} + x_5 \\begin{pmatrix} 7/48 \\\\ -7/48 \\\\ -13/48 \\\\ 0 \\\\ 1 \\end{pmatrix} $$ 零空间 $ N(A) $ 的基是： $$ \\left\\{ \\begin{pmatrix} -53/96 \\\\ 5/96 \\\\ 71/96 \\\\ 1 \\\\ 0 \\end{pmatrix}, \\begin{pmatrix} 7/48 \\\\ -7/48 \\\\ -13/48 \\\\ 0 \\\\ 1 \\end{pmatrix} \\right\\} $$\n(c)\n我们对矩阵 $ A $ 施行初等行变换：\n$$ \\begin{align*} \u0026 \\begin{pmatrix} 1 \u0026 2 \u0026 3 \u0026 4 \\\\ 5 \u0026 6 \u0026 7 \u0026 8 \\\\ 9 \u0026 10 \u0026 11 \u0026 12 \\\\ 13 \u0026 14 \u0026 15 \u0026 16 \\end{pmatrix} \\xrightarrow{\\begin{smallmatrix} R_2 \\to R_2 - 5R_1 \\\\ R_3 \\to R_3 - 9R_1 \\\\ R_4 \\to R_4 - 13R_1 \\end{smallmatrix}} \\begin{pmatrix} 1 \u0026 2 \u0026 3 \u0026 4 \\\\ 0 \u0026 -4 \u0026 -8 \u0026 -12 \\\\ 0 \u0026 -8 \u0026 -16 \u0026 -24 \\\\ 0 \u0026 -12 \u0026 -24 \u0026 -36 \\end{pmatrix} \\\\ \\\\ \u0026 \\xrightarrow{R_2 \\to -\\frac{1}{4}R_2} \\begin{pmatrix} 1 \u0026 2 \u0026 3 \u0026 4 \\\\ 0 \u0026 1 \u0026 2 \u0026 3 \\\\ 0 \u0026 -8 \u0026 -16 \u0026 -24 \\\\ 0 \u0026 -12 \u0026 -24 \u0026 -36 \\end{pmatrix} \\xrightarrow{\\begin{smallmatrix} R_1 \\to R_1 - 2R_2 \\\\ R_3 \\to R_3 + 8R_2 \\\\ R_4 \\to R_4 + 12R_2 \\end{smallmatrix}} \\begin{pmatrix} 1 \u0026 0 \u0026 -1 \u0026 -2 \\\\ 0 \u0026 1 \u0026 2 \u0026 3 \\\\ 0 \u0026 0 \u0026 0 \u0026 0 \\\\ 0 \u0026 0 \u0026 0 \u0026 0 \\end{pmatrix} \\end{align*} $$ 此为矩阵 $ A $ 的简化行阶梯形 $ A' $。\n简化行阶梯形矩阵 $ A' $ 有 2 个主元，因此 $ A $ 的秩是 $ 2 $。 $$ \\text{rank}(A) = 2 $$\n由上述步骤得到： $$ A' = \\begin{pmatrix} 1 \u0026 0 \u0026 -1 \u0026 -2 \\\\ 0 \u0026 1 \u0026 2 \u0026 3 \\\\ 0 \u0026 0 \u0026 0 \u0026 0 \\\\ 0 \u0026 0 \u0026 0 \u0026 0 \\end{pmatrix} $$\n我们要求解 $ Ax=0 $，这等价于求解 $ A'x=0 $。将 $ A' $ 写回方程组形式： $$ \\begin{cases} x_1 - x_3 - 2x_4 = 0 \u0026 \\implies x_1 = x_3 + 2x_4 \\\\ x_2 + 2x_3 + 3x_4 = 0 \u0026 \\implies x_2 = -2x_3 - 3x_4\\ \\end{cases} $$ 解向量 $ x $ 可以写为： $$ x = \\begin{pmatrix} x_1 \\\\ x_2 \\\\ x_3 \\\\ x_4 \\end{pmatrix} = \\begin{pmatrix} x_3 + 2x_4 \\\\ -2x_3 - 3x_4 \\\\ x_3 \\\\ x_4 \\end{pmatrix} = x_3 \\begin{pmatrix} 1 \\\\ -2 \\\\ 1 \\\\ 0 \\end{pmatrix} + x_4 \\begin{pmatrix} 2 \\\\ -3 \\\\ 0 \\\\ 1 \\end{pmatrix} $$ 零空间 $ N(A) $ 的基是： $$ \\left\\{ \\begin{pmatrix} 1 \\\\ -2 \\\\ 1 \\\\ 0 \\end{pmatrix}, \\begin{pmatrix} 2 \\\\ -3 \\\\ 0 \\\\ 1 \\end{pmatrix} \\right\\} $$ 唯一性：\n简化行阶梯形是唯一的。无论通过何种初等行变换序列，任何矩阵的简化行阶梯形都是唯一的。\nExercise 6 (1)\n设 $ r = \\text{column-rank}(A) $。这意味着 $ A $ 的列空间 $ C(A) $ 具有维数 $ r $。因此存在 $ r $ 个线性无关的列向量 $ a_{i_1}, \\dots, a_{i_r} $，它们构成 $ C(A) $ 的一组基。于是令 $ A_{\\text{basis}} = [a_{i_1} \\dots a_{i_r}] $ 是一个 $ m \\times r $ 矩阵。\n由于 $ A $ 的每列 $ a_j $ 都可以表示为这组基的线性组合，即 $ a_j = A_{\\text{basis}} b_j $（其中 $ b_j \\in \\mathbb{R}^r $）。我们将这些向量 $ b_j $ 拼接起来形成一个 $ r \\times n $ 矩阵 $ B = [b_1 \\dots b_n] $。这样，我们就有 $ A = A_{\\text{basis}} B $，即 $ A=[a_{i_1} \\dots a_{i_r}]B $。\n(2)\n根据 (i) 的结果，我们有 $ A = A_{\\text{basis}} B $，其中 $ A_{\\text{basis}} $ 是 $ m \\times r $ 矩阵，$ B $ 是 $ r \\times n $ 矩阵。\n根据提示，我们从行向量的观点来看矩阵乘法，矩阵 $ A $ 的每一行都是矩阵 $ B $ 的行的线性组合。具体来说，如果 $ A $ 的第 $ k $ 行是 $ A_k $，$ A_{\\text{basis}} $ 的第 $ k $ 行是 $ (A_{\\text{basis}})_k $，则 $ A_k = (A_{\\text{basis}})_k B $。这表明 $ A_k $ 位于 $ B $ 的行空间 $ R(B) $ 之内。\n因此，$ A $ 的所有行都位于 $ R(B) $ 中。这意味着 $ A $ 的行空间 $ R(A) $ 是 $ B $ 的行空间 $ R(B) $ 的一个子空间。 所以，$ \\text{dim}(R(A)) \\le \\text{dim}(R(B)) $，即 $ \\text{row-rank}(A) \\le \\text{row-rank}(B) $。由于 $ B $ 是一个 $ r \\times n $ 矩阵，其行空间最多有 $ r $ 个线性无关的行，所以 $ \\text{row-rank}(B) \\le r $，因此 $$ \\text{row-rank}(A) \\le r = \\text{column-rank}(A) $$\n(3)\n对称地，我们直接可以将 $ (2) $ 的结果应用于矩阵 $ A $ 的转置 $ A^T $。矩阵 $ A^T $ 是一个 $ n \\times m $ 矩阵，根据 $ (2) $ 的结论，我们对 $ A^T $ 施加这个结论： $$ \\text{row-rank}(A^T) \\le \\text{column-rank}(A^T) $$ 同时我们又有 $ \\text{row-rank}(A^T) = \\text{column-rank}(A),\\text{column-rank}(A^T) = \\text{row-rank}(A) $，因此可以得到 $$ \\text{column-rank}(A) \\le \\text{row-rank}(A) $$\n","permalink":"https://diefish1024.github.io/posts/class-notes/math1205h-linear-algebra/math1205h-hw7/","summary":"\u003ch2 id=\"exercise-1\"\u003eExercise 1\u003c/h2\u003e\n\u003cp\u003e首先初等行变换保持了行向量之间的线性关系，因此保证了矩阵的行空间不会改变，从而它的行秩自然也不便。同时对于列秩，这等价于左乘一个一个初等矩阵，此时显然 $ Ax=0 $ 与 $ EAx=0 $ 等价，说明两者有相同的零空间，因此列秩也不边。\u003c/p\u003e\n\u003cp\u003e对于列变换，和行变换完全同理，也可以证明行秩和列秩都不变。\u003c/p\u003e\n\u003cp\u003e下面证明矩阵 $ A $ 可以通过初等操作化为 $ \\begin{pmatrix}I \u0026 0 \\\\ 0 \u0026 0\\end{pmatrix} $。设 $ \\mathrm{rank}(A)=r $，那么我们先通过初等行变换将 $ A $ 化成阶梯矩阵的形式，得到 $ \\begin{pmatrix}I_{r} \u0026 R \\\\ 0 \u0026 0\\end{pmatrix} $。再对这个结果进行初等列变换，可以直接消除掉 $ R $ 部分中的所有非零元素，并且不影响其他部分。最终就可以化简为 $ \\begin{pmatrix}I \u0026 0 \\\\ 0 \u0026 0\\end{pmatrix} $。\u003c/p\u003e\n\u003ch2 id=\"exercise-2\"\u003eExercise 2\u003c/h2\u003e\n\u003cp\u003e我们需要证明通过任意执行步骤的高斯消元得到的行阶梯矩阵，其主元数量是相同的，从而说明矩阵的秩是一个唯一的值，和消元过程无关。\u003c/p\u003e\n\u003cp\u003e由于高斯消元本质上就是一系列初等矩阵变换操作，根据第一问我们已经证明了这些操作不会改变矩阵的秩，因此最后得到的阶梯矩阵的秩也不变，最终主元数量就是秩的数量必然相同，等于原来的秩。\u003c/p\u003e\n\u003ch2 id=\"exercise-3\"\u003eExercise 3\u003c/h2\u003e\n\u003cp\u003e若 $ c=0 $，那么显然有\n$$ \n\nA\\cdot \\begin{pmatrix}\n1 \\\\ 1 \\\\ \\vdots \\\\ 1\n\\end{pmatrix} = \\mathbf{0}\n\n $$\n说明 $ \\text{rank}(A)\\neq n $，因此 $ A $ 不可逆，矛盾，所以 $ c\\neq 0 $。\u003c/p\u003e","title":"MATH1205H HW7"},{"content":"题目\nProblem 1 (1)\n设每次合成仙丹为一次尝试。 在每次尝试中：\n合成成功：概率为 $ p $。 产生 $ 1 $ 份仙丹。 消耗 $ 2 $ 份仙果。 合成失败：概率为 $ 1-p $。 产生 $ 0 $ 份仙丹。 消耗 $ 1 $ 份仙果。 我们关注的是平均每份仙果可以得到多少仙丹。这可以理解为仙丹产出的期望值与仙果消耗的期望值之比。\n每次尝试中，获得的仙丹数量的期望值 $ \\mathbb{E}[\\text{仙丹}] $ 为： $$ \\mathbb{E}[\\text{仙丹}] = 1 \\cdot p + 0 \\cdot (1-p) = p $$\n每次尝试中，消耗的仙果数量的期望值 $ \\mathbb{E}[\\text{仙果}] $ 为： $$ \\mathbb{E}[\\text{仙果}] = 2 \\cdot p + 1 \\cdot (1-p) = 2p + 1 - p = p + 1 $$\n那么，平均每份仙果可以得到的仙丹数量为： $$ \\frac{\\mathbb{E}[\\text{仙丹}]}{\\mathbb{E}[\\text{仙果}]}= \\frac{p}{p+1} $$\n因此平均一份仙果可以得到 $ p / (p+1) $ 份仙丹。\n(2)\n商品价格 $ P_{现}=2\\,\\text{元/份} $，初始资金 $ C_{0}=1000\\,\\text{元} $。设现在购买 $ x $ 份商品，则 $ 0 \\le x \\le \\dfrac{C_0}{P_{现}} = 1000 / 2 = 500 $。 当前交易后，剩余现金为 $ 1000 - 2x $ 元，持有商品 $ x $ 份。\nCase 1：为了最大化最终金钱，最优策略是在一周后将所有商品卖出。共有两种情况，概率均为 $ \\dfrac{1}{2} $：\n一周后商品价格涨至 $ 4 $ 元/份。 卖出 $ x $ 份商品，获得 $ 4x $ 元。最终金钱为 $ 1000+2x $ 元。 一周后商品价格跌至 $ 1 $ 元/份。卖出 $ x $ 份商品，获得 $ x $ 元。最终金钱为 $ 1000 - x $ 元。 最终金钱的期望值 $ \\mathbb{E}[\\text{金钱}] $ 为： $$ \\mathbb{E}[\\text{金钱}] = \\frac{1}{2}(1000 + 2x) + \\frac{1}{2}(1000 - x) = \\frac{1}{2}(2000 + x) = 1000 + \\frac{x}{2} $$ 为了最大化 $ \\mathbb{E}[\\text{金钱}] $，我们需要最大化 $ x $。根据 $ 0 \\le x \\le 500 $， $ x $ 的最大值为 $ 500 $。\n因此，策略为：\n现在：购买 $ 500 $ 份商品。 一周后：无论商品价格涨跌，卖出所有 $ 500 $ 份商品。 若价格为 $ 4 $ 元/份，最终得到 $ 500 \\times 4 = 2000 $ 元。 若价格为 $ 1 $ 元/份，最终得到 $ 500 \\times 1 = 500 $ 元。 此时期望金钱为 $ 1000 + 500/2 = 1250 $ 元。 Case 2：为了最大化最终商品数量，最优策略是在一周后将所有现金和商品都转换为商品。共有两种情况，概率均为 $ \\dfrac{1}{2} $：\n一周后商品价格涨至 $ 4 $ 元/份 (概率 $ 1/2 $)。此时拥有 $ (1000 - 2x) $ 现金和 $ x $ 份商品。卖出 $ x $ 份商品，获得 $ 4x $ 元。总现金为 $ (1000 - 2x) + 4x = 1000 + 2x $ 元。用所有现金购买商品，可购买 $ (1000 + 2x) / 4 = 250 + x/2 $ 份商品。 一周后商品价格跌至 $ 1 $ 元/份 (概率 $ 1/2 $)。此时拥有 $ (1000 - 2x) $ 现金和 $ x $ 份商品。卖出 $ x $ 份商品，获得 $ x $ 元。总现金为 $ (1000 - 2x) + x = 1000 - x $ 元。用所有现金购买商品，可购买 $ (1000 - x) / 1 = 1000 - x $ 份商品。 最终商品数量的期望值 $ \\mathbb{E}[\\text{商品}] $ 为： $$ \\mathbb{E}[\\text{商品}] = \\frac{1}{2}(250 + \\frac{x}{2}) + \\frac{1}{2}(1000 - x) = \\frac{1}{2}(1250 - \\frac{x}{2}) = 625 - \\frac{x}{4} $$ 为了最大化 $ \\mathbb{E}[\\text{商品}] $，我们需要最小化 $ x $。根据 $ 0 \\le x \\le 500 $， $ x $ 的最小值为 $ 0 $。\n因此，策略为：\n现在：不购买任何商品。此时现金为 $ 1000 $ 元，持有 $ 0 $ 份商品。 一周后：无论商品价格涨跌，用所有现金购买商品。 若价格为 $ 4 $ 元/份，用 $ 1000 $ 元购买 $ 1000 / 4 = 250 $ 份商品。 若价格为 $ 1 $ 元/份，用 $ 1000 $ 元购买 $ 1000 / 1 = 1000 $ 份商品。 此时期望商品数量为 $ 625 - 0/4 = 625 $ 份。 (3)\n马尔可夫不等式：我们需要对于每个 $ a\\in \\mathbb{R}_{\u003e0} $ 找出对应的随机变量 $ X $ 满足 $$ \\mathbb{P}[X\\geq a] = \\dfrac{\\mathbb{E}[X]}{a} $$ 直接取 $ X=a $ 即可，显然成立。\n切比雪夫不等式：同样直接取 $ X=a $。那么 $ \\mathbb{P}[\\left| X-\\mathbb{E}[X] \\right|\\geq a]=0 $，同时 $ \\mathrm{Var}(X)=0 $（因为 $ X $ 为常数），因此可以取到等号。或者更直接地由于这是马尔可夫不等式的直接推论，两者取等条件相同。\nProblem 2 冒泡排序一次操作减少一个逆序对，因此实际上我们需要分析的是一个随机排列中逆序对数量 $ X $。需要分别求出 $ \\mathbb{E}[X] $ 和 $ \\mathrm{Var}[X] $。\n(1)\n求解 $ \\mathbb{E}[X] $。我们直接定义指示变量 $ \\mathbb{I}_{i,j}=[i\u003c j\\land a_{i}\u003ea_{j}] $，表示 $ (a_{i},a_{j}) $ 构成一个逆序对。于是 $$ X = \\sum_{1\\leq i\u003c j\\leq n}\\mathbb{I}_{i,j} $$ 根据期望的可加性 $$ \\mathbb{E}[X] = E\\left[ \\sum_{1\\leq i\u003c j\\leq n}\\mathbb{I}_{i,j} \\right] = \\sum_{1\\leq i\u003c j\\leq n}\\mathbb{E}[\\mathbb{I}_{i,j}] $$ 对于单个指示变量的期望，$ \\mathbb{E}[\\mathbb{I}_{i,j}]=\\mathbb{P}(a_{i}\u003ea_{j}) $。由于排列随即均匀，对于任意一个数它出现在位置 $ i $ 和 $ j $ 的概率是相同的，所以 $ \\mathbb{P}(a_{i}\u003ea_{j})= \\frac{1}{2} $，所以 $$ \\mathbb{E}[X] = \\sum_{1\\leq i\u003c j\\leq n} \\dfrac{1}{2} = \\dfrac{n(n-1)}{4} $$\n(2)\n求解 $ \\mathrm{Var}[X] $。由于 $ \\mathrm{Var}[X]=\\mathbb{E}[X^{2}]-(\\mathbb{E}[X])^{2} $，因此我们求出 $ \\mathbb{E}[X^{2}] $ 即可。同理 $ (1) $，我们得到 $$ X^{2} = \\left( \\sum_{1\\leq i\u003c j\\leq n}\\mathbb{I}_{i,j} \\right)^{2} = \\sum_{1\\leq i\u003c j\\leq n}\\mathbb{I}_{i,j} + \\sum_{(i,j)\\neq(k,l)}\\mathbb{I}_{i,j}\\mathbb{I}_{k,l} $$ 根据期望的可加性，我们直接考虑计算 $ \\mathbb{E}[\\mathbb{I}_{i,j}\\mathbb{I}_{k,l}] $。我们发现每对不同的 $ (i,j),(k,l) $ 会被重复计算两次，因此我们令 $ i\u003c k $，最后计数乘以 $ 2 $ 即可。分类讨论：\n若 $ (i,j),(k,l) $ 没有重叠，那么共 $ \\binom{ n }{ 4 }\\times 3 $ 种选择，对期望贡献为 $ \\frac{3\\binom{ n }{ 4 }}{4} $。 若 $ \\{ i,j \\}\\cap \\{ k,l \\}\\neq \\emptyset $，分别考虑 $ 3 $ 种重合方式，每种有 $ \\binom{ n }{ 3 } $ 种选择，发现对期望的贡献为 $$ \\left( \\dfrac{1}{3} + \\dfrac{1}{6} + \\dfrac{1}{3} \\right) \\cdot \\binom{ n }{ 3 } = \\dfrac{5}{6}\\binom{ n }{ 3 } $$ 综上，得到 $$ \\mathbb{E}[\\mathbb{I}_{i,j}\\mathbb{I}_{k,l}] = 2\\left[ \\dfrac{3}{4}\\binom{ n }{ 4 } + \\dfrac{5}{6}\\binom{ n }{ 3 } \\right] = \\dfrac{3}{2}\\binom{ n }{ 4 } + \\dfrac{5}{3}\\binom{ n }{ 3 } $$ 得到 $$ \\mathbb{E}[X^{2}] = \\dfrac{n(n-1)}{4} + \\dfrac{3}{2}\\cdot \\dfrac{n(n-1)(n-2)(n-3)}{24} + \\dfrac{5}{3}\\cdot \\dfrac{n(n-1)(n-2)}{6} = \\dfrac{n(n-1)(9n^{2}-5n+10)}{144} $$ 从而 $$ \\mathrm{Var}[X] = \\mathbb{E}[X^{2}] - (\\mathbb{E}[X])^{2} = \\dfrac{n(n-1)(9n^{2}-5n+10)}{144} - \\dfrac{n^{2}(n-1)^{2}}{16} = \\dfrac{n(n-1)(2n+5)}{72} $$ Problem 3 (1)\n要证明 $ \\mathbb{E}[\\hat{m}]=m $，我们只需要证明 $ \\mathbb{E}[2^{X}-1]=m $，即 $ \\mathbb{E}[2^{X}]=m+1 $。我们设 $ X_{k} $ 为接受第 $ k $ 个输入后计数器的值，定义 $ T_{k}=\\mathbb{E}[2^{X_{k}}] $，只需要证明 $ T_{m}=m+1 $ 即可。现在我们求 $ T_{k} $ 的递推式。\n考虑在第 $ k $ 个输入时计数器的变化，$ k-1 $ 个输入之后计数器的值为 $ X_{k-1} $，那么第 $ k $ 个输入到达时：\n以 $ \\mathbb{P}=2^{-X_{k-1}} $ 的概率变为 $ X_{k}=X_{k-1}+1 $。 以 $ \\mathbb{P}=1-2^{-X_{k-1}} $ 的概率还是 $ X_{k}=X_{k-1} $。 那么我们得到对于给定 $ X_{k-1}=x $，有 $$ \\mathbb{E}[2^{X_{k}}\\mid X_{k-1}=x] = 2^{-x}\\cdot 2^{x+1} + (1-2^{-x})\\cdot 2^{x} = 1 + 2^{x} $$ 这就得到了 $$ T_{k} = \\mathbb{E}[2^{X_{k}}] = \\mathbb{E}[1+2^{X_{k-1}}] = T_{k-1} + 1 $$ 再带入 $ T_{1}=2 $，显然就得到了 $ T_{m}=m+1 $，于是我们就证明了输出的 $ \\hat{m} $ 是无偏的。\n(2)\n我们先考虑求出 $ \\mathbb{E}[\\hat{m}^{2}]=\\mathbb{E}[(2^{X}-1)^{2}] $，核心在于求出 $ \\mathbb{E}[2^{2X}] $。类似 $ (1) $，令 $ S_{k}=\\mathbb{E}[2^{2X_{k}}] $，考虑求出其递推式。\n对于 $ X_{k-1}=x $，有 $$ \\mathbb{E}[2^{2X_{k}}\\mid X_{k-1}=x] = 2^{-x}\\cdot 2^{2x+2} + (1-2^{-x})\\cdot 2^{2x} = 3\\cdot 2^{x} + 2^{2x} $$ 从而 $$ S_{k} = S_{k-1} + 3T_{k-1} = S_{k-1} + 3k $$ 带入 $ S_{1}=4 $，得到 $$ \\mathbb{E}[2^{2X_{m}}] = S_{m} = \\dfrac{3}{2}m^{2} + \\dfrac{3}{2}m + 1 $$ 于是 $$ \\mathbb{E}[\\hat{m}^{2}] = \\mathbb{E}[(2^{X}-1)^{2}] = S_{m} - 2T_{m} + 1 = \\dfrac{3}{2}m^{2} - \\dfrac{1}{2}m $$ 以及 $$ \\mathrm{Var}[\\hat{m}] = \\mathbb{E}[\\hat{m}^{2}]-\\mathbb{E}[\\hat{m}]^{2} = \\dfrac{1}{2}m^{2} - \\dfrac{1}{2}m \\leq \\dfrac{m^{2}}{2} $$ 带入切比雪夫不等式，得到 $$ \\mathbb{P}[\\left| \\hat{m}-m \\right| \\geq \\varepsilon m] \\leq \\dfrac{\\mathrm{Var}[\\hat{m}]}{(\\varepsilon m)^{2}} = \\dfrac{\\dfrac{1}{2}m^{2} - \\dfrac{1}{2}m}{(\\varepsilon m)^{2}} \u003c \\dfrac{1}{2\\varepsilon^{2}} $$ 因此上界为 $ \\dfrac{1}{2\\varepsilon^{2}} $。\n(3)\n显然 $ \\mathbb{E}[\\hat{m}^{*}]=m $，我们需要求出 $ \\mathrm{Var}[\\hat{m}^{*}] $。根据方差的性质，我们有 $$ \\begin{align*} \\mathrm{Var}[\\hat{m}^{*}] \u0026 = \\mathrm{Var}\\left[ \\dfrac{1}{t}\\sum_{i=1}^{t}\\hat{m}_{i} \\right] \\\\ \u0026 = \\dfrac{1}{t^{2}}\\mathrm{Var}\\left[ \\sum_{i=1}^{t} \\hat{m}_{i} \\right] \\\\ \u0026 = \\dfrac{1}{t^{2}}\\sum_{i=1}^{t} \\mathrm{Var}[\\hat{m}_{i}] \\\\ \u0026 = \\dfrac{1}{t}\\mathrm{Var}[\\hat{m}] \\end{align*} $$ 重新带入切比雪夫不等式，就得到了 $$ \\mathbb{P}[\\left| \\hat{m}^{*}-m \\right| \\geq \\varepsilon m] \\leq \\dfrac{\\mathrm{Var}[\\hat{m}^{*}]}{(\\varepsilon m)^{2}} \u003c \\dfrac{1}{2t\\cdot\\varepsilon^{2}} $$ (4)\n取 $ \\varepsilon=0.1 $，我们需要 $$ \\dfrac{1}{2\\times 0.1^{2}\\times t} \u003c 1\\% \\implies t \u003e 5000 $$ 至少 $ 5000 $ 次实验。\n存储需要 $ 5000\\times\\lceil \\log_{2}\\lceil \\log_{2}m \\rceil \\rceil $ 比特。\nProblem 4 (1)\n根据提示，我们假设在 $ H_{0}=H^{*} $ 时取到最大值，定义 $ \\mathcal{P}' $ 为包含 $ H^{*} $ 作为子图。由于 $ H^{*}\\subseteq H $，因此若 $ G $ 满足 $ \\mathcal{P} $，那么一定满足 $ \\mathcal{P}' $，这就得到了 $$ \\mathbb{P}[G \\text{ satisfies } \\mathcal{P}] \\leq \\mathbb{P}[G \\text{ satisfies } \\mathcal{P}'] $$ 我们接着考虑 $ G $ 中包含的和 $ H^{*} $ 同构的图的数量 $ X $，显然有 $ \\mathbb{P}[G\\text{ satisfies }\\mathcal{P}']=\\mathbb{P}[X\\geq 1] $。\n计算 $ X $ 的期望，有 $$ \\mathbb{E} [X] = \\binom{ n }{ \\left| V(H^{*}) \\right| } p(n)^{\\left| E(H^{*}) \\right| } $$ 带入 $ p(n)\u003c n^{-1 / r(H)} $，以及 $ r(H)= \\frac{\\left| E(H^{*}) \\right|}{\\left| V(H^{*}) \\right|} $，得到 $$ p(n)^{\\left| E(H^{*}) \\right| } \u003c n^{- \\left| E(H^{*}) \\right|/{r(H)} } = n^{-\\left| V(H^{*}) \\right| } $$ 因此 $$ \\mathbb{E}[X] \u003c \\binom{ n }{ \\left| V(H^{*}) \\right| } \\cdot n^{-\\left| V(H^{*}) \\right| } = \\dfrac{n^{\\underline{\\left| V(H^{*}) \\right| }}}{\\left| V(H^{*}) \\right| !}\\cdot n^{-\\left| V(H^{*}) \\right| } \u003c \\dfrac{1}{\\left| V(H^{*}) \\right| !} $$ 在 $ n\\to \\infty $ 时显然也有 $ \\dfrac{1}{\\left| V(H^{*}) \\right|!}\\to 0 $。\n于是根据马尔可夫不等式，得到 $$ \\mathbb{P}[G\\text{ satisfies }\\mathcal{P}']=\\mathbb{P}[X\\geq 1] \\leq \\mathbb{E}[X] \\to 0 $$ 从而得到了 $$ \\mathbb{P}[G\\text{ satisfices }\\mathcal{P}] \\to 0 $$\n(2)\n首先同理第一问，计算 $ X $ 的期望 $$ \\mathbb{E}[X] = \\sum_{i=1}^{m} \\mathbb{E}[X_{i}] = m\\cdot p(n)^{\\left| E(H) \\right| } $$ 接着由于需要计算方差，我们考虑 $ \\mathbb{E}[X^{2}] $，有 $$ \\mathbb{E}[X^{2}] = \\mathbb{E}\\left[ \\left( \\sum_{i=1}^{m}X_{i} \\right)^{2} \\right] = \\sum_{i=1}^{m} \\sum_{j=1}^{m} \\mathbb{E}[X_{i}X_{j}] $$ 并且其中 $ X_{i}X_{j}=1 $ 代表 $ G\\text{ contains }S_{i}\\cup S_{j} $，因此 $ \\mathbb{E}[X_{i}X_{j}]=\\mathbb{P}[G\\text{ contains }S_{i}\\cup S_{j}] $。\n带入方差表达式得到 $$ \\begin{align*} \\text{Var}[X] \u0026 = \\mathbb{E}[X^{2}] - (\\mathbb{E}[X])^{2} \\\\ \u0026 = \\sum_{i,j\\in[m_{n}]}\\mathbb{P}[G\\text{ contains }S_{i}\\cup S_{j}] - (\\mathbb{E}[X])^{2} \\\\ \u0026 \u003c \\sum_{i,j\\in[m_{n}]}\\mathbb{P}[G\\text{ contains }S_{i}\\cup S_{j}] \\\\ \u0026 \u003c \\sum_{i,j\\in[m_{n}]:E(S_{i}\\cap S_{j})\\neq \\emptyset} \\mathbb{P}[G\\text{ contains }S_{i}\\cup S_{j}] \\end{align*} $$ (3)\n首先根据容斥原理，$ S_{i}\\cup S_{j} $ 包含 $ 2E(H)-e $ 条边。那么根据定义，我们就有 $$ \\mathbb{P}[G\\text{ contains }S_{i}\\cup S_{j}] = p(n)^{2\\left| E(H) \\right| - e} = \\Theta(p(n)^{2\\left| E(H) \\right| - e}) $$ 并且 $ S_{i}\\cup S_{j} $ 有 $ 2\\left| V(H) \\right|-v $ 个点，因此从 $ n $ 个点中分配 $ S_{i}\\cup S_{j} $ 中的点，有 $ \\binom{ n }{ 2\\left| V(H) \\right|-v } $ 种方案，再在这些点中分配 $ S_{i}\\cap S_{j} $ 中的点以及分别 $ S_{i},S_{j} $ 的点，合计方案数为 $$ \\begin{align*} \u0026 \\binom{ n }{ 2\\left| V(H) \\right| - v } \\cdot \\binom{ 2\\left| V(H) \\right| - v }{ v } \\cdot \\binom{ 2\\left| V(H) \\right| - 2v }{ \\left| V(H) \\right| - v } \\\\ \u0026 \u003c n^{2\\left| V(H) \\right| - v}\\cdot \\dfrac{(2\\left| V(H) \\right| -v)^{\\underline{v}}\\cdot (2\\left| V(H)-2v \\right|) ^{\\underline{\\left| V(H) \\right| - v}}}{(2\\left| V(H)-v \\right| )!\\cdot v!\\cdot (\\left| V(H)-v \\right| )!} \\\\ \u0026 = \\mathcal{O}(n^{2\\left| V(H) \\right| - v}) \\end{align*} $$\n(4)\n我们只需证明 $ \\text{Var}[X]=o((\\mathbb{E}[X])^{2}) $ 即可。\n首先，注意到 $ \\mathbb{E}[X] = \\Theta(n^{|V(H)|} p(n)^{|E(H)|}) $。\n对于方差，利用 $ (2) $ 的结论，当 $ i \\neq j $ 且 $ E(S_i \\cap S_j) = \\emptyset $ 时，$ X_i $ 和 $ X_j $ 独立，因此 $$ \\text{Var}[X] \\leq \\mathbb{E}[X] + \\sum_{i,j \\in [m_n]: E(S_i \\cap S_j) \\neq \\emptyset} \\mathbb{P}[G \\text{ contains } S_i \\cup S_j] $$ 根据 $ (3) $ 的结论，对于每个固定的 $ (v, e) $（其中 $ v $ 和 $ e $ 分别是 $ S_i \\cap S_j $ 的点数和边数，且 $ 1 \\leq e \\leq 2|E(H)|-1 $），有\n满足条件的 $ (i,j) $ 对数为 $ \\mathcal{O}(n^{2|V(H)|-v}) $ 每对的概率为 $ \\Theta(p(n)^{2|E(H)|-e}) $ 因此 $$ \\begin{align*} \\text{Var}[X] \u0026\\leq \\mathbb{E}[X] + \\sum_{v,e} \\mathcal{O}(n^{2|V(H)|-v} p(n)^{2|E(H)|-e}) \\\\ \u0026= \\mathbb{E}[X] + \\sum_{v,e} \\mathcal{O}\\left((n^{|V(H)|} p(n)^{|E(H)|})^2 \\cdot n^{-v} p(n)^{-e}\\right) \\\\ \\end{align*} $$\n对于 $ H $ 的任意子图 $ H_0 $，若 $ |V(H_0)| = v $，$ |E(H_0)| = e $，则根据 $ r(H) $ 的定义 $$ \\frac{e}{v} \\leq r(H) \\quad \\Rightarrow \\quad e \\leq r(H) \\cdot v $$ 当 $ p(n) \\gg n^{-1/r(H)} $ 时，存在 $ \\epsilon \u003e 0 $ 使得 $ p(n) \u003e n^{-1/r(H)+\\epsilon} $（当 $ n $ 充分大）。因此 $$ n^{-v} p(n)^{-e} \u003c n^{-v} \\cdot n^{e(1/r(H)-\\epsilon)} = n^{e/r(H) - v - e\\epsilon} $$\n由于 $ e \\leq r(H) \\cdot v $，即 $ e/r(H) \\leq v $，所以 $ e/r(H) - v - e\\epsilon \\leq -e\\epsilon \u003c 0 $。因此 $ n^{-v} p(n)^{-e} \\to 0 $。\n由于 $ (v,e) $ 的可能取值是有限的（$ \\mathcal{O}(1) $ 种），我们得到 $$ \\text{Var}[X] = o((\\mathbb{E}[X])^2) $$ 从而由切比雪夫不等式 $$ \\mathbb{P}[X=0] \\leq \\mathbb{P}[|X - \\mathbb{E}[X]| \\geq \\mathbb{E}[X]] \\leq \\frac{\\text{Var}[X]}{(\\mathbb{E}[X])^2} \\to 0 $$ 因此 $$ \\mathbb{P}[X \\geq 1] = 1 - \\mathbb{P}[X=0] \\xrightarrow{n \\to \\infty} 1 $$ 这就完成了证明。\n","permalink":"https://diefish1024.github.io/posts/class-notes/math2701-probability-theory/math2701-hw2/","summary":"\u003cp\u003e\u003ca href=\"https://notes.sjtu.edu.cn/s/b5m_-jXDU\"\u003e题目\u003c/a\u003e\u003c/p\u003e\n\u003ch2 id=\"problem-1\"\u003eProblem 1\u003c/h2\u003e\n\u003cp\u003e\u003cstrong\u003e(1)\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e设每次合成仙丹为一次尝试。 在每次尝试中：\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003e合成成功\u003c/strong\u003e：概率为 $ p $。\n\u003cul\u003e\n\u003cli\u003e产生 $ 1 $ 份仙丹。\u003c/li\u003e\n\u003cli\u003e消耗 $ 2 $ 份仙果。\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e合成失败\u003c/strong\u003e：概率为 $ 1-p $。\n\u003cul\u003e\n\u003cli\u003e产生 $ 0 $ 份仙丹。\u003c/li\u003e\n\u003cli\u003e消耗 $ 1 $ 份仙果。\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e我们关注的是平均每份仙果可以得到多少仙丹。这可以理解为仙丹产出的期望值与仙果消耗的期望值之比。\u003c/p\u003e\n\u003cp\u003e每次尝试中，获得的仙丹数量的期望值 $ \\mathbb{E}[\\text{仙丹}] $ 为：\n$$ \n\\mathbb{E}[\\text{仙丹}] = 1 \\cdot p + 0 \\cdot (1-p) = p\n $$\u003c/p\u003e\n\u003cp\u003e每次尝试中，消耗的仙果数量的期望值 $ \\mathbb{E}[\\text{仙果}] $ 为：\n$$ \n\\mathbb{E}[\\text{仙果}] = 2 \\cdot p + 1 \\cdot (1-p) = 2p + 1 - p = p + 1\n $$\u003c/p\u003e","title":"MATH2701 HW2"},{"content":"Exercise 1 Let $ A $ be an $ n \\times n $ matrix. Prove the equivalence between:\n(i) There is a $ B $ with $ AB = I $.\n(ii) There is a $ C $ with $ CA = I $.\nProof:\nWe show both conditions are equivalent to $ \\operatorname{rank}(A) = n $.\nIf there exists $ B $ with $ AB = I $, then $ A $ is surjective, so $ \\operatorname{rank}(A) = n $.\nIf there exists $ C $ with $ CA = I $, then $ A $ is injective, so $ \\operatorname{rank}(A) = n $.\nConversely, if $ \\operatorname{rank}(A) = n $, then $ A $ is invertible (as $ A $ is square), so both $ AB = I $ and $ CA = I $ hold with $ B = C = A^{-1} $.\nExercise 2 Give an $ m \\times n $ matrix $ A $ such that:\nThere is a $ B $ with $ AB = I $.\nThere is no $ C $ with $ CA = I $.\nSolution:\nWe need $ m \u003e n $ and $ \\operatorname{rank}(A) = n $.\nConsider $ A = \\begin{pmatrix} 1 \u0026 0 \\\\ 0 \u0026 1 \\\\ 0 \u0026 0 \\end{pmatrix} $, a $ 3 \\times 2 $ matrix with $ \\operatorname{rank}(A) = 2 $.\nSince $ \\operatorname{rank}(A) = 2 = n $, the columns are linearly independent, so $ A $ has a right inverse $ B = \\begin{pmatrix} 1 \u0026 0 \u0026 0 \\\\ 0 \u0026 1 \u0026 0 \\end{pmatrix} $ with $ AB = I_2 $.\nHowever, $ \\operatorname{rank}(A) = 2 \u003c 3 = m $, so $ A $ is not surjective, hence has no left inverse. If $ CA = I_3 $ existed, then $ \\operatorname{rank}(I_3) = 3 \\leq \\operatorname{rank}(A) = 2 $, a contradiction.\nExercise 3 Find all solutions of the following systems of linear equations, where $ x_1, x_2, x_3, x_4 $ are variables and $ \\lambda $ is a parameter.\n(1) $$ \\begin{cases} 2x_1 - x_2 + x_3 + x_4 = 1, \\\\ x_1 + 2x_2 - x_3 + 4x_4 = 2, \\\\ x_1 + 7x_2 - 4x_3 + 11x_4 = \\lambda. \\end{cases} $$\n(2) $$ \\begin{cases} \\lambda x_1 + x_2 + x_3 + x_4 = 1, \\\\ x_1 + \\lambda x_2 + x_3 + x_4 = \\lambda, \\\\ x_1 + x_2 + \\lambda x_3 + x_4 = \\lambda^2, \\\\ x_1 + x_2 + x_3 + \\lambda x_4 = \\lambda^3. \\end{cases} $$\nSolution:\n(1) Form the augmented matrix and perform row reduction: $$ \\left( \\begin{array}{cccc|c} 2 \u0026 -1 \u0026 1 \u0026 1 \u0026 1 \\\\ 1 \u0026 2 \u0026 -1 \u0026 4 \u0026 2 \\\\ 1 \u0026 7 \u0026 -4 \u0026 11 \u0026 \\lambda \\end{array} \\right) $$ After Gaussian elimination, we obtain: $$ \\left( \\begin{array}{cccc|c} 1 \u0026 0 \u0026 1 \u0026 6 \u0026 4 \\\\ 0 \u0026 1 \u0026 -1 \u0026 -1 \u0026 -1 \\\\ 0 \u0026 0 \u0026 0 \u0026 0 \u0026 \\lambda-5 \\end{array} \\right) $$\nIf $ \\lambda \\neq 5 $: no solution. If $ \\lambda = 5 $: infinitely many solutions with two free variables. Setting $ x_3 = s, x_4 = t $, we get: $$ x_1 = 4-s-6t, \\quad x_2 = -1+s+t, \\quad x_3 = s, \\quad x_4 = t. $$\n(2) Form the augmented matrix with parameter $ \\lambda $:\n$$ \\left( \\begin{array}{cccc|c} \\lambda \u0026 1 \u0026 1 \u0026 1 \u0026 1 \\\\ 1 \u0026 \\lambda \u0026 1 \u0026 1 \u0026 \\lambda \\\\ 1 \u0026 1 \u0026 \\lambda \u0026 1 \u0026 \\lambda^2 \\\\ 1 \u0026 1 \u0026 1 \u0026 \\lambda \u0026 \\lambda^3 \\end{array} \\right) $$ Case 1: $ \\lambda = 1 $\nThe system becomes $ x_1 + x_2 + x_3 + x_4 = 1 $ (all four equations are identical). Setting $ x_2 = s, x_3 = t, x_4 = u $ as free variables: $$ x_1 = 1 - s - t - u, \\quad x_2 = s, \\quad x_3 = t, \\quad x_4 = u. $$\nCase 2: $ \\lambda = -3 $\nPerforming row operations leads to an inconsistent system. Specifically, after reduction we obtain a row of the form $ (0, 0, 0, 0 \\mid c) $ with $ c \\neq 0 $. No solution exists.\nCase 3: $ \\lambda \\notin {-3, 1} $\nSubtracting appropriate multiples of rows, we can reduce the system. Notice that if all $ x_i $ are equal, say $ x_i = c $, then:\nFirst equation: $ (\\lambda + 3)c = 1 $ Second equation: $ (\\lambda + 3)c = \\lambda $ Third equation: $ (\\lambda + 3)c = \\lambda^2 $ Fourth equation: $ (\\lambda + 3)c = \\lambda^3 $ For consistency, we need $ 1 = \\lambda = \\lambda^2 = \\lambda^3 $, which is impossible for $ \\lambda \\neq 1 $. However, the right-hand sides satisfy $ 1 + \\lambda + \\lambda^2 + \\lambda^3 = b $.\nAfter complete row reduction, we find that the system has rank 4 (full rank) when $ \\lambda \\neq -3, 1 $, giving a unique solution: $$ x_1 = x_2 = x_3 = x_4 = \\frac{1 + \\lambda + \\lambda^2 + \\lambda^3}{\\lambda + 3} = c. $$ This can be verified by substitution into the original equations.\nExercise 4 Use Gaussian elimination to calculate an upper triangular system $ Ux = c $ for the linear system $ Ax = b $. Write down the elementary matrix in each step and point out the failures you meet.\n(i) $ A = \\begin{pmatrix} 0 \u0026 1 \u0026 2 \\\\ 3 \u0026 4 \u0026 5 \\\\ 6 \u0026 7 \u0026 8 \\end{pmatrix} $ and $ b = \\begin{pmatrix} 0 \\\\ 1 \\\\ 1 \\end{pmatrix} $.\n(ii) $ A = \\begin{pmatrix} 1 \u0026 4 \u0026 7 \\\\ 2 \u0026 5 \u0026 8 \\\\ 3 \u0026 6 \u0026 9 \\end{pmatrix} $ and $ b = 0 $.\n(iii) $ A = \\begin{pmatrix} 0 \u0026 1 \u0026 2 \\\\ 7 \u0026 8 \u0026 3 \\\\ 6 \u0026 5 \u0026 4 \\end{pmatrix} $ and $ b = 0 $.\nSolution:\n(i) $ A = \\begin{pmatrix} 0 \u0026 1 \u0026 2 \\\\ 3 \u0026 4 \u0026 5 \\\\ 6 \u0026 7 \u0026 8 \\end{pmatrix} $, $ b = \\begin{pmatrix} 0 \\\\ 1 \\\\ 1 \\end{pmatrix} $\nFailure: The first pivot position is zero, so we need a row swap.\nStep 1: Swap rows 1 and 2. $$ P_{12} = \\begin{pmatrix} 0 \u0026 1 \u0026 0 \\\\ 1 \u0026 0 \u0026 0 \\\\ 0 \u0026 0 \u0026 1 \\end{pmatrix} $$\nAfter applying: $ \\begin{pmatrix} 3 \u0026 4 \u0026 5 \\\\ 0 \u0026 1 \u0026 2 \\\\ 6 \u0026 7 \u0026 8 \\end{pmatrix} $, $ b = \\begin{pmatrix} 1 \\\\ 0 \\\\ 1 \\end{pmatrix} $\nStep 2: Eliminate position (3,1) using $ E_{31} $. $$ E_{31} = \\begin{pmatrix} 1 \u0026 0 \u0026 0 \\\\ 0 \u0026 1 \u0026 0 \\\\ -2 \u0026 0 \u0026 1 \\end{pmatrix} $$\nAfter applying: $ \\begin{pmatrix} 3 \u0026 4 \u0026 5 \\\\ 0 \u0026 1 \u0026 2 \\\\ 0 \u0026 -1 \u0026 -2 \\end{pmatrix} $, $ b = \\begin{pmatrix} 1 \\\\ 0 \\\\ -1 \\end{pmatrix} $\nStep 3: Eliminate position (3,2) using $ E_{32} $. $$ E_{32} = \\begin{pmatrix} 1 \u0026 0 \u0026 0 \\\\ 0 \u0026 1 \u0026 0 \\\\ 0 \u0026 1 \u0026 1 \\end{pmatrix} $$\nAfter applying: $ U = \\begin{pmatrix} 3 \u0026 4 \u0026 5 \\\\ 0 \u0026 1 \u0026 2 \\\\ 0 \u0026 0 \u0026 0 \\end{pmatrix} $, $ c = \\begin{pmatrix} 1 \\\\ 0 \\\\ -1 \\end{pmatrix} $\nFailure: The system is inconsistent since the last row gives $ 0 = -1 $.\n(ii) $ A = \\begin{pmatrix} 1 \u0026 4 \u0026 7 \\\\ 2 \u0026 5 \u0026 8 \\\\ 3 \u0026 6 \u0026 9 \\end{pmatrix} $, $ b = 0 $\nStep 1: Eliminate position (2,1) using $ E_{21} $. $$ E_{21} = \\begin{pmatrix} 1 \u0026 0 \u0026 0 \\\\ -2 \u0026 1 \u0026 0 \\\\ 0 \u0026 0 \u0026 1 \\end{pmatrix} $$\nAfter applying: $ \\begin{pmatrix} 1 \u0026 4 \u0026 7 \\\\ 0 \u0026 -3 \u0026 -6 \\\\ 3 \u0026 6 \u0026 9 \\end{pmatrix} $, $ b = 0 $\nStep 2: Eliminate position (3,1) using $ E_{31} $. $$ E_{31} = \\begin{pmatrix} 1 \u0026 0 \u0026 0 \\\\ 0 \u0026 1 \u0026 0 \\\\ -3 \u0026 0 \u0026 1 \\end{pmatrix} $$\nAfter applying: $ \\begin{pmatrix} 1 \u0026 4 \u0026 7 \\\\ 0 \u0026 -3 \u0026 -6 \\\\ 0 \u0026 -6 \u0026 -12 \\end{pmatrix} $, $ b = 0 $\nStep 3: Eliminate position (3,2) using $ E_{32} $. $$ E_{32} = \\begin{pmatrix} 1 \u0026 0 \u0026 0 \\\\ 0 \u0026 1 \u0026 0 \\\\ 0 \u0026 -2 \u0026 1 \\end{pmatrix} $$\nAfter applying: $ U = \\begin{pmatrix} 1 \u0026 4 \u0026 7 \\\\ 0 \u0026 -3 \u0026 -6 \\\\ 0 \u0026 0 \u0026 0 \\end{pmatrix} $, $ c = 0 $\nFailure: The third row is zero, indicating the matrix is singular. The system has infinitely many solutions (with one free variable).\n(iii) $ A = \\begin{pmatrix} 0 \u0026 1 \u0026 2 \\\\ 7 \u0026 8 \u0026 3 \\\\ 6 \u0026 5 \u0026 4 \\end{pmatrix} $, $ b = 0 $\nFailure: The first pivot position is zero, requiring a row swap.\nStep 1: Swap rows 1 and 2. $$ P_{12} = \\begin{pmatrix} 0 \u0026 1 \u0026 0 \\\\ 1 \u0026 0 \u0026 0 \\\\ 0 \u0026 0 \u0026 1 \\end{pmatrix} $$\nAfter applying: $ \\begin{pmatrix} 7 \u0026 8 \u0026 3 \\\\ 0 \u0026 1 \u0026 2 \\\\ 6 \u0026 5 \u0026 4 \\end{pmatrix} $, $ b = 0 $\nStep 2: Eliminate position (3,1) using $ E_{31} $. $$ E_{31} = \\begin{pmatrix} 1 \u0026 0 \u0026 0 \\\\ 0 \u0026 1 \u0026 0 \\\\ -\\frac{6}{7} \u0026 0 \u0026 1 \\end{pmatrix} $$\nAfter applying: $ \\begin{pmatrix} 7 \u0026 8 \u0026 3 \\\\ 0 \u0026 1 \u0026 2 \\\\ 0 \u0026 -\\frac{13}{7} \u0026 \\frac{10}{7} \\end{pmatrix} $, $ b = 0 $\nStep 3: Eliminate position (3,2) using $ E_{32} $. $$ E_{32} = \\begin{pmatrix} 1 \u0026 0 \u0026 0 \\\\ 0 \u0026 1 \u0026 0 \\\\ 0 \u0026 \\frac{13}{7} \u0026 1 \\end{pmatrix} $$\nAfter applying: $ U = \\begin{pmatrix} 7 \u0026 8 \u0026 3 \\\\ 0 \u0026 1 \u0026 2 \\\\ 0 \u0026 0 \u0026 \\frac{36}{7} \\end{pmatrix} $, $ c = 0 $\nThe system has a unique solution (the trivial solution $ x = 0 $).\nExercise 5 Use Gauss-Jordan to calculate the inverse of the following matrices.\n(i) $ \\begin{pmatrix} 16 \u0026 15 \u0026 14 \u0026 13 \\\\ 5 \u0026 4 \u0026 3 \u0026 12 \\\\ 6 \u0026 1 \u0026 2 \u0026 11 \\\\ 7 \u0026 8 \u0026 9 \u0026 10 \\end{pmatrix} $.\n(ii) $ \\begin{pmatrix} 1 \u0026 1 \u0026 10 \u0026 1 \\\\ 1 \u0026 10 \u0026 1 \u0026 1 \\\\ 1 \u0026 1 \u0026 1 \u0026 10 \\\\ 10 \u0026 1 \u0026 1 \u0026 1 \\end{pmatrix} $.\n(iii) $ aa^T - I_n $ with $ a = \\begin{pmatrix} 1 \\\\ \\vdots \\\\ 1 \\end{pmatrix} \\in \\mathbb{R}^n $.\nSolution:\n(i) For $ A = \\begin{pmatrix} 16 \u0026 15 \u0026 14 \u0026 13 \\\\ 5 \u0026 4 \u0026 3 \u0026 12 \\\\ 6 \u0026 1 \u0026 2 \u0026 11 \\\\ 7 \u0026 8 \u0026 9 \u0026 10 \\end{pmatrix} $:\nForm the augmented matrix $ [A | I_4] $ and apply row operations to reduce $ A $ to $ I_4 $.\nAfter Gauss-Jordan elimination, we obtain:\n$$ A^{-1} = \\begin{pmatrix} \\dfrac{83}{690} \u0026 - \\dfrac{2}{15} \u0026 \\dfrac{1}{6} \u0026 - \\dfrac{62}{345} \\\\ \\dfrac{34}{345} \u0026 \\dfrac{11}{30} \u0026 - \\dfrac{1}{3} \u0026 - \\dfrac{139}{690} \\\\ - \\dfrac{17}{138} \u0026 - \\dfrac{1}{3} \u0026 \\dfrac{1}{6} \u0026 \\dfrac{26}{69} \\\\ - \\dfrac{6}{115} \u0026 \\dfrac{1}{10} \u0026 0 \u0026 \\dfrac{11}{230} \\end{pmatrix} $$ (ii) For $ A = \\begin{pmatrix} 1 \u0026 1 \u0026 10 \u0026 1 \\\\ 1 \u0026 10 \u0026 1 \u0026 1 \\\\ 1 \u0026 1 \u0026 1 \u0026 10 \\\\ 10 \u0026 1 \u0026 1 \u0026 1 \\end{pmatrix} $:\nForm $ [A | I_4] $ and reduce. After row operations:\n$$ A^{-1} = \\frac{1}{117} \\begin{pmatrix} -1 \u0026 -1 \u0026 -1 \u0026 12 \\\\ -1 \u0026 12 \u0026 -1 \u0026 -1 \\\\ 12 \u0026 -1 \u0026 -1 \u0026 -1 \\\\ -1 \u0026 -1 \u0026 12 \u0026 -1 \\end{pmatrix} $$ (iii) For $ M = aa^T - I_n $ where $ a = \\begin{pmatrix} 1 \\\\ \\vdots \\\\ 1 \\end{pmatrix} \\in \\mathbb{R}^n $:\nForm the augmented matrix $ [M | I_n] $ and apply row operations to reduce $ M $ to $ I_n $.\nAfter Gauss-Jordan elimination, we obtain: $$ M^{-1} = \\frac{1}{n-1} aa^T - I_n $$ Explicitly, $ M^{-1} $ has diagonal entries $ \\frac{1}{n-1}-1 $ and off-diagonal entries $ \\frac{1}{n-1} $.\n","permalink":"https://diefish1024.github.io/posts/class-notes/math1205h-linear-algebra/math1205h-hw6/","summary":"\u003ch2 id=\"exercise-1\"\u003eExercise 1\u003c/h2\u003e\n\u003cblockquote\u003e\n\u003cp\u003eLet $ A $ be an $ n \\times n $ matrix. Prove the equivalence between:\u003c/p\u003e\n\u003cp\u003e(i) There is a $ B $ with $ AB = I $.\u003c/p\u003e\n\u003cp\u003e(ii) There is a $ C $ with $ CA = I $.\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e\u003cstrong\u003eProof\u003c/strong\u003e:\u003c/p\u003e\n\u003cp\u003eWe show both conditions are equivalent to $ \\operatorname{rank}(A) = n $.\u003c/p\u003e\n\u003cp\u003eIf there exists $ B $ with $ AB = I $, then $ A $ is surjective, so $ \\operatorname{rank}(A) = n $.\u003c/p\u003e","title":"MATH1205H HW6"},{"content":"Problem 1 证明存在常数 $ c \u003e 1 $ 和 $ N \u003e 0 $，使得当 $ n \u003e N $ 时， $ [n] $ 上树的同构类数量至少为 $ c^n $ 。\n证\n我们需要的同构类的数量则可以看成 $ n $ 个点无标号的树的数量。需要证明这个数量增长的足够快。\n首先根据 Cayley 公式，$ n $ 个点的有标号的树的数量为 $ n^{n-2} $。显然所有无标号的树的数量大于 $ \\dfrac{n^{n-2}}{n!} $，因为这里直接假设所有点都是对称的，但是实际上一棵有标号的树并不会对应 $ n! $ 颗无标号的树。我们直接取 $ c=2 $，于是就只需要证明存在 $ N\u003e0 $ 满足在 $ n\u003eN $ 时有 $$ \\dfrac{n^{n-2}}{n!} \u003e 2^{n} $$ 我们使用斯特林公式，在 $ n $ 足够大时有 $$ n! \\approx \\sqrt{ 2\\pi n }\\left( \\dfrac{n}{e} \\right)^{n} $$ 带入下界，得到 $$ \\dfrac{n^{n-2}}{n!} \\approx \\dfrac{e^{n}}{\\sqrt{ 2\\pi}\\cdot n^{5 / 2}} $$ 所以只需要证明在 $ n\u003eN $ 时有 $$ (\\sqrt{ 2\\pi })^{1 / n} \\cdot n^{5 / 2n} \u003c \\dfrac{e}{2} $$ 对于左式，显然有 $$ \\lim_{ n \\to \\infty } [(\\sqrt{ 2\\pi })^{1 / n} \\cdot n^{5 / 2n}] = 1 \u003c \\dfrac{e}{2} $$ 根据极限的定义，我们总能找到一个 $ N $ 满足条件。因此得证！\nProblem 2 假设 $ G $ 是 $ [n] $ 上的一个图，且 $ G \\cong \\overline{G} $ 。证明如果 $ n = 4k + 1 $ （其中 $ k $ 是某个整数），则存在一个度为 $ 2k $ 的顶点。 对于哪些 $ n $ 值，存在一个 $ [n] $ 上的图 $ G $ 使得 $ G \\cong \\overline{G} $ 成立？证明你的答案。 (1)\n我们需要证明一个无向图和它的补图同构时，如果 $ n=4k+1 $，那么存在度数为 $ \\frac{n-1}{2} $ 的顶点。\n首先我们设 $ G=(V,E) $。$ G \\cong \\overline{G} $ 说明对于任意 $ v\\in V $，均存在 $ u\\in V $ 满足 $ \\text{deg}(v) = (n-1)-\\text{deg}(u) $（补图中所有点的度数组成的序列和原来相同）。这说明对于任意一个度数 $ d $，均存在 $ (n-1)-d $ 与之对应。\n假设不存在 $ d= \\frac{n-1}{2} $，那么我们就能把所有点按照度数两两配对成度数为 $ (d,n-1-d) $ 的对（因为 $ d\\neq n-1-d $）。然而由于 $ n $ 是奇数，必然有一个点无法配对，因此矛盾。所以必然存在度数为 $ \\frac{n-1}{2} $ 的点。\n(2)\n首先必须要满足 $ G $ 和 $ \\overline{G} $ 的边数相等，因此 $$ \\left| E \\right| = \\binom{ n }{ 2 } - \\left| E \\right| $$ 得到 $ \\left| E \\right|= \\dfrac{n(n-1)}{4} $，从而有 $ n=4k $ 或 $ n=4k+1 $。\n接着我们考虑用更形式化的方式描述 $ G \\cong \\overline{G} $。这等价于存在一个 $ n $ 的置换 $ \\varphi:[n]\\to[n] $ 满足对于所有 $ (u,v)\\in E $，那么 $ (\\varphi(u),\\varphi(v))\\not\\in E $。\n我们现在分别对 $ n=4k $ 和 $ n=4k+1 $ 两种情况都构造出对应的 $ G $ ，证明只要 $ n\\equiv 0,1\\pmod 4 $，就存在对应的 $ G $。\nCase 1：若 $ n\\equiv 0\\pmod 4 $。我们取 $ \\varphi[n]=(2,3,\\dots,n,1) $，即 $ \\varphi(k)=k+1\\pmod n $。由于 $ n $ 为偶数，所以我们将所有点按照 $ 1,\\dots,n $ 编号，可以将所有的点按照编号分成奇数和偶数两组，显然在这种构造下，令 $ G $ 包含所有两端点编号为奇数的边，比如 $ (u,v) $，必然有 $ \\varphi(u,v)\\not\\in E $。\n除此之外还需要包含一半的两端编号奇偶不同的边。若 $ i $ 为奇数，$ j $ 为偶数，我们考虑边 $ (i,j) $ 和所有端点编号之差（$ \\text{mod }n $）相同的边，显然对于任意 $ u\\in[n] $，都能找到对应的 $ v\\equiv u+(i-j)\\pmod n $ 使得 $ (u,v) $ 为这样的一条边，所以我们不妨设所有的这些边为 $ (1,j_{1}),(2,j_{2}),\\dots ,(n,j_{n}) $，并且这些边按照 $ \\varphi $ 的调用关系形成了一个长度为 $ n $ 的环。所以我们直接在这个环上间隔地取边加入到 $ G $ 中，就构造出了正确的边集，具体而言，取 $ (2k+1,j_{2k+1}) $。对于所有的环，都用这样的方式取出一半的边加入到 $ G $，最终得到的边集 $$ E = \\{ (u,v)\\mid u\\equiv v\\equiv 1\\pmod n \\} \\cup \\{ (u,(u+t)\\text{ mod }n)\\mid u \\in [n],t \\in \\{1,3,\\dots,n-1 \\} \\} $$ 容易验证这时 $ \\varphi(E)\\cap E=\\emptyset $ 并且 $ \\varphi(E)\\cup E=\\binom{[n] }{ 2 } $。\nCase 2：若 $ n\\equiv 1\\pmod 4 $。设 $ n = 4k + 1 $。将顶点集标记为 $ \\{0, 1, \\dots, 4k-1, \\infty\\} $。定义置换 $ \\varphi $ 如下： $ \\varphi(\\infty) = \\infty $，且对于 $ i = 0, 1, \\dots, 4k-1 $， $ \\varphi(i) = (i + 1) \\mod 4k $。\n该置换 $ \\varphi $ 在边集上的作用将所有可能的边根据端点编号的差值划分为不同的组，每个组的大小均为偶数。具体而言：\n与 $ \\infty $ 相连的边 $ \\{\\infty, i\\} $（$ i = 0, \\dots, 4k-1 $）形成一个为大小 $ 4k $（偶数）的组。 其余边 $ \\{i, j\\} $（$ i, j \\in \\{0, \\dots, 4k-1\\} $， $ i \\neq j $）的形成的组大小也均为偶数（取决于差异 $ d = |i - j| \\mod 4k $，但均为偶数）。 对于每个组（视为 $ \\varphi $ 作用下的环），选择交替的半数边加入 （即同一组中相邻边一在 $ G $ 中，一不在，确保与 $ \\varphi(G) = \\overline{G} $ 一致）。由于总数为偶数，此选择无矛盾，且确保 $ E \\cup \\varphi(E) = \\binom{[n]}{2} $ 且 $ E \\cap \\varphi(E) = \\emptyset $，从而 $ G \\cong \\overline{G} $。\n此构造证明了当 $ n \\equiv 1 \\pmod{4} $ 时，存在满足条件的图 $ G $。\nProblem 3 在一个连通图 $ G $ 中，如果存在不止一条最长路径，证明任意两条最长路径都共享一个共同顶点。\n证\n假设有两条不重合的最长路径，端点分别为 $ (s,t),(s',t') $，路径长度为 $ l $。设 $ (s,t) $ 上的顶点 $ a $ 和 $ (s',t') $ 上的顶点 $ b $ 满足 $ (a,b) $ 的最短路径 $ S $ 不属于 $ (s,t) $ 和 $ (s',t') $。我们设 $ (s,a) $ 的长度为 $ d_{1} $，$ (b,t') $ 的长度为 $ d_{2} $。\n因此我们可以以此构造出 $ 4 $ 条路径：\n$ s\\to a\\to b\\to t' $：长度为 $ d_{1}+\\left| S \\right|+d_{2} $。 $ s\\to a\\to b\\to s' $：长度为 $ d_{1}+\\left| S \\right|+l-d_{2} $。 $ t\\to a\\to b\\to t' $：长度为 $ l-d_{1}+\\left| S \\right|+d_{2} $。 $ t\\to a\\to b\\to s' $：长度为 $ l-d_{1}+\\left| S \\right|+l-d_{2} $。 这 $ 4 $ 条路径长度之和为 $ 4l+4\\left| S \\right| $，说明其平均长度为 $ l+\\left| S \\right|\u003el $，其中肯定至少有一条长度大于 $ l $ 的路径，这与 $ l $ 是最长路径矛盾！\n说明不存在不重合的最长路径。\nProblem 4 (Bonus) 证明或反驳：在一个连通图中，所有最长路径（如果多于一条）都共享一个共同顶点。\n反例\n我们考虑构造一个图满足，对于图中任意一个点都存在一条最长路径不经过这个点，这样所有最长路径的交集就是空集，可以作为一个反例。\n考虑这样一个图，最长路径长度为 $ 9 $，并且总共 $ 12 $ 个顶点，任意去掉一个点，都还存在经过 $ 10 $ 个点的最长路径，符合我们的构造，这就得到了一个反例。\n","permalink":"https://diefish1024.github.io/posts/class-notes/cs0901-combinatorics/cs0901-hw4/","summary":"\u003ch2 id=\"problem-1\"\u003eProblem 1\u003c/h2\u003e\n\u003cp\u003e证明存在常数 $ c \u003e 1 $ 和 $ N \u003e 0 $，使得当 $ n \u003e N $ 时， $ [n] $ 上树的同构类数量至少为 $ c^n $ 。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e证\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e我们需要的同构类的数量则可以看成 $ n $ 个点无标号的树的数量。需要证明这个数量增长的足够快。\u003c/p\u003e\n\u003cp\u003e首先根据 Cayley 公式，$ n $ 个点的有标号的树的数量为 $ n^{n-2} $。显然所有无标号的树的数量大于 $ \\dfrac{n^{n-2}}{n!} $，因为这里直接假设所有点都是对称的，但是实际上一棵有标号的树并不会对应 $ n! $ 颗无标号的树。我们直接取 $ c=2 $，于是就只需要证明存在 $ N\u003e0 $ 满足在 $ n\u003eN $ 时有\n$$ \n\n\\dfrac{n^{n-2}}{n!} \u003e 2^{n}\n\n $$\n我们使用斯特林公式，在 $ n $ 足够大时有\n$$ \n\nn! \\approx \\sqrt{ 2\\pi n }\\left( \\dfrac{n}{e} \\right)^{n}\n\n $$\n带入下界，得到\n$$ \n\n\\dfrac{n^{n-2}}{n!} \\approx \\dfrac{e^{n}}{\\sqrt{ 2\\pi}\\cdot n^{5 / 2}}\n\n $$\n所以只需要证明在 $ n\u003eN $ 时有\n$$ \n\n(\\sqrt{ 2\\pi })^{1 / n} \\cdot n^{5 / 2n} \u003c \\dfrac{e}{2}\n\n $$\n对于左式，显然有\n$$ \n\n\\lim_{ n \\to \\infty } [(\\sqrt{ 2\\pi })^{1 / n} \\cdot n^{5 / 2n}] = 1 \u003c \\dfrac{e}{2}\n\n $$\n根据极限的定义，我们总能找到一个 $ N $ 满足条件。因此得证！\u003c/p\u003e","title":"CS0901 HW4"},{"content":"Exercise 1 Let $ S \\subseteq V $ be a subset of vectors in a vector space $ V $. A finite subset $ S' \\subseteq S $ is maximally linearly independent in $ S $ if\n$ S' $ is linearly independent, and\nfor any $ v \\in S \\setminus S' $ the set $ S' \\cup \\{v\\} $ is not linearly independent.\nProve that:\n(i) $ S' $ is maximally linearly independent in $ S $ if and only if $ S' $ (viewed as a sequence of vectors) is a basis for $ \\operatorname{span}(S) $.\n(ii) A finite subset $ S \\subseteq V $ constitutes a basis for $ V $ if and only if $ S $ is maximally linearly independent in $ V $.\n(ii) Every finite $ S $ must have a maximally linearly independent $ S' \\subseteq S $ (without assuming that $ V $ is finite dimensional).\nProof:\n(i)\nIf $ S' $ is maximally linearly independent in $ S $, then it is linearly independent. For any $ v \\in S \\setminus S' $, $ S' \\cup \\{v\\} $ is dependent, so $ v \\in \\operatorname{span}(S') $. Thus, $ \\operatorname{span}(S) = \\operatorname{span}(S') $, making $ S' $ a basis for $ \\operatorname{span}(S) $.\nConversely, if $ S' $ is a basis for $ \\operatorname{span}(S) $, it is linearly independent. For any $ v \\in S \\setminus S' $, $ v \\in \\operatorname{span}(S) = \\operatorname{span}(S') $, so $ S' \\cup \\{v\\} $ is dependent.\n(ii)\nIf $ S $ is a finite basis for $ V $, it is linearly independent and spans $ V $. For any $ v \\in V \\setminus S $, $ v \\in \\operatorname{span}(S) $, so $ S \\cup \\{v\\} $ is dependent, making $ S $ maximally linearly independent in $ V $.\nConversely, if $ S $ is maximally linearly independent in $ V $, it is linearly independent. For any $ v \\in V \\setminus S $, $ S \\cup \\{v\\} $ is dependent, so $ v \\in \\operatorname{span}(S) $, hence $ \\operatorname{span}(S) = V $, making $ S $ a basis.\n(iii)\nStart with the empty set, which is linearly independent. Iteratively add vectors from $ S $ that preserve independence until no more can be added. The resulting finite subset is maximally linearly independent in $ S $.\nExercise 2 Let $ u_1, \\ldots, u_n, v, w \\in V $ be linearly dependent. Assume that $ u_1, \\ldots, u_n $ are linearly independent. Then one of the following holds.\n(i) $ v $ is a linear combination of $ u_1, \\ldots, u_n $.\n(ii) $ w $ is a linear combination of $ u_1, \\ldots, u_n $.\n(iii) $ u_1, \\ldots, u_n, v $ are all linear combinations of $ u_1, \\ldots, u_n, w $, and vice versa.\nSince $ \\{u_1, \\ldots, u_n, v, w\\} $ is dependent, there exist scalars not all zero such that $ \\sum a_i u_i + b v + c w = 0 $. If $ b = c = 0 $, this contradicts the independence of the $ u_i $. Thus, $ b \\neq 0 $ or $ c \\neq 0 $ (or both).\nIf $ b \\neq 0 $ and $ c = 0 $, then $ v = -\\frac{1}{b} \\sum a_i u_i $, so (i) holds. If $ b = 0 $ and $ c \\neq 0 $, then $ w = -\\frac{1}{c} \\sum a_i u_i $, so (ii) holds. If $ b \\neq 0 $ and $ c \\neq 0 $, then $ v = -\\frac{1}{b} (\\sum a_i u_i + c w) $ and $ w = -\\frac{1}{c} (\\sum a_i u_i + b v) $, so $ \\operatorname{span}\\{u_1, \\ldots, u_n, v\\} = \\operatorname{span}\\{u_1, \\ldots, u_n, w\\} $, and (iii) holds. Exercise 3 Given $ v_1 = \\begin{pmatrix} 1 \\\\ 1 \\\\ 0 \\\\ 1 \\end{pmatrix}, \\quad v_2 = \\begin{pmatrix} 1 \\\\ 3 \\\\ 0 \\\\ 2 \\end{pmatrix}, \\quad v_3 = \\begin{pmatrix} 2 \\\\ 3 \\\\ 2 \\\\ 1 \\end{pmatrix}, \\quad v_4 = \\begin{pmatrix} -1 \\\\ 1 \\\\ 0 \\\\ 0 \\end{pmatrix}, $\nfind the vector that is not a linear combination of the rest.\nThe vector $ v_3 $ is not a linear combination of the rest, as $ \\operatorname{span}\\{v_1, v_2, v_4\\} $ lies in the subspace where the third coordinate is zero, but $ v_3 $ has third coordinate 2.\nExercise 4 Let $ V $ be finite-dimensional. Under what condition the basis of $ V $ is unique?\nThe basis is unique if and only if $ \\dim V = 0 $, i.e., $ V = \\{0\\} $, where the unique basis is the empty set. For $ \\dim V \\geq 1 $, there are infinitely many bases.\nExercise 5 Consider the vector space $ \\mathbb{R}^4 $. Construct a basis containing the following two vectors.\n$ (1, 1, 0, 1), \\ (10, 7, 2, 3). $ One such basis is $ \\{(1,1,0,1), (10,7,2,3), (0,0,1,0), (0,0,0,1)\\} $.\nExercise 6 Let $ V $ be a finite dimensional vector space. Let $ W $ be a subspace of $ V $. Prove that $ W \\subsetneq V \\iff \\dim(W) \u003c \\dim(V) $.\nHere, $ W \\subsetneq V $ means that $ W $ is a proper subset of $ V $, i.e., $ W \\subseteq V $ but $ W \\neq V $.\nIf $ \\dim W \u003c \\dim V $, then $ W \\neq V $, as subspaces of equal dimension coincide.\nConversely, if $ W \\subsetneq V $, suppose $ \\dim W = \\dim V $. Then extending a basis of $ W $ to $ V $ would require no additional vectors, implying $ W = V $, a contradiction. Thus, $ \\dim W \u003c \\dim V $.\nExercise 7 Let $ A $ be an $ m \\times n $ matrix with $ m \u003c n $.\n(i) Prove that the column vectors of $ A $ are linearly dependent.\n(ii) Using (i) to show that for every $ b \\in \\mathbb{R}^m $ the system of linear equations $ Ax = b $ either has no solution or has infinitely many solutions.\n(iii) Prove that the column rank of $ A $ is $ m $ if and only if for every $ b \\in \\mathbb{R}^m $ the system $ Ax = b $ has infinitely many solutions.\n(i)\nThe $ n $ columns are vectors in $ \\mathbb{R}^m $ with $ n \u003e m $, so they are linearly dependent.\n(ii)\nBy (i), $ \\dim \\ker A \\geq 1 $. The solution set to $ Ax = b $ is either empty (no solution) or an affine subspace of dimension $ \\dim \\ker A \\geq 1 $ (infinitely many solutions).\n(iii)\nIf column rank is $ m $, then $ \\operatorname{span} $ of columns is $ \\mathbb{R}^m $, so $ Ax = b $ is always consistent. By (ii), it has infinitely many solutions.\nConversely, if always infinitely many solutions, then always consistent, so column space is $ \\mathbb{R}^m $, hence column rank $ m $.\nExercise 8 Let $ A $ be an $ m \\times n $ matrix. Prove that there is an $ n \\times m $ matrix $ B $ such that $ BA = I $ if and only if the row rank of $ A $ is $ n $.\nThe equation $ BA = I_n $ means $ A $ has a left inverse, equivalent to $ A $ being injective (full column rank), i.e., rank $ n $. Since row rank equals column rank, this is equivalent to row rank $ n $.\n","permalink":"https://diefish1024.github.io/posts/class-notes/math1205h-linear-algebra/math1205h-hw5/","summary":"\u003ch2 id=\"exercise-1\"\u003eExercise 1\u003c/h2\u003e\n\u003cblockquote\u003e\n\u003cp\u003eLet $ S \\subseteq V $ be a subset of vectors in a vector space $ V $. A finite subset $ S' \\subseteq S $ is maximally linearly independent in $ S $ if\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e$ S' $ is linearly independent, and\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003efor any $ v \\in S \\setminus S' $ the set $ S' \\cup \\{v\\} $ is not linearly independent.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eProve that:\u003c/p\u003e\n\u003cp\u003e(i) $ S' $ is maximally linearly independent in $ S $ if and only if $ S' $ (viewed as a sequence of vectors) is a basis for $ \\operatorname{span}(S) $.\u003c/p\u003e","title":"MATH1205H HW5"},{"content":"Exercise 1 Give a basis for the vector space $ M_{m\\times n}(\\mathbb{R}) $ consisting of all $ m \\times n $ matrices.\nA basis consists of the matrices $ E_{ij} $ for $ 1 \\leq i \\leq m $ and $ 1 \\leq j \\leq n $, where $ E_{ij} $ has a 1 in the $ (i,j) $-th position and 0 elsewhere.\nExercise 2 Give a basis for $ V = \\mathbb{R}^+ = \\{x \\mid x \\in \\mathbb{R} \\text{ with } x \u003e 0\\} $ with $ x \\oplus x' = x \\times x' $ and $ c \\otimes x = x^c $.\nThis is a one-dimensional vector space. A basis is $ \\{e\\} $, where $ e $ is the base of the natural logarithm, since any $ x \u003e 0 $ can be written as $ (\\ln x) \\otimes e = e^{\\ln x} = x $, and the \u0026ldquo;zero\u0026rdquo; element is 1.\nExercise 3 Is there a vector space $ V $ such that\n(i) $ |V| \u003e 1 $, i.e., $ V \\neq \\{0\\} $, and\n(ii) $ |V| $ is finite, i.e., it contains only finitely many vectors?\nNo such vector space exists over $ \\mathbb{R} $. If $ V $ contains a nonzero vector $ v $, then the scalars multiples $ \\{c v \\mid c \\in \\mathbb{R}\\} $ form an infinite set, contradicting the finiteness.\nExercise 4 Find the largest possible number of linearly independent vectors among\n$ v_1 = \\begin{pmatrix} 1 \\\\ -1 \\\\ 0 \\\\ 0 \\end{pmatrix}, \\quad v_2 = \\begin{pmatrix} 1 \\\\ 0 \\\\ -1 \\\\ 0 \\end{pmatrix}, \\quad v_3 = \\begin{pmatrix} 1 \\\\ 0 \\\\ 0 \\\\ -1 \\end{pmatrix}, \\quad v_4 = \\begin{pmatrix} 0 \\\\ 1 \\\\ -1 \\\\ 0 \\end{pmatrix}, \\quad v_5 = \\begin{pmatrix} 0 \\\\ 1 \\\\ 0 \\\\ -1 \\end{pmatrix}, \\quad v_6 = \\begin{pmatrix} 0 \\\\ 0 \\\\ 1 \\\\ -1 \\end{pmatrix}. $ These vectors lie in the three-dimensional subspace of $ \\mathbb{R}^4 $ where the sum of components is zero. Thus, the largest number of linearly independent vectors is 3.\nExercise 5 Find the null space $ N(A) $ and column space $ C(A) $ for the following matrices and give a basis for $ N(A) $ and $ C(A) $ respectively.\n(i) $ A = \\begin{pmatrix} 2 \u0026 3 \u0026 4 \u0026 5 \u0026 1 \\\\ 0 \u0026 1 \u0026 0 \u0026 1 \u0026 0 \\end{pmatrix} $\n(ii) $ A = \\begin{pmatrix} 1 \u0026 0 \u0026 2 \u0026 3 \\\\ 2 \u0026 2 \u0026 4 \u0026 5 \\\\ 1 \u0026 2 \u0026 4 \u0026 3 \\\\ 5 \u0026 6 \u0026 16 \u0026 15 \\\\ 4 \u0026 4 \u0026 10 \u0026 11 \\end{pmatrix} $\n(i)\nThe null space $ N(A) $ has dimension 3， and a basis is $ \\left\\{ \\begin{pmatrix} 1 \\\\ 1 \\\\ 0 \\\\ -1 \\\\ 0\\end{pmatrix}, \\begin{pmatrix}-2 \\\\ 0 \\\\ 1 \\\\ 0 \\\\ 0 \\end{pmatrix}, \\begin{pmatrix}1 \\\\ 0 \\\\ 0 \\\\ 0 \\\\ -2\\end{pmatrix} \\right\\} $.\nThe column space $ C(A) $ is the span of the columns of $ A $, and a basis is $ \\left\\{ \\begin{pmatrix} 2 \\\\ 4 \\\\ 1 \\\\ 1 \\\\ 1 \\end{pmatrix}, \\begin{pmatrix} 3 \\\\ 5 \\\\ 0 \\\\ 0 \\\\ 0 \\end{pmatrix} \\right\\} $.\n(ii)\nThe null space $ N(A) $ has dimension 1, and a basis is $ \\left\\{ \\begin{pmatrix} -4 \\\\ 1 \\\\ -1 \\\\ 2 \\end{pmatrix} \\right\\} $.\nThe column space $ C(A) $ has dimension 3, and a basis is $ \\left\\{ \\begin{pmatrix} 1 \\\\ 2 \\\\ 1 \\\\ 5 \\\\ 4 \\end{pmatrix}, \\begin{pmatrix} 0 \\\\ 2 \\\\ 2 \\\\ 6 \\\\ 4 \\end{pmatrix}, \\begin{pmatrix} 2 \\\\ 4 \\\\ 4 \\\\ 16 \\\\ 10 \\end{pmatrix} \\right\\} $.\nExercise 6 Calculate $ k \\in \\mathbb{R} $ such that the sequence $ v_1 - k v_2 $, $ v_2 - k v_3 $, $ v_3 - k v_4 $, $ v_4 - k v_1 $ is linearly independent, where\n$ v_1 = \\begin{pmatrix} 1 \\\\ 1 \\\\ 1 \\\\ 1 \\end{pmatrix}, \\quad v_2 = \\begin{pmatrix} 0 \\\\ 1 \\\\ 1 \\\\ 1 \\end{pmatrix}, \\quad v_3 = \\begin{pmatrix} 0 \\\\ 0 \\\\ 1 \\\\ 1 \\end{pmatrix}, \\quad v_4 = \\begin{pmatrix} 0 \\\\ 0 \\\\ 0 \\\\ 1 \\end{pmatrix}. $ Sol: $$ \\begin{align*} w_{1} \u0026 = v_{1}-kv_{2} = \\begin{pmatrix} 1 \\\\ 1-k \\\\ 1-k \\\\ 1-k \\end{pmatrix}, w_{2}= v_{2} - kv_{3} = \\begin{pmatrix} 0 \\\\ 1 \\\\ 1-k \\\\ 1-k \\end{pmatrix}, \\\\ \\\\ w_{3} \u0026 = v_{3} - kv_{4} = \\begin{pmatrix} 0\\\\ 0 \\\\ 1 \\\\ 1-k \\end{pmatrix}, w_{4} = v_{4} - kv_{1} = \\begin{pmatrix} -k \\\\ -k \\\\ -k \\\\ 1-k \\end{pmatrix}, \\\\ \\\\ M \u0026 = \\begin{pmatrix} w_{1} \u0026 w_{2} \u0026 w_{3} \u0026 w_{4} \\end{pmatrix} = \\begin{pmatrix} 1 \u0026 0 \u0026 0 \u0026 -k \\\\ 1-k \u0026 1 \u0026 0 \u0026 -k \\\\ 1-k \u0026 1-k \u0026 1 \u0026 -k \\\\ 1-k \u0026 1-k \u0026 1-k \u0026 1-k \\end{pmatrix} \\end{align*} $$ Then we calculate the determinant of matrix $ M $, which is $$ \\det(M) = 1-k^{4} $$ So the sequence is linearly independent if and only if $ k^4 \\neq 1 $, i.e., $ k \\neq \\pm 1 $.\nExercise 7 Let $ V $ be a vector space and $ S_1, S_2 \\subseteq V $. Prove that:\n(i) If $ S_1 \\subseteq S_2 $, then $ \\operatorname{span}(S_1) \\subseteq \\operatorname{span}(S_2) $.\n(ii) $ \\operatorname{span}(S_1) = \\operatorname{span}(\\operatorname{span}(S_1)) $.\n(iii) If $ S_1 \\subseteq \\operatorname{span}(S_2) $, then $ \\operatorname{span}(S_1) \\subseteq \\operatorname{span}(S_2) $.\nProof:\n(i)\nAny linear combination of elements from $ S_1 $ is also a linear combination of elements from $ S_2 $, using zero coefficients for elements in $ S_2 \\setminus S_1 $. Thus, $ \\operatorname{span}(S_1) \\subseteq \\operatorname{span}(S_2) $.\n(ii)\nElements of $ \\operatorname{span}(\\operatorname{span}(S_1)) $ are linear combinations of elements from $ \\operatorname{span}(S_1) $, which are themselves linear combinations from $ S_1 $, hence linear combinations from $ S_1 $. So $ \\operatorname{span}(\\operatorname{span}(S_1)) \\subseteq \\operatorname{span}(S_1) $. The reverse inclusion is immediate.\n(iii)\nEach element of $ S_1 $ is a linear combination from $ S_2 $, so any linear combination from $ S_1 $ is a linear combination of linear combinations from $ S_2 $, hence a linear combination from $ S_2 $. Thus, $ \\operatorname{span}(S_1) \\subseteq \\operatorname{span}(S_2) $.\nExercise 8 Let $ V $ be a vector space and $ v, e_1, \\ldots, e_n \\in V $. We have already used the following terminology in our class. We say that $ v $ can be represented by $ e_1, \\ldots, e_n $ if $ v $ can be written as a linear combination of $ e_1, \\ldots, e_n $, or equivalently\n$ v \\in \\operatorname{span}(\\{e_1, \\ldots, e_n\\}) $.\nThis can be extended as follows. Let $ v \\in V $ and $ S, S_1, S_2 \\subseteq V $\n$ v $ can be represented by $ S $ if $ v \\in \\operatorname{span}(S) $.\n$ S_1 $ can be represented by $ S_2 $ if every $ v \\in S_1 $ can be represented by $ S_2 $.\nProve that:\n(i) $ S_1 $ can be represented by $ S_2 $ if and only if $ \\operatorname{span}(S_1) \\subseteq \\operatorname{span}(S_2) $.\n(ii) If $ S $ can be represented by $ S_1 $, and $ S_1 $ can be represented by $ S_2 $, then $ S $ can be represented by $ S_2 $.\n(iii) Assume $ v \\in S $ and $ v $ can be represented by $ S \\setminus \\{v\\} $, then\n$ \\operatorname{span}(S \\setminus \\{v\\}) = \\operatorname{span}(S) $.\nProof:\n(i)\n$ S_1 $ can be represented by $ S_2 $ means $ S_1 \\subseteq \\operatorname{span}(S_2) $, which by Exercise 7(iii) is equivalent to $ \\operatorname{span}(S_1) \\subseteq \\operatorname{span}(S_2) $.\n(ii)\nIf $ S $ is represented by $ S_1 $, then $ S \\subseteq \\operatorname{span}(S_1) $. If $ S_1 $ is represented by $ S_2 $, then $ \\operatorname{span}(S_1) \\subseteq \\operatorname{span}(S_2) $ by (i). Thus, $ S \\subseteq \\operatorname{span}(S_1) \\subseteq \\operatorname{span}(S_2) $, so $ S $ is represented by $ S_2 $.\n(iii)\nLet $ T = S \\setminus \\{v\\} $. Since $ v \\in \\operatorname{span}(T) $, $ \\operatorname{span}(S) = \\operatorname{span}(T \\cup \\{v\\}) \\subseteq \\operatorname{span}(T) + \\operatorname{span}(\\{v\\}) \\subseteq \\operatorname{span}(T) + \\operatorname{span}(T) = \\operatorname{span}(T) $. Also, $ \\operatorname{span}(T) \\subseteq \\operatorname{span}(S) $, so equality holds.\n","permalink":"https://diefish1024.github.io/posts/class-notes/math1205h-linear-algebra/math1205h-hw4/","summary":"\u003ch2 id=\"exercise-1\"\u003eExercise 1\u003c/h2\u003e\n\u003cblockquote\u003e\n\u003cp\u003eGive a basis for the vector space $ M_{m\\times n}(\\mathbb{R}) $ consisting of all $ m \\times n $ matrices.\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003eA basis consists of the matrices $ E_{ij} $ for $ 1 \\leq i \\leq m $ and $ 1 \\leq j \\leq n $, where $ E_{ij} $ has a 1 in the $ (i,j) $-th position and 0 elsewhere.\u003c/p\u003e\n\u003ch2 id=\"exercise-2\"\u003eExercise 2\u003c/h2\u003e\n\u003cblockquote\u003e\n\u003cp\u003eGive a basis for $ V = \\mathbb{R}^+ = \\{x \\mid x \\in \\mathbb{R} \\text{ with } x \u003e 0\\} $ with $ x \\oplus x' = x \\times x' $ and $ c \\otimes x = x^c $.\u003c/p\u003e","title":"MATH1205H HW4"},{"content":"Problem 1 证明 $$ \\begin{align*} \\sum_{i=0}^{n} (-1)^{i}\\binom{ n }{ i } \\binom{ n+m-i }{ k-i } = \\binom{ m }{ k } \\\\ \\sum_{i=0}^{n} \\binom{ k }{ i } D_{n-i} = \\sum_{j=0}^{n-k} (-1)^{j}\\binom{ n-k }{ j } (n-j)! \\end{align*} $$ 证 1\n对于第一个式子，我们考虑组合意义。设有 $ A,B $ 两个集合，分别包含 $ n $ 和 $ m $ 个元素，总共 $ n+m $ 个元素。我们希望从集合 $ B $ 中恰好选择 $ k $ 个元素。我们可以通过容斥原理的补集形式求解，定义事件 $ A_{i} $ 为所选的 $ k $ 个元素中至少包含 $ i $ 个来自 $ A $ 的元素，那么我们需要求解的事件集合为 $ U\\setminus\\bigcup_{i\\leq n}A_{i} $，并且 $$ \\left| A_{i} \\right| = \\binom{ n }{ i } \\binom{ n+m-i }{ k-i } $$ 因此根据容斥原理，就可以得到 $$ \\left| U\\setminus \\bigcup_{i\\leq n}A_{i} \\right| = \\sum_{i=0}^{n} (-1)^{i}\\binom{ n }{ i } \\binom{ n+m-i }{ k-i } = \\binom{ m }{ k } $$\n对于第二个式子，同样考虑组合意义。我们可以假定 $ n\\geq k $，否则两侧均为零。设有 $ n $ 个元素的排列，分成 $ A $ 和 $ B $ 两部分，分别包含 $ k $ 和 $ n-k $ 个元素。左侧所有枚举所有 $ A $ 中元素的组合固定，剩下的进行错排，可以表示 $ A $ 中元素任意，$ B $ 中元素必须为错排的方案数。我们同样考虑通过容斥原理的补集形式来求解。右侧我们定义事件 $ B_{i} $ 表示 $ B $ 中至少有 $ i $ 个元素不是错排（值等于自己的编号），剩下的数随意，于是 $ \\left| B_{i} \\right|=\\binom{ n-k }{ i }(n-i)! $。同时我们需要求解的事件集合为 $ U\\setminus\\bigcup_{i=1}^{n-k}B_{i} $，因此根据容斥原理可以得到 $$ \\left| U\\setminus \\bigcup_{j=1}^{n-k}B_{j} \\right| = \\sum_{i=0}^{n} \\binom{ k }{ i } D_{n-i} = \\sum_{j=0}^{n-k} (-1)^{j}\\binom{ n-k }{ j } (n-j)! $$ 证 2：\n这两个式子和二项反演都有一定的类似之处。 $$ g_{n} = \\sum_{i=0}^{n} \\binom{ n }{ i } f_{i} \\implies f_{n} = \\sum_{i=0}^{n} (-1)^{n-i}\\binom{ n }{ i } g_{i} $$ 我们直接证明二项反演。\n将 $ g_{i} $ 的表达式带入要证明的式子，只需证明 $$ \\begin{align*} \\\\ f_{n} \u0026 = \\sum_{i=0}^{n} (-1)^{n-i}\\binom{ n }{ i } \\sum_{j=0}^{i} \\binom{ i }{ j } f_{j} \\\\ \u0026 = \\sum_{i=0}^{n} \\sum_{j=0}^{i} (-1)^{n-i}\\binom{ n }{ i } \\binom{ i }{ j } f_{j} \\\\ \u0026 = \\sum_{i=0}^{n} \\sum_{j=0}^{i} (-1)^{n-i}\\binom{ n }{ j } \\binom{ n-j }{ i-j } f_{j} \\\\ \u0026 = \\sum_{j=0}^{n}\\binom{ n }{ j } f_{j} \\sum_{i=j}^{n} (-1)^{n-i}\\binom{ n-j }{ i-j } \\\\ \u0026 = \\sum_{j=0}^{n} \\binom{ n }{ j } f_{j}\\cdot \\left( \\sum_{i=0}^{n-j} (-1)^{n+j-i}\\binom{ n-j }{ i } \\right) \\\\ \u0026 = \\sum_{j=0}^{n} \\binom{ n }{ j } f_{j}\\cdot[n-j=0] \\\\ \u0026 = f_{n} \\end{align*} $$ 这就证明了二项式反演。\n因此对于第一个式子 $$ \\sum_{i=0}^{n} (-1)^{i}\\binom{ n }{ i } \\binom{ n+m-i }{ k-i } = \\sum_{i=0}^{n} (-1)^{n-i}\\binom{ n }{ i } \\binom{ m+i }{ k-n+i } $$ 令 $ g_{i}:=\\binom{ m+i }{ k-n+i } $，那么上式就是 $ \\sum_{i=0}^{n}(-1)^{n-i}\\binom{ n }{ i }g_{i} $。\n根据组合意义，显然有恒等式 $$ g_{t} = \\binom{ m+t }{ k-n+t } = \\sum_{i=0}^{t} \\binom{ t }{ i } \\binom{ m }{ k-n+(t-i) } = \\sum_{i=0}^{t} \\binom{ t }{ i } \\binom{ m }{ k-n+i } $$ 因此我们直接取 $ f_{i}=\\binom{ m }{ k-n+i } $ 就可以得到 $$ \\sum_{i=0}^{n} \\binom{ n }{ i } f_{i} = g_{n} \\implies \\sum_{i=0}^{n} (-1)^{n-i}\\binom{ n }{ i } g_{i} = f_{n} = \\binom{ m }{ k } $$ 对于 $$ \\sum_{i=0}^{n} \\binom{ k }{ i } D_{n-i} = \\sum_{j=0}^{n-k} (-1)^{j}\\binom{ n-k }{ j } (n-j)! $$ 似乎构造比较复杂，暂时搁置这个思路(\nProblem 2 (1)\n有多少种方法可以从 $ n $ 个元素的序列中选择 $ k $ 个非连续的元素？\n解\n设从 $ n $ 个元素中选择 $ k $ 个元素的全体集合为 $ U $，$ A_i $ $ (1 \\leq i \\leq k-1) $ 表示选择的 $ k $ 个数中第 $ i $ 和 $ i+1 $ 个数同时被选中的事件。我们需要用容斥原理计算 $ \\left| U \\setminus \\bigcup_{i=1}^{k-1} A_i \\right| $。\n全集：$ |U| = \\binom{n}{k} $。\n单项和：$ |A_i| = \\binom{n-1}{k-1} $，因此 $$ \\sum_{i=1}^{k-1} |A_i| = (k-1) \\binom{n-1}{k-1} $$\n$ m $ 重交集：对于 $ 1 \\leq i_1 \u003c i_2 \u003c \\cdots \u003c i_m \\leq k-1 $，$ \\bigcup_{j=1}^{m}A_{i_{j}} $ 等价于从 $ n-m $ 中选取 $ k-m $ 个数，方案数为 $ \\binom{ n-m }{ k-m } $。\n因此 $$ \\sum_{S\\in[n]\\land \\left| S \\right| =m} \\left( \\bigcup_{i\\in S}A_{i} \\right) = \\binom{ k-1 }{ m } \\binom{ n-m }{ k-m } $$\n由容斥原理 $$ \\left| U\\setminus \\bigcup_{i=1}^{k-1}A_{i} \\right| = \\sum_{m=0}^{k-1} (-1)^{m}\\binom{ k-1 }{ m } \\binom{ n-m }{ k-m } $$\n通过组合意义，可以得到该式化简后等于 $$ \\binom{n-k+1}{k} $$ (2)\n有多少种方法可以从 $ n $ 个元素的循环排列中选择 $ k $ 个非连续的元素？\n解\n设从 $ n $ 个元素的循环排列中选择 $ k $ 个元素的全体集合为 $ U $，$ A_i $ $ (1 \\leq i \\leq k) $ 表示选择的 $ k $ 个数中第 $ i $ 和第 $ i+1 $（模 $ k $）个数在循环上相邻的事件。我们需要用容斥原理计算 $ \\left| U \\setminus \\bigcup_{i=1}^{k} A_i \\right| $。\n全集：$ |U| = \\binom{n}{k} $。\n单项和：对于 $ 1 \\leq i \\leq k-1 $，$ |A_i| = \\binom{n-1}{k-1} $；对于 $ A_k $（首尾相邻），$ |A_k| = \\binom{n-2}{k-2} $，因此 $$ \\sum_{i=1}^{k} |A_i| = (k-1) \\binom{n-1}{k-1} + \\binom{n-2}{k-2} $$\n$ m $ 重交集：对于 $ 1 \\leq i_1 \u003c i_2 \u003c \\cdots \u003c i_m \\leq k $，若这些事件在循环上形成 $ c $ 个连通段，则 $ \\left|\\bigcap_{j=1}^{m}A_{i_{j}}\\right| = \\binom{n-(m+c)}{k-(m+c)} $。\n设 $ N_k(m,c) $ 为从 $ k $ 个事件中选 $ m $ 个形成恰好 $ c $ 个连通段的方案数，则 $$ \\sum_{1 \\leq i_1 \u003c \\cdots \u003c i_m \\leq k} \\left|\\bigcap_{j=1}^{m}A_{i_{j}}\\right| = \\sum_{c=1}^{\\min(m,k)} N_k(m,c) \\binom{n-(m+c)}{k-(m+c)} $$\n其中 $ N_k(m,c) = \\frac{k}{m} \\binom{m}{c} \\binom{m-c}{c} $（将 $ m $ 个事件在 $ k $ 个位置的循环上分成 $ c $ 个连通段）。\n由容斥原理 $$ \\left| U\\setminus \\bigcup_{i=1}^{k}A_{i} \\right| = \\sum_{m=0}^{\\lfloor k/2 \\rfloor} (-1)^{m} \\sum_{c=1}^{m} N_k(m,c) \\binom{n-(m+c)}{k-(m+c)} $$\n通过组合意义，可以得到该式化简后等于 $$ \\frac{n}{n-k}\\binom{n-k}{k} $$\n组合意义：从 $ n $ 个位置的循环排列中选择 $ k $ 个位置，使得任意两个选中位置不相邻的方案数。可通过将 $ k $ 个选中位置和 $ n-k $ 个未选中位置交替排列的方式理解此公式。\n(3)\n假设我们希望将 $ n $ 对夫妇安排在一张圆桌周围，其中男性和女性交替排列，并且每位女性与她的丈夫不相邻。座位旋转视为相同。证明安排的数量为： $$ (n-1)!\\sum_{k=0}^{n} (-1)^{k} \\dfrac{2n}{2n-k}\\binom{2n-k}{k} (n-k)! $$\n解\n设 $ A_i $ 表示第 $ i $ 对夫妇相邻的事件。\n全集：男女交替排列，考虑旋转等价。固定一名男性的位置，其余 $ n-1 $ 名男性排列有 $ (n-1)! $ 种，$ n $ 名女性排列有 $ n! $ 种，因此 $$ |U| = (n-1)! \\cdot n! $$ 单项和：将第 $ i $ 对夫妇视为一个单元，该单元内部有 2 种排法（考虑男女交替约束）。剩余排列方式为 $ (n-1)! \\cdot (n-1)! $，因此 $$ |A_i| = 2(n-1)!(n-1)!, \\quad \\sum_{i=1}^{n} |A_i| = 2n(n-1)!(n-1)! $$ $ m $ 重交集：选定 $ m $ 对夫妇 $ i_1, \\ldots, i_m $ 相邻。在圆桌的 $ 2n $ 个座位上选择 $ m $ 个不重叠的相邻座位对，考虑循环对称性，方案数为 $ \\frac{n}{n-m}\\binom{2n-m}{m} $。\n将 $ m $ 对夫妇分配到这 $ m $ 个座位对：$ m! $ 每对夫妇内部排列：考虑男女交替的整体约束，共有 2 种全局配置 剩余 $ n-m $ 对夫妇的男女各自排列：$ (n-m)! \\times (n-m)! $ 因此 $$ \\left|\\bigcap_{j=1}^{m} A_{i_j}\\right| = \\frac{2}{2n-m}\\binom{2n-m}{m} m! (n-m)!^2 $$\n$ m $ 重交集和： $$ \\sum_{1 \\leq i_1 \u003c \\cdots \u003c i_m \\leq n} \\left|\\bigcap_{j=1}^{m} A_{i_j}\\right| = \\binom{n}{m} \\cdot \\frac{2}{2n-m}\\binom{2n-m}{m} m! (n-m)!^2 = \\frac{2n!}{2n-m}\\binom{2n-m}{m} (n-m)! $$\n由容斥原理： $$ \\left|U \\setminus \\bigcup_{i=1}^{n} A_i\\right| = \\sum_{k=0}^{n} (-1)^k \\frac{2n!}{2n-k}\\binom{2n-k}{k} (n-k)! = (n-1)!\\sum_{k=0}^{n} (-1)^k \\frac{2n}{2n-k}\\binom{2n-k}{k} (n-k)! $$\nProblem 3 (1)\n假设 $ f,g,h $ 都是数论函数，满足 $$ g(n) = \\sum_{d|n}df(d), \\quad h(n) = \\sum_{d|n}f(d) $$ 证明 $$ h(n) = \\dfrac{1}{n} \\sum_{d|n} \\varphi(n/d)g(d) $$ 证\n我们讲 $ g(d) $ 带入目标表达式，得到 $$ \\begin{align*} h(n) \u0026 = \\dfrac{1}{n} \\sum_{d|n}\\varphi\\left( \\dfrac{n}{d} \\right)\\left( \\sum_{e|d}ef(e) \\right) \\\\ \u0026 = \\dfrac{1}{n} \\sum_{e|d, d|n}\\varphi\\left( \\dfrac{n}{d} \\right)ef(e) \\\\ \u0026 \\xlongequal{d=ek} \\dfrac{1}{n}\\sum_{e|n}\\sum_{k|(n / e)} \\varphi\\left( \\dfrac{n}{ek} \\right)ef(e) \\\\ \u0026 = \\dfrac{1}{n}\\sum_{e|n}ef(e) \\sum_{k|(n / e)} \\varphi\\left( \\dfrac{n / e}{k} \\right) \\end{align*} $$ 由于 $ \\sum_{k|m}\\varphi(k)=m $，因此 $$ \\sum_{k|(n / e)} \\varphi\\left( \\dfrac{n / e}{k} \\right) = \\dfrac{n}{e} $$ 带入得到 $$ h(n) = \\dfrac{1}{n}\\sum_{e|n}ef(e) \\cdot \\dfrac{n}{e} = \\sum_{e|n}f(e) = \\sum_{d|n}f(d) $$ 得证！\n(2)\n希望用 $ q $ 种颜色对一条由 $ n $ 颗珠子组成的项链进行着色。确定 $ N_n $，即着色方案的数量，其中如果两种着色方案可以通过旋转互相得到，则认为它们是相同的。\n同样地，可以将 $ N_n $ 定义为在 $ [q] $ 上的循环序列的数量，其中通过旋转得到的两个序列被认为是相同的。求 $ N_n $ 。\n（提示：设 $ M(d) $ 为长度为 $ d $ 且非周期性的循环序列的数量。）\n解\n按照提示设出 $ M(d) $，那么找项链最小的循环节，容易得到 $$ N_{n} = \\sum_{d|n} M(d) $$ 我们需要计算 $ M(d) $。考虑普通序列和循环序列之间的关系。对于长度 $ n $，普通序列的总数为 $ q^{n} $，而每个最小周期为 $ d $ 的循环序列对应 $ d $ 中不同的表示，因此数量为 $ dM(d) $，这就得到了 $$ q^{n}= \\sum_{d|n}dM(d) $$ 因此根据上一问的结论，我们就得到了 $$ N_{n} = \\dfrac{1}{n}\\sum_{d|n}\\varphi\\left( \\dfrac{d}{n} \\right)q^{d} $$\nProblem 4 考虑一个偏序集 $ \\mathcal{P} = (P, \\preccurlyeq) $，其中 $$ P = \\{(a_1, a_2, a_3, a_4) : a_i \\in [4]\\} $$ 并且 $ (a_1, a_2, a_3, a_4) \\preccurlyeq (b_1, b_2, b_3, b_4) $ 当且仅当对于所有 $ i $ 都有 $ a_i \\le b_i $。求满足 $ \\mu(x, y) \u003c 0 $ 的序对 $ x, y \\in P $ 的数量。\n解\n对于两个 $ x,y\\in P $，根据讲义的 Lemma 4.24，莫比乌斯函数的积性，得到 $$ \\mu(x,y) = \\prod_{i=1}^{4}\\mu_{[4]}(x_{i},y_{i}) $$ 对于一个 $ [4] $ 的链，我们直接计算 $ \\mu_{[4]}(a,b) $：\n如果 $ a \\not\\leq b $，那么 $ \\mu_{[4]}(a,b)=0 $。 如果 $ a=b $，那么 $ \\mu_{[4]}(a,b)=1 $。 如果 $ b=a+1 $，那么 $ \\mu_{[4]}(a,b)=-1 $。 如果 $ b\\geq a+2 $，那么 $ \\mu_{[4]}(a,b)=-\\sum_{k=a}^{b-1}\\mu_{[4]}(a,k)=0 $。 因此对于 $ x,y\\in P $，$ \\mu(x,y)\\neq 0 $ 当且进行对于所有 $ i $ 满足 $ y_{i}-x_{i}\\leq 1 $。定义 $ k $ 为 $ y_{i}=x_{i}+1 $ 的下标数量，其余 $ y_{i}=x_{i} $，于是就有 $$ \\mu(x,y) = (-1)^{k} $$ 小于 $ 0 $ 当且仅当 $ k=1,3 $。\n我们分开计算 $ k=1,3 $ 的序对数量：\n$ k=1 $，根据组合意义可以得到总数为 $ \\binom{ 4 }{ 1 }\\times 3^{1} \\times 4^{3}=768 $。 $ k=3 $，总数为 $ \\binom{ 4 }{ 3 }\\times 3^{3} \\times 4=432 $。 因此总数为 $ 768+432=1200 $。\nProblem 5 挑选两个在 $ [100] $ 范围内均匀、独立随机的数字 $ a $ 和 $ b $。在 $ [100] $ 上的偏序关系定义为整除关系，求 $ \\mu(a, b) = -1 $ 的概率。\n解\n我们考虑直接算出所有满足条件的 $ (a,b) $ 的总数。对于 $ \\mu(a,b) $，分类讨论：\n如果 $ a \\not\\mid b $，那么 $ \\mu(a,b)=0 $。 如果 $ a=b $，那么 $ \\mu(a,b)=1 $。 如果 $ b=ka $（$ k \\geq 2 $），那么 $ \\mu(a,b)=\\mu(1,k) $，其中 $ \\mu(1,k)=(-1)^{\\omega(k)} $ 当 $ k $ 无平方因子，否则 $ \\mu(1,k)=0 $。 因此 $ \\mu(a,b)=-1 $ 当且仅当 $ k $ 无平方因子且 $ \\omega(k) $ 为奇数。定义 $ m $ 为 $ \\omega(k) $ 的奇数值，其可能取值 $ m=1,3 $（因 $ k \\leq 100 $，最大 $ m=3 $）。\n我们分开计算 $ m=1,3 $ 的序对数量：\n$ m=1 $（$ k $ 为素数），总数为 $ \\sum_{p \\leq 100} \\lfloor 100/p \\rfloor =171 $。 $ m=3 $（$ k $ 为三个不同素数的乘积），此类 $ k=30,42,66,70,78 $，总数为 $ \\lfloor 100/30 \\rfloor + \\lfloor 100/42 \\rfloor + \\lfloor 100/66 \\rfloor + \\lfloor 100/70 \\rfloor + \\lfloor 100/78 \\rfloor =3+2+1+1+1=8 $。 因此总数为 $ 171+8=179 $，于是 $$ \\mathbb{P}(\\mu(a,b)=-1) = \\dfrac{179}{100^{2}} = \\dfrac{179}{10000}. $$\nProblem 6 设 $ a_1, a_2, \\dots, a_n $ 是一些实数，它们的绝对值都满足 $ |a_i| \\ge 1 $。考虑所有 $ 2^n $ 种线性组合 $ \\sum_{i=1}^{n} \\epsilon_i \\cdot a_i $，其中每个 $ \\epsilon_i $ 可以取值 $ \\{-1, +1\\} $。请证明，这些和中落在任意区间 $ (x-1, x+1) $ 内的数量至多为 $ \\binom{n}{\\lfloor n/2 \\rfloor} $。\n证\n我们稍微转化一下题目，令 $ b_{i}=2a_{i} $，取 $ \\{ b_{n} \\} $ 的幂集 $ \\mathcal{P} $，对于 $ S\\in \\mathcal{P} $，$ S $ 中所有元素之和显然可以有一组 $ \\sum_{i=1}^{n}\\epsilon_{i}\\cdot a_{i} $ 平移得到，就这样 $ \\mathcal{P} $ 可以和 $ 2^{n} $ 中 $ a_{i} $ 的线性组合一一对应。并且我们只需要考虑落在任意区间中的数量，所以平移操作并不会造成影响，于是我们的问题就转化成了 $ \\mathcal{P} $ 中集合的元素之和落在任意区间 $ (x-1,x+1) $ 内的集合数量至多位 $ \\binom{ n }{ \\lfloor n / 2 \\rfloor } $。\n假设集合 $ S $ 是一个满足条件的集合。由于 $ \\left| b_{i} \\right|=2\\left| a_{i} \\right|\u003e2 $，因此在 $ S $ 的基础上任意添加一个原来不包含的元素，至少会导致元素之和变化 $ 2 $，从而一定不会落在 $ (x-1,x+1) $ 中。这说明了若 $ \\sum_{S}\\in(x-1,x+1) $，那么任意 $ S' $ 满足 $ S\\subset S' $，都有 $ \\sum_{S'}\\not\\in (x-1,x+1) $。\n因此我们直接考虑偏序集 $ (\\mathcal{P},\\subseteq) $。根据上面的分析，显然元素之和落在 $ (x-1,x+1) $ 的所有集合一定是一个反链。直接利用 Sperner 定理，得到此时反链的数量至多为 $ \\binom{ n }{ \\lfloor n / 2 \\rfloor } $，因此满足条件的集合数量也至多为 $ \\binom{ n }{ \\lfloor n / 2 \\rfloor } $。\n","permalink":"https://diefish1024.github.io/posts/class-notes/cs0901-combinatorics/cs0901-hw3/","summary":"\u003ch2 id=\"problem-1\"\u003eProblem 1\u003c/h2\u003e\n\u003cp\u003e证明\n$$ \n\n\\begin{align*}\n\\sum_{i=0}^{n} (-1)^{i}\\binom{ n }{ i } \\binom{ n+m-i }{ k-i } = \\binom{ m }{ k }  \\\\\n\\sum_{i=0}^{n} \\binom{ k }{ i } D_{n-i} = \\sum_{j=0}^{n-k} (-1)^{j}\\binom{ n-k }{ j } (n-j)!\n\\end{align*}\n\n $$\n\u003cstrong\u003e证 1\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e对于第一个式子，我们考虑组合意义。设有 $ A,B $ 两个集合，分别包含 $ n $ 和 $ m $ 个元素，总共 $ n+m $ 个元素。我们希望从集合 $ B $ 中恰好选择 $ k $ 个元素。我们可以通过容斥原理的补集形式求解，定义事件 $ A_{i} $ 为所选的 $ k $ 个元素中至少包含 $ i $ 个来自 $ A $ 的元素，那么我们需要求解的事件集合为 $ U\\setminus\\bigcup_{i\\leq n}A_{i} $，并且\n$$ \n\n\\left| A_{i} \\right| = \\binom{ n }{ i } \\binom{ n+m-i }{ k-i } \n\n $$\n因此根据容斥原理，就可以得到\n$$ \n\n\\left| U\\setminus \\bigcup_{i\\leq n}A_{i} \\right| = \\sum_{i=0}^{n} (-1)^{i}\\binom{ n }{ i } \\binom{ n+m-i }{ k-i } = \\binom{ m }{ k }  \n\n $$\u003c/p\u003e","title":"CS0901 HW3"},{"content":"题目\nProblem 1.1 设 $ \\mathcal{F} $ 是一个有限的 $ \\sigma $-代数。定义其中“最小\u0026quot;的元素为其包含于 $ \\mathcal{F} $ 中的子集仅为自身和空集，形式化地描述，若 $ A\\in \\mathcal{F} $ 为“最小”的元素，那么如果 $ B\\in \\mathcal{F} $ 并且 $ B\\subseteq A $，那么一定有 $ B\\in \\{ \\emptyset,A \\} $。\n可以证明这样的元素存在并且有限：如果不存在，那么我们每次任取一个 $ \\mathcal{F} $ 中的元素，都能找到属于它的一个更小的元素，但 $ \\mathcal{F} $ 是有限集，所以这样的过程不可能一直重复下去，因此“最小”元素必然存在并且有限。\n我们设所有这些不同的“最小”元素为 $ S=\\{ A_{1},A_{2},\\dots,A_{n} \\} $。我们先证明这构成了全空间的一个分划：\n首先这些元素肯定两两不相交，否则不满足“最小”的定义。假设 $ A_{i}\\cap A_{j}= C\\neq\\emptyset $，根据“最小”，非空的 $ C $ 是 $ A_{i} $ 的子集，一定有 $ C=A_{i} $，同样也有 $ C=A_{j} $，这就推出了 $ A_{i}=A_{j} $，从而矛盾。\n其次证明这些元素的并集为全空间。设全空间为 $ X $，并且 $ A=\\bigcup_{i=1}^{n}A_{i} $，令 $ A^{c}=X\\setminus A $。如果 $ A^{c} $ 不是空集，我们肯定能找出一个“最小元素” $ A'\\subseteq A^{c} $，这与我们取出了所有“最小”元素的前题矛盾。因此 $ X=A $，所有“最小”元素的并集为全空间。结合两两不相交的性质，我们就证明了这构成了全空间的一个分划。\n下面证明 $ \\mathcal{F} $ 的大小为 $ 2^{n} $。我们考虑 $ S $ 的所有子集的集合 $ 2^{S} $。根据 $ \\sigma $-代数的性质，由于 $ S $ 的任意一个子集都是若干个 $ \\mathcal{F} $ 中元素的并，因此必然也是 $ \\mathcal{F} $ 中的元素，于是 $ \\mathcal{F} $ 中至少有 $ 2^{\\left| S \\right|}=2^{n} $ 个元素。如果除此之外 $ \\mathcal{F} $ 中还有别的元素，根据上面的证明，这违反了 $ S $ 为全空间的分划的条件，因此 $ \\mathcal{F} $ 的大小为 $ 2^{n} $。\n综上我们证明了有限 $ \\sigma $-代数 $ \\mathcal{F} $ 的大小为 $ 2^{n} $，并且能找到一个恰有 $ n $ 个元素的全空间的分划。\nProblem 1.2 (1)\n设每个人的生日为 $ b_{k} $，那么样本空间 $ \\Omega=\\{ (b_{1},b_{2},\\dots,b_{n})| b_{k}\\in[m]\\text{ for }k\\in[n]\\} $。对于事件 $ A_{i,j} $ 表示 $ i $ 和 $ j $ 在同一天，我们有 $$ A_{i,j} = \\{ (b_{1},b_{2},\\dots,b_{n})\\in\\Omega : b_{i} = b_{j} \\} $$ 因此 $ \\left| A_{i,j} \\right|=m\\cdot m^{n-2} $，可以得到 $ \\mathbb{P}(A_{i,j})= \\frac{\\left| A_{i,j} \\right|}{\\left| \\Omega \\right|}=\\frac{1}{m} $。\n要证明两两独立性，我们需要证明对于任意两个不同事件 $ A_{i,j},A_{k,l} $（其中 $ i\u003c j,k\u003c l $ 并且 $ \\{ i,j \\}\\neq \\{ k,l \\} $），需要有 $$ \\mathbb{P}(A_{i,j}\\cap A_{k,l})=\\mathbb{P}(A_{i,j})\\cdot \\mathbb{P}(A_{k,l}) = \\dfrac{1}{m^{2}} $$ 下面我们计算 $ \\left| A_{i,j}\\cap A_{k,l} \\right| $。分类讨论。\n如果 $ \\{ i,j \\}\\cap \\{ k,l \\}\\neq \\emptyset $，也就是两个事件共享某一个学生，此时确定三个人的生日相同，有 $$ |A_{i,j}\\cap A_{k,l}| = m\\cdot m^{n-3} = m^{n-2} $$ 如果 $ \\{ i,j \\}\\cap \\{ k,l \\}=\\emptyset $，此时 $$ \\left| A_{i,j}\\cap A_{k,l} \\right| = m^{2}\\cdot m^{n-4}=m^{n-2} $$ 因此无论那种情况，都有 $$ \\mathbb{P}(A_{i,j}\\cap A_{k,l})=\\dfrac{\\left| A_{i,j}\\cap A_{k,l} \\right| }{\\left| \\Omega \\right| }= \\dfrac{1}{m^{2}} $$ 因此 $$ \\mathbb{P}(A_{i,j}\\cap A_{k,l})=\\mathbb{P}(A_{i,j})\\cdot \\mathbb{P}(A_{k,l}) $$\n于是证明了 $ A_{i,j} $ 两两独立。\n(2)\n我们直接考虑 $ A_{1,2}, A_{2,3}, A_{1,3} $ 三个事件。事件 $ A_{1,2}\\cap A_{2,3}\\cap A_{1,3} $ 说明 $ 1,2,3 $ 三个人的生日在同一天，因此 $$ \\mathbb{P}(A_{1,2}\\cap A_{2,3}\\cap A_{1,3}) = \\dfrac{m\\cdot m^{n-3}}{m^{n}} = \\dfrac{1}{m^{2}} $$ 然而 $$ \\mathbb{P}(A_{1,2})\\cdot \\mathbb{P}(A_{2,3})\\cdot \\mathbb{P}(A_{1,3}) = \\left( \\dfrac{1}{m} \\right)^{3} = \\dfrac{1}{m^{3}} \\neq \\mathbb{P}(A_{1,2}\\cap A_{2,3}\\cap A_{1,3}) $$ 这就说明了它们并不相互独立。\n(3)\n首先不妨令 $ n\\leq m $，否则必然有两个人生日相同，肯定不是满足条件的 $ n $ 的最小值。我们直接考虑班上任意两个人的生日都不相同，设为事件 $ B $，我们需要 $ \\mathbb{P}(B)\\leq \\frac{1}{2} $。下面计算 $ B $ 中含有的样本数量 $$ \\left| B \\right| = m^{\\underline{n}} $$ 因此 $$ \\mathbb{P}(B) = \\dfrac{m^{\\underline{n}}}{m^{n}} = \\dfrac{30^{\\underline{n}}}{30^{n}} $$ 使用计算机依次计算 $ n=3,4,\\dots $ 我们可以发现 $$ \\mathbb{P}(B)|_{n=6} \\approx 0.59,\\quad \\mathbb{P}(B)|_{n=7} \\approx 0.47 \u003c \\dfrac{1}{2} $$ 这就得到了 $ n_{\\min}=7 $。\nProblem 1.3 (1) $$ \\begin{align*} \\\\ F \\searrow E \\implies \u0026 \\mathbb{P}(E|F) = \\dfrac{\\mathbb{P}(EF)}{\\mathbb{P}(F)} \\leq \\mathbb{P}(E) \\\\ \\implies \u0026 \\mathbb{P}(EF) \\leq \\mathbb{P}(E)\\cdot \\mathbb{P}(F) \\\\ \\implies \u0026 \\mathbb{P}(F|E) = \\dfrac{\\mathbb{P}(EF)}{\\mathbb{P}(E)} \\leq \\mathbb{P}(F) \\\\ \\implies \u0026 E \\searrow F \\end{align*} $$ (2)\n不正确，直接令 $ F,G $ 为发生概率不为 $ 1 $ 的同一个事件，显然这不会违背条件，但是有 $$ \\mathbb{P}(G|F) = 1 \\not\\le \\mathbb{P}(G) $$\n(3)\n不正确。考虑集合 $ \\Omega=\\{ 1,2,3,4 \\} $，每个样本点的概率均为 $ \\frac{1}{4} $，我们令 $ E=\\{ 1,2 \\},F=\\{ 1,3 \\},G=\\{ 1,4 \\} $，这时 $$ \\mathbb{P}(E|F) = \\dfrac{1}{2} \\leq \\mathbb{P}(E) = \\dfrac{1}{2}, \\mathbb{P}(E|G) = \\dfrac{1}{2}\\leq \\mathbb{P}(E) = \\dfrac{1}{2} $$ 但是 $$ \\mathbb{P}(E|(F\\cap G)) = 1 \\not\\leq \\mathbb{P}(E) $$\nProblem 2 (1)\nCase 1：如果 $ j\\leq K $，那么必然不会被录用，此时 $ \\mathbb{P}(A|B_{j})=0 $。\nCase 2：如果 $ j=K+1 $，那么必然被录用，此时 $ \\mathbb{P}(A|B_{j})=1 $。\nCase 3：如果 $ j\u003eK+1 $，这是如果想要被录用，必须要有前 $ j-1 $ 个面试者中表现最好的人出现在前 $ K $ 轮面试，否则就会先于第 $ j $ 个人被录用。由于出现在每个位置的概率都相等，因此此时 $ \\mathbb{P}(A|B_{j})=\\frac{K}{j-1} $。\n综上， $$ \\mathbb{P}(A|B_{j}) = \\begin{cases} 0 \u0026 ,j\\leq K \\\\ \\dfrac{K}{j-1} \u0026 ,j \u003eK \\end{cases} $$ (2)\n由于 $ P(B_{j})=\\dfrac{1}{n}\\,\\text{for }j\\in[n] $，因此根据全概率公式，有 $$ \\mathbb{P}(A) = \\sum_{j=1}^{n} \\mathbb{P}(A|B_{j})\\cdot \\mathbb{P}(B_{j}) = \\dfrac{1}{n}\\sum_{j=K+1}^{n} \\dfrac{K}{j-1} = \\dfrac{K}{n}\\sum_{j=K}^{n-1} \\dfrac{1}{j} $$\n(3)\n根据提示，在 $ n,K $ 足够大时 $$ \\mathbb{P}(A)\\approx \\dfrac{K}{n}\\cdot \\ln \\dfrac{n}{K} \\xlongequal{p= \\frac{K}{n}}-p\\ln p = \\varphi(p) $$ 对 $ \\varphi(p) $ 求极值，容易得到在 $ p= \\frac{1}{e} $ 时 $ \\varphi(p)_{\\max}= \\frac{1}{e} $。\n因此我们取 $ K\\approx \\dfrac{n}{e} $，可以得到 $$ \\mathbb{P}(A)\\approx \\dfrac{1}{e} \\approx 0.368 $$\nProblem 3 (1)\n由于 $ A_{i,\\sigma_{i}}\\in \\{ 0,1 \\} $，因此 $ \\prod_{i=1}^{n}A_{i,\\sigma(i)}=[\\forall i\\in[n],A_{i,\\sigma(i)}=1]=[\\sigma \\in T_{n}] $。因此 $ \\sum_{\\sigma \\in S}\\prod_{i=1}^{n}A_{i,\\sigma(i)} $ 表示 $ T_{n} $ 中的置换的数量。\n如果一个映射 $ f\\in T_{n} $ 是完美匹配，必然有 $ f $ 是 $ [n] $ 的一个置换，否则无法让 $ V_{1},V_{2} $ 中的点两两匹配（反证法易证）；并且如果 $ f\\in T_{n} $ 是 $ [n] $ 的一个置换，带入定义，同样容易证明这是一个完美匹配。因此 $ f $ 是一个完美匹配和 $ f $ 是一个置换为充要条件。因此 $ M $ 成立当且仅当 $ f $ 为一个置换，于是 $ \\left| M \\right|=\\sum_{\\sigma \\in S}\\prod_{i=1}^{n}A_{i,\\sigma(i)} $。这就有 $$ \\mathbb{P}(M) = \\dfrac{\\left| M \\right| }{\\left| T_{n} \\right|} = \\dfrac{\\sum_{\\sigma \\in S}\\prod_{i=1}^{n}A_{i,\\sigma(i)}}{\\left| T_{n} \\right| } $$ (2)\n首先根据上一问的分析，事件 $ E_{\\emptyset}=M $（映射的值域刚好是 $ [n] $ 等价于这是一个置换）。因此事件 $ E_{\\emptyset} $ 的补集 $ E_{\\emptyset}^{c} $ 表示 $ f $ 不是满射，值域为 $ \\{ 1 \\} $ 或 $ \\{ 2 \\} $，两种可能分别表示元素 $ 2 $ 或元素 $ 2 $ 不在值域中，对应事件 $ E_{2} $ 和 $ E_{1} $，于是 $ E_{\\emptyset}^{c}=E_{1}\\cup E_{2} $。\n根据容斥原理 $$ \\mathbb{P}(E_{1}\\cup E_{2}) = \\mathbb{P}(E_{1}) + \\mathbb{P}(E_{2}) - \\mathbb{P}(E_{1}E_{2}) $$ 于是 $$ \\mathbb{P}(E_{\\emptyset}) = 1-\\mathbb{P}(E_{1}\\cup E_{2}) = 1-\\mathbb{P}(E_{1})-\\mathbb{P}(E_{2}) + \\mathbb{P}(E_{1}E_{2}) $$ 下面我们带入 $ E^{+}_{*} $：\n$ E_{\\emptyset}^{+}=T_{n}\\implies\\mathbb{P}(E_{\\emptyset}^{+})=1 $。 $ E_{\\{ 1 \\}}^{+} = \\bigcap_{j\\in \\{ 1 \\}}E_{j}=E_{1}\\implies \\mathbb{P}(E_{\\{ 1 \\}}^{+})=\\mathbb{P}(E_{1}) $。 $ E_{\\{ 2 \\}}^{+} = \\bigcap_{j\\in \\{ 2 \\}}E_{j}=E_{1}\\implies \\mathbb{P}(E_{\\{ 2 \\}}^{+})=\\mathbb{P}(E_{2}) $。 $ E_{\\{ 1,2 \\}}^{+} = \\bigcap_{j\\in \\{ 1,2 \\}}E_{j}=E_{1}E_{2}\\implies \\mathbb{P}(E_{\\{ 1 \\}}^{+})=\\mathbb{P}(E_{1}E_{2}) $。 得到 $$ \\mathbb{P}(E_{\\emptyset}) = \\mathbb{P}(E_{\\emptyset}^{+}) - \\mathbb{P}(E_{\\{ 1 \\}}^{+}) - \\mathbb{P}(E_{\\{ 2 \\}}^{+})+\\mathbb{P}(E_{\\{ 1,2 \\}}^{+}) $$ (3) 同理 $ (2) $，我们有 $ E_{\\emptyset}^{c}=\\bigcup_{i=1}^{n}E_{i} $，根据容斥原理 $$ \\mathbb{P}\\left( \\bigcup_{i=1}^{n}E_{i} \\right) = \\sum_{r=1}^{n} (-1)^{r-1}\\sum_{J\\subseteq[n],|J|=r}\\mathbb{P}\\left( \\bigcap_{j\\in J}E_{j} \\right) $$\n$ E_{j} $ 表示映射的值域是 $ [n]\\setminus\\{ j \\} $ 的子集。$ \\forall J\\subseteq[n] $，我们有 $ [n]\\setminus J=\\bigcap_{j\\in J}([n]\\setminus \\{ j \\}) $，于是 $$ E_{J}^{+} = \\bigcap_{j\\in J}E_{j} \\implies \\mathbb{P}(E_{J}^{+}) = \\mathbb{P}\\left( \\bigcap_{j\\in J}E_{j} \\right) $$ 因此 $$ \\sum_{r=1}^{n} (-1)^{r-1}\\sum_{J\\subseteq[n],|J|=r}\\mathbb{P}\\left( \\bigcap_{j\\in J}E_{j} \\right) = \\sum_{r=1}^{n} (-1)^{r-1}\\sum_{J\\subseteq[n],|J|=r}\\mathbb{P}\\left( E_{J}^{+} \\right) $$ 带入得到 $$ \\begin{align*} \\mathbb{P}(M)=\\mathbb{P}(E_{\\emptyset}) \u0026 = 1-\\mathbb{P}(E_{\\emptyset}^{+}) \\\\ \u0026 = 1 - \\sum_{r=1}^{n} (-1)^{r-1}\\sum_{J\\subseteq[n],|J|=r}\\mathbb{P}\\left( E_{J}^{+} \\right) \\\\ \u0026 = \\mathbb{P}(E_{\\emptyset}^{+})- \\sum_{r=1}^{n} (-1)^{r-1}\\sum_{J\\subseteq[n],|J|=r}\\mathbb{P}\\left( E_{J}^{+} \\right) \\\\ \u0026 = \\sum_{r=0}^{n} (-1)^{r}\\sum_{J\\subseteq[n],|J|=r}\\mathbb{P}\\left( E_{J}^{+} \\right) \\\\ \u0026 = \\sum_{J\\subseteq[n]}(-1)^{\\left| J \\right| }\\mathbb{P}(E_{J}^{+}) \\end{align*} $$ (4)\n要证明 $ \\mathbb{P}(E_{J}^{+})=\\left( \\prod_{i=1}^{n}\\left( \\sum_{j\\in [n]\\setminus J} A_{i,j}\\right) \\right) / \\left| T_{n} \\right| $，我们只需要证明 $ \\left| E_{J}^{+} \\right|=\\prod_{i=1}^{n}\\left( \\sum_{j\\in [n]\\setminus J} A_{i,j}\\right) $。\n我们需要找出所有在 $ T_{n} $ 中并且值域为 $ [n]\\setminus J $ 的映射的数量。对于每个 $ i $，可能的 $ f(i) $ 的数量为 $ \\sum_{j\\in [n]\\setminus J}A_{i,j} $（映射到 $ [n]\\setminus J $ 并且图中存在对应的边）。根据乘法原理，由于每个 $ i $ 相互独立，因此总的映射数量为 $$ \\left| E_{J}^{+} \\right|=\\prod_{i=1}^{n}\\left( \\sum_{j\\in [n]\\setminus J} A_{i,j}\\right) $$ 于是 $$ \\mathbb{P}(E_{J}^{+}) = \\dfrac{\\left| E_{J}^{+} \\right| }{\\left| T_{n} \\right| } = \\dfrac{\\prod_{i=1}^{n}\\left( \\sum_{j\\in [n]\\setminus J} A_{i,j}\\right)}{\\left| T_{n} \\right| } $$ 直接带入 $ (3) $ 中得到的容斥原理公式，即可得到 $$ \\begin{align*} \\mathbb{P}(M) \u0026 = \\sum_{J\\subseteq[n]}(-1)^{\\left| J \\right| }\\mathbb{P}(E_{J}^{+}) \\\\ \u0026 = \\sum_{J\\subseteq[n]}(-1)^{\\left| J \\right| }\\dfrac{\\prod_{i=1}^{n}\\left( \\sum_{j\\in [n]\\setminus J} A_{i,j}\\right)}{\\left| T_{n} \\right| } \\\\ \u0026 = \\dfrac{\\sum_{J\\subseteq[n]}(-1)^{\\left| J \\right| }\\prod_{i=1}^{n}\\left( \\sum_{j\\in [n]\\setminus J} A_{i,j}\\right)}{\\left| T_{n} \\right| } \\end{align*} $$\nProblem 4 (1)\n我们定义 $ A_{k} $ 为执行完 $ k $ 次缩边操作以后，最小割 $ C $ 中任意一条边都还没有被删掉的概率，那么 $ p(G,t)=\\mathbb{P}(A_{n-t}) $。\n为了分析 $ A_{k} $，我们定义事件 $ B_{k} $ 为第 $ k $ 次缩边选择的不是 $ C $ 中的点，于是 $ A_{k}=\\bigcap_{i=1}^{k}B_{i} $。因此根据链式法则，得到 $$ p(G,t)=\\mathbb{P}(A_{n-t}) = \\prod_{i=1}^{n-t}\\mathbb{P}\\left( B_{i}\\bigg|\\bigcap_{j=1}^{i-1}B_{i} \\right) $$ 我们关心这个概率的下界，需要说明在前 $ i-1 $ 轮都没有选到 $ C $ 中的边的情况下，第 $ i $ 轮时图中剩下的边足够多。设最小割的大小为 $ k $，注意到此时图中每个点的度数都不小于 $ k $，否则直接取这些边就能得到一个更小的割。因此我们可以知道在第 $ i-1 $ 轮结束，剩下 $ n-i+1 $ 个节点时，图中至少有 $ \\frac{k}{2}(n-i+1) $ 条边，这就可以得到 $$ \\mathbb{P}\\left( B_{i}\\bigg|\\bigcap_{j=1}^{i-1}B_{j} \\right) \\geq 1 - \\dfrac{k}{\\frac{k}{2}\\cdot(n-i+1)} = \\dfrac{n-i-1}{n-i+1} $$ 带入即可得到 $$ \\begin{align*} p(G,t) \u0026 \\geq \\prod_{i=1}^{n-t} \\frac{n-i-1}{n-i+1} = \\dfrac{t(t-1)}{n(n-1)} \\\\ \u0026 = \\dfrac{\\left\\lceil \\frac{n}{\\sqrt{ 2 }} \\right\\rceil \\left\\lceil 1 + \\frac{n}{\\sqrt{ 2 }} \\right\\rceil }{n(n-1)} \\\\ \u0026 \\geq \\dfrac{\\left\\lceil n + \\sqrt{ 2 } \\right\\rceil }{2(n-1)} \u003e \\dfrac{1}{2} \\end{align*} $$ (2)\n我们定义事件 $ A_{1},A_{2} $ 分别表示把图缩到 $ G_{1},G_{2} $ 后没有删掉 $ C $ 中的边，事件 $ B_{1},B_{2} $ 分别表示 KS 算法以 $ G_{1},G_{2} $ 为输入，正确输出了最小割。\n根据第一问，$ \\mathbb{P}(A_{i})=p(G,t)\u003e \\frac{1}{2} $。根据题目条件，$ \\mathbb{P}(B_{i})=p(t)\u003e \\frac{c}{\\log t} $。由于事件 $ A_{i},B_{i} $ 独立（两个算法互不干扰），因此我们对于一个图先执行 contract 算法再执行 KS 算法能正确输出最小割的概率为 $$ \\mathbb{P}(A_{i}\\cap B_{i})=\\mathbb{P}(A_{i})\\cdot\\mathbb{P}(B_{i}) \u003e \\dfrac{1}{2}\\cdot \\dfrac{c}{\\log t} \\xlongequal{c' = c / 2} \\dfrac{c'}{\\log t} $$ 由于我们最后选择的是较小的边集，因此 $ \\text{KS}(G_{1}),\\text{KS}(G_{2}) $ 中只要有一个正确输出了最小割，我们就可以成功找到最小割，因此正确输出最小割的概率为 $$ \\begin{align*} p_{\\text{success}} \u0026 = 1- (1-\\mathbb{P}(A_{1}\\cap B_{1}))(1-\\mathbb{P}(A_{2}\\cap B_{2})) \\\\ \u0026 \u003e 1-\\left( 1-\\dfrac{c'}{\\log t} \\right)^{2} \\\\ \u0026 = \\dfrac{2c'}{\\log t} - \\dfrac{(c')^{2}}{(\\log t)^{2}} \\end{align*} $$\n（经询问 ai 关于 $ \\Omega $ 定义后作出）根据 $ \\Omega $ 记号的定义，$ f(n)=\\Omega(g(n)) $ 说明存在正常数 $ k $ 和 $ n_{0} $ 使得当 $ n\\geq n_{0} $ 时，$ f(n)\\geq k\\cdot g(n) $。\n对于 $ p_{\\text{succsee}} $，我们有（在 $ n\u003e3 $ 时显然有 $ t\u003c n $） $$ p_{\\text{success}} \u003e \\dfrac{1}{\\log t}\\left( 2c' - \\dfrac{(c')^{2}}{\\log t} \\right) \u003e \\dfrac{1}{\\log n}\\left( 2c' - \\dfrac{(c')^{2}}{\\log t} \\right) $$\n当 $ n $ 足够大时，我们显然可以使得 $ \\log t\u003ec' $，此时 $ 2c'-(c')^{2}/(\\log t)\u003ec' $，于是 $$ p_{\\text{success}} \u003e \\dfrac{1}{\\log n}\\cdot c' $$ 根据定义，这就证明了 $ p_{\\text{success}}=\\Omega\\left( \\frac{1}{\\log n} \\right) $。\n(3)\n根据 $ (2) $ 的提示，我们考虑递归调用 contract 算法。下面给出递归算法 $ f $ 的描述：\n输入：无向图 $ G $，规模为 $ n $。 若 $ n\\leq n_{0} $（$ n_{0} $ 为一个比较小的边界值），直接暴力求出最小割。 否则令 $ t=\\lceil 1+n / \\sqrt{ 2 } \\rceil $，独立分别执行两次 contract 算法： $ G_{1}\\leftarrow\\text{contract}(G,t) $； $ G_{2}\\leftarrow\\text{contract}(G,t) $。 分别对 $ G_{1},G_{2} $ 执行递归，返回 $ \\min\\{ f(G_{1}),f(G_{2}) \\} $。 我们设 $ p(n) $ 为单次执行算法 $ f $ 在规模为 $ n $ 的图 $ G $ 上能达到的正确率，那么我们有 $$ p(n) \u003e 1-\\left( 1-\\dfrac{1}{2}p(t) \\right)^{2} = p(t) - \\dfrac{1}{4}p^{2}(t),\\quad t = \\left\\lceil 1+\\dfrac{n}{\\sqrt{ 2 }} \\right\\rceil $$ 由于我们只用考虑 $ n $ 较大的情形，因此可以近似地认为 $ t=\\frac{n}{\\sqrt{ 2 }} $，于是 $$ p(n) \u003e p\\left( \\dfrac{n}{\\sqrt{ 2 }} \\right) - \\dfrac{1}{4}p^{2}\\left( \\dfrac{n}{\\sqrt{ 2 }} \\right) $$ 为了分析这个递推式，我们设递归层数为 $ r=\\left\\lfloor \\log_{\\sqrt{ 2 }} \\frac{n}{n_{0}} \\right\\rfloor=\\Theta(\\log n) $，如果当前递归层数为 $ r-k $，令概率为 $ q_{k} $，于是 $$ q_{k+1} \u003e q_{k} - \\dfrac{1}{4}q_{k}^{2} $$ 对这个式子进一步化简 $$ \\begin{align*} \\dfrac{1}{q_{k+1}} \u0026 \u003c \\dfrac{1}{q_{k}\\left( 1-\\frac{1}{4}q_{k} \\right)} \\\\ \u0026 = \\dfrac{1}{q_{k}}\\cdot \\dfrac{1}{1-\\frac{1}{4}q_{k}} \\\\ \u0026 \u003c \\dfrac{1}{q_{k}} \\left( 1 + \\dfrac{1}{4}q_{k} \\right) \\\\ \u0026 = \\dfrac{1}{q_{k}} + \\dfrac{1}{4} \\end{align*} $$ 因此 $$ \\dfrac{1}{q_{k}} \u003c \\dfrac{1}{q_{0}} + \\dfrac{k}{4} = 1 + \\dfrac{k}{4} \\implies q_{k} \u003e \\dfrac{1}{1 + k / 4} = \\Omega\\left( \\dfrac{1}{k} \\right) $$ （实际上我们并不是从 $ q_{0} $ 开始迭代，不过这并不影响我们计算下界，为了计算方便，直接从 $ q_{0} $ 开始计算，并且认为 $ q_{0}=1 $）\n回到 $ p(n) $，我们这就推出了 $$ p(n) \u003e \\dfrac{4}{r+4} \\implies p(n) = \\Omega\\left( \\dfrac{1}{\\log n} \\right) $$ 所以重复算法 $ O(\\log n) $ 次可以以比较高的概率得到正确答案。下面我们证明这个概率大于 $ \\dfrac{2}{3} $。\n设重复算法 $ \\lceil \\log_{2} n \\rceil $ 次，能得到最小割的概率为 $ p_{\\text{success}} $，那么 $$ p_{\\text{success}} = 1 - (1 - p(n))^{\\lceil \\log_{2} n \\rceil } \u003e 1 - e^{ -p(n) \\cdot \\lceil \\log_{2} n \\rceil } $$\n由于递归层数 $ r=\\left\\lfloor 2\\log_{2} \\dfrac{n}{n_{0}} \\right\\rfloor $，对于足够大的 $ n $，我们可以忽略小常数 $ n_{0} $，因此 $ r\\approx 2\\log_{2}n $。于是 $$ p(n) \u003e \\dfrac{4}{r+4} \\approx \\dfrac{2}{\\log_{2}n + 2} $$ 带入得到 $$ p_{\\text{success}} \u003e 1 - e^{ - \\frac{2\\log_{2} n}{\\log_{2}n + 2} } $$\n我们要证明 $ p_{\\text{success}}\u003e\\frac{2}{3} $，只需要证明 $ \\exp\\left( - \\frac{2\\log_{2}n}{\\log_{2}n + 2} \\right) \u003c \\frac{1}{3} $，即 $$ \\dfrac{2\\log_{2}n}{\\log_{2}n + 2} \u003e \\ln 3 \\approx 1.1 $$ 对于比较大的 $ n $，这是显然成立的。因此我们重复 $ \\lceil \\log_{2}n \\rceil $ 次这个算法能得到正确答案的概率大于 $ \\dfrac{2}{3} $。\n接着求出这个算法的复杂度。设 $ T(n) $ 表示规模为 $ n $ 的图需要的运算次数，那么我们可以得到递推式 $$ T(n) = 2T\\left( \\dfrac{n}{\\sqrt{ 2 }} \\right) + O(m) $$ 如果 $ m=\\Theta(n^{2}) $，是稠密图，那么根据主定理，$ T(n)=\\Theta(n^{2}\\log n) $。\n如果为稀疏图，递归项的是主导，复杂度为 $ T(n)=\\Theta(n^{2}) $。\n综上，算法复杂度为 $ O(n^{2}\\log ^{2}n)=\\tilde{O}(n^{2}) $。优于原来的算法。\n","permalink":"https://diefish1024.github.io/posts/class-notes/math2701-probability-theory/math2701-hw1/","summary":"\u003cp\u003e\u003ca href=\"https://notes.sjtu.edu.cn/s/gHhl2fhcm\"\u003e题目\u003c/a\u003e\u003c/p\u003e\n\u003ch2 id=\"problem-11\"\u003eProblem 1.1\u003c/h2\u003e\n\u003cp\u003e设 $ \\mathcal{F} $ 是一个有限的 $ \\sigma $-代数。定义其中“最小\u0026quot;的元素为其包含于 $ \\mathcal{F} $ 中的子集仅为自身和空集，形式化地描述，若 $ A\\in \\mathcal{F} $ 为“最小”的元素，那么如果 $ B\\in \\mathcal{F} $ 并且 $ B\\subseteq A $，那么一定有 $ B\\in \\{ \\emptyset,A \\} $。\u003c/p\u003e\n\u003cp\u003e可以证明这样的元素存在并且有限：如果不存在，那么我们每次任取一个 $ \\mathcal{F} $ 中的元素，都能找到属于它的一个更小的元素，但 $ \\mathcal{F} $ 是有限集，所以这样的过程不可能一直重复下去，因此“最小”元素必然存在并且有限。\u003c/p\u003e\n\u003cp\u003e我们设所有这些不同的“最小”元素为 $ S=\\{ A_{1},A_{2},\\dots,A_{n} \\} $。我们先证明这构成了全空间的一个分划：\u003c/p\u003e\n\u003cp\u003e首先这些元素肯定两两不相交，否则不满足“最小”的定义。假设 $ A_{i}\\cap A_{j}= C\\neq\\emptyset $，根据“最小”，非空的 $ C $ 是 $ A_{i} $ 的子集，一定有 $ C=A_{i} $，同样也有 $ C=A_{j} $，这就推出了 $ A_{i}=A_{j} $，从而矛盾。\u003c/p\u003e","title":"MATH2701 HW1"},{"content":"Exercise 1 (Multiplication of block matrices). Consider two block matrices $$ A = \\begin{pmatrix} A_{11} \u0026 \\cdots \u0026 A_{1t} \\\\ \\vdots \u0026 \\ddots \u0026 \\vdots \\\\ A_{p1} \u0026 \\cdots \u0026 A_{pt} \\end{pmatrix} \\quad \\text{and} \\quad B = \\begin{pmatrix} B_{11} \u0026 \\cdots \u0026 B_{1q} \\\\ \\vdots \u0026 \\ddots \u0026 \\vdots \\\\ B_{t1} \u0026 \\cdots \u0026 B_{tq} \\end{pmatrix} $$ Moreover, for every $ i \\in [p] $, $ j \\in [t] $, and $ l \\in [q] $ the number of columns of $ A_{ij} $ is equal to the number of rows of $ B_{jl} $. In particular, $ A_{ij} \\cdot B_{jl} $ is defined. Prove that $$ A \\cdot B = \\begin{pmatrix} C_{11} \u0026 \\cdots \u0026 C_{1q} \\\\ \\vdots \u0026 \\ddots \u0026 \\vdots \\\\ C_{p1} \u0026 \\cdots \u0026 C_{pq} \\end{pmatrix} $$ with $$ C_{il} = \\sum_{j \\in [t]} A_{ij} B_{jl} $$ for any $ i \\in [p] $ and $ l \\in [q] $.\nProof:\nLet $ A = (a_{\\alpha\\beta}) $ and $ B = (b_{\\beta\\gamma}) $. The entry $ (AB)_{\\alpha\\gamma} $ is given by $ (AB)_{\\alpha\\gamma} = \\sum_{\\beta} a_{\\alpha\\beta} b_{\\beta\\gamma} $.\nConsider a specific entry $ (C_{il})_{uv} $ within the block $ C_{il} $ of the product matrix $ AB $. This entry corresponds to a global row index $ \\alpha $ in $ A $\u0026rsquo;s $ i $-th block row (specifically, the $ u $-th row within that block row) and a global column index $ \\gamma $ in $ B $\u0026rsquo;s $ l $-th block column (specifically, the $ v $-th column within that block column).\nThe summation over $ \\beta $ can be partitioned according to the column blocks of $ A $ and the row blocks of $ B $ that correspond to the intermediate index $ j $. Specifically, the range of $ \\beta $ for which $ a_{\\alpha\\beta} $ belongs to $ A_{ij} $ and $ b_{\\beta\\gamma} $ belongs to $ B_{jl} $ forms a segment. Summing these segments yields: $$ (C_{il})_{uv} = \\sum_{\\beta} a_{\\alpha\\beta} b_{\\beta\\gamma} = \\sum_{j=1}^{t} \\left( \\sum_{\\substack{\\beta_j \\in \\text{columns of } A_{ij} \\\\ \\text{and rows of } B_{jl}}} (A_{ij})_{u\\beta_j} (B_{jl})_{\\beta_j v} \\right) $$ The inner sum $ \\sum_{\\beta_j} (A_{ij})_{u\\beta_j} (B_{jl})_{\\beta_j v} $ precisely represents the $ (u,v) $-th entry of the product matrix $ A_{ij} B_{jl} $.\nTherefore, we can write: $$ (C_{il})_{uv} = \\sum_{j=1}^{t} (A_{ij} B_{jl})_{uv} $$ Since this equality holds for every entry $ (u,v) $ in the block $ C_{il} $, it follows that the block matrix equation is true: $$ C_{il} = \\sum_{j \\in [t]} A_{ij} B_{jl} $$\nExercise 2 Let $ P $ be a permutation matrix and consider its column vectors $ p_1, \\ldots, p_n $. (i) Prove that each pair of distinct (i.e., $ i \\neq j $) $ p_i $ and $ p_j $ are perpendicular. (ii) Prove each $ p_i $ is a unit vector. (iii) Using (i) and (ii) prove that $ P^{-1} = P^T $.\n(i)\nFor distinct columns $ p_i $ and $ p_j $ (where $ i \\neq j $), each vector has a single \u0026lsquo;1\u0026rsquo; at different positions.\nWhen computing their dot product $ p_i^T p_j = \\sum_k (p_i)_k (p_j)_k $, for any given $ k $, at least one of $ (p_i)_k $ or $ (p_j)_k $ must be \u0026lsquo;0\u0026rsquo; because their \u0026lsquo;1\u0026rsquo;s are in different rows. Thus, $ (p_i)_k (p_j)_k = 0 $ for all $ k $, which implies $ p_i^T p_j = 0 $. Therefore, $ p_{i} $ and $ p_j $ are perpendicular for $ i \\neq j $.\n(ii)\nA column vector $ p_i $ has exactly one \u0026lsquo;1\u0026rsquo; and all other entries are \u0026lsquo;0\u0026rsquo;, its norm is $ p_i^T p_i = \\sum_k (p_i)_k^2 = 1 $. Therefore, $ \\|p_i\\| = 1 $, proving $ p_i $ is a unit vector.\n(iii)\nConsider the entry $ (P^T P)_{ij} $ of the product $ P^T P $. This entry is the dot product of the $ i $-th column of $ P $ with its $ j $-th column: $ (P^T P)_{ij} = p_i^T p_j $.\nFrom part (i), if $ i \\neq j $, then $ p_i^T p_j = 0 $. From part (ii), if $ i = j $, then $ p_i^T p_i = 1 $. Thus $ P^T P = I $, therefore, $ P^{-1} = P^T $.\nExercise 3 Let $ A = [a_1, \\ldots, a_n] $ be an $ n \\times n $ matrix such that $ A^{-1} = A^T $. Prove: (i) Each pair of distinct column vectors $ a_i $ and $ a_j $ are perpendicular. (ii) Each $ a_i $ is a unit vector. Prove that the same is true for the row vectors of $ A $.\n(i) \u0026amp; (ii) Proof for Column Vectors\nGiven $ A^{-1} = A^T $, it follows that $ A^T A = I $.\nThe entry $ (A^T A)_{kl} $ is the dot product of the $ k $-th column of $ A $ ($ a_k $) and the $ l $-th column of $ A $ ($ a_l $), i.e., $ (A^T A)_{kl} = a_k^T a_l $.\nSince $ A^T A = I $, we have:\nFor $ k \\neq l $: $ a_k^T a_l = 0 $. This proves that distinct column vectors $ a_k $ and $ a_l $ are perpendicular. For $ k = l $: $ a_k^T a_k = 1 $. This proves that $ \\|a_k\\|^2 = 1 $, so each column vector $ a_k $ is a unit vector. Proof for Row Vectors\nLet $ A $ have row vectors $ r_1, \\ldots, r_n $. From $ A^{-1} = A^T $, it also follows that $ A A^T = I $.\nThe entry $ (A A^T)_{kl} $ is the dot product of the $ k $-th row of $ A $ ($ r_k $) and the $ l $-th row of $ A $ ($ r_l $), i.e., $ (A A^T)_{kl} = r_k r_l^T $.\nSince $ A A^T = I $, we have:\nFor $ k \\neq l $: $ r_k r_l^T = 0 $. This proves that distinct row vectors $ r_k $ and $ r_l $ are perpendicular. For $ k = l $: $ r_k r_k^T = 1 $. This proves that $ \\|r_k\\|^2 = 1 $, so each row vector $ r_k $ is a unit vector. Exercise 4 Let $ A $ be a square matrix such that there are $ B $ and $ C $ with $ BA = AC = I $. Note we didn\u0026rsquo;t assume per se $ B = C $. However, prove that $ B = C $. In particular $ A $ is invertible with $ A^{-1} = B = C $.\nProof: $$ \\begin{align*} BA \u0026 = I \\\\ (BA)C \u0026 = IC = C \\\\ B(AC)\u0026 = C \\\\ BI = B \u0026 = C \\end{align*} $$ Thus, $ B $ and $ C $ must be equal. This proves that if both a left inverse and a right inverse exist for a square matrix $ A $, they are unique and identical, defining the inverse $ A^{-1} = B = C $.\nExercise 5 This is intended to repeat what we have learnt in the class. Prove in a vector space: (i) $ 0v = 0 $. (ii) $ (-1)v = -v $. (iii) $ -(v + w) = (-v) + (-w) $. (iv) $ c0 = 0 $. (v) $ c(-v) = (-c)v = -(cv) $.\n(i) $$ 0v = (0+0)v = 2\\cdot0v \\implies 0v = 0 $$ (ii) $$ v + (-1)v = (1 + (-1))v = 0v =0 \\implies (-1)v = -v $$ (iii) $$ (v+w) + ((-v) + (-w)) = (v + (-v)) + (w + (-w)) = 0 \\implies (-v+w) = (-v) + (-w) $$ (iv) $$ c\\cdot \\vec{0} = c\\cdot(\\vec{0} + \\vec{0}) = 2(c \\cdot \\vec{0}) \\implies c\\cdot \\vec{0} = 0 $$ (v) $$ c(-v) = c((-1)v) = (c \\cdot (-1))v = (-c)v $$ $$ cv + (-c)v = (c + (-c))v = 0v = 0 \\implies (-c)v = -(cv) $$\nCombining these, we have $ c(-v) = (-c)v = -(cv) $.\n","permalink":"https://diefish1024.github.io/posts/class-notes/math1205h-linear-algebra/math1205h-hw3/","summary":"\u003ch2 id=\"exercise-1\"\u003eExercise 1\u003c/h2\u003e\n\u003cblockquote\u003e\n\u003cp\u003e(Multiplication of block matrices). Consider two block matrices\n$$ \n\n A = \\begin{pmatrix}\n A_{11} \u0026 \\cdots \u0026 A_{1t} \\\\\n \\vdots \u0026 \\ddots \u0026 \\vdots \\\\\n A_{p1} \u0026 \\cdots \u0026 A_{pt}\n \\end{pmatrix}\n \\quad \\text{and} \\quad\n B = \\begin{pmatrix}\n B_{11} \u0026 \\cdots \u0026 B_{1q} \\\\\n \\vdots \u0026 \\ddots \u0026 \\vdots \\\\\n B_{t1} \u0026 \\cdots \u0026 B_{tq}\n \\end{pmatrix}\n \n $$\nMoreover, for every $ i \\in [p] $, $ j \\in [t] $, and $ l \\in [q] $ the number of columns of $ A_{ij} $ is equal to the number of rows of $ B_{jl} $. In particular, $ A_{ij} \\cdot B_{jl} $ is defined. Prove that\n$$ \n\n A \\cdot B = \\begin{pmatrix}\n C_{11} \u0026 \\cdots \u0026 C_{1q} \\\\\n \\vdots \u0026 \\ddots \u0026 \\vdots \\\\\n C_{p1} \u0026 \\cdots \u0026 C_{pq}\n \\end{pmatrix}\n \n $$\nwith\n$$ \n\n C_{il} = \\sum_{j \\in [t]} A_{ij} B_{jl}\n \n $$\nfor any $ i \\in [p] $ and $ l \\in [q] $.\u003c/p\u003e","title":"MATH1205H HW3"},{"content":"Exercise 1 What rows or columns or matrices do you multiply to find\nthe second column of $ AB $ ? the first row of $ AB $ ? the entry in row $ 3 $, column $ 5 $ of $ AB $ ? the entry in row $ 1 $, column $ 1 $ of $ CDE $ ? To find the second column of $ AB $, we multiply matrix $ A $ by the second column of matrix $ B $.\nMultiply the first row of $ A $ by matrix $ B $.\nMultiply the third row of $ A $ and the fifth column of $ B $.\nMultiply first the first row of $ C $ by $ D $, then product the first column of $ E $.\nExercise 2 Show that $ (A + B)^2 $ is different from $ A^2 + 2AB + B^2 $, when $ A=\\begin{pmatrix} 1 \u0026 2 \\\\ 0 \u0026 0 \\end{pmatrix} $ and $ B=\\begin{pmatrix} 1 \u0026 0 \\\\ 3 \u0026 0 \\end{pmatrix} $.\nWrite down the correct rule for $ (A + B)(A + B) = A^2 + \\_\\_\\_\\_\\_\\_\\_\\_ + B^2 $.\nFirst, we find the sum of matrices $ A $ and $ B $ : $$ A+B = \\begin{pmatrix} 1 \u0026 2 \\\\ 0 \u0026 0 \\end{pmatrix} + \\begin{pmatrix} 1 \u0026 0 \\\\ 3 \u0026 0 \\end{pmatrix} = \\begin{pmatrix} 1+1 \u0026 2+0 \\\\ 0+3 \u0026 0+0 \\end{pmatrix} = \\begin{pmatrix} 2 \u0026 2 \\\\ 3 \u0026 0 \\end{pmatrix} $$ Next, we compute the square of $ (A+B) $ : $$ (A+B)^2 = \\begin{pmatrix} 2 \u0026 2 \\\\ 3 \u0026 0 \\end{pmatrix} \\begin{pmatrix} 2 \u0026 2 \\\\ 3 \u0026 0 \\end{pmatrix} = \\begin{pmatrix} 10 \u0026 4 \\\\ 6 \u0026 6 \\end{pmatrix} $$ Then we need to compute $ A^2 $, $ B^2 $, and $ 2AB $ separately.\n$$ A^2 = \\begin{pmatrix} 1 \u0026 2 \\\\ 0 \u0026 0 \\end{pmatrix} \\begin{pmatrix} 1 \u0026 2 \\\\ 0 \u0026 0 \\end{pmatrix} = \\begin{pmatrix} 1 \u0026 2 \\\\ 0 \u0026 0 \\end{pmatrix}, B^2 = \\begin{pmatrix} 1 \u0026 0 \\\\ 3 \u0026 0 \\end{pmatrix} \\begin{pmatrix} 1 \u0026 0 \\\\ 3 \u0026 0 \\end{pmatrix} = \\begin{pmatrix} 1 \u0026 0 \\\\ 3 \u0026 0 \\end{pmatrix} $$ $$ AB = \\begin{pmatrix} 1 \u0026 2 \\\\ 0 \u0026 0 \\end{pmatrix} \\begin{pmatrix} 1 \u0026 0 \\\\ 3 \u0026 0 \\end{pmatrix} = \\begin{pmatrix} 7 \u0026 0 \\\\ 0 \u0026 0 \\end{pmatrix} $$ Thus, we can calculate the result $$ A^2 + 2AB + B^2 = \\begin{pmatrix} 1 \u0026 2 \\\\ 0 \u0026 0 \\end{pmatrix} + \\begin{pmatrix} 14 \u0026 0 \\\\ 0 \u0026 0 \\end{pmatrix} + \\begin{pmatrix} 1 \u0026 0 \\\\ 3 \u0026 0 \\end{pmatrix} = \\begin{pmatrix} 16 \u0026 2 \\\\ 3 \u0026 0 \\end{pmatrix} $$ We found: $ (A+B)^2 = \\begin{pmatrix} 10 \u0026 4 \\\\ 6 \u0026 6 \\end{pmatrix} ,A^2 + 2AB + B^2 = \\begin{pmatrix} 16 \u0026 2 \\\\ 3 \u0026 0 \\end{pmatrix} $.\nSince $ \\begin{pmatrix} 10 \u0026 4 \\\\ 6 \u0026 6 \\end{pmatrix} \\neq \\begin{pmatrix} 16 \u0026 2 \\\\ 3 \u0026 0 \\end{pmatrix} $, we have shown that $ (A + B)^2 $ is different from $ A^2 + 2AB + B^2 $ for the given matrices. This difference arises because matrix multiplication is generally not commutative ($ AB \\neq BA $).\nThe correct rule for expanding $ (A+B)(A+B) $ for matrices $ A $ and $ B $ is: $ (A + B)(A + B) = A^2 + \\underline{AB+BA} + B^2 $.\nExercise 3 If you do a row operation on $ A $ and then a column operation, the result is the same as if you did the column operation first. Why is this true?\nProof:\nPerforming a row operation on a matrix $ A $ is equivalent to multiplying $ A $ on its left by a corresponding elementary matrix, let\u0026rsquo;s call it $ E_R $. So, the operation results in $ E_R A $. Then, perform the column operation on the result $ E_R A $. This means multiplying $ E_R A $ on the right by $ E_C $, giving the final result $ (E_R A) E_C $.\nPerforming a column operation on a matrix $ A $ is equivalent to multiplying $ A $ on its right by a corresponding elementary matrix, let\u0026rsquo;s call it $ E_C $. So, the operation results in $ A E_C $. Then, perform the row operation on the result $ A E_C $. This means multiplying $ A E_C $ on the left by $ E_R $, giving the final result $ E_R (A E_C) $.\nAccording to the associativity of matrix multiplication, we have $ (E_R A) E_C = E_R (A E_C) $. Therefore, the final matrix result is the same regardless of the order in which the row and column operations are performed.\nExercise 4 Let $ A=\\begin{pmatrix} 2 \u0026 3 \\\\ 1 \u0026 2 \\\\ 7 \u0026 100 \\end{pmatrix} $. Prove that there is no $ 2 \\times 3 $ matrix $ B $ such that $ AB = I $.\n(Please only use the materials we have learnt so far, in particular the geometric interpretation of $ Ab $ is a linear combination of the column vectors of $ A $).\nProof:\nFirstly, if $ AB=I $, $ I $ must be the $ 3 \\times 3 $ identity matrix ($ I_3 $).\nConsidering the column space of matrix $ A $, which has two column vectors: $ A_1 = \\begin{pmatrix} 2 \\\\ 1 \\\\ 7 \\end{pmatrix} $ and $ A_2 = \\begin{pmatrix} 3 \\\\ 2 \\\\ 100 \\end{pmatrix} $. These two vectors are linearly independent, so the column space $ Col(A) $ is a two-dimensional subspace of $ \\mathbb{R}^3 $ (a plane through the origin).\nIf $ AB=I_3 $, then each column of $ I_3 $ must be in the column space of $ A $. That is, for each standard basis vector $ e_j $ (the columns of $ I_3 $), there must exist a column vector $ b_j $ from $ B $ such that $ A b_j = e_j $. This means $ e_j $ must be a linear combination of $ A $\u0026rsquo;s column vectors, and thus $ e_j \\in Col(A) $.\nThe columns of $ I_3 $ are $ e_1=\\begin{pmatrix} 1 \\\\ 0 \\\\ 0 \\end{pmatrix} $, $ e_2=\\begin{pmatrix} 0 \\\\ 1 \\\\ 0 \\end{pmatrix} $, and $ e_3=\\begin{pmatrix} 0 \\\\ 0 \\\\ 1 \\end{pmatrix} $. These three vectors are linearly independent and span the entire $ \\mathbb{R}^3 $. However, $ Col(A) $ is only a two-dimensional subspace. A two-dimensional subspace cannot contain three linearly independent vectors that span a three-dimensional space.\nTherefore, there is no $ 2 \\times 3 $ matrix $ B $ such that $ AB=I $.\nExercise 5 Let $ m, n \\ge 1 $ and $ A, B $ two $ m \\times n $ matrices. Prove that if for all $ x \\in \\mathbb{R}^n $ we have $ Ax = Bx $, then $ A = B $.\nProof:\nWe are given $ Ax = Bx $ for all $ x \\in \\mathbb{R}^n $. This can be rewritten as $ (A-B)x = 0 $ for all $ x \\in \\mathbb{R}^n $. Let . Then the condition becomes for all .\nConsider the standard basis vectors $ e_1, e_2, \\ldots, e_n $ in $ \\mathbb{R}^n $. Since $ Cx=0 $ for all $ x $, it must hold for each $ e_j $. Therefore, implies that every column of is the zero vector.\nIf all columns of matrix $ C $ are the zero vector, then $ C $ must be the zero matrix. Since $ C=A-B $, we have $ A-B=0 $, which implies $ A=B $.\n","permalink":"https://diefish1024.github.io/posts/class-notes/math1205h-linear-algebra/math1205h-hw2/","summary":"\u003ch2 id=\"exercise-1\"\u003eExercise 1\u003c/h2\u003e\n\u003cblockquote\u003e\n\u003cp\u003eWhat rows or columns or matrices do you multiply to find\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003ethe second column of $ AB $ ?\u003c/li\u003e\n\u003cli\u003ethe first row of $ AB $ ?\u003c/li\u003e\n\u003cli\u003ethe entry in row $ 3 $, column $ 5 $ of $ AB $ ?\u003c/li\u003e\n\u003cli\u003ethe entry in row $ 1 $, column $ 1 $ of $ CDE $ ?\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/blockquote\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003eTo find the second column of $ AB $, we multiply matrix $ A $ by the second column of matrix $ B $.\u003c/p\u003e","title":"MATH1205H HW2"},{"content":"Principle of Inclusion and Exclusion 对于任意有限集合 $ A_1, A_2, \\dots, A_n $，容斥原理如下： $$ \\left| \\bigcup_{i=1}^{n} A_i \\right| = \\sum_{i=1}^{n} \\left| A_i \\right| - \\sum_{1\\leq i\u003c j\\leq n} \\left| A_i \\cap A_j \\right| + \\dots + (-1)^{n} \\left| \\bigcap_{i=1}^{n} A_i \\right| $$\n可更紧凑地表示为 $$ \\left| \\bigcup_{i=1}^{n} A_i \\right| = \\sum_{k=1}^{n} (-1)^{k-1} \\sum_{S \\subseteq [n], |S|=k} \\left| \\bigcap_{i \\in S} A_i \\right| $$ 或 $$ \\left| \\bigcup_{i=1}^{n} A_i \\right| = \\sum_{\\emptyset \\neq S \\subseteq [n]} (-1)^{|S|-1} \\left| \\bigcap_{i \\in S} A_i \\right| $$\n证\n我们通过观察每个元素 $ x $ 对等式两边的贡献来证明。若 $ x $ 不属于任何集合 $ A_i $，则其贡献为 $ 0 $。若 $ x $ 属于恰好 $ m \\geq 1 $ 个集合，则对左侧贡献 $ 1 $，对右侧贡献 $ \\sum_{j=1}^m (-1)^{j-1} \\binom{m}{j} $。由二项式定理，$ \\sum_{j=0}^m (-1)^j \\binom{m}{j} = 0 $（当 $ m \\geq 1 $），故 $ \\sum_{j=1}^m (-1)^{j-1} \\binom{m}{j} = 1 $，等式成立。\n补集形式\n在组合学中，常使用补集形式。给定全集 $ U $ 和子集 $ B_1, B_2, \\dots, B_n $（视为“坏事件”），不属于任何 $ B_i $ 的元素数量为： $$ \\left| U \\setminus \\bigcup_{i=1}^n B_i \\right| = \\sum_{S \\subseteq [n]} (-1)^{|S|} \\left| \\bigcap_{i \\in S} B_i \\right| $$\n其中约定 $ \\bigcap_{i \\in \\emptyset} B_i = U $。\nDerangements and Surjective Functions Surjective Counting 考虑从 $ [n] $ 到 $ [m] $ 的满射（surjective functions）。设全集 $ U $ 为所有映射，$ |U| = m^n $。定义 $ B_i $ 为没有元素映射到 $ i \\in [m] $ 的映射集合，则 $ \\left| \\bigcap_{k \\in S} B_k \\right| = (m - |S|)^n $。由补集形式，满射数量为： $$ m! \\left\\{ n \\atop m \\right\\} = \\sum_{k=0}^m (-1)^k \\binom{m}{k} (m-k)^n = \\sum_{k=0}^m (-1)^{m-k} \\binom{m}{k} k^n $$\nDerangement Counting 错排：一个置换 $ f: [n] \\to [n] $ 称为错排，若无固定点，即 $ \\forall x \\in [n], f(x) \\neq x $。错排的循环分解不含大小为 $ 1 $ 的循环。$ D_n $ 表示 $ n $ 个元素的错排数量。\n方法 1：容斥原理\n设 $ U $ 为 $ [n] $ 上的所有置换，$ |U| = n! $。定义 $ B_i $ 为固定 $ i $ 的置换集合（$ f(i) = i $）。则 $ \\left| \\bigcap_{i \\in S} B_i \\right| = (n - |S|)! $，错排数量为 $$ D_n = \\sum_{S \\subseteq [n]} (-1)^{|S|} (n - |S|)! = n! \\sum_{k=0}^n \\frac{(-1)^k}{k!} $$ 当 $ n \\to \\infty $，$ D_n / n! \\approx 1/e $，表示随机置换为错排的概率趋于 $ 1/e $。\n方法 2：循环分解\n分解成大小 $ \\geq 2 $ 的循环。对于一个大小至少为 $ 2 $ 的循环，它的 EGF 为 $$ C(x) = \\ln \\dfrac{1}{1-x} - x $$ 错排看成一系列这样的循环的集合，所以 $$ D(x) = \\exp(C(x)) = \\dfrac{1}{1-x}\\cdot e^{ -x } $$ 从而 $$ \\begin{align*} D_{n} = n![x^{n}]D(x) \u0026 = n!\\sum_{k=0}^{n} ([x^{k}]e^{ -x })\\left( [x^{n-k} ] \\dfrac{1}{1-x} \\right) \\\\ \u0026 = n!\\sum_{k=0}^{n} \\dfrac{(-1)^{k}}{k!}\\cdot 1 \\end{align*} $$\n方法 3：指数生成函数\n先求出递推式\n递推 1：$ D_n = (n-1)(D_{n-1} + D_{n-2}) $，初始条件 $ D_0 = 1 $，$ D_1 = 0 $。\n证：考虑错排 $ f $，$ f(n) = k \\neq n $。分两种情况：\n若 $ f(k) = n $，移除 $ n $ 和 $ k $，其余 $ n-2 $ 个元素形成错排，贡献 $ (n-1)D_{n-2} $。 若 $ f(k) \\neq n $，构造 $ g: [n-1] \\to [n-1] $，使 $ g(i) = f(i) $（$ i \\neq k $），$ g(k) = n $，$ g $ 为 $ [n-1] $ 上的错排，贡献 $ (n-1)D_{n-1} $。 递推 2：$ D_n = n D_{n-1} + (-1)^n $。\n证：由第一种递推关系代数推导，或考虑若 $ \\sigma(n) = n $，则其余 $ n-1 $ 个元素形成错排，贡献 $ D_{n-1} $。\n定义 $ D(x) = \\sum_{n=0}^\\infty \\frac{D_n}{n!} x^n $。由递推 $ D_n = n D_{n-1} + (-1)^n $，得微分方程 $ D(x) - x D'(x) = e^{-x} $，解得 $ D(x) = \\frac{e^{-x}}{1-x} $。展开： $$ D(x) = \\left( \\sum_{k=0}^\\infty \\frac{(-1)^k}{k!} x^k \\right) \\left( \\sum_{j=0}^\\infty x^j \\right) $$\n提取 $ x^n $ 的系数，$ \\frac{D_n}{n!} = \\sum_{k=0}^n \\frac{(-1)^k}{k!} $，即 $ D_n = n! \\sum_{k=0}^n \\frac{(-1)^k}{k!} $。\n方法 3：置换拆分\n把一个置换看成若干个环的组合，错排表示拆分中没有大小为 $ 1 $ 的环。（后续过程待完成）\n方法 4：固定点计数\n恰有 $ k $ 个固定点的置换数为 $ \\binom{n}{k} D_{n-k} $。总置换数为 $$ n! = \\sum_{k=0}^n \\binom{n}{k} D_{n-k} $$ 通过莫比乌斯反演，可推导 $ D_n $ 的显式公式。\n积和式\n定义 $ n \\times n $ 矩阵 $ A = (a_{i,j}) $ 的积和式为 $$ \\text{perm } A = \\sum_{\\sigma \\in S_n} \\prod_{i=1}^n a_{i, \\sigma(i)} $$\n若 $ A $ 为 0-1 矩阵，perm $ A $ 计数满足 $ a_{i, \\sigma(i)} \\neq 0 $ 的置换数。特别地，$ D_n = \\text{perm}(1_n - I_n) $。对于二分图的邻接矩阵，perm $ A $ 计数完美匹配数量。\n容斥计算积和式\n设 $ U = S_n $，$ B_i = {\\sigma \\in S_n \\mid a_{i, \\sigma(i)} = 0} $。令 $ R = {(i,j) \\mid a_{i,j} = 0} $，$ r_k $ 为 $ R $ 中 $ k $ 个互不共享行或列的坐标对数量。则 $$ \\sum_{S: |S|=k} \\left| \\bigcap_{i \\in S} B_i \\right| = r_k (n-k)! $$\n积和式为 $$ \\text{perm } A = \\sum_{k=0}^n (-1)^k r_k (n-k)! $$\n更优方法：设 $ U $ 为满足 $ a_{i,f(i)} \\neq 0 $ 的映射集合，$ B_i $ 为 $ f^{-1}(i) = \\emptyset $ 的映射集合。则： $$ |U| = \\prod_{i=1}^n \\left( \\sum_{j=1}^n a_{i,j} \\right), \\quad \\left| \\bigcap_{k \\in S} B_k \\right| = \\prod_{i=1}^n \\left( \\sum_{j \\in [n] \\setminus S} a_{i,j} \\right) $$\nRyser 公式： $$ \\text{perm } A = \\sum_{S \\subseteq [n]} (-1)^{|S|} \\prod_{i=1}^n \\left( \\sum_{j \\in [n] \\setminus S} a_{i,j} \\right) $$\nMöbius Inversion in Number Theory 欧拉函数\n欧拉函数 $ \\phi(n) $ 为 $ [n] $ 中与 $ n $ 互质的正整数数量： $$ \\phi(n) = \\sum_{k=1}^n [\\gcd(n,k) = 1] $$ $ \\phi(n) $ 是积性函数：若 $ \\gcd(a,b) = 1 $，则 $ \\phi(ab) = \\phi(a)\\phi(b) $。对于素数 $ p $，$ \\phi(p) = p-1 $，$ \\phi(p^r) = (p-1)p^{r-1} $。\n性质：$ \\sum_{d|n} \\phi(d) = n $。\n证：对于 $ k \\in [n] $，若 $ \\gcd(n,k) = d $，则 $ \\gcd(n/d, k/d) = 1 $。故 $$ n = \\sum_{d|n} |{k \\in [n] \\mid \\gcd(n,k) = d}| = \\sum_{d|n} \\phi(n/d) = \\sum_{d|n} \\phi(d) $$\n容斥计算 $ \\phi(n) $\n设 $ n = p_1^{r_1} \\dots p_m^{r_m} $，$ U = [n] $，$ B_i = \\{k \\in [n] \\mid p_i | k\\} $。则 $ \\phi(n) = \\left| U \\setminus \\bigcup_{i=1}^m B_i \\right| $，且 $ \\left| \\bigcap_{i \\in S} B_i \\right| = \\frac{n}{\\prod_{i \\in S} p_i} $。由补集形式 $$ \\phi(n) = n \\prod_{i=1}^m \\left( 1 - \\frac{1}{p_i} \\right) $$ 莫比乌斯函数 $$ \\mu(n) = \\begin{cases} 1 \u0026 \\text{若 } n = 1 \\\\ 0 \u0026 \\text{若 } \\exists p, p^2 | n \\\\ (-1)^k \u0026 \\text{若 } n = p_1 \\dots p_k \\text{（不同素数）} \\end{cases} $$则 $$ \\phi(n) = \\sum_{d|n} \\mu(d) \\frac{n}{d} $$\n莫比乌斯反演公式\n若 $ f = g * 1 = \\sum_{d|n} g(d) $，则 $$ g = f * \\mu = \\sum_{d|n} f(d) \\mu(n/d) $$\n证明：设 $ n = p_1^{r_1} \\dots p_m^{r_m} $，$ U = \\bigcup_{d|n} T_d $，$ T_d = \\{(d,j) \\mid 1 \\leq j \\leq g(d)\\} $，$ B_i = \\{(d,j) \\in U \\mid p_i \\mid d\\} $。则 $ g(n) = \\left| U \\setminus \\bigcup B_i \\right| $，且 $ |U| = f(n) $，$ \\left| \\bigcap_{i \\in S} B_i \\right| = f\\left( n / \\prod_{i \\in S} p_i \\right) $。由补集形式： $$ g(n) = \\sum_{S \\subseteq [m]} (-1)^{|S|} f \\left( n / \\prod_{i \\in S} p_i \\right) = \\sum_{d|n} \\mu(d) f(n/d) $$\n集合函数反演\n若 $ f(S) = \\sum_{T \\subseteq S} g(T) $，则 $$ g(S) = \\sum_{T \\subseteq S} (-1)^{|S|-|T|} f(T) $$\n应用：有限域上不可约多项式\n在有限域 $ F_q $（$ q = p^t $）上，次数为 $ n $ 的首一不可约多项式数量 $ N_n $ 满足 $$ q^n = \\sum_{d|n} d N_d $$\n由莫比乌斯反演 $$ N_n = \\frac{1}{n} \\sum_{d|n} \\mu(n/d) q^d $$\n证：设 $ F(x) = \\sum_{n=0}^\\infty q^n x^n = \\frac{1}{1-qx} $ 为首一多项式数量的 OGF。由唯一分解定理 $$ F(x) = \\prod_{d=1}^\\infty \\left( \\frac{1}{1-x^d} \\right)^{N_d} $$\n取对数并比较 $ x^n $ 系数，得 $ q^n = \\sum_{d|n} d N_d $，再反演得结果。\n","permalink":"https://diefish1024.github.io/posts/class-notes/cs0901-combinatorics/lect3-the-principle-of-inclusion-and-exclusion/","summary":"\u003ch2 id=\"principle-of-inclusion-and-exclusion\"\u003ePrinciple of Inclusion and Exclusion\u003c/h2\u003e\n\u003cp\u003e对于任意有限集合 $ A_1, A_2, \\dots, A_n $，容斥原理如下：\n$$ \n  \n\\left| \\bigcup_{i=1}^{n} A_i \\right| = \\sum_{i=1}^{n} \\left| A_i \\right| - \\sum_{1\\leq i\u003c j\\leq n} \\left| A_i \\cap A_j \\right| + \\dots + (-1)^{n} \\left| \\bigcap_{i=1}^{n} A_i \\right|  \n\n $$\u003cbr\u003e\n可更紧凑地表示为\n$$ \n  \n\\left| \\bigcup_{i=1}^{n} A_i \\right| = \\sum_{k=1}^{n} (-1)^{k-1} \\sum_{S \\subseteq [n], |S|=k} \\left| \\bigcap_{i \\in S} A_i \\right|  \n\n $$\n或\n$$ \n  \n\\left| \\bigcup_{i=1}^{n} A_i \\right| = \\sum_{\\emptyset \\neq S \\subseteq [n]} (-1)^{|S|-1} \\left| \\bigcap_{i \\in S} A_i \\right|  \n\n $$\u003c/p\u003e","title":"Lect3-The Principle of Inclusion and Exclusion"},{"content":"Problem 1 用生成函数求解递推式 $$ a_{n} = 4a_{n-1} - 5a_{n-2} + 2a_{n-3} $$ 初始值为 $ a_{0}=0,a_{1}=3,a_{2}=7 $。\n解：\n设数列 $ \\{ a_{n} \\} $ 的生成函数为 $ F(x) $，那么根据递推式和初值 $ a_{0}=0,a_{1}=3,a_{2}=7 $ 得到 $$ F(x) = 4xF(x) - 5x^{2}F(x) + 2x^{3}F(x) + 3x - 5x^{2} $$ 得到 $$ F(x) = \\dfrac{5x^{2}-3x}{2x^{3}-5x^{2}+4x-1} = \\dfrac{3x-5x^{2}}{(1-x)^{2}(1-2x)} $$ 我们希望分解成 $$ \\dfrac{A}{1-x} + \\dfrac{B}{(1-x)^{2}} + \\dfrac{C}{1-2x} $$ 待定系数可以解得 $$ F(x) = \\dfrac{-3}{1-x} + \\dfrac{2}{(1-x)^{2}} + \\dfrac{1}{1-2x} $$ 展开得到 $$ F(x) = \\sum_{n=0}^{\\infty} (-3+2(n+1)+2^{n})x^{n} $$ 因此 $$ a_{n} = -3+2(n+1)+2^{n} = 2^{n} + 2n - 1 $$\nProblem 2 (1)\n设 $ f(n) $ 为集合 $ [n] $ 中不包含两个连续数字的子集数量，求 $ f(n) $ 的递推关系。\n解：\n容易得到 $ f(0)=1,f(1)=2,f(2)=3,f(3)=\\dots $。考虑集合 $ [n]=\\{ 1,2,\\dots,n \\} $，如果选择的子集中包含 $ n $，那么一定不包含 $ n-1 $，等价于从 $ [n-2] $ 中选择；如果不包含 $ n $，那么等价于从 $ [n-1] $ 中选择，因此 $ f(n)=f(n-1)+f(n-2) $。这样就找出了 $ f(n) $ 的递推关系，进一步同理斐波那契数列，我们考虑求出通项。\n设生成函数 $ F(x)=\\sum_{n=0}^{\\infty}f(n)x^{n} $，满足 $ F(x)=xF(x-1)+x^{2}F(x-2)+1+x $，解出 $$ F(x) = \\dfrac{1+x}{1-x-x^{2}} \\xlongequal{\\phi= \\frac{1+\\sqrt{ 5 }}{2},\\psi= \\frac{1-\\sqrt{ 5 }}{2}} \\dfrac{\\phi^{2} / \\sqrt{ 5 }}{1 - \\phi x} - \\dfrac{\\psi^{2} / \\sqrt{ 5 }}{1 - \\psi x} $$ 展开得到 $$ F(x) = \\sum_{n=0}^{\\infty} \\left( \\dfrac{\\phi^{n+2}- \\psi^{n+2}}{\\sqrt{ 5 }} \\right)x^{n} $$ 于是 $$ f(n) = \\dfrac{\\phi^{n+2} - \\psi^{n+2}}{\\sqrt{ 5 }} = \\dfrac{1}{\\sqrt{ 5 }}\\left( \\left( \\dfrac{1+\\sqrt{ 5 }}{2} \\right)^{n+2} - \\left( \\dfrac{1-\\sqrt{ 5 }}{2} \\right)^{n+2} \\right) $$\n(2)\n设 $ f(n,k) $ 为集合 $ [n] $ 中不包含两个连续数字的 $ k $-子集（大小为 $ k $ 的子集）的数量。求 $ f(n,k) $ 的递推关系，找到一个合适的生成函数，并求出这些数本身。\n解：\n同理先考虑 $ f(n,k) $ 的递推关系。从 $ [n] $ 中选出不包含连续数字的大小为 $ k $ 的子集，如果选出的子集包含 $ n $，那么可以看成从 $ [n-2] $ 中选取有 $ k-1 $ 个元素的子集，否则看成从 $ [n-1] $ 中选出 $ k $ 个元素，得到递推式 $$ f(n,k)=f(n-2,k-1) + f(n-1,k) $$ 边界条件有 $ f(n,0)=1,f(n,k\u003c 0)=f(n,k\u003en)=0,f(1,1)=1 $。\n于是我们定义 $$ F_{k}(x) = \\sum_{n=0}^{\\infty} f(n,k)x^{n} $$ 对于 $ k=0 $， $$ F_{0}(x) = \\sum_{n=0}^{\\infty} x^{n} = \\dfrac{1}{1-x} $$ $ k=1 $ 时 $$ F_{1}(x) = \\sum_{n=0}^{\\infty} nx^{n} = \\dfrac{x}{(1-x)^{2}} $$ $ k\u003e 1 $ 时边界条件不会影响递推 $$ F_{k}(x) = \\sum_{n=k}^{\\infty} f(n,k)x^{n} = \\sum_{n=k}^{\\infty} f(n-1,k)x^{n} + \\sum_{n=k}^{\\infty} f(n-2,k-1)x^{n} = xF_{k}(x) + x^{2}F_{k-1}(x) $$ 于是 $$ F_{k}(x) = \\dfrac{x^{2}}{1-x}F_{k-1}(x) = \\left( \\dfrac{x^{2}}{1-x} \\right)^{k-1}F_{1}(x) = \\dfrac{x^{2k-1}}{(1-x)^{k+1}} $$ 现在需要从这个形式中提取出 $ f(n,k) $。\n根据广义二项式定理 $$ \\dfrac{1}{(1-x)^{k+1}} = \\sum_{n=0}^{\\infty} \\binom{ n+k }{ k } x^{n} $$ 带入即可得到 $$ F_{k} = \\sum_{n=0}^{\\infty} \\binom{ n+k }{ k } x^{n+2k-1} \\xlongequal{m=n+2k-1} \\sum_{m=2k-1}^{\\infty} \\binom{ m-k+1 }{ k } x^{m} $$\n于是 $$ f(n,k)=\\binom{ n-k+1 }{ k } \\quad (n\\geq 2k) $$ （显然 $ n\u003c 2k-1 $ 时不可能找出不含两个连续数字，大小为 $ k $ 的子集，结果符合直觉）\n(3)\n设 $ F_{n} $ 为斐波那契数列的第 $ n $ 项，证明 $$ F_{n+1} = \\sum_{k\\geq 0}\\binom{ k }{ n-k } $$ 证：\n由于斐波那契数列，有 $ F_{n+1}=F_{n}+F_{n-1} $，容易推导出其生成函数为 $ G(x) = \\dfrac{1}{1-x-x^{2}} $。\n现在考虑 $ h_{n}=\\sum_{k\\geq 0}\\binom{ k }{ n-k } $，生成函数为 $ H(x)=\\sum_{n=0}^{\\infty}h_{n}x^{n} $，化简得到 $$ \\begin{align*} H(x) \u0026 = \\sum_{n=0}^{\\infty} \\sum_{k=0 }^{\\infty} \\binom{ k }{ n-k }x^{n} \\\\ \u0026 \\xlongequal{ i=k,j=n-k} \\sum_{i=0}^{\\infty} \\sum_{j=0}^{\\infty} \\binom{ i }{ j } x^{i+j} \\\\ \u0026 = \\sum_{i=0}^{\\infty} x^{i}\\sum_{j=0}^{i} \\binom{ i }{ j } x^{j} \\\\ \u0026 = \\sum_{i=0}^{\\infty} x^{i}\\cdot(1+x)^{i} = \\sum_{i=0}^{\\infty} (x+x^{2})^{i} \\\\ \u0026 = \\dfrac{1}{1-x-x^{2}} = G(x) \\end{align*} $$ 因此 $ F_{n+1}=h_{n} $，证毕！\nProblem 3 (1)\n对于任意正整数 $ n $ 和 $ k $，定义 $ f(n, k) $ 如下：对于将 $ n $ 写成有序的 $ k $ 个非负整数之和的每一种方式，设 $ S $ 为这 $ k $ 个整数的乘积。那么 $ f(n, k) $ 是通过这种方式获得的所有 $ S $ 的总和。请找到 $ f(n, k) $ 的合适生成函数，并求出这些数本身。\n证 1\n设 $ x_{1}+x_{2}+\\dots+x_{k}=n $，我们需要 $ \\prod_{i=1}^{k}x_{i} $。\n对于 $ x_{i} $，它对求和的贡献就是 $ x_{i} $，所以我们考虑生成函数 $ \\sum_{x_{i}=0}^{\\infty}x_{i}z^{x_{i}}=\\frac{z}{(1-z)^{2}} $。$ k $ 个这样的变量叠加可以表示为 $$ \\left( \\sum_{x_{1}=0}^{\\infty} x_{1}z^{x_{1}} \\right)\\left( \\sum_{x_{2}=0}^{\\infty} x_{2}z^{x_{2}} \\right)\\dots\\left( \\sum_{x_{k}=0}^{\\infty} x_{k}z^{x_{k}} \\right) = \\dfrac{z^{k}}{(1-z)^{2k}} $$ 展开以后就可以得到 $$ \\sum_{x_{1},\\dots,x_{n}} \\prod_{i=1}^{k}x_{i}\\cdot z^{\\sum x_{i}} = \\sum_{n=1}^{\\infty} f(n,k)z^{n} = \\dfrac{z^{k}}{(1-z)^{2k}} $$ 因此 $ f(n,k) $ 的生成函数为 $$ H_{k}(x) = \\dfrac{x^{k}}{(1-x)^{2k}} $$ 由于 $$ \\dfrac{1}{(1-x)^{2k}} = \\sum_{n=0}^{\\infty} \\binom{ n+2k-1 }{ 2k-1 } x^{n} $$ 于是 $$ H_{k}(x) = \\sum_{n=0}^{\\infty} \\binom{ n+2k-1 }{ 2k-1 } x^{n+k} \\xlongequal{m=n+k} \\sum_{m=k}^{\\infty} \\binom{ m+k-1 }{ 2k-1 } x^{m} $$ 于是 $$ f(n,k) = \\binom{ n+k-1 }{ 2k-1 } $$\n证 2\n考虑递推关系 $$ f(n,k) = \\begin{cases} 0 \u0026 ,k\\geq n+1 \\\\ n \u0026 ,k = 1 \\\\ \\sum_{r=0}^{n} rf(n-r,k-1) \u0026 ,\\text{others} \\end{cases} $$ 于是设对应的生成函数为 $ H_{k}(x) $。\n首先 $$ H_{1}(x) = \\sum_{n=0}^{\\infty} nx^{n} = \\dfrac{x}{(1-x)^{2}} $$ 之后我们需要对 $ H_{k}(x) $ 建立递推关系： $$ \\begin{align*} H_{k}(x) \u0026 = \\sum_{n=0}^{\\infty} f(n,k)x^{n} = \\sum_{n=0}^{\\infty} \\sum_{r=0}^{n} rf(n-r,k-1)x^{n} \\\\ \u0026 \\xlongequal{i=r,j=n-r} \\sum_{i=0}^{\\infty} \\sum_{j=0}^{\\infty} if(j,k-1)x^{i+j} \\\\ \u0026 = \\sum_{j=0}^{\\infty} f(j,k-1)x^{j}\\left( \\sum_{i=0}^{\\infty} ix^{i} \\right) \\\\ \u0026 = H_{1}(x)\\cdot H_{k-1}(x) \\end{align*} $$ 于是 $$ H_{k}(x) = \\dfrac{x}{(1-x)^{2}}H_{k-1}(x) = \\dfrac{x^{k}}{(1-x)^{2k}} $$ 后续步骤相同。\n(2)\n设 $ f(n, k, c) $ 为将 $ n $ 写成有序的 $ k $ 个整数之和的方式数量，其中每个整数至少为 $ c $。请找到 $ f(n, k, c) $ 的合适生成函数，并求出这些数本身。\n证：\n同理 $ (1) $ ，由于此时需要的是计数，每个值的贡献都是 $ 1 $，因此对于 $ x_{i} $ 的生成函数为 $ \\sum_{x_{i}=c}^{\\infty}z^{x_{i}} = \\dfrac{z^{c}}{1-z} $ 因此 $ k $ 个变量叠加表示为 $$ \\left( \\sum_{x_{1}=c}^{\\infty} z^{x_{1}} \\right)\\left( \\sum_{x_{2}=c}^{\\infty} z^{x_{2}} \\right)\\dots\\left( \\sum_{x_{k}=c}^{\\infty} z^{x_{k}} \\right) = \\dfrac{z^{ck}}{(1-z)^{k}} $$ 同时展开可以得到 $$ H_{c,k}(z) = \\sum_{n=ck}^{\\infty} f(n,c,k)z^{n} = \\dfrac{z^{ck}}{(1-z)^{k}} $$ 这就得到了 $ f(n,c,k) $ 的生成函数。\n下面求出数列通项。根据广义二项式定理 $$ \\dfrac{1}{(1-z)^{k}} = \\sum_{n=0}^{\\infty} \\binom{ n+k-1 }{ k-1 } z^{n} $$ 于是 $$ \\begin{align*} H_{c,k}(z) \u0026 = \\sum_{n=0}^{\\infty} \\binom{ n+k-1 }{ k-1 } z^{n+ck} \\\\ \u0026 \\xlongequal{m = n+ck} \\sum_{m=ck}^{\\infty} \\binom{ m-ck+k-1 }{ k-1 } z^{m} \\end{align*} $$ 得到 $$ f(n,c,k) = \\dbinom{ n-ck+k-1 }{ k-1 } $$\n","permalink":"https://diefish1024.github.io/posts/class-notes/cs0901-combinatorics/cs0901-hw2/","summary":"\u003ch2 id=\"problem-1\"\u003eProblem 1\u003c/h2\u003e\n\u003cp\u003e用生成函数求解递推式\n$$ \n\na_{n} = 4a_{n-1} - 5a_{n-2} + 2a_{n-3}\n\n $$\n初始值为 $ a_{0}=0,a_{1}=3,a_{2}=7 $。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e解\u003c/strong\u003e：\u003c/p\u003e\n\u003cp\u003e设数列 $ \\{ a_{n} \\} $ 的生成函数为 $ F(x) $，那么根据递推式和初值 $ a_{0}=0,a_{1}=3,a_{2}=7 $ 得到\n$$ \n\nF(x) = 4xF(x) - 5x^{2}F(x) + 2x^{3}F(x) + 3x - 5x^{2}\n\n $$\n得到\n$$ \n\nF(x) = \\dfrac{5x^{2}-3x}{2x^{3}-5x^{2}+4x-1} = \\dfrac{3x-5x^{2}}{(1-x)^{2}(1-2x)}\n\n $$\n我们希望分解成\n$$ \n\n\\dfrac{A}{1-x} + \\dfrac{B}{(1-x)^{2}} + \\dfrac{C}{1-2x}\n\n $$\n待定系数可以解得\n$$ \n\nF(x) = \\dfrac{-3}{1-x} + \\dfrac{2}{(1-x)^{2}} + \\dfrac{1}{1-2x}\n\n $$\n展开得到\n$$ \n\nF(x) = \\sum_{n=0}^{\\infty} (-3+2(n+1)+2^{n})x^{n}\n\n $$\n因此\n$$ \n\na_{n} = -3+2(n+1)+2^{n} = 2^{n} + 2n - 1\n\n $$\u003c/p\u003e","title":"CS0901 HW2"},{"content":"Exercise 1 Let $ f:\\mathbb{R}\\to\\mathbb{R} $ be a function. Prove that the following are equivalent: (i) There is a constant $ a\\in\\mathbb{R} $ such that for every$ x\\in\\mathbb{R} $ we have$ f(x)=ax $. (ii) For all $ x_1,x_2,c,x\\in\\mathbb{R} $ we have $ f(x_1+x_2)=f(x_1)+f(x_2) $ and $ f(cx)=c\\,f(x) $.\n(i ⇒ ii)\nAssume there exists $ a\\in\\mathbb{R} $ such that $ f(x)=a x $ for all $ x\\in\\mathbb{R} $ . Then for any $ x_1,x_2,c,x\\in\\mathbb{R} $ ,\n$ f(x_1+x_2)=a(x_1+x_2)=ax_1+ax_2=f(x_1)+f(x_2) $; $ f(cx)=a(cx)=c(ax)=c\\,f(x) $. Hence (ii) holds.\n(ii ⇒ i)\nAssume (ii) hold for all real scalars. Define $ a:=f(1) $. For any $ x\\in\\mathbb{R} $ we can write $ x=x\\cdot 1 $; by homogeneity, we have $ f(x)=f(x\\cdot 1)=x\\,f(1)=a x $.\nThus (i) holds with $ a=f(1) $. Therefore (i) and (ii) are equivalent.\nExercise 2 Describe geometrically (line, plane, or all of $ \\mathbb{R}^3 $) all linear combinations of the given vectors.\n(a) $ \\begin{pmatrix}1\\\\2\\\\3\\end{pmatrix} $ and $ \\begin{pmatrix}3\\\\6\\\\9\\end{pmatrix} $.\nObserve that$ \\begin{pmatrix}3\\\\6\\\\9\\end{pmatrix}=3\\begin{pmatrix}1\\\\2\\\\3\\end{pmatrix} $, so the two vectors are colinear. Hence their span is $ \\mathrm{Span}=\\{\\, t\\begin{pmatrix}1\\\\2\\\\3\\end{pmatrix}\\mid t\\in\\mathbb{R}\\,\\} $, which is a line. (b) $ \\begin{pmatrix}1\\\\0\\\\0\\end{pmatrix} $ and $ \\begin{pmatrix}0\\\\2\\\\3\\end{pmatrix} $.\nThese two vectors are not scalar multiples of each other, hence they are linearly independent. Therefore their span $ \\mathrm{Span}=\\{\\, \\alpha\\begin{pmatrix}1\\\\0\\\\0\\end{pmatrix}+\\beta\\begin{pmatrix}0\\\\2\\\\3\\end{pmatrix}\\mid \\alpha,\\beta\\in\\mathbb{R}\\,\\} $ is a plane. (c) $ \\begin{pmatrix}2\\\\0\\\\0\\end{pmatrix} $, $ \\begin{pmatrix}0\\\\2\\\\2\\end{pmatrix} $ and $ \\begin{pmatrix}2\\\\2\\\\3\\end{pmatrix} $.\nForm the matrix with these as columns and compute the determinant: $$ \\det\\begin{pmatrix} 2 \u0026 0 \u0026 2\\\\ 0 \u0026 2 \u0026 2\\\\ 0 \u0026 2 \u0026 3 \\end{pmatrix} \\neq 0. $$ Since the determinant is nonzero, the three vectors are linearly independent,therefore their span all of $ \\mathbb{R}^3 $. Answers:\n(a) a line. (b) a plane. (c) all of $ \\mathbb{R}^3 $. Exercise 3 Consider $ v=(1,-2,1) $ and $ w=(0,1,-1) $. Find $ c $ and $ d $ such that $ c v+d w=(3,3,-6) $. Why is $ (3,3,6) $ impossible?\nLet $ c v+d w=(3,3,-6) $. Comparing coordinates: $$ \\begin{cases} c = 3 \\\\ -2c+d=9 \\\\ c-d=-6 \\end{cases} $$ It can be solved that $ c=3 $ and $ d=9 $.\nFor $ (3,3,6) $, the first coordinate again forces $ c=3 $, and the second gives $ d=9 $, hence the third would be $ c-d=3-9=-6\\neq 6 $. Therefore it is impossible. Equivalently, every linear combination satisfies $ y+z=-x $ (since $ y=-2c+d $ and $ z=c-d $), but the vector $ (3,3,6) $ has $ y+z=9\\neq -3 $; hence it does not lie in $ \\mathrm{Span}\\{v,w\\} $.\nExercise 4 In the following, tacitly assume that every matrix operation is well-defined. Prove: (i) $ A+B=B+A $. (ii) $ c(A+B)=cA+cB $. (iii) $ A+(B+C)=(A+B)+C $. (iv) $ A(B+C)=AB+AC $. (v) $ (A+B)C=AC+BC $. (vi) $ A(BC)=(AB)C $.\nWrite $ A=(a_{ij}) $, $ B=(b_{ij}) $, $ C=(c_{ij}) $. Use the entrywise definitions of addition and multiplication.\n(i) Commutativity of addition: For all $ i,j $, $ (A+B)_{ij}=a_{ij}+b_{ij}=b_{ij}+a_{ij}=(B+A)_{ij} $. Hence $ A+B=B+A $.\n(ii) Distributivity of scalar multiplication over addition: For all $ i,j $, $ \\big(c(A+B)\\big)_{ij}=c(a_{ij}+b_{ij})=ca_{ij}+cb_{ij}=(cA+cB)_{ij} $.\n(iii) Associativity of addition: For all $ i,j $, $ \\big(A+(B+C)\\big)_{ij}=a_{ij}+(b_{ij}+c_{ij})=(a_{ij}+b_{ij})+c_{ij}=\\big((A+B)+C\\big)_{ij} $.\n(iv) Left distributivity of multiplication: $$ \\big(A(B+C)\\big)_{ij} =\\sum_k a_{ik}(b_{kj}+c_{kj}) =\\sum_k a_{ik}b_{kj}+\\sum_k a_{ik}c_{kj} =(AB)_{ij}+(AC)_{ij} =(AB+AC)_{ij}. $$\n(v) Right distributivity of multiplication: $$ \\big((A+B)C\\big)_{ij} =\\sum_k (a_{ik}+b_{ik})c_{kj} =\\sum_k a_{ik}c_{kj}+\\sum_k b_{ik}c_{kj} =(AC)_{ij}+(BC)_{ij} =(AC+BC)_{ij}. $$\n(vi) Associativity of multiplication: $$ \\big(A(BC)\\big)_{ij} =\\sum_k a_{ik}(BC)_{kj} =\\sum_k a_{ik}\\sum_\\ell b_{k\\ell}c_{\\ell j} =\\sum_\\ell\\Big(\\sum_k a_{ik}b_{k\\ell}\\Big)c_{\\ell j} =\\big((AB)C\\big)_{ij}. $$\nTherefore all properties (i)–(vi) hold.\nExercise 5 Let$ A=\\begin{pmatrix}3\u00261\\\\[2pt] 1\u0026-3\\end{pmatrix} $. Compute $ A^{50} $ and $ A^{51} $.\nFirst compute$ A^2 $: $$ A^2 =\\begin{pmatrix}3\u00261\\\\ 1\u0026-3\\end{pmatrix} \\begin{pmatrix}3\u00261\\\\ 1\u0026-3\\end{pmatrix} =\\begin{pmatrix} 3\\cdot 3+1\\cdot 1 \u0026 3\\cdot 1+1\\cdot(-3)\\\\ 1\\cdot 3+(-3)\\cdot 1 \u0026 1\\cdot 1+(-3)\\cdot(-3) \\end{pmatrix} =\\begin{pmatrix}10\u00260\\\\ 0\u002610\\end{pmatrix} =10\\,I_2. $$ Thus $ A^2=10I_2 $. It follows that for any integer $ n\\ge 1 $,\nif $ n $ is even, $ A^n=(A^2)^{n/2}=10^{n/2}I_2 $; if $ n $ is odd, $ A^n=A\\cdot A^{n-1}=A\\cdot 10^{(n-1)/2}I_2=10^{(n-1)/2}A $. Therefore,\n$ A^{50}=10^{25}I_2 $, $ A^{51}=10^{25}A=10^{25}\\begin{pmatrix}3\u00261\\\\[2pt] 1\u0026-3\\end{pmatrix} $. ","permalink":"https://diefish1024.github.io/posts/class-notes/math1205h-linear-algebra/math1205h-hw1/","summary":"\u003ch2 id=\"exercise-1\"\u003eExercise 1\u003c/h2\u003e\n\u003cblockquote\u003e\n\u003cp\u003eLet $ f:\\mathbb{R}\\to\\mathbb{R} $ be a function. Prove that the following are equivalent:\n(i) There is a constant $ a\\in\\mathbb{R} $ such that for every$ x\\in\\mathbb{R} $ we have$ f(x)=ax $.\n(ii) For all $ x_1,x_2,c,x\\in\\mathbb{R} $ we have $ f(x_1+x_2)=f(x_1)+f(x_2) $ and $ f(cx)=c\\,f(x) $.\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e\u003cstrong\u003e(i ⇒ ii)\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eAssume there exists $ a\\in\\mathbb{R} $ such that $ f(x)=a x $ for all $ x\\in\\mathbb{R} $ . Then for any $ x_1,x_2,c,x\\in\\mathbb{R} $ ,\u003c/p\u003e","title":"MATH1205H HW1"},{"content":"考虑上一节引入的二项式定理 $$ (1+x)^{n} = \\sum_{k=0}^{n} \\binom{ n }{ k } x^{k} $$ 这可以理解成我们把二项系数转换成了一个函数，这使得我们能更有效地操作和分析序列，这个工具被成为生成函数。\nOrdinary Generating Functions 给定序列 $ \\{ a_{n} \\}_{n\\geq 0} $，由 $ \\{ a_{n} \\} $ 定义的普通生成函数 (OGF) 为： $$ G(x) = \\sum_{n\\geq 0} a_{n}x^{n} $$ 虽然看起来 OGF 并没有被很好的定义，对于和某些数列，这个形式不会收敛，但是实际上生成函数并不能被看成一个真正的函数，它是一个形式幂级数，并且不被要求收敛。\n以下是一些生成函数的基础例子： $$ G(x) = 1+x+x^{2}+x^{3} +\\dots = \\dfrac{1}{1-x} $$ $$ G(x) = 1+ax+a^{2}x^{2} + a^{3}x^{3} + \\dots = \\dfrac{1}{1-ax} $$\n给定一个序列，写出他的生成函数是很容易的。尽管找到他的闭合形式不容易，但是我们一般不需要这样做。相反，我们需要考虑给定一个闭合形式，需要如何知道其对应的序列。\n我们约定 $ [x^{n}]G(x) $ 表示生成函数中 $ x^{n} $ 的系数。\n理论上我们总可以使用泰勒级数来得到 $ [x^{n}]G(x) $。\nNewton’s Generalized Binomial Theorem\n如果 $ x $ 是任何实数并且 $ \\left| x \\right|\u003c1 $，并且 $ r $ 是任何复数，我们有： $$ (1+x)^{r} = \\sum_{n=0}^{\\infty} \\binom{ r }{ n } x^{n} $$ 其中 $$ \\binom{ r }{ n } = \\dfrac{r^{\\underline{n}}}{n!} $$ 例如 $$ \\dfrac{1}{1+x} = (1+x)^{-1} = \\sum_{n=0}^{\\infty} \\binom{ -1 }{ n } x^{n} = 1-x+x^{2}-x^{3}+\\dots $$\nOperations on Generating Functions Convolution 多项式乘法（卷积）在某种意义上编码了乘法原理和加法原理。令 $ F(x)=\\sum_{n=0}^{\\infty}f_{n}x^{n},G(x)=\\sum_{n=0}^{\\infty}g_{n}x^{n} $，那么 $$ [x^{n}](F(x)G(x)) = \\sum_{n=0}^{\\infty} f_{k}g_{n-k} $$ 我们称这为卷积 (convolution) 。这有清晰的组合意义，表示从 $ F\\cup G $ 中选择 $ n $ 个元素。\nExamples Example 1\n假设有 $ 5 $ 个相同蓝色球，$ 3 $ 个相同绿色球，$ 2 $ 个相同红色球，问有几种方式从几种选择 $ 6 $ 个球？\n解：\n我们通过生成函数来解决这个问题，令 $ \\{ b_{n} \\},\\{ g_{n} \\},\\{ r_{n} \\} $ 分别为选择蓝色、绿色、红色球的方案数，显然由于每种颜色的球相同，我们容易得到他们对应的生成函数分别为 $$ \\begin{align*} B(x) \u0026 = 1+x+x^{2}+x^{3}+x^{4}+x^{5} \\\\ G(x) \u0026 = 1+x+x^{2}+x^{3} \\\\ R(x) \u0026 = 1+x+x^{2} \\end{align*} $$ 那么我们就能得到 $ F(x)=B(x)G(x)R(x) $ 为选择三种球方案的生成函数，选择 $ 6 $ 个球的方案数为 $$ [x^{6}]F(x) = \\dots $$\nExample 2 (Multiset Number)\n回顾十二重计数法中的多重集数 $ \\left( \\binom{ m }{ n } \\right) $，表示从 $ [m] $ 中选择大小为 $ n $ 的多重集（允许元素重复）的数量，我们可以用生成函数证明 $$ \\left( \\binom{ m }{ n } \\right) = \\binom{ n+m-1 }{ n } = \\binom{ n+m-1 }{ m-1 } $$ 证：\n设 $ \\left( \\binom{ m }{ n } \\right) $ 的生成函数为 $$ F(x) = \\sum_{n=0}^{\\infty} \\left(\\binom{ m }{ n }\\right) x^{n} $$ 我们考虑对于单个元素 $ i $ 的集合，其被选择 $ k $ 次的方案数显然都为 $ 1 $，所以对应生成函数为 $$ F_{i}(x) = \\sum_{n=0}^{\\infty} x^{n} = \\dfrac{1}{1-x} $$ 于是 $$ F(x) = F_{1}(x)F_{2}(x)\\dots F_{m}(x) = \\dfrac{1}{(1-x)^{m}} $$ 从而 $$ \\left( \\binom{ m }{ n } \\right) = [x^{n}]F(x) = \\binom{ -m }{ n } (-r)^{n} = \\binom{ n+m-1 }{ n } $$ 因此得证。\nExample 3\n对于每个正整数 $ n $，将 $ n $ 分割成若干个奇数之和的方案数等于将 $ n $ 分割成若干个不同的数之和的方案数。\n证：\n令 $ o_{n} $ 为将 $ n $ 分割成奇数的的方案数，$ d_{n} $ 为分割成不同部分的方案数，并且令 $ O_{n} $ 和 $ D_{n} $ 分别为他们对应的生成函数。\n对于奇数，我们有 $$ \\begin{align*} O(x) \u0026 = (1+x+x^{2}+\\dots)(1+x^{3}+(x^{3})^{2} + \\dots)(1+x^{5}+(x^{5})^{2} + \\dots)\\dots \\\\ \u0026 = \\dfrac{1}{1-x}\\cdot \\dfrac{1}{1-x^{3}}\\cdot \\dfrac{1}{1-x^{5}}\\cdot\\dots \\\\ \u0026 = \\prod_{k\\,\\text{mod}\\,2=1} \\dfrac{1}{1-x^{k}} \\end{align*} $$\n对于不同部分，我们有 $$ \\begin{align*} D(x) \u0026 = (1+x)(1+x^{2})(1+x^{3})\\dots \\\\ \u0026 = \\dfrac{1-x^{2}}{1-x}\\cdot \\dfrac{1-x^{4}}{1-x^{2}}\\cdot \\dfrac{1-x^{6}}{1-x^{3}}\\cdot \\dots \\\\ \u0026 = \\prod_{k=1}^{\\infty} \\dfrac{1-x^{2k}}{1-x^{k}} \\\\ \u0026 = \\prod_{k\\,\\text{mod}\\,2=1} \\dfrac{1}{1-x^{k}} \\end{align*} $$ 因此 $ O(x)=D(x) $，从而 $ o_{n}=d_{n} $，方案数相等。\nOperations Solving Recurrence 生成函数最重要的应用之一是解决递推关系并找到闭合形式，现在我们介绍一些例子。\n一个经典例子是求解斐波那契数列，过程可以参考作业解答，此处不再重复。\n另一个例子是卡特兰数。我们已知其递推关系是 $$ C_{0}=1,\\quad C_{n} = \\sum_{k=0}^{n-1} C_{k}C_{n-1-k}\\,,\\forall n\\geq 1 $$ 我们令 $ G(x) $ 为卡特兰数的生成函数。递推关系表明我们应该考虑乘法。 $$ \\begin{align*} G(x) \u0026 = C_{0} + \\sum_{n=1}^{\\infty} \\sum_{k=0}^{n-1} C_{k}C_{n-1-l}x^{n} \\\\ G(x)^{2} \u0026 = \\left( \\sum_{n=0}^{\\infty} C_{n}x^{n} \\right)^{2} = \\sum_{n=0}^{\\infty} \\left( \\sum_{k=0}^{n} C_{k}C_{n-k} \\right)x^{n} \\\\ \\implies xG(x)^{2} \u0026 = \\sum_{n=1}^{\\infty}\\left( \\sum_{k=0}^{n-1} C_{k}C_{n-1-k} \\right)x^{n} \\\\ \\end{align*} $$ 因此我们有 $$ G(x) = 1+ xG(x)^{2} \\implies G(x) = \\dfrac{1\\pm \\sqrt{ 1-4x }}{2x} $$ 这两个解中只有一个是我们需要的生成函数，注意到 $ \\lim_{ x \\to 0 }G(x)=C_{0}=1 $，容易验证 $$ G(x) = \\dfrac{1-\\sqrt{ 1-4x }}{2x} $$ 现在我们通过广义二项式定理展开 $ \\sqrt{ 1-4x }=(1-4x)^{1 / 2} $ ，再带入原式得到 $$ G(x) = \\sum_{n=0}^{\\infty} \\dfrac{1}{n+1}\\binom{ 2n }{ n } x^{n} $$ 这就算出了 $$ C_{n} = \\dfrac{1}{n+1}\\binom{ 2n }{ n } $$\n最后一个例子是第二类斯特林数。其递推关系为 $$ \\left\\{ 0 \\atop 0 \\right\\} = 0,\\quad \\left\\{ n\\atop k \\right\\} = k\\left\\{ n-1 \\atop k \\right\\} + \\left\\{ n-1 \\atop k-1 \\right\\} \\quad \\text{for } (n,k) \\neq (0,0) $$ 由于存在两个索引，所以此时有三个生成函数候选： $$ \\begin{align*} A(x,y) \u0026 = \\sum_{n=0}^{\\infty} \\sum_{k=0}^{\\infty} \\left\\{ n \\atop k \\right\\} x^{n}y^{k} \\\\ B_{k}(x) \u0026 = \\sum_{n=0}^{\\infty} \\left\\{ n\\atop k \\right\\} x^{n} \\\\ C_{n}(y) \u0026 = \\sum_{k=0}^{\\infty} \\left\\{ n \\atop k \\right\\} y^{k} \\end{align*} $$ 然而由于我们并不知道如何处理多元生成函数，因此 $ A(x,y) $ 应该首先被排除。如果选择 $ C_{n}(y) $，那么递推关系中的 $ k\\left\\{ n-1\\atop k \\right\\} $ 无疑会涉及到微分，这会使得操作更加复杂。因此我们使用 $ B_{k}(x) $ 作为生成函数。\n注意到 $$ B_{k}(x) = \\sum_{n=k}^{\\infty} \\left\\{ n \\atop k \\right\\}x^{k} = kxB_{k}(x) + xB_{k-1}(x) \\quad \\text{for } k\\geq 1 $$ 并且 $ B_{0}(x)=1 $。\n于是 $$ B_{k}(x) = \\dfrac{x}{1-kx}B_{k-1}(x) = \\dfrac{x^{k}}{(1-x)(1-2x)\\dots(1-kx)} = \\prod_{i=1}^{k} \\dfrac{x}{1-ix} $$ 我们的目标是找到 $ [x^{n}]B_{k}(x) $ 的显式公式。一个很自然的思路是把 $ B_{k}(x) $ 写成 $$ B_{k}(x) = \\sum_{i=1}^{k} \\dfrac{r_{i}x}{1-ix} $$ 为了找到 $ r_{i} $，我们固定某个 $ j\\in[k] $ 并将两边乘以 $ 1-jx $。这就得到了 $$ \\dfrac{x^{k}}{\\prod_{i\\neq j}(1-ix)} = r_{j}x + \\sum_{i\\neq j} \\dfrac{r_{i}x}{1-ix}(1-jx) $$ 再令 $ x=1 / j $，我们就得到了 $$ \\dfrac{(1 /j)^{k}}{\\prod_{i\\neq j}(1-i / j)} = \\dfrac{r_{j}}{j}\\implies r_{j} = \\dfrac{(-1)^{k-j}}{(j-1)!(k-j)!} $$ 于是就得到了 $$ \\left\\{ n\\atop k \\right\\} = [x^{n}]B_{k}(x) = \\sum_{i=1}^{k} r_{i}i^{n-1} = \\sum_{i=1}^{k} \\dfrac{(-1)^{k-i}}{(i-1)!(k-i)!}i^{n-1} $$\nExponential Generating Function 一般而言，OGF 对于计数子集的数量非常有用，然而它可能不适用于计数置换或者带标签元素。例如 $ [n] $ 上的置换数量的 OGF 是什么，显然有 $$ F(x) = 1+x+2x^{2}+6x^{3}+\\dots=\\sum_{n=0}^{\\infty} n!x^{n} $$ 我们尝试找出它的闭合形式。由于 $ [x^{n}]F(x)=n[x^{n-1}]F(x) $，这提示我们使用微分运算 $$ F(x) = 1+x(xF(x))' = 1+xF(x) + x^{2}F'(x) $$ 然而这类微分方程通常没有闭合形式的解。\n于是这就需要引入指数生成函数 (EGF)，它用于处理置换或者带标签元素的计数。\n对于序列 $ \\{ a_{n} \\}_{n\\geq 0} $，由 $ \\{ a_{n} \\} $ 定义的 EGF 为 $$ G(x) = \\sum_{n=0}^{\\infty} \\dfrac{a_{n}}{n!}x^{n} $$ 置换：容易看出由 $ n! $ 定义的 EGF 为 $ \\dfrac{1}{1-x} $。\n循环置换：圆排列数量为 $ (n-1)! $，容易得到其生成函数为 $ \\sum_{n=1}^{\\infty} \\frac{1}{n}x^{n}=-\\ln(1-x) $。\n为了更好的理解 EGF 的组合含义，我们考虑两个指数生成函数的乘积。设 $ \\hat{F}(x) = \\sum_{n=0}^{\\infty} \\frac{1}{n!}f_{n}x^{n} $，且 $ \\hat{G}(x) = \\sum_{n=0}^{\\infty} \\frac{1}{n!}g_{n}x^{n} $ ，那么容易看出 $$ [x^{n}](\\hat{F}(x)\\hat{G}(x)) = \\sum_{k=0}^{n} \\dfrac{f_{k}}{k!} \\dfrac{g_{n-k}}{(n-k)!} $$ 于是 $ \\hat{F}(x)\\hat{G}(x) $ 对应序列的通项为 $$ h_{n} = n![x^{n}](\\hat{F}(x)\\hat{G}(x)) = \\sum_{k=0}^{n} \\binom{ n }{ k } f_{k}g_{n-k} $$ 这表示我们不仅枚举元素的数量，还枚举他们的位置或者标签。\n现在我们考虑指数生成函数的一个应用。假设有一个 $ 1 \\times n $ 的棋盘，我们想用蓝色、绿色和红色为每个格子着色。要求红色格子的数量必须是偶数，并且至少有一个蓝色格子。我们的目标是确定棋盘着色的方式数量 $ f_n $。 令 $ \\{b_n\\} $、$ \\{g_n\\} $、$ \\{r_n\\} $ 分别为用单一颜色蓝色、绿色和红色为 $ n $ 个格子着色的方式数量序列。那么它们对应的指数生成函数是： $$ \\begin{align*} \u0026 \\hat{B}(x) = \\sum_{n \\ge 1} \\frac{1}{n!} x^n = e^x - 1 \u0026 (\\text{至少一个蓝色格子}) \\\\ \u0026 \\hat{G}(x) = \\sum_{n \\ge 0} \\frac{1}{n!} x^n = e^x \u0026 (\\text{任意数量的绿色格子}) \\\\ \u0026 \\hat{R}(x) = \\sum_{n \\ge 0, n \\text{ 偶数}} \\frac{1}{n!} x^n = 1 + \\frac{x^2}{2!} + \\frac{x^4}{4!} + \\dots = \\frac{e^x + e^{-x}}{2} \u0026 (\\text{偶数个红色格子}) \\end{align*} $$ 因此 $ \\{f_n\\} $ 的指数生成函数是： $$ \\begin{align*} \\hat{F}(x) \u0026 = \\hat{B}(x) \\cdot \\hat{G}(x) \\cdot \\hat{R}(x) \\\\ \u0026 = (e^x - 1)e^x \\frac{e^x + e^{-x}}{2} \\\\ \u0026 = \\frac{e^{2x} - e^x}{2} (e^x + e^{-x}) \\\\ \u0026 = \\frac{e^{3x} + e^x - e^{2x} - 1}{2} \\\\ \u0026 = \\frac{1}{2} \\left( \\sum_{n \\ge 0} \\frac{3^n}{n!} x^n - \\sum_{n \\ge 0} \\frac{2^n}{n!} x^n + \\sum_{n \\ge 0} \\frac{1^n}{n!} x^n - 1 \\right) \\end{align*} $$ 这给出了： $$ f_n = n! \\cdot [x^n]\\hat{F}(x) = \\begin{cases} 0, \u0026 n = 0 \\\\ \\frac{3^n - 2^n + 1}{2}, \u0026 n \\ge 1 \\end{cases} $$\n类似地，回想一下 $ \\left\\{\\substack{n \\\\ k}\\right\\} $ 计算将 $ [n] $ 分割成 $ k $ 个相同非空子集的方式数量，因此 $ k!\\left\\{\\substack{n \\\\ k}\\right\\} $ 具有指数生成函数： $$ \\sum_{n \\ge 0} k!\\left\\{\\substack{n \\\\ k}\\right\\} \\frac{x^n}{n!} = (e^x - 1)^k $$\n","permalink":"https://diefish1024.github.io/posts/class-notes/cs0901-combinatorics/lect2-generating-functions/","summary":"\u003cp\u003e考虑上一节引入的二项式定理\n$$ \n\n(1+x)^{n} = \\sum_{k=0}^{n} \\binom{ n }{ k } x^{k}\n\n $$\n这可以理解成我们把二项系数转换成了一个函数，这使得我们能更有效地操作和分析序列，这个工具被成为\u003cstrong\u003e生成函数\u003c/strong\u003e。\u003c/p\u003e\n\u003ch2 id=\"ordinary-generating-functions\"\u003eOrdinary Generating Functions\u003c/h2\u003e\n\u003cp\u003e给定序列 $ \\{ a_{n} \\}_{n\\geq 0} $，由 $ \\{ a_{n} \\} $ 定义的\u003cstrong\u003e普通生成函数 (OGF)\u003c/strong\u003e 为：\n$$ \n\nG(x) = \\sum_{n\\geq  0} a_{n}x^{n}\n\n $$\n虽然看起来 OGF 并没有被很好的定义，对于和某些数列，这个形式不会收敛，但是实际上生成函数并不能被看成一个真正的函数，它是一个\u003cstrong\u003e形式幂级数\u003c/strong\u003e，并且不被要求收敛。\u003c/p\u003e\n\u003cp\u003e以下是一些生成函数的基础例子：\n$$ \n\nG(x) = 1+x+x^{2}+x^{3} +\\dots = \\dfrac{1}{1-x}\n\n $$\n$$ \n\nG(x) = 1+ax+a^{2}x^{2} + a^{3}x^{3} + \\dots = \\dfrac{1}{1-ax}\n\n $$\u003c/p\u003e\n\u003cp\u003e给定一个序列，写出他的生成函数是很容易的。尽管找到他的闭合形式不容易，但是我们一般不需要这样做。相反，我们需要考虑给定一个闭合形式，需要如何知道其对应的序列。\u003c/p\u003e\n\u003cp\u003e我们约定 $ [x^{n}]G(x) $ 表示生成函数中 $ x^{n} $ 的系数。\u003c/p\u003e","title":"Lect2-Generating Functions"},{"content":"Introduction 条件概率指一个事件在另一个事件发生的条件下发生的概率，用记号 $ \\mathbb{P}(A|B) $ 表示，仅在 $ \\mathbb{P}(B)\u003e0 $ 时有定义： $$ \\mathbb{P}(A|B) = \\dfrac{\\mathbb{P}(A \\cap B)}{P(B)} $$ 可以写成 $$ \\mathbb{P}(A \\cap B) = \\mathbb{P}(B)\\cdot \\mathbb{P}(A|B) $$\n对于 $ n $ 个事件，连续使用上式，即可得到 $$ \\mathbb{P}\\left( \\bigcap_{i=1}^{n}A_{i} \\right) = \\prod_{k=1}^{n} \\mathbb{P}\\left( A_{k}\\bigg|\\bigcap_{i=1}^{k-1}A_{i} \\right) $$ 这个式子被称为 链式法则。\nIndependence 对于事件 $ A,B $，如果 $ \\mathbb{P}(A\\cap B)=\\mathbb{P}(A)\\mathbb{P}(B) $，或者等价地 $ \\mathbb{P}(A|B)=\\mathbb{P}(A) $，那么我们称 $ A $ 和 $ B $ 是独立的。这表明 $ A $ 或 $ B $ 自己是否发生对对方是否发生没有影响。\n推广到 $ n $ 个事件上有：对于事件 $ A_{1},\\dots,A_{n} $，如果他们是相互独立的，说明对于任意的 $ I\\subseteq[n] $ ，有 $$ \\mathbb{P}\\left( \\bigcap_{i\\in I}A_{i} \\right) = \\prod_{i\\in I}\\mathbb{P}(A)_{i} $$ 这个定义非常强，因为它要求对于所有的 $ I\\subseteq[n] $ 都成立。\n如果把定义改成只要求 $ I\\in \\binom{ [n] }{ 2 } $，可以得到两两独立的定义。\n目前这都是关于有限集的定义，对于无穷多个事件 $ \\{ A_{j} \\}_{j\\in J} $（这要求 $ J $ 是可数集，否则概率没有定义），我们说它们是互相独立的，当且仅当对于 $ J $ 的任意一个有限子集 $ I $，$ \\{ A_{i} \\}_{i\\in I} $ 相互独立。\nLaw of Total Probability 假设事件 $ B_{1},B_{2},\\dots,B_{n}\\in \\mathcal{F} $ 构成了样本空间的一个划分，即 $ \\Omega=\\bigcup_{i=1}^{n}B_{i} $ 并且对于 $ i\\neq j $，有 $ B_{i}\\cap B_{j}=\\emptyset $。根据集合论的知识，我们可以推导出对于任意集合 $ A $，$ A\\cap B_{i} $ 也构成了 $ A $ 的一个划分。如果我们取 $ A\\in\\mathcal{F} $，根据概率论公理，我们有 $$ \\mathbb{P}(A) = \\mathbb{P}\\left( \\bigcup_{n\\geq 1}(A\\cap B_{n}) \\right) = \\sum_{n\\geq 1} \\mathbb{P}(A\\cap B_{i}) $$ 这就得到了 全概率公式。写成条件概率的形式，可以得到 $$ \\mathbb{P}(A) = \\sum_{n\\geq 1}\\mathbb{P}(B_{n})\\mathbb{P}(A|B_{n}) $$\nSome Examples 无限悖论 假设有无穷个球，用 $ k=1,2,\\dots $ 来编号，并有一个无穷大的箱子。考察“放球”和“拿球”的过程。\n放球过程表述为：对于 $ n=0,1,2,\\dots $，在 12 点前的 $ 2^{-n} $ 分钟放入编号为 $ 10n+1,10n+2,\\dots,10(n+1) $ 的球。\n我们再使用不同的方式把球拿出来（假设拿和放都在瞬间完成）：\n12 点前 $ 2^{-n} $ 分钟放完球后，从箱子里拿出 $ 10(n+1) $ 号球。\n这种情况下 12 点时箱子里会有无穷的球，因为编号不是 10 的倍数的球都没有被拿出来。\n12 点前 $ 2^{-n} $ 分钟放完球后，从箱子里拿出 $ (n+1) $ 号球。\n此时 12 点时箱子里一个球都没有，因为每个球都能找到一个对应的时刻被拿出来。\n我们可以发现同样是拿一个球，最后的效果居然完全不同。我们现在考虑，如果随机拿出一个球又会怎么样？\n12 点前 $ 2^{-n} $ 分钟放完球后，从箱子里均匀随机地拿出一个球。\n我们计算每个球在 12 点的时候留在箱子里的概率。以 1 号球为例，其余类似。对于每个 $ n $，用事件 $ A_{n} $ 表示在 $ n $ 轮操作后 1 号球还在箱子里这个事件。我们需要关注的是 $$ A_{\\infty} := \\bigcap_{n\\geq 0}A_{n} = \\lim_{ n \\to \\infty } A_{n} $$ 根据上一节中概率测度的连续性，我们有 $ \\mathbb{P}(\\lim_{ n \\to \\infty }A_{n})=\\lim_{ n \\to \\infty }\\mathbb{P}(A_{n}) $。因此只需要计算 $ \\mathbb{P}(A_{n}) $ 即可。我们再定义一个事件 $ B_{n} $ 表示第 $ n $ 轮拿出来的不是 1 号球，则有 $ A_{n}=B_{0}\\cap B_{1}\\cap\\dots \\cap B_{n} $。使用链式法则，就可以得到 $$ \\mathbb{P}(A_{n}) = \\mathbb{P}\\left( \\bigcap_{i=1}^{n}B_{i} \\right) = \\prod_{k=0}^{n}\\mathbb{P}\\left( B_{k}\\bigg|\\bigcap_{i\u003c k}B_{i} \\right) $$ 其中事件 $ B_{k}|\\bigcap_{i\u003c k}B_{i} $ 有非常明显的组合意义，显然这个概率是 $ 1- \\dfrac{1}{9(k+1)+1} $。\n因此 $$ \\mathbb{P}(A_{n}) = \\prod_{k=0}^{n} \\left( 1 - \\dfrac{1}{9(k+1)+1} \\right) \\leq e^{ -\\sum_{k=0}^{n} 1/(9k+10) } $$ 由于级数 $ \\sum_{k=0}^{n} \\frac{1}{9k+10} $ 发散，所以 $ \\lim_{ n \\to \\infty }\\mathbb{P}(A_{n})=0 $，所以 12 点时 1 号球还在箱子里的概率 $ \\mathbb{P}(S_{1}) $ 为 0。类似地，还能得到其他球的概率 $ \\mathbb{P}(S_{n})=0 $。我们现在需要知道 12 点时箱子里还有球的概率，即 $ \\mathbb{P}(\\exists n \\subset \\mathbb{N},S_{n}) $，利用上一届的 union-bound，可以得到 $$ \\mathbb{P}(\\exists n \\subset \\mathbb{N},S_{n}) \\leq \\sum_{n\\geq 1}\\mathbb{P}(S_{n})=0 $$\nKarger 最小割算法 一个经典的问题是求图上的最小割。给定一个连通无向图 $ G(V,E) $，我们说边集 $ C \\subseteq E $ 是一个割，当且仅当删掉 $ C $ 以后剩下的 $ G(V,E\\setminus C) $ 是不连通的。我们需要寻找图上最小的一个割。\n我们在此处考虑用一个随机算法求解这个问题。\n定义图上的缩边操作：给定 $ e=\\{ u,v \\}\\in E $，我们将 $ u,v $ 合并成一个点，并删掉这条边，把缩完之后的图记为 $ G / e $。 Kager 算法的原理非常简单，从 $ G $ 出发，每次随机选择一条边，把它缩掉，重复执行 $ n-2 $ 之后图里面就会只剩下两个点，这时我们再输出所有剩下的边。\n这个算法“有可能”输出省却答案的原理是，由于我们关心的是”最小”的割，那么我们每一步选到割中的边的概率就不会太大。为了谈论这个概率，我们需要选择合适的概率空间。一个自然的想法是选择算法执行过程中所有删除的边的序列作为样本空间。\n设 $ C $ 是一个固定的最小割，并且其大小为 $ k $，我们需要计算最终输出 $ C $ 的概率。这需要我们执行的过程中，每一次都没有选到 $ C $ 中的边。我们用 $ A_{k} $ 来表示第 $ k $ 次执行完缩边操作后，$ C $ 中的任意一条边还没有被删掉的概率。\n为了分析 $ \\mathbb{P}(A_{k}) $，同理上一个例子中的想法，我们定义 $ B_{k} $ 为第 $ k $ 次缩边选择的不是 $ C $ 中的边这一事件，那么显然有 $ A_{k}=\\bigcap_{i=1}^{k}B_{i} $，因此根据链式法则，我们有 $$ \\mathbb{P}(\\text{output}=C) = \\mathbb{P}(A_{n-2}) = \\prod_{i=1}^{n-2}\\mathbb{P}\\left(B_{i}\\bigg| \\bigcap_{j=1}^{i-1}B_{j}\\right) $$ 我们需要找出一个这个概率的下界。我们想要说明每一轮都有比较大的概率选不到 $ C $ 中的边，由于选取是均匀的，所以只需要证明在第 $ i $ 轮，已知前 $ i-1 $ 轮都没有选到 $ C $ 中的边的情况下，图中剩下的边足够多即可。\n一个重要的观察是，此时图中每个点的度数都不小于 $ k $。原因是由于缩边这种操作不会破坏割的性质，如果有点的度数小于 $ k $，在原图中直接取这些边就得到了一个小于 $ k $ 的割。\n有了这个观察，我们就知道在第 $ i-1 $ 轮，剩下 $ n-i+1 $ 个顶点时，至少还有 $ \\frac{k}{2}\\cdot(n-i+1) $ 条边，所以我们就有 $$ \\mathbb{P}\\left( B_{i}\\bigg|\\bigcap_{j=1}^{i-1}B_{j} \\right) \\geq 1 - \\dfrac{k}{\\frac{k}{2} \\cdot (n-i+1)} = \\dfrac{n-i-1}{n-i+1} $$ 这说明 $$ \\mathbb{P}(A_{n-2}) \\geq \\prod_{i=1}^{n-2} \\dfrac{n-i-1}{n-i+1} = \\dfrac{2}{n(n-1)} $$ 因此我们的算法至少有 $ \\frac{2}{n(n-1)} $ 的概率可以输出 $ C $。如果我们重复这个算法 $ N=50n(n-1) $ 次，并且输出这么多次中找到的最小的割，那么这个割是最小割的概率至少有 $$ 1-\\left( 1- \\dfrac{2}{n(n-1)} \\right)^{N} \\geq 1 - e^{ -100 } $$ 使用并查集来维护的话，复杂度大约为 $ O(n^{2}m) $。\n","permalink":"https://diefish1024.github.io/posts/class-notes/math2701-probability-theory/lect3-conditional-probability/","summary":"\u003ch2 id=\"introduction\"\u003eIntroduction\u003c/h2\u003e\n\u003cp\u003e条件概率指一个事件在另一个事件发生的条件下发生的概率，用记号 $ \\mathbb{P}(A|B) $ 表示，仅在 $ \\mathbb{P}(B)\u003e0 $\n时有定义：\n$$ \n\n\\mathbb{P}(A|B) = \\dfrac{\\mathbb{P}(A \\cap B)}{P(B)}\n\n $$\n可以写成\n$$ \n\n\\mathbb{P}(A \\cap B) = \\mathbb{P}(B)\\cdot \\mathbb{P}(A|B)\n\n $$\u003c/p\u003e\n\u003cp\u003e对于 $ n $ 个事件，连续使用上式，即可得到\n$$ \n\n\\mathbb{P}\\left( \\bigcap_{i=1}^{n}A_{i} \\right) = \\prod_{k=1}^{n} \\mathbb{P}\\left( A_{k}\\bigg|\\bigcap_{i=1}^{k-1}A_{i} \\right)\n\n $$\n这个式子被称为 \u003ca href=\"https://en.wikipedia.org/wiki/Chain_rule_(probability)\"\u003e链式法则\u003c/a\u003e。\u003c/p\u003e\n\u003ch2 id=\"independence\"\u003eIndependence\u003c/h2\u003e\n\u003cp\u003e对于事件 $ A,B $，如果 $ \\mathbb{P}(A\\cap B)=\\mathbb{P}(A)\\mathbb{P}(B) $，或者等价地 $ \\mathbb{P}(A|B)=\\mathbb{P}(A) $，那么我们称 $ A $ 和 $ B $ 是独立的。这表明 $ A $ 或 $ B $ 自己是否发生对对方是否发生没有影响。\u003c/p\u003e","title":"Lect3-Conditional Probability"},{"content":"Motivation 例题：在圆上“随机”选一段弧，问弧长大于圆周的 $ \\frac{1}{3} $ 的概率？（Bertrand paradox）\n至少三种自然的“均匀化”模型会给出不同答案：\n对弧长参数均匀（在 $ [0, 2\\pi) $ 上均匀取长度，再随机起点）。 对端点在圆上独立均匀（等价于随机两点确定弧，需指定取较短或较长弧）。 对中心角或几何构造的中间量均匀（如均匀选角度后裁剪）。 核心问题：如何定义“随机”？不同“随机化”方案导致不同答案。\n讨论概率问题必须先明确概率空间（样本空间、事件族与概率测度），否则“概率”无从谈起。\nProbability Space 一个概率空间由三元组 $ (\\Omega, \\mathcal{F}, \\mathbb{P}) $ 构成：\n$ \\Omega $：样本空间（一次随机试验所有可能结果）。 $ \\mathcal{F} \\subseteq 2^{\\Omega} $：事件族（允许讨论与运算的集合）。 $ \\mathbb{P} : \\mathcal{F} \\to [0,1] $：概率测度（赋予事件概率）。 记号说明：\n$ \\Omega $：样本空间。 $ 2^{\\Omega} $：$ \\Omega $ 的幂集（所有子集的集合）。 为什么 $ \\mathbb{P} $ 要定义在 $ \\mathcal{F} $ 上而非直接在 $ \\Omega $ 上？\n离散可数时，取 $ \\mathcal{F} = 2^{\\Omega} $ 可行，且对单点赋值即可确定所有事件的概率。 连续时不同：单点的概率通常为 $ 0 $，但不可数并可有正概率；且 $ 2^{\\Omega} $ 中存在不可测集合，无法一致赋值（见下文 Vitali set 与 Axiom of Choice）。因此需选择一个足够大又可控的 $ \\sigma $- 代数作为事件族。 Sigma-Algebra 要求 $ \\mathcal{F} $ 构成一个 $ \\sigma $- 代数（域）：\n$ \\emptyset \\in \\mathcal{F},\\ \\Omega \\in \\mathcal{F} $。 若 $ A \\in \\mathcal{F} $，则其补集 $ A^{c} \\in \\mathcal{F} $。 若 $ A_{1}, A_{2}, \\dots \\in \\mathcal{F} $，则可数并 $ \\bigcup_{n \\ge 1} A_{n} \\in \\mathcal{F} $。 注：由德摩根律得可数交封闭。 “$ \\sigma $”表示对可数并封闭。\n直觉：这些封闭性保证我们做常见的事件运算不“跑出”可测范围。\nProbability Measure 概率测度 $ \\mathbb{P} : \\mathcal{F} \\to [0,1] $ 满足： 规范化：$ \\mathbb{P}(\\emptyset) = 0,\\ \\mathbb{P}(\\Omega) = 1 $。 补集关系：对任意 $ A \\in \\mathcal{F} $，$ \\mathbb{P}(A) = 1 - \\mathbb{P}(A^{c}) $。 可数可加性（对两两不交）：若 $ A_{i} \\cap A_{j} = \\emptyset $（$ i \\neq j $），则 $$ \\mathbb{P}\\Big( \\bigcup_{n \\ge 1} A_{n} \\Big) = \\sum_{n \\ge 1} \\mathbb{P}(A_{n}) $$ 若 $ \\Omega $ 可数且 $ \\mathcal{F} = 2^{\\Omega} $，记 $ p_{\\omega} := \\mathbb{P}(\\{\\omega\\}) $，则任意 $ A \\subseteq \\Omega $ 满足 $$ \\mathbb{P}(A) = \\sum_{\\omega \\in A} p_{\\omega} $$\nSet Operations and Event Semantics 集合—事件对应：\n$ A $：事件 $ A $ 发生。 $ A \\cup B $：至少一个发生。 $ A \\cap B $：同时发生。 $ A \\setminus B $：$ A $ 且不 $ B $。 $ A \\subseteq B $：$ A $ 蕴含 $ B $。 $ A \\cap B = \\emptyset $：不能同时发生。 $ A \\cup B = \\Omega $：必有一个发生。 这些操作在 $ \\mathcal{F} $ 内封闭（由 $ \\sigma $- 代数性质和德摩根律）。\nInclusion–Exclusion and Union Bound 单调性：若 $ A \\subseteq B $，则 $ \\mathbb{P}(A) \\le \\mathbb{P}(B) $。 证：写 $ B = A \\cup (B \\setminus A) $，并为不交，故 $ \\mathbb{P}(B) = \\mathbb{P}(A) + \\mathbb{P}(B \\setminus A) \\ge \\mathbb{P}(A) $.\n二集合容斥： $$ \\mathbb{P}(A \\cup B) = \\mathbb{P}(A) + \\mathbb{P}(B) - \\mathbb{P}(A \\cap B) $$\n并界（union bound, Boole 不等式）： $$ \\mathbb{P}\\Big( \\bigcup_{n} A_{n} \\Big) \\le \\sum_{n} \\mathbb{P}(A_{n}) $$\nLimits of Events 集合序列的极限： 若 $ A_{1} \\subseteq A_{2} \\subseteq \\cdots $，则 $$ \\lim_{n \\to \\infty} A_{n} = \\bigcup_{n \\ge 1} A_{n} $$ 若 $ A_{1} \\supseteq A_{2} \\supseteq \\cdots $，则 $$ \\lim_{n \\to \\infty} A_{n} = \\bigcap_{n \\ge 1} A_{n} $$ 测度的“连续性”（极限与测度交换）： 若 $ A_{n} \\uparrow $，则 $ \\mathbb{P}(\\lim A_{n}) = \\lim\\limits_{n \\to \\infty} \\mathbb{P}(A_{n}) $。 若 $ A_{n} \\downarrow $，则 $ \\mathbb{P}(\\lim A_{n}) = \\lim\\limits_{n \\to \\infty} \\mathbb{P}(A_{n}) $。 递增情形用不交分解与可数可加性；递减情形用德摩根律转化。 证：\n只证明递增（非降）的情形。\n使用极限的定义，有（类比裂项） $$ \\mathbb{P}(\\lim_{ n \\to \\infty } A_{n}) = \\mathbb{P}\\left( \\bigcup_{n\\geq 1}A_{n} \\right) = \\mathbb{P}\\left( A_{1} \\cup \\bigcup_{n\\geq\t2}(A_{n}\\setminus A_{n-1}) \\right) $$ 于是就把 $ \\lim_{ n \\to \\infty }A_{n} $ 写成了一堆不交集合的并，那么根据 $ \\mathbb{P} $ 的第三条公理，可以得到 $$ \\mathbb{P}(\\lim_{ n \\to \\infty } A_{n}) = \\mathbb{P}(A_{1}) + \\sum_{n\\geq 2}\\mathbb{P}(A_{n}\\setminus A_{n-1}) = \\mathbb{P}(A_{1}) + \\lim_{ N \\to \\infty } \\sum_{n=2}^{N} (\\mathbb{P}(A_{n})- \\mathbb{P}(A_{n-1})) = \\lim_{ n \\to \\infty } \\mathbb{P}(A_{n}) $$\nWhy Not Take All Subsets? 关于前面提到的为什么事件集 $ \\mathcal{F} $ 不能直接等于 $ 2^{\\Omega} $ 的问题，在这里给出一个证明。\n考虑问题，如何在 $ \\Omega = [0,1) $ 上定义“均匀分布” $ \\mathbb{P} $ ？\n直觉要求：\n长度一致性：对区间 $ (a,b) \\subset [0,1) $，$ \\mathbb{P}((a,b)) = b - a $。 平移不变性：对任意 $ I \\subset [0,1) $ 与 $ r \\in [0,1) $，有 $ \\mathbb{P}(I) = \\mathbb{P}(I + r) $，其中 $ I + r = \\{ (x + r) \\bmod 1 : x \\in I \\} $。 Vitali set（使用 Axiom of Choice）表明：若令 $ \\mathcal{F} = 2^{[0,1)} $，并要求上面两条与 $ \\sigma $- 可加性，则产生矛盾：（证明用到有理数集的什么性质？为什么一定要通过有理数？）\n定义等价关系 $ x \\sim y \\iff x - y \\in \\mathbb{Q} $，将 $ [0,1) $ 划分为等价类。 用 Axiom of Choice 从每个等价类选一代表，得集合 $ N $。 对每个 $ r \\in \\mathbb{Q} \\cap [0,1) $，令 $ N_{r} := N + r = \\{ (x+r) \\bmod 1: x \\in N\\} $，可证 $ \\{ N_{r} \\} $ 两两不交（反证法）且并为 $ [0,1) $ 的平移副本覆盖。 可数可加性与平移不变性给出 $$ 1 = \\mathbb{P}([0,1)) = \\sum_{r} \\mathbb{P}(N_{r}) = \\sum_{r} \\mathbb{P}(N) $$ 若 $ \\mathbb{P}(N) = 0 $，右端为 $ 0 $；若 $ \\mathbb{P}(N) \u003e 0 $，右端为 $ +\\infty $，均矛盾。 结论：$ 2^{[0,1)} $ 中存在不可测集合，无法一致赋予概率。 正确做法：取最小且足够的 $ \\sigma $- 代数（Borel $ \\sigma $- 代数）\n令 $ \\mathcal{F} $ 为包含所有开区间的最小 $ \\sigma $- 代数（Borel）。 在该 $ \\mathcal{F} $ 上存在与长度一致且平移不变的测度（勒贝格测度在 $ [0,1) $ 的限制），从而得到期望的“均匀分布”。 Discrete vs Continuous 离散可数： 可取 $ \\mathcal{F} = 2^{\\Omega} $，对单点赋值（质量函数）即可决定所有事件的概率。 连续不可数： 单点概率常为 $ 0 $，但不可数并可得正概率；不可测集合阻止我们将 $ \\mathcal{F} $ 取为 $ 2^{\\Omega} $。必须选取如 Borel（或其完备化）这样的“可测”结构。 Summary 概率论以 $ (\\Omega, \\mathcal{F}, \\mathbb{P}) $ 为基础对象。“随机”的语义由此三元组精确定义。 $ \\sigma $- 代数的可数封闭性与测度的可数可加性是技术与直觉的统一；它们保证常见事件运算与极限操作的可用性。 并界与容斥是估算复杂事件概率的常用工具。 在不可数空间，Axiom of Choice 导致不可测集合的存在，解释了为何不能取 $ \\mathcal{F} = 2^{\\Omega} $. ","permalink":"https://diefish1024.github.io/posts/class-notes/math2701-probability-theory/lect2-probability-space/","summary":"\u003ch2 id=\"motivation\"\u003eMotivation\u003c/h2\u003e\n\u003cp\u003e例题：在圆上“随机”选一段弧，问弧长大于圆周的 $ \\frac{1}{3} $ 的概率？（\u003ca href=\"https://en.wikipedia.org/wiki/Bertrand_paradox_(probability)\"\u003eBertrand paradox\u003c/a\u003e）\u003c/p\u003e\n\u003cp\u003e至少三种自然的“均匀化”模型会给出不同答案：\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e对弧长参数均匀（在 $ [0, 2\\pi) $ 上均匀取长度，再随机起点）。\u003c/li\u003e\n\u003cli\u003e对端点在圆上独立均匀（等价于随机两点确定弧，需指定取较短或较长弧）。\u003c/li\u003e\n\u003cli\u003e对中心角或几何构造的中间量均匀（如均匀选角度后裁剪）。\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e核心问题：如何定义“随机”？不同“随机化”方案导致不同答案。\u003c/p\u003e\n\u003cp\u003e讨论概率问题必须先明确概率空间（样本空间、事件族与概率测度），否则“概率”无从谈起。\u003c/p\u003e\n\u003ch2 id=\"probability-space\"\u003eProbability Space\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e一个概率空间由三元组 $ (\\Omega, \\mathcal{F}, \\mathbb{P}) $ 构成：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e$ \\Omega $：样本空间（一次随机试验所有可能结果）。\u003c/li\u003e\n\u003cli\u003e$ \\mathcal{F} \\subseteq 2^{\\Omega} $：事件族（允许讨论与运算的集合）。\u003c/li\u003e\n\u003cli\u003e$ \\mathbb{P} : \\mathcal{F} \\to [0,1] $：概率测度（赋予事件概率）。\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e记号说明：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e$ \\Omega $：样本空间。\u003c/li\u003e\n\u003cli\u003e$ 2^{\\Omega} $：$ \\Omega $ 的幂集（所有子集的集合）。\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e为什么 $ \\mathbb{P} $ 要定义在 $ \\mathcal{F} $ 上而非直接在 $ \\Omega $ 上？\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e离散可数时，取 $ \\mathcal{F} = 2^{\\Omega} $ 可行，且对单点赋值即可确定所有事件的概率。\u003c/li\u003e\n\u003cli\u003e连续时不同：单点的概率通常为 $ 0 $，但不可数并可有正概率；且 $ 2^{\\Omega} $ 中存在不可测集合，无法一致赋值（见下文 Vitali set 与 Axiom of Choice）。因此需选择一个\u003cstrong\u003e足够大又可控\u003c/strong\u003e的 $ \\sigma $- 代数作为事件族。\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"sigma-algebra\"\u003eSigma-Algebra\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e要求 $ \\mathcal{F} $ 构成一个 $ \\sigma $- 代数（域）：\u003c/p\u003e","title":"Lect2-Probability Space"},{"content":"Problem 1 (1)\n求 $$ \\sum_{k=0}^{n} \\binom{ 2n }{ 2k } $$\n解\n$$ \\begin{align*} \u0026 \\sum_{k=0}^{n} (-1)^{k}\\binom{ n }{ k } = 0 \\\\ \\implies \u0026 \\sum_{k=0}^{2n} (-1)^{k}\\binom{ 2n }{ k } =0 \\\\ \\implies \u0026 \\sum_{k=0}^{2n} \\binom{ 2n }{ 2k } = \\sum_{k=1}^{2n} \\binom{ 2n }{ 2k - 1 } \\end{align*} $$ 同时由于 $$ \\sum_{k=0}^{2n} \\binom{ 2n }{ 2k } + \\sum_{k=1}^{2n} \\binom{ 2n }{ 2k - 1 } = \\sum_{k=0}^{2n} \\binom{ 2n }{ k } = 2^{2n} $$ 得到 $$ \\sum_{k=0}^{2n} \\binom{ 2n }{ 2k } = 2^{2n-1} $$\n(2)\n求 $$ \\sum_{k=0}^{3n} \\binom{ 3n }{ 3k } $$\n解\n同理 (1) 的解法，设 $ z $ 为一个三次单位根，那么根据二项式定理有 $$ \\sum_{k=0}^{n} z^{k}\\binom{ n }{ k } = (1 + z)^{n} $$ 那么设 $ \\sum_{k=0}^{3n}\\binom{ 3n }{ 3k }=A,\\,\\sum_{k=0}^{3n-1}\\binom{ 3n }{ 3k+1 }=B,\\,\\sum_{k=0}^{3n-1}\\binom{ 3n }{ 3k+2 }=C $，就能得到 $$ A + z\\cdot B + z^{2}\\cdot C = (1 + z)^{3n} $$\n设 $ \\omega=e^{ \\frac{2\\pi i}{3} } $ ，则有 $ 1+\\omega+\\omega^{2}=0,\\omega^{3}=1 $. 分别令 $ z \\in \\{ 1,\\omega,\\omega^{2} \\} $ 带入上式，得到 $$ \\begin{cases} A + B + C \u0026 = (1+1)^{3n} \\\\ A + \\omega B + \\omega^{2}C \u0026 = (1+\\omega)^{3n} \\\\ A + \\omega^{2}B + \\omega C \u0026 = (1 + \\omega^{2})^{3n} \\end{cases} $$ 将三式相加并利用 $ 1+\\omega+\\omega^{2}=0 $ 的性质，移项即可得到 $$ A = \\dfrac{2^{3n} + (1+\\omega)^{3n} + (1+\\omega^{2})^{3n}}{3} $$ 带入 $ \\omega=-\\dfrac{1}{2}+\\dfrac{\\sqrt{ 3 }}{2}\\cdot i $ 得到 $ 1+\\omega=e^{ \\frac{\\pi i}{3} },1+\\omega^{2}=e^{ - \\frac{\\pi i}{3} } $ ，带入上式并化简可得 $$ \\sum_{k=0}^{n} \\binom{ 3n }{ 3k } = \\dfrac{2^{3n} + 2(-1)^{n}}{3} $$\nProblem 2 (1) $$ \\binom{ n }{ m } \\binom{ m }{ k } = \\binom{ n }{ k } \\binom{ n-k }{ m-k } $$ 证 1\n考虑左右两边组合意义：\n$ \\binom{ n }{ m }\\binom{ m }{ k } $ 可以表示在 $ n $ 个人中先选出 $ m $ 个人，再在这 $ m $ 个人中选出 $ k $ 个人的概率，本质上是把 $ n $ 个人分成了 $ 3 $ 类，每类分别有 $ n-m,\\,m-k,\\,k $ 个人。\n$ \\binom{ n }{ k }\\binom{ n-k }{ m-k } $ 可以看成在 $ n $ 个人里面选出 $ k $ 个人，再在剩下 $ n-k $ 个人中选出 $ m-k $ 个人，同样也可以看成是分成了分别有 $ n-m,\\,m-k,\\,k $ 个人的三类。\n因此左右表示同一个组合意义，值必然相同。\n证 2 $$ \\binom{ n }{ m } \\binom{ m }{ k } = \\dfrac{n^{\\underline{m}}}{m!}\\cdot \\dfrac{m^{\\underline{k}}}{k!} = \\dfrac{n^{\\underline{k}}}{k!}\\cdot \\dfrac{n^{\\underline{m}}}{n^{\\underline{k}}}\\cdot \\dfrac{m^{\\underline{k}}}{m!} = \\dfrac{n^{\\underline{k}}}{k!}\\cdot \\dfrac{(n-k)^{\\underline{m-k}}}{(m-k)!} = \\binom{ n }{ k } \\binom{ n-k }{ m-k } $$\n(2) $$ \\sum_{k=0}^{r} \\binom{ n+k }{ k } = \\binom{ n+r+1 }{ r } $$ 证 1\n考虑组合意义。\n右式变形为 $ \\binom{ n+r+1 }{ n+1 } $ 可以表示为在 $ n+r+1 $ 个人中选出 $ n+1 $ 个人的方案数。\n左侧变形为 $ \\sum \\binom{ n+k }{ n } $ 可以看成枚举要选的最后一个人是第 $ n+k+1 $ 个人，在前 $ n+k $ 个人中选择 $ n $ 个人，所有情况的和恰好也是在 $ n+r+1 $ 个人中选出 $ n+1 $ 个人的方案数。\n因此左右两次可以表达同一个组合意义，值相同。\n证 2\n考虑等式 $$ \\binom{ n+k }{ k } + \\binom{ n+k }{ k-1 } = \\binom{ n+k+1 }{ k } $$ 移项得到 $$ \\binom{ n+k }{ k } = \\binom{ n+k+1 }{ k } - \\binom{ n+k }{ k-1 } $$ 在求和可得 $$ \\sum_{k=0}^{r} \\binom{ n+k }{ k } = \\sum_{k=0}^{r} \\left[ \\binom{ n+k+1 }{ k } - \\binom{ n+k }{ k-1 } \\right] = \\binom{ n+r+1 }{ r } - \\binom{ n }{ -1 } $$ 认为 $ \\binom{ n }{ k } $ 在 $ k\u003en $ 或者 $ k\u003c 0 $ 时 $ \\binom{ n }{ k }=0 $ ，则可得到 $$ \\sum_{k=0}^{r} \\binom{ n+k }{ k } = \\binom{ n+r+1 }{ r } $$\n(3) $$ \\sum_{k=0}^{n} \\binom{ n }{ k } ^{2}k = n\\binom{ 2n-1 }{ n-1 } $$ 证 1\n考虑组合意义，同样以在班级中选人举例。\n由于 $ 2\\binom{ 2n-1 }{ n-1 }=\\binom{ 2n }{ n } $，右侧变形为 $ \\frac{n}{2}\\binom{ 2n }{ n } $ ，可以表示在 $ 2n $ 个人（男女各一半）的班级中选出 $ n $ 个人当班委，再在这 $ n $ 个人中选出一个男生当班长的方案数。\n左侧变成 $ \\sum_{k=0}^{n}\\binom{ n }{ k }\\binom{ n }{ n-k }k $ ，对于每个 $ k $ 表示 $ n $ 个男生 $ n $ 个女生的班级中，男生选出 $ k $ 个人，女生选出 $ n-k $ 个人，共 $ n $ 个人当班委，再从 $ k $ 个男生班委中选出一个人当班长的方案数。把所有 $ k $ 的情况合起来，同样可以得到在男女各半的 $ 2n $ 个人中选出 $ n $ 个班委和一个男生班长的方案数。\n因此左右两式可以表达同一个组合意义，值相同。\n证 2\n将恒等式 $$ k\\binom{ n }{ k } = n\\binom{ n-1 }{ k-1 } = n\\binom{ n-1 }{ n-k } $$ 带入左式，左右两侧消去 $ n $ 后，只需证 $$ \\sum_{k=0}^{n} \\binom{ n }{ k } \\binom{ n-1 }{ n-k } = \\binom{ 2n-1 }{ n-1 } $$ 根据 Vandermonde 卷积 $$ \\sum_{k=0}^{n} \\binom{ n }{ k } \\binom{ n-1 }{ n-k } = \\binom{ n + n - 1 }{ n } = \\binom{ 2n-1 }{ n } $$ 因此原式得证！\n(4) $$ \\sum_{i=0}^{a} \\binom{ a }{ i } \\binom{ b+i }{ a } = \\sum_{i=0}^{a} \\binom{ a }{ i } \\binom{ b }{ i } 2^{i} $$ 证 1\n从组合意义证明，同样以班级选班委举例。考虑一个班级有 $ a $ 个班委和 $ b $ 个非班委，现进行班委换届。\n左式对于每个 $ i $ ，$ \\binom{ a }{ i }\\binom{ b+i }{ a } $ 表示 $ a $ 个班委中有 $ i $ 个人有意愿再参与下一届的班委选举，在 $ b+i $ 个人中选举产生新的 $ a $ 个班委。每种情况加起来，表示 $ a $ 个原班委自由选择是否参加选举的前提下班委换届的所有方案数。\n右式对于每个 $ i $ ，将 $ \\binom{ a }{ i } $ 变换为 $ \\binom{ a }{ a-i } $ ，$ \\binom{ a }{ a-i }\\binom{ b }{ i } $ 表示新一届班委中有 $ i $ 个来自原先 $ b $ 个非班委的方案数，$ 2^{i} $ 表示剩下没选上、未知竞选意愿的 $ i $ 个原班委所有竞选意愿的可能。将每种情况加起来，也同样可以得到 $ a $ 个原班委自由选择是否参选的前提下班委换届的方案数。\n因此左右两式可以表示相同的组合意义，值相同。\n证 2\n根据 Vandermonde 卷积 $$ \\binom{ b+i }{ a } = \\sum_{j=0}^{i} \\binom{ i }{ j } \\binom{ b }{ a-j } $$ 带入左式得到 $$ \\begin{align*} \\sum_{i=0}^{a} \\binom{ a }{ i } \\binom{ b+i }{ a } \u0026 = \\sum_{i=0}^{a} \\sum_{j=0}^{i} \\binom{ b }{ a-j } \\binom{ a }{ i } \\binom{ i }{ j } \\\\ \u0026 = \\sum_{i=0}^{a} \\sum_{j=0}^{i} \\binom{ b }{ a-j } \\binom{ a }{ j } \\binom{ a-j }{ i-j } \\\\ \u0026 = \\sum_{j=0}^{a} \\binom{ b }{ a-j } \\binom{ a }{ j } \\sum_{i=j}^{a} \\binom{ a-j }{ i-j } \\\\ \u0026 = \\sum_{j=0}^{a} \\binom{ b }{ a-j } \\binom{ a }{ a-j } 2^{a-j} \\\\ \u0026 \\xlongequal{i=a-j} \\sum_{i=0}^{a} \\binom{ b }{ i } \\binom{ a }{ i } 2^{i} \\end{align*} $$\nProblem 3 给定集合 $ A=\\{1,2,\\ldots,n\\} $ 与正整数 $ k $，从 $ A $ 中选出一组按三角阵排列的 $ \\binom{k+1}{2} $ 个子集 $$ \\begin{matrix} S_{1,1} \\\\ S_{2,1} \u0026 S_{2,2} \\\\ \\vdots \u0026 \\vdots \u0026 \\ddots \\\\ S_{k,1} \u0026 S_{k,2} \u0026 \\dots \u0026 S_{k,k} \\end{matrix} $$ 满足每个集合是它左边和上方的集合（如果存在）的子集。需要求出满足这个要求的选择方案数。\n解\n由于每个元素相互独立，具体方案和元素无关，因此可以考虑一个元素的合法出现方式（在哪些集合会包含这个元素）的总数，设为 $ f(k) $ ，那么最后答案即为 $ [f(k)]^{n} $ 。\n现在考虑 $ x\\in A $ ，根据包含关系，不难看出如果 $ x\\in S $ ，那么 $ S $ 左侧和上方（如果存在）的集合都会包含 $ x $。因此出现 $ x $ 的集合在 $ k $ 阶三角形中可以形成一个从 $ (1,1) $ 出发，每次可以向右或者下方通行的有向图。\n考虑某个合法方案，设元素最后一次出现在对角线（$ S_{1,1},\\dots,S_{k,k} $）的位置为 $ S_{r,r} $ ，那么根据包含关系，此时显然 $ x $ 包含于上方的 $ r $ 阶小三角阵中的每一个元素，并且不会出现在下方的 $ k-r $ 阶小三角方阵中（否则必然会再次出现在对角线中）。因此只需要考虑 $ x $ 在余下部分，也就是四个顶点分别为为 $ (r+1,1),(r+1,r),(k,1),(k,r) $ 的长方形区域中的合法方案数即可。\n对于这样的长方形区域，我们可以按行考虑，显然根据包含的规则， $ x $ 在每一行出现的形式必定是从最左侧开始连续的一段，并且上到下每一行 $ x $ 出现的次数是不降的。因此我们可以把这个问题转化为求一个长度为 $ k-r $ ，每个数范围为 $ 0\\sim r $ 的单调不降序列的方案数。设第 $ i $ 个数的值为 $ t_{i} $ ，那么方案数为 $$ \\begin{align*} \\sum_{t_{1}=0}^{r} \\sum_{t_{2}=0}^{t_{1}} \\dots \\sum_{t_{k-r}=0}^{t_{k-r-1}} 1 \u0026 = \\sum_{t_{1}=0}^{r} \\dots \\sum_{t_{k-r-1}=0}^{t_{k-r-2}} (t_{k-r-1} + 1) \\\\ \u0026 = \\sum_{t_{1}=0}^{r} \\dots \\sum_{t_{k-r-1}=0}^{t_{k-r-2}} \\binom{ t_{k-r-1} + 1 }{ 1 } \\\\ \u0026 = \\sum_{t_{1}=0}^{r} \\dots \\sum_{t_{k-r-2}=1}^{t_{k-r-3}} \\binom{ t_{k-r-2}+2 }{ 2 } \\\\ \u0026 \\dots \\\\ \u0026 = \\sum_{t_{1}=0}^{r} \\binom{ t_{1} + k-r-1 }{ k-r-1 } = \\binom{ k }{ k-r } \\end{align*} $$ 因此 $$ f(k) = \\sum_{r=0}^{k} \\binom{ k }{ k-r } = \\sum_{r=0}^{k} \\binom{ k }{ r } = 2^{k} $$ 所以方案数为 $$ [f(k)]^{n} = 2^{nk} $$\nProblem 4 给定一个长度为 $ mn+1 $ 的序列 $ a_{0},a_{1},\\ldots,a_{mn} $，其中每一项只可能取 $ 1 $ 或 $ 1-m $，并且满足总和 $$ \\sum_{i=0}^{mn} a_i = 1 . $$ 在此条件下：\n(1)\n证明：在该序列里，取值为 $ 1 $ 的项共有 $ mn-n+1 $ 个，而取值为 $ 1-m $ 的项共有 $ n $ 个。\n证\n设 $ 1 $ 有 $ a $ 个，$ 1-m $ 有 $ b $ 个，那么得到方程 $$ \\begin{cases} a + b = mn+1 \\\\ a + (1-m)b = 1 \\end{cases} $$ 直接可以解得 $$ \\begin{cases} a = mn-n+1 \\\\ b=n \\end{cases} $$\n(2)\n把序列首尾相接排成一个圆环。考虑所有可能的“起点”选择（即对序列做循环移位）。\n证明：恰好存在唯一一个起点 $ k $，使得从该位置开始依次相加得到的所有部分和都为正，即 $$ a_k,\\ a_k+a_{k+1},\\ \\ldots,\\ a_k+a_{k+1}+\\cdots+a_{k-1} $$ 全部大于 $ 0 $（下标按模 $ mn+1 $ 计算）。\n证\n考虑序列前缀和 $ S_{t} = \\sum_{i=0}^{t}a_{i} $ ，并且 $ S_{-1}=0 $。在序列 $ \\{ S_{-1},S_{0},\\dots,S_{mn} \\} $ 中存在最小值 $ S_{k} $，如果有多个，取其中下标最大的为 $ S_{k} $，显然 $ S_{k} $ 唯一。\n于是 $ \\forall r\\in \\{ k+1,\\dots,mn \\} $ ，有 $ S_{r}\u003eS_{k} $ ，因此从 $ k+1 $ 到 $ r $ 的子段和为 $ \\sum_{i=k+1}^{r}a_{i}=S_{r}-S_{k}\u003e0 $\n并且 $ \\forall l\\in \\{ 0,\\dots,k \\}: S_{l-1}\\leq S_{k} $ ，因此从 $ k+1 $ 开始的一段循环序列中的和为（考虑在原序列中这一段的补集）： $$ \\sum_{i=k+1}^{mn+1+l}a_{i\\bmod (mn+1)}=\\sum_{i=0}^{mn}a_{i} - \\sum_{i=l}^{k}a_{i}=1-(S_{k}-S_{l-1}) = 1+S_{l-1}-S_{k}\\geq 1 \u003e 0 $$\n综上，我们找出了唯一满足从该位置开始左右的部分和都为正的一个位置，证毕。\n(3)\n求满足“所有前缀部分和都为正”的序列 $ a_{0},a_{1},\\ldots,a_{mn} $ 的总数。\n证 1\n不考虑任意前缀和为正的限制，所有的序列总数为 $ \\binom{ mn+1 }{ n } $（总共 $ mn+1 $ 个数，选择 $ n $ 个数为 $ 1-m $）。\n对于任意一个序列，根据 $ (2) $ 的结论，存在唯一的 $ k $ 使得从 $ k $ 开始的所有前缀和为正，因此我们将改序列的下标向左平移 $ k $ 即可得到一个合法的序列。\n这说明每种圆排列都对应唯一一个合法的序列，所以答案为 $$ \\dfrac{1}{mn+1}\\binom{ mn+1 }{ n } $$\n证 2（没证出来😭）\n首先必然有 $ a_{0}=1 $ ，否则 $ a_{0}=1-m\u003c 0 $ 已经不满足条件。因此可以在原序列去掉 $ a_{0} $，问题的约束转化为 $ \\sum_{i=1}^{mn}a_{i}=0 $ ，保证从 $ a_{1} $ 开始的前缀和非负即可。\n将问题转化为在一个二维网格上路径计数的模型：从起点 $ O(0,0) $ 出发，每一步会向上走 $ 1 $ 格或者向右走 $ 1 $ 格，目标走到 $ D(n,n(m-1)) $，其中前缀和非负的约束转化为不能越过直线 $ l:y=(m-1)x $ 。\n我们将向上走的操作记为 $ U $，向右走的操作记为 $ R $，显然最终一个 $ R $ 可以对应 $ (m-1) $ 个 $ U $ 操作。由于一个 $ R $ 操作的跨度过大，使我们难以操作“路径中第一个不合法的点”，因此我们考虑将 $ R $ 拆解成粒度更小 $ (m-1) $ 个连续的 $ r $ 操作，可以看成向右移动 $ \\dfrac{1}{m-1} $ 格的距离。此时一条路径中含有 $ N=n(m-1) $ 个 $ U $ 操作和 $ r $ 操作。\n考虑一条不合法的路径，可以看成一个不合法的操作序列 $ S $，单独找出第一次越过 $ l $ 的 $ r $ 操作，可以将 $ S $ 分解成 $$ S = ArB $$ 其中 $ A $ 的末尾刚好在 $ l $ 上，满足 $ r=U $ （数量），$ B $ 为剩余序列。\n由于 $ A $ 的性质更好，所以参考 Catalan 数的证明，我们考虑将 $ A $ “反射”，将其中的所有 $ r $ 和 $ U $ 操作互换，得到 $ \\overline{A} $，从而构造出 $$ S'=\\overline{A}rB $$ 于是我们得到了一个不合法序列 $ S $ 和某个 $ S' $ 序列的双射。从 $ S' $ 映射会 $ S $ 同样只需要找出第一次到达 $ l $ 的位置找出 $ \\overline{A} $，再进行一次“反射”即可。\n我们再定义一个压缩操作，表示从左到右扫描一个序列，遇到 $ U $ 直接加入新的序列，遇到累计遇到 $ (m-1) $ 个 $ r $ 向新序列中加入一个 $ R $。这样对于任意一个 $ U $ 和 $ r $ 数量均为 $ N $ 的序列，压缩后都会得到一个无约束的 $ U-R $ 序列。我们将这个操作记为 $ C(S) $，$ S $ 表示操作的 $ U-r $ 序列。\n于是现在我们对于一条不合法的路径，将其细化为 $ U-r $ 序列 $ S $ 后再反射为 $ S' $，压缩后得到 $ P=C(S') $，这是一个无约束的 $ U-R $ 序列，含有 $ n $ 个 $ R $。\n// 通过手动计算小数据，可以猜出一个合法序列对应 $ n(m-1) $ 个非法序列的结论。并且注意到有 $ N $ 个 $ U $ 操作，因此希望通过引入某种“标记操作”，来标记某个 $ U $ 操作，来构造出一个 $ \\text{非法序列} \\leftrightarrow (\\text{合法序列},u^{*}) $ 的双射，其中 $ u^{*} $ 表示被标记的 $ U $ 操作。这样说明一个合法序列对应 $ N $ 个非法序列，于是合法序列数量为 $$ \\dfrac{1}{N+1}\\binom{ mn }{ n } = \\dfrac{1}{n(m-1)+1}\\binom{ mn }{ n } = \\dfrac{1}{mn+1}\\binom{ mn+1 }{ n } $$\n","permalink":"https://diefish1024.github.io/posts/class-notes/cs0901-combinatorics/cs0901-hw1/","summary":"\u003ch2 id=\"problem-1\"\u003eProblem 1\u003c/h2\u003e\n\u003cp\u003e\u003cstrong\u003e(1)\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e求\n$$ \n\n\\sum_{k=0}^{n} \\binom{ 2n }{ 2k } \n\n $$\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e解\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e$$ \n\n\\begin{align*}\n \u0026 \\sum_{k=0}^{n} (-1)^{k}\\binom{ n }{ k } = 0 \\\\\n\\implies \u0026 \\sum_{k=0}^{2n} (-1)^{k}\\binom{ 2n }{ k } =0 \\\\\n\\implies \u0026 \\sum_{k=0}^{2n} \\binom{ 2n }{ 2k } = \\sum_{k=1}^{2n} \\binom{ 2n }{ 2k - 1 } \n\\end{align*}\n\n $$\n同时由于\n$$ \n\n\\sum_{k=0}^{2n} \\binom{ 2n }{ 2k } + \\sum_{k=1}^{2n} \\binom{ 2n }{ 2k - 1 } = \\sum_{k=0}^{2n} \\binom{ 2n }{ k } = 2^{2n}\n\n $$\n得到\n$$ \n\n\\sum_{k=0}^{2n} \\binom{ 2n }{ 2k } = 2^{2n-1}\n\n $$\u003c/p\u003e","title":"CS0901 HW1"},{"content":"Product and Sum Principles 加法原理（分类计数） 若一个任务可分解为若干个互斥的子类，第 $ i $ 类有 $ a_i $ 种方案，则总数为 $ \\sum_i a_i $。 解释：互斥保证不重不漏，求和即“或”的计数。\n乘法原理（分步计数） 若一个任务分为若干个有序步骤，步骤 $ i $ 有 $ b_i $ 种选择且相互独立，则总数为 $ \\prod_i b_i $。 解释：有序步骤逐个做决定，“且”的计数对应乘法。\nConstructing Maps 有些组合证明可以依赖于构造映射：\n单射：不同原像映到不同像，用于证明下界或“可嵌入性”。 满射：像覆盖全体，用于证明上界可达或构造覆盖。 双射：建立集合 $ A $ 与 $ B $ 的一一对应，从而数 $ |A|=|B| $；这是“数某一个量 ⇒ 构造双射”的核心思想。 Twelvefoldway 将 $ n $ 个球放入 $ m $ 个盒子，球与盒子可“可区分/不可区分”，以及盒子容量约束“任意/至多 1/至少 1”。\n$ n $ $ m $ 任意 $ \\leq 1 $ $ \\geq 1 $ 不同 不同 $ m^{n} $ $ m^{\\underline{n}} $ $ m!\\left\\{ {n \\atop m} \\right\\} $ 同 不同 $ \\binom{ n+m-1 }{ m-1 } $ $ \\binom{ m }{ n } $ $ \\binom{ n-1 }{ m-1 } $ 不同 同 $ \\sum_{k=0}^{\\min(n,m)} \\left\\{ {n \\atop k} \\right\\} $ $ [n \\leq m] $ $ \\left\\{ {n \\atop m} \\right\\} $ 同 同 $ p_{\\leq m}(n) $ $ [n \\leq m] $ $ p(n,m) $ “把 $ n $ 个不同球分成 $ k $ 个非空无序盒”对应第二类斯特林数 $ \\left\\{ {n \\atop k} \\right\\} $。\nStirling Numbers of the Second Kind 定义：$ \\left\\{ {n \\atop k} \\right\\} $ 表示“将 $ n $ 个不同元素分成 $ k $ 个非空无序块”的方案数。\n基本递推：$$ \\left\\{ {n \\atop k} \\right\\} = \\left\\{ {n-1 \\atop k-1} \\right\\} + k \\left\\{ {n-1 \\atop k} \\right\\}, \\quad \\left\\{ {0 \\atop 0} \\right\\}=1 $$ 从组合意义上理解，元素 $ n $ 要么独自成新块（$ \\left\\{ {n-1 \\atop k-1} \\right\\} $），要么加入已有 $ k $ 个块之一（$ k \\left\\{ {n-1 \\atop k} \\right\\} $）。\n与降阶阶乘的分层展开：$$ m^{n} = \\sum_{k=1}^{n} \\left\\{ {n \\atop k} \\right\\} m^{\\underline{k}} $$ 组合证明：\n将 $ n $ 个不同球先“分组”为 $ k $ 个非空无序块： $ \\left\\{ {n \\atop k} \\right\\} $。 从 $ m $ 个可区分盒中选出并按顺序对应这 $ k $ 个块： $ m^{\\underline{k}} $。 按 $ k $ 分层求和即得全部映射 $ [n] \\to [m] $ 的总数 $ m^n $。 另一恒等式：$$ \\left\\{ {n \\atop m} \\right\\} = \\sum_{k=0}^{n-1} \\binom{ n-1 }{ k } \\left\\{ {n-k-1 \\atop k-1} \\right\\} $$\nVandermonde’s Convolution 范德蒙卷积： $$ \\binom{ r+s }{ n } = \\sum_{k=0}^{n} \\binom{ r }{ k } \\binom{ s }{ n-k } $$\n组合证明：从 $ r+s $ 个元素中选 $ n $ 个。分类：从前 $ r $ 个元素选 $ k $ 个、从后 $ s $ 个元素选 $ n-k $ 个，$ k $ 遍历 $ 0 $ 至 $ n $，互斥且完备，故求和。\n代数证明：用二项式定理展开 $ (1+x)^{r+s} = (1+x)^r (1+x)^s $，比对 $ x^n $ 的系数即得。\nBinomial Coefficients 对称性： $ \\binom{ n }{ k } = \\binom{ n }{ n-k } $ 组合：选 $ k $ 个等价于弃 $ n-k $ 个。\nPascal 恒等式： $ \\binom{ n }{ k } = \\binom{ n-1 }{ k } + \\binom{ n-1 }{ k-1 } $ 组合：考虑是否包含元素 $ n $。\n总和： $ \\sum_{k=0}^{n} \\binom{ n }{ k } = 2^{n} $ 组合：每元素选/不选两种，乘法原理；或代数用 $ (1+1)^n $。\n“曲棍球杆”恒等式： $ \\sum_{i=r}^{n} \\binom{ i }{ r } = \\binom{ n+1 }{ r+1 } $ 组合：给定最大元素，按其值分类累加；或用 Pascal 叠加。\n一阶矩： $ \\sum_{k=0}^{n} k \\binom{ n }{ k } = n 2^{n-1} $ 组合：双计数“选出子集并指定一个已选标记元素”；或代数对 $ (1+x)^n $ 求导令 $ x=1 $。\n二项式定理： $ (x+y)^{n} = \\sum_{k=0}^{n} \\binom{ n }{ k } x^{k} y^{n-k} $ 代数：展开乘法；组合：从 $ n $ 个因子中选 $ k $ 次取 $ x $。\n范德蒙卷积：见上一节。\n凸性与对数凹性：\n对于固定 $ n $，序列 $ \\left( \\binom{ n }{ 0 }, \\binom{ n }{ 1 }, \\dots, \\binom{ n }{ n } \\right) $ 是对称、单峰且对数凹：对所有可行 $ k $，有 $$ \\binom{ n }{ k }^{2} \\ge \\binom{ n }{ k-1 } \\binom{ n }{ k+1 } $$ 计算比值 $$ \\frac{ \\binom{ n }{ k } }{ \\binom{ n }{ k-1 } } = \\frac{ n-k+1 }{ k }, \\quad \\frac{ \\binom{ n }{ k+1 } }{ \\binom{ n }{ k } } = \\frac{ n-k }{ k+1 } $$ 由此得 $$ \\frac{ \\binom{ n }{ k }^{2} }{ \\binom{ n }{ k-1 } \\binom{ n }{ k+1 } } = \\frac{ k (k+1) }{ (n-k+1)(n-k) } \\cdot \\frac{ (n-k+1)(n-k) }{ k (k+1) } = 1 $$ Catalan Numbers 第 $ n $ 个卡特兰数 $$ C_n = \\frac{ 1 }{ n+1 } \\binom{ 2n }{ n } $$\n网格路径模型：从点 $ (0,0) $ 到 $ (n,n) $，每步向右 $ R $ 或向上 $ U $，要求路径始终不越过主对角线 $ y=x $。这等价于计数长度 $ 2n $ 的序列，任意前缀中 $ U $ 的数量不小于 $ R $ 的数量。\n经典反射法证明（Ballot/Reflection）：\n总路径数：不加限制，从 $ 2n $ 步中选出 $ n $ 步为 $ U $，共 $ \\binom{ 2n }{ n } $ 条。 计“坏”路径：越界的路径。设首次越界的时刻为第 $ t $ 步，此时 $ R $ 比 $ U $ 多一。将前 $ t $ 步关于直线 $ y=x $ 反射（交换 $ U $ 与 $ R $），得到一条从 $ (0,0) $ 到 $ (n+1,n-1) $ 的路径；此构造是坏路径与“从 $ (0,0) $ 到 $ (n+1,n-1) $ 的任意路径”之间的双射。因此坏路径数为 $ \\binom{ 2n }{ n-1 } $。 好路径数： $ \\binom{ 2n }{ n } - \\binom{ 2n }{ n-1 } = \\frac{ 1 }{ n+1 } \\binom{ 2n }{ n } $，即 $ C_n $。 本质抽象：两类操作 $ U $ 与 $ R $ 总数相等，且任意时刻“$ U $ 的累计数 ≥ $ R $ 的累计数”。同构到投票/括号配对/堆栈可行序等大量模型。\n","permalink":"https://diefish1024.github.io/posts/class-notes/cs0901-combinatorics/lect1-counting/","summary":"\u003ch2 id=\"product-and-sum-principles\"\u003eProduct and Sum Principles\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e加法原理（分类计数）\u003c/strong\u003e\n若一个任务可分解为若干个互斥的子类，第 $ i $ 类有 $ a_i $ 种方案，则总数为 $ \\sum_i a_i $。\n解释：互斥保证不重不漏，求和即“或”的计数。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e乘法原理（分步计数）\u003c/strong\u003e\n若一个任务分为若干个有序步骤，步骤 $ i $ 有 $ b_i $ 种选择且相互独立，则总数为 $ \\prod_i b_i $。\n解释：有序步骤逐个做决定，“且”的计数对应乘法。\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"constructing-maps\"\u003eConstructing Maps\u003c/h2\u003e\n\u003cp\u003e有些组合证明可以依赖于构造映射：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e单射\u003c/strong\u003e：不同原像映到不同像，用于证明下界或“可嵌入性”。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e满射\u003c/strong\u003e：像覆盖全体，用于证明上界可达或构造覆盖。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e双射\u003c/strong\u003e：建立集合 $ A $ 与 $ B $ 的一一对应，从而数 $ |A|=|B| $；这是“数某一个量 ⇒ 构造双射”的核心思想。\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"twelvefoldway\"\u003e\u003ca href=\"https://en.wikipedia.org/wiki/Twelvefold_way\"\u003eTwelvefoldway\u003c/a\u003e\u003c/h2\u003e\n\u003cp\u003e将 $ n $ 个球放入 $ m $ 个盒子，球与盒子可“可区分/不可区分”，以及盒子容量约束“任意/至多 1/至少 1”。\u003c/p\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth\u003e$ n $\u003c/th\u003e\n          \u003cth\u003e$ m $\u003c/th\u003e\n          \u003cth\u003e任意\u003c/th\u003e\n          \u003cth\u003e$ \\leq 1 $\u003c/th\u003e\n          \u003cth\u003e$ \\geq 1 $\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e不同\u003c/td\u003e\n          \u003ctd\u003e不同\u003c/td\u003e\n          \u003ctd\u003e$ m^{n} $\u003c/td\u003e\n          \u003ctd\u003e$ m^{\\underline{n}} $\u003c/td\u003e\n          \u003ctd\u003e$ m!\\left\\{ {n \\atop m} \\right\\} $\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e同\u003c/td\u003e\n          \u003ctd\u003e不同\u003c/td\u003e\n          \u003ctd\u003e$ \\binom{ n+m-1 }{ m-1 } $\u003c/td\u003e\n          \u003ctd\u003e$ \\binom{ m }{ n } $\u003c/td\u003e\n          \u003ctd\u003e$ \\binom{ n-1 }{ m-1 } $\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e不同\u003c/td\u003e\n          \u003ctd\u003e同\u003c/td\u003e\n          \u003ctd\u003e$ \\sum_{k=0}^{\\min(n,m)} \\left\\{ {n \\atop k} \\right\\} $\u003c/td\u003e\n          \u003ctd\u003e$ [n \\leq m] $\u003c/td\u003e\n          \u003ctd\u003e$ \\left\\{ {n \\atop m} \\right\\} $\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e同\u003c/td\u003e\n          \u003ctd\u003e同\u003c/td\u003e\n          \u003ctd\u003e$ p_{\\leq m}(n) $\u003c/td\u003e\n          \u003ctd\u003e$ [n \\leq m] $\u003c/td\u003e\n          \u003ctd\u003e$ p(n,m) $\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003e“把 $ n $ 个不同球分成 $ k $ 个非空无序盒”对应第二类斯特林数 $ \\left\\{ {n \\atop k} \\right\\} $。\u003c/p\u003e","title":"Lect1-Counting"},{"content":"课程讲义\n在这门课里，我们会专注于所谓的 科尔莫哥洛夫（Kolmogorov）的公理体系，它使得我们能够使用数学分析的工具来研究概率。\nSt. Petersburg Paradox 圣彼得堡悖论。假设一个基于抛硬币赌博的游戏，庄家会一直扔硬币直到结果是正面，如果扔了 $ k $ 次，那么就会给玩家 $ 2^{k} $ 元的奖金。现在的问题是你愿意花多少钱来购买一次玩这个游戏的机会。\n一个很自然的想法是计算游戏的期望，那么我们很容易发现期望收益是 $$ \\sum_{k \\geq 1} 2^{k}\\cdot 2^{-k} = 1 + 1 + \\dots = +\\infty $$ 这说明平均每一轮我们的收益是无穷大，然而在现实生活中你真的愿意花大价钱去玩这个游戏吗？或者可以写一个简单的程序模拟一下就会发现，在比如门票定为 $ 100 $ 元，玩几百局，还是会轻易地输掉几万块钱。我们生活中一个常见的直觉是如果重复一个随机过程足够多次，平均收益就会逐渐趋近于期望收益，这在概率论中叫做大数定律（Law of large numbers），但是在现实生活中我们并没有能力重复足够多游戏轮数去达到这个期望值。那么现在的问题就是如果定价用 $ a\\cdot n $ 元来购买 $ n $ 次游戏机会，$ a $ 定为多少是合理的？\n用这门课中后续会学习到的数学工具，我们可以得到答案为 $ \\log n $ （这个结果也符合我们实际的直觉）。\n随机游走 对二维随机游走问题的一个简化的建模是在 $ \\mathbb{Z}^{2} $ 的网格上随机游走，从原点 $ (0,0) $ 出发，每次以 $ \\dfrac{1}{4} $ 的概率往上下左右四个方向移动。我们现在询问，这个随机游走的路径是否会无数次回到原点？用 $ T $ 来表示第一次回到原点的时间，那么可以证明无数次回到原点等价于 $ \\mathbb{P}[T \u003c \\infty] = 1 $ ，也就是 $ T $ 以 $ 1 $ 的概率是有限的，当然目前只能从直觉上去理解，这个写法需要在后续的课程中去严格定义。\n关于这个问题的答案，波利亚证明了当考虑 $ n $ 维格点 $ \\mathbb{Z}^{n} $ 的随机游走时，对于 $ n\u003c 2 $ ，$ \\mathbb{P}[T \u003c \\infty] = 1 $ ，对于 $ n\\geq 2 $ ，$ \\mathbb{P}[T \u003c \\infty] \u003c 1 $。\n投资策略问题 考虑一个简化的投资模型，假设有两支股票，进行 $ T $ 天的交易，每一天选择一支股票进行投资。假设当前是 $ t $ 天，在这一天开始的时候，需要选定投资哪一只，在这一天结束的时候，可以看到收益。我们假设两只股票在第 $ t $ 天的收益是 $ r_{1}^{(t)},r_{2}^{(t)}\\in[0, 1] $。假设第 $ t $ 天玩家选择了投资股票 $ a_{t} $，则玩家在 $ t $ 天的总收益是 $$ R(T):=\\sum_{t=1}^{T} r_{a_{t}}^{(t)} $$ 那么我们如何选择一个好的投资策略？\n首先我们需要明确如何衡量一个投资策略的好坏。一个很自然的假设是把 $ R(T) $ 看成关于 $ T $ 的函数，希望 $ R(T) $ 能越大越好。但是我们的收益不仅仅和我们的策略有关，还和两只股票每天的收益挂钩，假设大环境不好，两只股票都亏钱，那不管投资策略怎么样都不能获得高收益。因此我们可以想到用我们的策略和表现最好的股票相比，这也就是懊悔值 (Regret) 的定义：对于给定投资策略，以及每天的收益情况 $ \\vec{r} = \\left(r_{1}^{(t)}, r_{2}^{(t)}\\right)_{1 \\leq t \\leq T} $ $$ \\text{Regret}(T) := \\left( \\max_{a\\in \\{ 1, 2 \\}} \\sum_{t = 1}^{T}r_{a}^{(t)} \\right) - R(T) $$ 朴素的理解就是，因为没有未卜先知而产生的懊悔程度。\n我们希望一个好的投资策略是，不管股票收益如何，我们的 $ \\text{Regret}(T) $ 都比较小。由于 $ \\text{Regret}(T) \\leq T $ ，因此我们希望策略满足 $ \\text{Regret}(T) = o(T) $ ，这表示当 $ T $ 足够大时，我们的策略事实上找到了最好的股票。\n我们可以证明，对于任何确定性的策略，都不可能达到 $ o(T) $ 的懊悔值。由于我们的策略是确定性的，第 $ t $ 天的选择完全取决于前 $ t-1 $ 天的选择和收益，因此如果假设有一个坏人针对我们的策略控制了市场，那他就可以预测我们的选择，如果我们会选择股票 $ 1 $ ，那他就让 $ r_{1}^{(t)}=0, r_{2}^{(t)}=1 $ ，反之亦然。计算这时候的懊悔值，很容易发现在这样针对性的设置下 $ R(T)=0 $。并且由于每一天的收益之和都是 $ 1 $ ，$ T $ 天的累计收益之和为 $ T $，因此一定有一个股票的 $ T $ 天累计收益之和 $ \\geq T / 2 $ ，这是就有 $ \\text{Regret}(T)\\geq T / 2 $。\nOnline Mirror Descent 可以看出，确定性的算法效果之所以不好，是因为对手可以进行针对性的设置，对应的我们可以使用随机化的策略来避免这一点。\n这就是所谓的在线镜像下降（Online Mirror Descent） 算法，它是一个在计算机科学非常著名的算法，在多个领域被重新发现过，因此，它也有很多其他的名字，比如 Multiplicative weight update method，Hedge 算法，EXP3 算法等。\n算法会每一轮维护一个分布 $ D_{t} $，玩家的决策来自于从这个分布中的采样，并且算法会根据每个回合的反馈来更新这个分布。\n初始情况 $ D_{0}=\\left( \\dfrac{1}{2}, \\dfrac{1}{2} \\right) $. 对于 $ t=1,2,\\dots,T $ 选择股票 $ a_{t}\\sim D_{t} $，并观察得到的 $ r_{1}^{(t)},r_{2}^{(t)} $. 更新 $ D_{t+1} $，使得 $ D_{t+1}(i) = \\dfrac{D_{t}(i)\\exp(-\\eta \\cdot(1 - r_{i}^{(t)}))}{\\sum_{k=1,2}D_{t}(k)\\exp(-\\eta \\cdot(1 - r_{k}^{(t)}))} $. 其中的参数 $ \\eta=\\sqrt{ \\dfrac{1}{T} } $ 。 算法本身思想很简单：这一轮哪个股票表现好，就在下一轮增加它被选取的概率。然后为什么要像算法这样操作，能不能用别的方式计算，背后的道理就要复杂得多。\n可以证明这个算法满足在期望上 $ \\text{Regret}(T)=o(\\sqrt{ T }) $（这个结果并非最优）。这个结论表示，有些时候使用随机化，可以让算法的效果产生质变。\n","permalink":"https://diefish1024.github.io/posts/class-notes/math2701-probability-theory/lect1-introduction/","summary":"\u003cp\u003e\u003ca href=\"https://chihaozhang.com/teaching/Prob2025/lectures/lec1/lec1.html\"\u003e课程讲义\u003c/a\u003e\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e在这门课里，我们会专注于所谓的 \u003ca href=\"https://en.wikipedia.org/wiki/Probability_axioms\"\u003e科尔莫哥洛夫（Kolmogorov）的公理体系\u003c/a\u003e，它使得我们能够使用数学分析的工具来研究概率。\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003ch2 id=\"stpetersburg-paradox\"\u003e\u003ca href=\"https://en.wikipedia.org/wiki/St._Petersburg_paradox\"\u003eSt. Petersburg Paradox\u003c/a\u003e\u003c/h2\u003e\n\u003cp\u003e圣彼得堡悖论。假设一个基于抛硬币赌博的游戏，庄家会一直扔硬币直到结果是正面，如果扔了 $ k $ 次，那么就会给玩家 $ 2^{k} $ 元的奖金。现在的问题是你愿意花多少钱来购买一次玩这个游戏的机会。\u003c/p\u003e\n\u003cp\u003e一个很自然的想法是计算游戏的期望，那么我们很容易发现期望收益是\n$$ \n\n\\sum_{k \\geq  1} 2^{k}\\cdot 2^{-k} = 1 + 1 + \\dots = +\\infty\n\n $$\n这说明平均每一轮我们的收益是无穷大，然而在现实生活中你真的愿意花大价钱去玩这个游戏吗？或者可以写一个简单的程序模拟一下就会发现，在比如门票定为 $ 100 $ 元，玩几百局，还是会轻易地输掉几万块钱。我们生活中一个常见的直觉是如果重复一个随机过程足够多次，平均收益就会逐渐趋近于期望收益，这在概率论中叫做\u003cstrong\u003e大数定律（\u003ca href=\"https://en.wikipedia.org/wiki/Law_of_large_numbers\"\u003eLaw of large numbers\u003c/a\u003e）\u003c/strong\u003e，但是在现实生活中我们并没有能力重复足够多游戏轮数去达到这个期望值。那么现在的问题就是如果定价用 $ a\\cdot n $ 元来购买 $ n $ 次游戏机会，$ a $ 定为多少是合理的？\u003c/p\u003e\n\u003cp\u003e用这门课中后续会学习到的数学工具，我们可以得到答案为 $ \\log n $ （这个结果也符合我们实际的直觉）。\u003c/p\u003e\n\u003ch2 id=\"随机游走\"\u003e随机游走\u003c/h2\u003e\n\u003cp\u003e对二维随机游走问题的一个简化的建模是在 $ \\mathbb{Z}^{2} $ 的网格上随机游走，从原点 $ (0,0) $ 出发，每次以 $ \\dfrac{1}{4} $ 的概率往上下左右四个方向移动。我们现在询问，这个随机游走的路径是否会无数次回到原点？用 $ T $ 来表示第一次回到原点的时间，那么可以证明无数次回到原点等价于 $ \\mathbb{P}[T \u003c \\infty] = 1 $ ，也就是 $ T $ 以 $ 1 $ 的概率是有限的，当然目前只能从直觉上去理解，这个写法需要在后续的课程中去严格定义。\u003c/p\u003e","title":"Lect1-Introduction"},{"content":"本文简要介绍通用矩阵乘（GEMM，General Matrix Multiplication）优化的基本概念和方法。GEMM 是 HPC 领域中最基础且计算密集型的工作负载之一。在人工智能、科学模拟和图像处理等领域，它的性能直接影响着整个应用程序的效率。虽然其数学概念简单，但高效的 GEMM 实现却需要对计算机体系结构有深刻的理解，包括缓存、SIMD 指令集和并行化技术。\nNaive GEMM GEMM 通常定义为 $ C = A \\times B $，对于矩阵 $ A \\in \\mathbb{R}^{M \\times K} $，矩阵 $ B \\in \\mathbb{R}^{K \\times N} $，其乘积矩阵 $ C\\in \\mathbb{R}^{M \\times N} $ 可以表示为 $$ C_{i,j} = \\sum_{k=0}^{K-1} A_{i,k}\\times B_{k,j} $$ 对应的朴素代码通常如下（默认行主序存储）：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 void gemm_naive(int M, int N, int K, const float* A, const float* B, float* C) { for (int i = 0; i \u0026lt; M; ++i) { for (int j = 0; j \u0026lt; N; ++j) { C[i][j] = 0.0f; // 初始化 C[i][j] } } for (int i = 0; i \u0026lt; M; ++i) { for (int j = 0; j \u0026lt; N; ++j) { for (int k = 0; k \u0026lt; K; ++k) { C[i][j] += A[i][k] * B[k][j]; } } } } 分析：\n浮点运算总数（FLOPs）：\n对于每个 $ C_{i,j} $ 元素，需要执行 $ K $ 次乘法和 $ K $ 次加法。 总共有 $ M \\times N $ 个 $ C_{i,j} $ 元素。 总操作数约为 $ 2 \\times M \\times N \\times K $ 次浮点运算。 内存访问总数：忽略循环变量和指令的开销。\n矩阵 $ C $ 的初始化需要 $ M \\times N $ 次写入；循环中矩阵 $ A $ 和矩阵 $ B $ 分别被读取 $ M \\times N \\times K $ 次，矩阵 $ C $ 被读取和写入共 $ 2 \\times M \\times N \\times K $ 次。 总内存访问次数约为 $ 4 M N K + M N $。 Why Slow? 尽管代码简洁，但这种实现方式存在严重的性能瓶颈：\n缓存利用率低：对 B[k][j] 的访问大概率导致缓存未命中。由于 B 是行主序存储，每次迭代 k 都会跳到 B 矩阵的下一行，这导致巨大的内存跨越，破坏了空间局部性。\n缺乏 SIMD 向量化潜力：编译器很难将这种混合访问模式有效向量化，因为对 $ B $ 的访问模式不佳。\n算法本身时间复杂度为 $ O(N^{3}) $。\n对这样的矩阵乘的算法优化可分为两类：\n基于算法分析的方法：根据矩阵乘计算特性，从数学角度优化，典型的算法包括 Strassen 算法 和 Coppersmith–Winograd 算法。 基于软件优化的方法：根据计算机存储系统的层次结构特性，选择性地调整计算顺序，主要有循环拆分向量化、内存重排等。 数学角度的优化暂且不在本文的讨论范围内，有机会将单独介绍，下面给出计算机体系结构角度的一些优化角度。\n1 × 4 Register Blocking 参考 how to optimize gemm 一文，我们把输出的计算按照列拆分成若干个 $ 1 \\times 4 $ 的小块，通过一次性处理 $ C $ 的一小块内存来减少内存操作，最大化寄存器的利用率。\n与其一次计算 $ C_{i,j} $ 一个元素，不如一次性计算 $ C_{i, j\\sim j+3} $ 四个连续元素，这很好地利用了 $ C $ 矩阵行内的空间局部性。把这四个元素加载到寄存器，可以大大减少对主存的访问次数。\n下文我们将最内层的循环称为微内核（micro kernel），比如 AddDot1x4 就是一个微内核。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 // AddDot1x4: 计算 C 的一个 1x4 块（按行主序） // Ai 指向 A 的第 i 行起始；Bj 指向 B 的第 j 列所在的起始位置；Cij 指向 C[i][j] inline void AddDot1x4(int K, const float* Ai, const float* Bj, float* Cij, int N) { float c0 = 0.0f, c1 = 0.0f, c2 = 0.0f, c3 = 0.0f; for (int k = 0; k \u0026lt; K; ++k) { float a = Ai[k]; const float* bk = Bj + k * N; // B[k][j..j+3] c0 += a * bk[0]; c1 += a * bk[1]; c2 += a * bk[2]; c3 += a * bk[3]; } Cij[0] = c0; Cij[1] = c1; Cij[2] = c2; Cij[3] = c3; } void gemm_1x4_blocked(int M, int N, int K, const float* A, const float* B, float* C) { for (int i = 0; i \u0026lt; M; ++i) { const float* Ai = \u0026amp;A[i * K]; for (int j = 0; j \u0026lt; N; j += 4) { int w = std::min(4, N - j); if (w == 4) { AddDot1x4(K, Ai, \u0026amp;B[j], \u0026amp;C[i * N + j], N); } else { // 处理尾部 \u0026lt;4 列 for (int jj = 0; jj \u0026lt; w; ++jj) { float acc = 0.f; for (int k = 0; k \u0026lt; K; ++k) acc += Ai[k] * B[k * N + (j + jj)]; C[i * N + j + jj] = acc; } } } } } 分析：\nFLOPs：仍为 $ 2 M N K $。 内存访问：（以元素计，忽略缓存命中） 读取 $ A $：对每个 $ 1 \\times 4 $ 块，每次 $ K $ 次，共 $ \\frac{M N}{4} \\times K = \\frac{M N K}{4} $。 读取 $ B $：每次 $ 4K $，共 $ \\frac{M N}{4} \\times 4K = M N K $。 写入 $ C $：每块写 $ 4 $ 次，共 $ M N $。无需读取 $ C $（寄存器累加后赋值）。 合计：$ \\frac{1}{4} M N K + 1 \\cdot M N K + M N = 1.25\\, M N K + M N $。 与 naive 相比，$ A $ 的读取减少了 $ 4 \\times $（复用到 4 个连续列），$ B $ 的读取次数相同但连续访问更友好，$ C $ 的访存从每次迭代读写降为仅写一次。\n加速比：\n在内存带宽主导的 Roofline 模型 下，性能与内存访问次数近似成反比，因此加速比为 $$ S_{\\text{1x4}} \\approx \\frac{4 M N K + M N}{1.25 M N K + M N} \\approx \\frac{4}{1.25} = 3.2 \\quad (K \\gg 1) $$\nLoop Unrolling and Pointer Optimization 为了进一步优化，我们在 AddDot1x4 内部使用指针迭代与循环展开，减少地址计算和分支开销，提升指令级并行性与寄存器利用。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 inline void AddDot1x4_unroll4(int K, const float* Ai, const float* Bj, float* Cij, int N) { float c0 = 0.f, c1 = 0.f, c2 = 0.f, c3 = 0.f; const float* a = Ai; const float* b = Bj; int k = 0; for (; k + 3 \u0026lt; K; k += 4) { float a0 = a[0], a1 = a[1], a2 = a[2], a3 = a[3]; const float* b0 = b + 0 * N; const float* b1 = b + 1 * N; const float* b2 = b + 2 * N; const float* b3 = b + 3 * N; c0 += a0 * b0[0] + a1 * b1[0] + a2 * b2[0] + a3 * b3[0]; c1 += a0 * b0[1] + a1 * b1[1] + a2 * b2[1] + a3 * b3[1]; c2 += a0 * b0[2] + a1 * b1[2] + a2 * b2[2] + a3 * b3[2]; c3 += a0 * b0[3] + a1 * b1[3] + a2 * b2[3] + a3 * b3[3]; a += 4; b += 4 * N; } for (; k \u0026lt; K; ++k) { float av = *a++; const float* bk = b; b += N; c0 += av * bk[0]; c1 += av * bk[1]; c2 += av * bk[2]; c3 += av * bk[3]; } Cij[0] = c0; Cij[1] = c1; Cij[2] = c2; Cij[3] = c3; } 分析：\nFLOPs：仍为 $ 2 M N K $。 内存访问：与 $ 1 \\times 4 $ 相同（$ 1.25\\, M N K + M N $），仅减少了地址计算和分支开销。 加速比：\n内存主导：与 $ 1 \\times 4 $ 相同，约 $ 3.2 \\times $。 计算主导：循环展开可进一步减少指令开销，常见提升在 $ 5\\% \\sim 15\\% $ 范围（与编译器和微架构相关）。 4 × 4 Register Blocking 不难意识到，用一样的逻辑可以把上面的寄存器分块从 $ 1 \\times 4 $ 扩展到 $ 4 \\times 4 $。这样可以进一步减少内存操作，提高效率。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 // AddDot4x4: 计算 C 的一个 4x4 块（行主序，传入 C 的起始为 C[i][j]） inline void AddDot4x4(int K, const float* Aij, const float* Bkj, float* Cij, int N, int Kstride) { float c00=0.f,c01=0.f,c02=0.f,c03=0.f, c10=0.f,c11=0.f,c12=0.f,c13=0.f, c20=0.f,c21=0.f,c22=0.f,c23=0.f, c30=0.f,c31=0.f,c32=0.f,c33=0.f; const float* a0 = Aij + 0 * Kstride; const float* a1 = Aij + 1 * Kstride; const float* a2 = Aij + 2 * Kstride; const float* a3 = Aij + 3 * Kstride; for (int k = 0; k \u0026lt; K; ++k) { float a0k = a0[k], a1k = a1[k], a2k = a2[k], a3k = a3[k]; const float* bk = Bkj + k * N; float b0 = bk[0], b1 = bk[1], b2 = bk[2], b3 = bk[3]; c00 += a0k * b0; c01 += a0k * b1; c02 += a0k * b2; c03 += a0k * b3; c10 += a1k * b0; c11 += a1k * b1; c12 += a1k * b2; c13 += a1k * b3; c20 += a2k * b0; c21 += a2k * b1; c22 += a2k * b2; c23 += a2k * b3; c30 += a3k * b0; c31 += a3k * b1; c32 += a3k * b2; c33 += a3k * b3; } Cij[0*N+0]=c00; Cij[0*N+1]=c01; Cij[0*N+2]=c02; Cij[0*N+3]=c03; Cij[1*N+0]=c10; Cij[1*N+1]=c11; Cij[1*N+2]=c12; Cij[1*N+3]=c13; Cij[2*N+0]=c20; Cij[2*N+1]=c21; Cij[2*N+2]=c22; Cij[2*N+3]=c23; Cij[3*N+0]=c30; Cij[3*N+1]=c31; Cij[3*N+2]=c32; Cij[3*N+3]=c33; } 分析：\nFLOPs：仍为 $ 2 M N K $。 内存访问（元素计）： 读取 $ A $：每块 $ 4K $，块数 $ \\frac{M}{4}\\times\\frac{N}{4} $，合计 $ \\frac{M N K}{4} $。 读取 $ B $：每块 $ 4K $，同上合计 $ \\frac{M N K}{4} $。 写入 $ C $：每块 $ 16 $ 次，共 $ M $。 合计：$ 0.5\\, M N K + M N $。 与 $ 1 \\times 4 $ 相比，$ B $ 的读取也减少了 $ 4 \\times $（同一批 $ B[k, j..j+3] $ 复用到 4 行），因此总体内存访问显著下降。\n加速比： $$ S_{\\text{4x4}} \\approx \\frac{4 M N K + M N}{0.5 M N K + M N} \\approx \\frac{4}{0.5} = 8 \\quad (K \\gg 1) $$\nSIMD Vectorization 现在我们引入 SIMD，以 Intel SSE 指令集为例（128-bit，单精度宽度 $ W = 4 $）。下面给出与 AddDot4x4 对齐的简化向量化微内核。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 #include \u0026lt;immintrin.h\u0026gt; inline void AddDot4x4_SSE(int K, const float* Aij, const float* Bkj, float* Cij, int N, int Kstride) { __m128 c0 = _mm_setzero_ps(); __m128 c1 = _mm_setzero_ps(); __m128 c2 = _mm_setzero_ps(); __m128 c3 = _mm_setzero_ps(); const float* a0 = Aij + 0 * Kstride; const float* a1 = Aij + 1 * Kstride; const float* a2 = Aij + 2 * Kstride; const float* a3 = Aij + 3 * Kstride; for (int k = 0; k \u0026lt; K; ++k) { __m128 b = _mm_loadu_ps(\u0026amp;Bkj[k * N]); // B[k][j..j+3] __m128 a0v = _mm_set1_ps(a0[k]); __m128 a1v = _mm_set1_ps(a1[k]); __m128 a2v = _mm_set1_ps(a2[k]); __m128 a3v = _mm_set1_ps(a3[k]); c0 = _mm_add_ps(c0, _mm_mul_ps(a0v, b)); c1 = _mm_add_ps(c1, _mm_mul_ps(a1v, b)); c2 = _mm_add_ps(c2, _mm_mul_ps(a2v, b)); c3 = _mm_add_ps(c3, _mm_mul_ps(a3v, b)); } _mm_storeu_ps(\u0026amp;Cij[0 * N], c0); _mm_storeu_ps(\u0026amp;Cij[1 * N], c1); _mm_storeu_ps(\u0026amp;Cij[2 * N], c2); _mm_storeu_ps(\u0026amp;Cij[3 * N], c3); } 分析：\nFLOPs：仍为 $ 2 M N K $。 内存访问：与标量 4×4 相同（$ 0.5\\, M N K + M N $）。SIMD 仅改变算术吞吐，不改变 DRAM 访存量。 计算主导场景的理论加速：约等于向量宽度 $ W $（SSE 单精度为 $ 4 $；AVX2 为 $ 8 $；AVX-512 为 $ 16 $）。若支持 FMA（如 AVX2/FMA、AVX-512），每周期可进一步提升。 加速比：\n内存主导：约 $ 8 \\times $（同 4×4）。 计算主导： 4×4 与 SIMD 的收益不可直接相乘，约 $ 8 \\times W $ 的上界不成立；更实际的估计是：在 4×4 将算术强度显著提升后，若仍处于计算主导，则 SIMD 可再带来 $ W \\times $ 左右的额外提升。 Cache Blocking（Macro-kernel） 尽管 SIMD 和寄存器分块（微内核）带来了巨大的性能提升，但当矩阵尺寸超出 CPU 缓存容量时，性能仍会因高昂的内存访问延迟而下降。缓存分块 (Cache Blocking) 旨在将矩阵操作分解成一系列小块操作，使这些块的数据能够长时间驻留在不同级别的缓存中（例如 L1、L2、L3），从而实现数据重用最大化。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 // 缓存分块 + 4x4 微内核 void gemm_blocked_4x4(int M, int N, int K, const float* A, const float* B, float* C) { const int MR = 4, NR = 4; const int KC = 128; // 需按架构调优 for (int kk = 0; kk \u0026lt; K; kk += KC) { int Kc = std::min(KC, K - kk); for (int i = 0; i \u0026lt; M; i += MR) { int Mb = std::min(MR, M - i); for (int j = 0; j \u0026lt; N; j += NR) { int Nb = std::min(NR, N - j); if (Mb == MR \u0026amp;\u0026amp; Nb == NR) { AddDot4x4(Kc, \u0026amp;A[i * K + kk], \u0026amp;B[kk * N + j], \u0026amp;C[i * N + j], N, K); } else { // 退化处理 for (int ii = 0; ii \u0026lt; Mb; ++ii) for (int jj = 0; jj \u0026lt; Nb; ++jj) { float acc = 0.f; for (int k = 0; k \u0026lt; Kc; ++k) acc += A[(i + ii) * K + (kk + k)] * B[(kk + k) * N + (j + jj)]; C[(i + ii) * N + (j + jj)] = acc + C[(i + ii) * N + (j + jj)]; } } } } } } 分析：\nFLOPs：仍为 $ 2 M N K $。 DRAM 级内存访问：（理想分块并有良好复用时） $ A $：每个元素从 DRAM 读入约 $ 1 $ 次，$ M K $。 $ B $：每个元素从 DRAM 读入约 $ 1 $ 次，$ K N $。 $ C $：每个元素从 DRAM 读写各 $ 1 $ 次，$ 2 M N $。 合计：$ M K + K N + 2 M N $。 通过按 $ K $ 维度切块，$ A $ 与 $ B $ 的面板在较小的 $ K_c $ 上反复被微内核复用；只要 $ K_c $、$ M_r $、$ N_r $ 选取得当，就能使复用主要发生在 L1/L2/L3 中，从 DRAM 的视角看，$ A $/$ B $ 基本只需读取一次。\n加速比： $$ S_{\\text{blocked}} \\approx \\frac{4 M N K + M N}{M K + K N + 2 M N} $$\n当 $ M = N = K = n $ 时，有 $ S \\approx \\frac{4 n^3}{4 n^2} = n $，随问题规模线性增长，实际受缓存与带宽上限限制。\nData Packing 即使有了缓存分块，如果原始矩阵的内存布局导致块内部的数据不连续（例如，行主序矩阵中的列访问），缓存效率仍然会受损。数据打包 (Packing) 通过将需要计算的矩阵块复制到临时的、内存连续且对齐的缓冲区中来解决这个问题。\n将 $ A $ 的 $ M_r \\times K_c $ 面板按“列优先、行紧凑”的形式打包，便于微内核顺序读取。 将 $ B $ 的 $ K_c \\times N_r $ 面板按“行优先、列紧凑”的形式打包，使得每个 $ k $ 的 $ B[k, j..j+N_r-1] $ 连续、对齐。 示例打包代码（以 $ M_r=4, N_r=4 $ 为例）：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 // pack A: 从行主序 A 中取 4xKc，按列（k）主序、行（r）紧凑存放：Apack[k*4 + r] void pack_A_4xKc(const float* A, int lda, float* Apack, int Kc) { for (int k = 0; k \u0026lt; Kc; ++k) { Apack[k * 4 + 0] = A[0 * lda + k]; Apack[k * 4 + 1] = A[1 * lda + k]; Apack[k * 4 + 2] = A[2 * lda + k]; Apack[k * 4 + 3] = A[3 * lda + k]; } } // pack B: 从行主序 B 中取 Kc x 4，按行（k）主序、列（c）紧凑存放：Bpack[k*4 + c] void pack_B_Kc4(const float* B, int ldb, float* Bpack, int Kc) { for (int k = 0; k \u0026lt; Kc; ++k) { const float* bk = B + k * ldb; Bpack[k * 4 + 0] = bk[0]; Bpack[k * 4 + 1] = bk[1]; Bpack[k * 4 + 2] = bk[2]; Bpack[k * 4 + 3] = bk[3]; } } 配合打包的 4×4 微内核（内层线性访问）：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 inline void AddDot4x4_packed(int Kc, const float* Ap, const float* Bp, float* Cij, int N) { __m128 c0 = _mm_setzero_ps(); __m128 c1 = _mm_setzero_ps(); __m128 c2 = _mm_setzero_ps(); __m128 c3 = _mm_setzero_ps(); for (int k = 0; k \u0026lt; Kc; ++k) { __m128 b = _mm_loadu_ps(\u0026amp;Bp[k * 4]); float a0 = Ap[k * 4 + 0]; float a1 = Ap[k * 4 + 1]; float a2 = Ap[k * 4 + 2]; float a3 = Ap[k * 4 + 3]; c0 = _mm_add_ps(c0, _mm_mul_ps(_mm_set1_ps(a0), b)); c1 = _mm_add_ps(c1, _mm_mul_ps(_mm_set1_ps(a1), b)); c2 = _mm_add_ps(c2, _mm_mul_ps(_mm_set1_ps(a2), b)); c3 = _mm_add_ps(c3, _mm_mul_ps(_mm_set1_ps(a3), b)); } _mm_storeu_ps(\u0026amp;Cij[0 * N], _mm_add_ps(c0, _mm_loadu_ps(\u0026amp;Cij[0 * N]))); _mm_storeu_ps(\u0026amp;Cij[1 * N], _mm_add_ps(c1, _mm_loadu_ps(\u0026amp;Cij[1 * N]))); _mm_storeu_ps(\u0026amp;Cij[2 * N], _mm_add_ps(c2, _mm_loadu_ps(\u0026amp;Cij[2 * N]))); _mm_storeu_ps(\u0026amp;Cij[3 * N], _mm_add_ps(c3, _mm_loadu_ps(\u0026amp;Cij[3 * N]))); } FLOPs：不变。 DRAM 访存：与“理想分块”一致（$ M K + K N + 2 M N $），但常数项更小（线性、对齐、可预取），SIMD 装载更高效。 OpenMP Parallelization 在多核 CPU 上，使用 OpenMP 对外层块循环并行是提升性能的有效手段。推荐在线程之间划分 $ (i, j) $ 的宏块，避免对同一 $ C $ 子块的写冲突。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 // OpenMP 并行的分块 GEMM（以 4x4 微内核 + K 分块为例） void gemm_blocked_omp(int M, int N, int K, const float* A, const float* B, float* C, int num_threads) { const int MR = 4, NR = 4, KC = 256, MC = 256, NC = 256; #pragma omp parallel num_threads(num_threads) { // 线程私有的临时打包缓冲区 std::vector\u0026lt;float\u0026gt; Ap(MR * KC), Bp(KC * NR); #pragma omp for collapse(2) schedule(static) for (int jc = 0; jc \u0026lt; N; jc += NC) { for (int ic = 0; ic \u0026lt; M; ic += MC) { int Nc = std::min(NC, N - jc); int Mc = std::min(MC, M - ic); for (int pc = 0; pc \u0026lt; K; pc += KC) { int Kc = std::min(KC, K - pc); for (int i = ic; i \u0026lt; ic + Mc; i += MR) { int Mb = std::min(MR, ic + Mc - i); for (int j = jc; j \u0026lt; jc + Nc; j += NR) { int Nb = std::min(NR, jc + Nc - j); if (Mb == MR \u0026amp;\u0026amp; Nb == NR) { pack_A_4xKc(\u0026amp;A[i * K + pc], K, Ap.data(), Kc); pack_B_Kc4(\u0026amp;B[pc * N + j], N, Bp.data(), Kc); AddDot4x4_packed(Kc, Ap.data(), Bp.data(), \u0026amp;C[i * N + j], N); } else { for (int ii = 0; ii \u0026lt; Mb; ++ii) for (int jj = 0; jj \u0026lt; Nb; ++jj) { float acc = 0.f; for (int k = 0; k \u0026lt; Kc; ++k) acc += A[(i + ii) * K + (pc + k)] * B[(pc + k) * N + (j + jj)]; C[(i + ii) * N + (j + jj)] += acc; } } } } } } } } } 分析：\nFLOPs：不变。 DRAM 访存：与“分块 + 打包”的单线程相同（$ M K + K N + 2 M N $）。 加速上界： 计算主导：理想线性加速 $ \\leq T $（线程数）。 内存主导：受内存带宽限制，$ \\leq \\frac{\\text{BW}_{\\text{并行}}}{\\text{BW}_{\\text{单线程}}} $。当达到带宽饱和后继续加线程收益有限。 加速比：\n在“分块 + 打包”基础上，OpenMP 将计算并行化。理想上界（计算主导）：$$ S_{\\text{blocked+packed+OMP}} \\approx \\min\\left(T,\\ \\frac{\\text{PeakFLOPs}}{\\text{单线程 FLOPs}}\\right) \\times \\frac{4 M N K + M N}{M K + K N + 2 M N} $$ 在带宽主导时，上式中 $ T $ 替换为带宽扩展比。 Method Comparison 为便于对比，下面给出各优化策略在“忽略缓存命中、以元素访问计”的内存访问与内存主导模型下的理论加速比（相对 naive）：\n方法 微内核形状 FLOPs 内存访问（元素数） 相对 naive 加速比（内存主导，$ K \\gg 1 $） naive 无 $ 2MNK $ $ 4MNK + MN $ $ 1.0 $ 1×4 寄存器分块 1×4 $ 2MNK $ $ 1.25MNK + MN $ $ \\approx 3.2 $ 1×4 + 展开 1×4 $ 2MNK $ $ 1.25MNK + MN $ $ \\approx 3.2 $（计算主导再 +5%~15%） 4×4 寄存器分块 4×4 $ 2MNK $ $ 0.5MNK + MN $ $ \\approx 8.0 $ 4×4 + SIMD（SSE） 4×4 $ 2MNK $ $ 0.5MNK + MN $ 内存主导 $ \\approx 8.0 $；计算主导再 $ \\times 4 $ 分块（$ K_{c} $）+ 打包 任意 $ 2MNK $ $ MK + KN + 2MN $ $ \\frac{4MNK+MN}{MK+KN+2MN} $（方阵约为 $ n $） 分块 + 打包 +OpenMP 任意 $ 2MNK $ $ MK + KN + 2MN $ 上式 × 并行效率（受带宽与可伸缩性限制） 上表的内存访问为“理想化、从 DRAM 角度”的估算，实际性能取决于缓存命中、预取、对齐、访存指令融合和前端/后端瓶颈等。\n采用 += 写回将引入对 $ C $ 的读操作；若事先知道目标 $ C $ 块为零，可进一步减少读流量。\nComparing with BLAS Libraries 现代 BLAS（如 Intel MKL、OpenBLAS、BLIS）普遍采用“三级分块 + 数据打包 + 专用微内核（含 SIMD/FMA）”的体系： 最外层：$ N_c $、$ M_c $、$ K_c $ 级别的宏分块，匹配 L3/L2。 中层：面板打包（AB-panel），顺序、对齐、预取友好。 内层：手写/内联汇编微内核，固定 $ M_r \\times N_r $，深度展开，寄存器阻塞，利用 FMA 与流水线。 对 x86： SSE 场景常见微内核大小约 $ 4 \\times 4 $。 AVX2/AVX-512 场景常见 $ M_r, N_r $ 更大（如 $ 6 \\times 16 $、$ 8 \\times 30 $ 等），并利用 FMA。 这些库还会进行： 多级预取策略（硬件/软件结合）。 NUMA 感知的任务分配与内存归属（first-touch）。 针对边界块的专门路径和对齐优化。 Summary 从“寄存器分块（微内核）→ SIMD → 缓存分块（宏内核）→ 数据打包 → OpenMP 并行”的路径逐层优化了 GEMM 性能。\n核心思想：\n用寄存器保存部分和，显著减少对 $ C $ 的读写。 通过 $ 1 \\times 4 \\to 4 \\times 4 $ 提高 $ A $/$ B $ 的复用，降低 DRAM 访存。 用 SIMD/FMA 提高每条指令的 FLOPs。 宏分块与打包让复用在 L1/L2/L3 内生效，将 DRAM 流量降到 $ MK + KN + 2MN $ 的量级。 OpenMP 在多核扩展吞吐，但需注意带宽瓶颈与 NUMA。 在内存主导模型下的理论加速（相对 naive）：\n$ 1 \\times 4 $：约 $ 3.2 \\times $。 $ 4 \\times 4 $：约 $ 8 \\times $。 分块 + 打包：约 $ \\frac{4MNK+MN}{MK+KN+2MN} $（方阵近似 $ n $）。 SIMD 与 OpenMP 的收益叠加取决于是否进入计算主导。 References How to optimize GEMM（FLAME wiki） 通用矩阵乘（GEMM）优化算法 OpenBLAS ","permalink":"https://diefish1024.github.io/posts/hpc/gemm-%E7%AE%97%E6%B3%95%E4%BC%98%E5%8C%96/","summary":"\u003cp\u003e本文简要介绍通用矩阵乘（\u003ca href=\"https://en.wikipedia.org/wiki/Basic_Linear_Algebra_Subprograms#Level_3\"\u003eGEMM\u003c/a\u003e，General Matrix Multiplication）优化的基本概念和方法。GEMM 是 HPC 领域中最基础且计算密集型的工作负载之一。在人工智能、科学模拟和图像处理等领域，它的性能直接影响着整个应用程序的效率。虽然其数学概念简单，但高效的 GEMM 实现却需要对计算机体系结构有深刻的理解，包括缓存、SIMD 指令集和并行化技术。\u003c/p\u003e\n\u003ch2 id=\"naive-gemm\"\u003eNaive GEMM\u003c/h2\u003e\n\u003cp\u003eGEMM 通常定义为 $ C = A \\times B $，对于矩阵 $ A \\in \\mathbb{R}^{M \\times K} $，矩阵 $ B \\in \\mathbb{R}^{K \\times N} $，其乘积矩阵 $ C\\in \\mathbb{R}^{M \\times N} $ 可以表示为\n$$ \n\nC_{i,j} = \\sum_{k=0}^{K-1} A_{i,k}\\times B_{k,j} \n\n $$\n对应的朴素代码通常如下（默认行主序存储）：\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cdiv class=\"chroma\"\u003e\n\u003ctable class=\"lntable\"\u003e\u003ctr\u003e\u003ctd class=\"lntd\"\u003e\n\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode\u003e\u003cspan class=\"lnt\"\u003e 1\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 2\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 3\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 4\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 5\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 6\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 7\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 8\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 9\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e10\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e11\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e12\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e13\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e14\n\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\n\u003ctd class=\"lntd\"\u003e\n\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-cpp\" data-lang=\"cpp\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"kt\"\u003evoid\u003c/span\u003e \u003cspan class=\"nf\"\u003egemm_naive\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"kt\"\u003eint\u003c/span\u003e \u003cspan class=\"n\"\u003eM\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"kt\"\u003eint\u003c/span\u003e \u003cspan class=\"n\"\u003eN\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"kt\"\u003eint\u003c/span\u003e \u003cspan class=\"n\"\u003eK\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"k\"\u003econst\u003c/span\u003e \u003cspan class=\"kt\"\u003efloat\u003c/span\u003e\u003cspan class=\"o\"\u003e*\u003c/span\u003e \u003cspan class=\"n\"\u003eA\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"k\"\u003econst\u003c/span\u003e \u003cspan class=\"kt\"\u003efloat\u003c/span\u003e\u003cspan class=\"o\"\u003e*\u003c/span\u003e \u003cspan class=\"n\"\u003eB\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"kt\"\u003efloat\u003c/span\u003e\u003cspan class=\"o\"\u003e*\u003c/span\u003e \u003cspan class=\"n\"\u003eC\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"k\"\u003efor\u003c/span\u003e \u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"kt\"\u003eint\u003c/span\u003e \u003cspan class=\"n\"\u003ei\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"mi\"\u003e0\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e \u003cspan class=\"n\"\u003ei\u003c/span\u003e \u003cspan class=\"o\"\u003e\u0026lt;\u003c/span\u003e \u003cspan class=\"n\"\u003eM\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e \u003cspan class=\"o\"\u003e++\u003c/span\u003e\u003cspan class=\"n\"\u003ei\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"k\"\u003efor\u003c/span\u003e \u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"kt\"\u003eint\u003c/span\u003e \u003cspan class=\"n\"\u003ej\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"mi\"\u003e0\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e \u003cspan class=\"n\"\u003ej\u003c/span\u003e \u003cspan class=\"o\"\u003e\u0026lt;\u003c/span\u003e \u003cspan class=\"n\"\u003eN\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e \u003cspan class=\"o\"\u003e++\u003c/span\u003e\u003cspan class=\"n\"\u003ej\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e            \u003cspan class=\"n\"\u003eC\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"n\"\u003ei\u003c/span\u003e\u003cspan class=\"p\"\u003e][\u003c/span\u003e\u003cspan class=\"n\"\u003ej\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"mf\"\u003e0.0f\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e \u003cspan class=\"c1\"\u003e// 初始化 C[i][j]\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"k\"\u003efor\u003c/span\u003e \u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"kt\"\u003eint\u003c/span\u003e \u003cspan class=\"n\"\u003ei\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"mi\"\u003e0\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e \u003cspan class=\"n\"\u003ei\u003c/span\u003e \u003cspan class=\"o\"\u003e\u0026lt;\u003c/span\u003e \u003cspan class=\"n\"\u003eM\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e \u003cspan class=\"o\"\u003e++\u003c/span\u003e\u003cspan class=\"n\"\u003ei\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"k\"\u003efor\u003c/span\u003e \u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"kt\"\u003eint\u003c/span\u003e \u003cspan class=\"n\"\u003ej\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"mi\"\u003e0\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e \u003cspan class=\"n\"\u003ej\u003c/span\u003e \u003cspan class=\"o\"\u003e\u0026lt;\u003c/span\u003e \u003cspan class=\"n\"\u003eN\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e \u003cspan class=\"o\"\u003e++\u003c/span\u003e\u003cspan class=\"n\"\u003ej\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e            \u003cspan class=\"k\"\u003efor\u003c/span\u003e \u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"kt\"\u003eint\u003c/span\u003e \u003cspan class=\"n\"\u003ek\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"mi\"\u003e0\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e \u003cspan class=\"n\"\u003ek\u003c/span\u003e \u003cspan class=\"o\"\u003e\u0026lt;\u003c/span\u003e \u003cspan class=\"n\"\u003eK\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e \u003cspan class=\"o\"\u003e++\u003c/span\u003e\u003cspan class=\"n\"\u003ek\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e                \u003cspan class=\"n\"\u003eC\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"n\"\u003ei\u003c/span\u003e\u003cspan class=\"p\"\u003e][\u003c/span\u003e\u003cspan class=\"n\"\u003ej\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e \u003cspan class=\"o\"\u003e+=\u003c/span\u003e \u003cspan class=\"n\"\u003eA\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"n\"\u003ei\u003c/span\u003e\u003cspan class=\"p\"\u003e][\u003c/span\u003e\u003cspan class=\"n\"\u003ek\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e \u003cspan class=\"o\"\u003e*\u003c/span\u003e \u003cspan class=\"n\"\u003eB\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"n\"\u003ek\u003c/span\u003e\u003cspan class=\"p\"\u003e][\u003c/span\u003e\u003cspan class=\"n\"\u003ej\u003c/span\u003e\u003cspan class=\"p\"\u003e];\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e            \u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\u003c/tr\u003e\u003c/table\u003e\n\u003c/div\u003e\n\u003c/div\u003e\u003cp\u003e\u003cstrong\u003e分析\u003c/strong\u003e：\u003c/p\u003e","title":"GEMM 算法优化"},{"content":"如何更好更快地访问内存是 HPC 中最大的瓶颈之一，仅仅了解 SIMD 或并行编程接口是不足够的，本文将梳理计算机的内存层次结构、缓存友好编程、内存墙现象、NUMA 架构以及预取技术。\nUnderstanding Memory Hierarchy 为了充分利用现代 CPU 的性能，我们必须理解数据是如何在不同层级的内存组件之间流动的。\nRegisters, Caches, and Main Memory 寄存器 (Registers)： CPU 内置的、容量最小但速度最快的数据存储单元，用于存储正在被 CPU 活跃操作的数据。CPU 直接在寄存器上执行大部分计算。\n缓存 (Cache)： 位于 CPU 和主内存之间的小容量、高速存储区域。它们的目的是通过存储最可能被 CPU 再次访问的数据来减少对主内存的访问延迟。\nL1 缓存 (Level 1 Cache)：最小、最快，通常分为数据缓存 (L1d) 和指令缓存 (L1i)，每个 CPU 核心独有。其访问速度与 CPU 核心时钟周期相近。 L2 缓存 (Level 2 Cache)：比 L1 大且慢，每个 CPU 核心独有或由几个核心共享。 L3 缓存 (Level 3 Cache)：最大、最慢的缓存，通常由同一 CPU 插槽上的所有核心共享。 主内存 (Main Memory/RAM)： 容量远大于缓存，但访问速度慢得多。当数据不在任何缓存中时，CPU 必须从主内存中获取。\nTLB (Translation Lookaside Buffer)： TLB 是一个专用的高性能缓存，用于存储虚拟地址到物理地址的转换映射。当 CPU 访问一个虚拟地址时，它首先检查 TLB。如果找到对应的物理地址（TLB 命中），则可以快速进行内存访问；如果未找到（TLB 未命中），则需要查询页表，这将导致显著的延迟。理解 TLB 对于优化内存页访问模式，尤其是在处理大型数据集时至关重要。\n通过这种多级内存层次结构访问内存，我们需要尽可能满足局部性原理来提高效率：\n时间局部性 (Temporal Locality)：如果一个数据项最近被访问过，那么它很可能在不久的将来再次被访问。 空间局部性 (Spatial Locality)：如果一个数据项被访问了，那么它附近的内存地址中的数据项也很可能在不久的将来被访问。 Cache-Friendly Programming 编写“缓存友好”的代码意味着组织数据和访问模式，最大化缓存命中率。\nCache Line and Performance Impact 缓存行 (Cache Line)： 缓存和主内存之间数据传输的最小单元，通常为 64 字节。当 CPU 从主内存中请求一个字节时，整个缓存行都会被加载到缓存中。 这强调了空间局部性：如果你的程序按顺序访问内存，那么一次缓存加载可以为未来的访问提供多个数据项，从而提高效率。 伪共享 (False Sharing)：如果两个或多个独立的变量不幸地位于同一个缓存行中，并且被不同的 CPU 核心修改，那么即使它们逻辑上不相关，也会因为缓存一致性协议导致大量的缓存行失效和重新加载，从而严重影响性能。 Cache Hit/Miss and Coherence 缓存命中 (Cache Hit)：当 CPU 需要的数据已经在某个缓存级别中时，访问速度非常快。 缓存未命中 (Cache Miss)：当 CPU 需要的数据不在任何缓存中时，必须从更慢的内存级别（最终是主内存）获取数据，这会引入延迟。未命中可分为： 强制性未命中 (Compulsory Miss/Cold Miss)：首次访问数据。 容量性未命中 (Capacity Miss)：缓存太小，无法容纳所有活跃数据。 冲突性未命中 (Conflict Miss)：多个数据项映射到缓存中的同一个位置。 缓存一致性 (Cache Coherence)： 在多核处理器系统中，不同的核心可能有同一份数据在各自的缓存副本中。为了确保所有核心看到的数据是一致的最新版本，需要缓存一致性协议，如 MESI (Modified, Exclusive, Shared, Invalid) 协议。理解这些协议有助于避免伪共享等问题。 SoA vs. AoS 选择正确的数据布局对缓存性能至关重要。这部分在 HPC 中的 C 和 C++ 中也有提及。\n结构体数组 (AoS: Array of Structs)： struct Point { float x, y, z; } points[N];\n这种布局下，一个 Point 结构体的所有成员在内存中是连续的。如果你的代码经常需要访问一个点的所有坐标，这种布局是高效的。 数组结构体 (SoA: Struct of Arrays)： struct { float x[N], y[N], z[N]; } points_soa;\n如果你需要对所有点的 $ x $ 坐标执行操作，那么可以高效地利用缓存行，因为内存访问是高度连续的。对于 SIMD 向量化操作来说，SoA 通常更优化。 选择 SoA 还是 AoS 取决于数据访问模式：如果经常需要访问一个对象的所有属性，AoS 可能更好（但要注意缓存行对齐和填充）。如果经常需要对多个对象的某个特定属性进行批处理操作，SoA 通常是更好的选择。\nThe Memory Wall 内存墙是指 CPU 的计算速度与主内存的访问速度之间日益扩大的差距。CPU 处理能力的增长远远快于内存延迟的改进速度，这意味着即使 CPU 理论上可以执行大量的指令，但如果它必须经常等待数据从主内存中加载，那么大部分时间都会处于空闲状态，从而限制了实际的应用程序性能。\n解决方案：\n优化算法，减少对内存的访问次数。 最大化缓存命中率，利用数据局部性。 采用预取技术来隐藏内存访问延迟。 NUMA Architectures Non-Uniform Memory Access Challenges NUMA (Non-Uniform Memory Access) ，即非一致性内存访问架构，在多处理器系统中变得越来越普遍。在 NUMA 系统中，每个 CPU (或 CPU 插槽) 都有一组直接连接的本地内存，访问本地内存比访问连接到另一个 CPU 的远端内存要快得多。不同的内存器件和 CPU 核心从属不同的 Node，每个 Node 都有自己的集成内存控制器（IMC，Integrated Memory Controller）。\n如果一个线程在 CPU0 上运行，却频繁访问挂载在 CPU1 上的内存，性能会显著下降，因为数据必须通过处理器间互连（如 Intel 的 UPI 或 AMD 的 Infinity Fabric）传输，这会引入额外的延迟。\n不当的内存放置策略可能导致严重的性能瓶颈，甚至超过内存墙的限制。\nNUMA Optimization with numactl 为了在 NUMA 架构下获得最佳性能，我们必须确保计算尽可能地在靠近其所访问数据的 CPU 核心上进行。numactl 是一个强大的 Linux 命令行工具，它允许我们精确控制进程的 CPU 亲和性和内存分配策略。\n查看 NUMA 节点布局：numactl --hardware 命令可以显示系统中所有的 NUMA 节点、每个节点的 CPU 核心及其本地内存大小。 1 numactl --hardware 输出示例：\n1 2 3 4 5 6 7 8 9 10 11 available: 2 nodes (0-1) node 0 cpus: 0 1 2 3 node 0 size: 16000 MB node 0 free: 15000 MB node 1 cpus: 4 5 6 7 node 1 size: 16000 MB node 1 free: 15000 MB node distances: node 0 1 0: 10 21 1: 21 10 这表示系统有 2 个 NUMA 节点（0 和 1）。节点 0 拥有 CPU 核心 0-3，节点 1 拥有 CPU 核心 4-7。node distances 表示访问本地内存的成本为 10，访问远端内存的成本为 21，远端访问的开销约为本地的两倍。\n重要 numactl 选项： --cpunodebind \u0026lt;nodes\u0026gt;：将进程或线程绑定到指定 NUMA 节点上的 CPU 核心。例如，--cpunodebind=0 将进程限制在节点 0 上的 CPU。 --membind \u0026lt;nodes\u0026gt;：强制所有内存分配都来自指定 NUMA 节点。例如，--membind=1 将所有内存都从节点 1 分配。 --localalloc：在当前线程运行的 NUMA 节点上分配内存。这是最佳实践，因为它确保了数据存储在距离计算最近的位置。 --physcpubind \u0026lt;cpus\u0026gt;：将进程或线程绑定到特定的物理 CPU 核心。 NUMA Memory Access Test 可以通过一个简单的多线程数组求和程序来演示 numactl 对 NUMA 性能的影响。程序会分配一个非常大（足够超出 cache）的数组，然后使用 OpenMP 让多个线程并行计算数组元素的总和。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 #include \u0026lt;iostream\u0026gt; #include \u0026lt;vector\u0026gt; #include \u0026lt;numeric\u0026gt; #include \u0026lt;chrono\u0026gt; #include \u0026lt;omp.h\u0026gt; #include \u0026lt;algorithm\u0026gt; // 确保足够大以超出缓存并触及 NUMA 效应 const size_t ARRAY_SIZE = 1000000000ULL; int main() { std::cout \u0026lt;\u0026lt; \u0026#34;Allocating array of \u0026#34; \u0026lt;\u0026lt; ARRAY_SIZE * sizeof(long long) / (1024 * 1024 * 1024.0) \u0026lt;\u0026lt; \u0026#34; GB...\u0026#34; \u0026lt;\u0026lt; std::endl; std::vector\u0026lt;long long\u0026gt; data(ARRAY_SIZE); #pragma omp parallel for for (size_t i = 0; i \u0026lt; ARRAY_SIZE; ++i) { data[i] = i % 100; } std::cout \u0026lt;\u0026lt; \u0026#34;Array initialized.\u0026#34; \u0026lt;\u0026lt; std::endl; int num_threads = 2; omp_set_num_threads(num_threads); std::cout \u0026lt;\u0026lt; \u0026#34;Using \u0026#34; \u0026lt;\u0026lt; num_threads \u0026lt;\u0026lt; \u0026#34; OpenMP threads.\u0026#34; \u0026lt;\u0026lt; std::endl; long long total_sum = 0; auto start = std::chrono::high_resolution_clock::now(); #pragma omp parallel reduction(+:total_sum) { int thread_id = omp_get_thread_num(); size_t chunk_size = ARRAY_SIZE / num_threads; size_t start_idx = thread_id * chunk_size; size_t end_idx = std::min(start_idx + chunk_size, ARRAY_SIZE); std::cout \u0026lt;\u0026lt; \u0026#34;Thread \u0026#34; \u0026lt;\u0026lt; thread_id \u0026lt;\u0026lt; \u0026#34; processing from \u0026#34; \u0026lt;\u0026lt; start_idx \u0026lt;\u0026lt; \u0026#34; to \u0026#34; \u0026lt;\u0026lt; end_idx \u0026lt;\u0026lt; std::endl; for (size_t i = start_idx; i \u0026lt; end_idx; ++i) { total_sum += data[i]; } } auto end = std::chrono::high_resolution_clock::now(); std::chrono::duration\u0026lt;double\u0026gt; diff = end - start; std::cout \u0026lt;\u0026lt; \u0026#34;Calculated total sum: \u0026#34; \u0026lt;\u0026lt; total_sum \u0026lt;\u0026lt; std::endl; std::cout \u0026lt;\u0026lt; \u0026#34;Time taken: \u0026#34; \u0026lt;\u0026lt; diff.count() \u0026lt;\u0026lt; \u0026#34; seconds\u0026#34; \u0026lt;\u0026lt; std::endl; return 0; } 可以使用 GCC 编译这个程序：\n1 g++ -std=c++11 -O3 -fopenmp numa_test.cpp -o numa_test （由于我的电脑只有一个 NUMA 核心，所以下面测试无法进行。。。）\nBaseline： 1 ./numa_test 远端内存访问：CPU 在节点 1，内存绑定到节点 0。这时所有数据都是远端访问，理论上性能应该最差。 1 numactl --cpunodebind=1 --membind=0 ./numa_test 本地内存访问：CPU 在节点 0，内存绑定到节点 0。这是理性的 NUMA 配置，所有数据访问都是本地的。 1 numactl --cpunodebind=0 --membind=0 ./numa_test 真实多线程场景：CPU 绑定到节点 0 和 1，但内存仅分配到节点 0。跑在节点 1 上的线程将进行远端内存访问。 1 2 export OMP_NUM_THREADS=2 numactl --cpunodebind=0,1 --membind=0 ./numa_test Prefetching 预取 (Prefetching) 是一种技术，它尝试在 CPU 实际需要数据之前，就将其从较慢的内存层级加载到较快的缓存中。这有助于隐藏内存访问延迟，使 CPU 能够专注于计算。\n硬件预取器 (Hardware Prefetcher)： 现代 CPU 内置的智能逻辑单元，它们会监控内存访问模式，并根据检测到的模式（如顺序访问）自动预测接下来可能需要哪些数据，将其提前加载到缓存中。\n优点：全自动，无需程序员干预。 缺点：有时预测不准确，可能将无用数据加载到缓存中，挤出有用数据，甚至增加内存总线流量。 编译器预取 (Compiler Prefetching)： 一些编译器能够根据代码中的循环和访问模式，在编译时插入预取指令。通过 -O3 等优化选项或特定的编译器提示，可以启用此功能。\n软件预取 (Software Prefetching)： 程序员可以通过使用特殊的 CPU 指令（通常通过内联函数 Intrinsics 暴露）显式地告诉 CPU 预取哪些数据。 例如，在 x86 架构上：\n1 2 3 4 5 6 7 8 9 10 11 12 #include \u0026lt;xmmintrin.h\u0026gt; // For _mm_prefetch void process_data(int* arr, int n) { for (int i = 0; i \u0026lt; n; ++i) { // 在实际访问 arr[i + PREFETCH_DISTANCE] 之前提前预取 if (i + PREFETCH_DISTANCE \u0026lt; n) { _mm_prefetch((char*)\u0026amp;arr[i + PREFETCH_DISTANCE], _MM_HINT_T0); } // 处理 arr[i] // ... } } 当硬件预取器无法有效应对复杂的访问模式时，软件预取可以提供更精确的控制。 需要程序员手动插入，可能会增加代码复杂性，不当使用可能导致性能下降。 Summary 在 HPC 领域，仅依靠 CPU 的原始计算能力和并行编程模型是不够的。深入理解计算机内存，是编写高性能代码的基础。通过采用缓存友好的编程，如优化数据布局和分块算法，我们可以显著提高应用程序的性能，真正发挥现代 CPU 的潜力。\nReference 每个程序员都应该知道的 CPU 知识：NUMA（知乎） 浅解 NUMA 机制（知乎） ","permalink":"https://diefish1024.github.io/posts/hpc/%E5%85%B3%E4%BA%8E%E5%86%85%E5%AD%98/","summary":"\u003cp\u003e如何更好更快地访问内存是 HPC 中最大的瓶颈之一，仅仅了解 SIMD 或并行编程接口是不足够的，本文将梳理计算机的内存层次结构、缓存友好编程、内存墙现象、NUMA 架构以及预取技术。\u003c/p\u003e\n\u003ch2 id=\"understanding-memory-hierarchy\"\u003eUnderstanding Memory Hierarchy\u003c/h2\u003e\n\u003cp\u003e为了充分利用现代 CPU 的性能，我们必须理解数据是如何在不同层级的内存组件之间流动的。\u003c/p\u003e\n\u003ch3 id=\"registers-caches-and-main-memory\"\u003eRegisters, Caches, and Main Memory\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e寄存器 (Registers)\u003c/strong\u003e： CPU 内置的、容量最小但速度最快的数据存储单元，用于存储正在被 CPU 活跃操作的数据。CPU 直接在寄存器上执行大部分计算。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e缓存 (Cache)\u003c/strong\u003e： 位于 CPU 和主内存之间的小容量、高速存储区域。它们的目的是通过存储最可能被 CPU 再次访问的数据来减少对主内存的访问延迟。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eL1 缓存 (Level 1 Cache)\u003c/strong\u003e：最小、最快，通常分为数据缓存 (L1d) 和指令缓存 (L1i)，每个 CPU 核心独有。其访问速度与 CPU 核心时钟周期相近。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eL2 缓存 (Level 2 Cache)\u003c/strong\u003e：比 L1 大且慢，每个 CPU 核心独有或由几个核心共享。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eL3 缓存 (Level 3 Cache)\u003c/strong\u003e：最大、最慢的缓存，通常由同一 CPU 插槽上的所有核心共享。\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e主内存 (Main Memory/RAM)\u003c/strong\u003e： 容量远大于缓存，但访问速度慢得多。当数据不在任何缓存中时，CPU 必须从主内存中获取。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eTLB (Translation Lookaside Buffer)\u003c/strong\u003e： TLB 是一个专用的高性能缓存，用于存储虚拟地址到物理地址的转换映射。当 CPU 访问一个虚拟地址时，它首先检查 TLB。如果找到对应的物理地址（TLB 命中），则可以快速进行内存访问；如果未找到（TLB 未命中），则需要查询页表，这将导致显著的延迟。理解 TLB 对于优化内存页访问模式，尤其是在处理大型数据集时至关重要。\u003c/p\u003e","title":"关于内存"},{"content":"去年超算队招新唯一没有解决的一道题，今在 Gemini 老师的帮助下成功解决，决定重写一份题解报告。\nDescription 题目传送门\n题目要求参赛者优化一个 C 语言函数 rotate_the_bit_vector，函数功能是对一个 bit vector 中的一个指定子区间进行循环旋转操作。\n具体而言，题目给的 bit_vector 是一种内存紧凑的数据结构，将 8 个 bit 打包存储到一个字节中。参赛者需要在只修改 submit_func.c 一个文件的前提下重写其中的 rotate_the_bit_vector 函数，使其在大规模数据时尽可能快。\n最后评分程序会通过三个不同的 benchmark (-s, -m, -l) 来衡量，每个测试中的数据规模会随着层数的增加而几何级增长，最终的得分取决于规定时间内能到达的“层数”，层数越高。说明性能越好，最终分数也越高。\nAnalysis Three-Reversal Algorithm 假设要移动的区间长度为 $ n $ ，需要移动 $ k $ 位；由于向右旋转 $ k $ 位可以等效于向左旋转 $ n-k $ 位，因此只讨论向左的移动。\n题目提供了一个初始的性能极差的实现，通过逐位移动 $ k $ 次来实现 $ k $ 位循环旋转，复杂度为 $ O(n^{2}) $。根据这个原始实现很容易想到一个初步的优化方案：\n问题的核心是把数组 [A|B] 变成 [B|A] ，一个经典的算法是三步翻转法：如果我们把翻转操作记为 ' ，A' 表示数组 A 前后反转，那么可以发现原问题的操作实际上等价于三次翻转操作：[A'|B']' = [B|A] ，复杂度为 $ O(n) $ ，代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 #include \u0026#34;./bit_vector.h\u0026#34; #include \u0026lt;assert.h\u0026gt; #include \u0026lt;stdbool.h\u0026gt; #include \u0026lt;sys/types.h\u0026gt; static void reverse_bits(bit_vector_t* const bit_vector, size_t start, size_t end) { while (start \u0026lt; end) { bool temp = bit_vector_get(bit_vector, start); bit_vector_set(bit_vector, start, bit_vector_get(bit_vector, end)); bit_vector_set(bit_vector, end, temp); start++; end--; } } static size_t modulo(const ssize_t n, const size_t m) { const ssize_t signed_m = (ssize_t)m; assert(signed_m \u0026gt; 0); const ssize_t result = ((n % signed_m) + signed_m) % signed_m; assert(result \u0026gt;= 0); return (size_t)result; } void rotate_the_bit_vector(bit_vector_t* const bit_vector, const size_t bit_offset, const size_t bit_length, const ssize_t bit_right_amount) { assert(bit_offset + bit_length \u0026lt;= bit_vector_get_bit_sz(bit_vector)); if (bit_length \u0026lt;= 1) { return; } size_t left_shift = modulo(-bit_right_amount, bit_length); if (left_shift == 0) { return; } // 1. reverse [0, left_shift - 1] reverse_bits(bit_vector, bit_offset, bit_offset + left_shift - 1); // 2. reverse [left_shift, bit_length - 1] reverse_bits(bit_vector, bit_offset + left_shift, bit_offset + bit_length - 1); // 3. reverse [0, bit_length - 1] reverse_bits(bit_vector, bit_offset, bit_offset + bit_length - 1); } 运行测试程序发现只能得到 72 pts\n1 2 3 4 5 6 7 8 9 check result: PASSED performance of -s: 26 performance of -m: 32 performance of -l: 37 ------score-------- -s : 60.00 /100 -m : 72.73 /100 -l : 76.00 /100 total score: 71.82 /100 Performance Analysis with perf 根据题目的提示，我们应该使用 perf 工具来分析性能的瓶颈：\n1 perf record ./everybit -s 运行结束之后生成了一个名为 perf.data 的文件，之后再运行指令分析报告\n1 perf report 输出的交互式界面显示\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 Overhead Command Shared Object Symbol 47.99% everybit everybit [.] bit_vector_set 20.29% everybit everybit [.] bit_vector_get 16.12% everybit everybit [.] bitmask 11.66% everybit everybit [.] reverse_bits 3.26% everybit libc.so.6 [.] __random 0.15% everybit libc.so.6 [.] rand 0.08% everybit [vdso] [.] __vdso_clock_gettime 0.08% everybit everybit [.] bit_vector_randfill 0.08% everybit ld-linux-x86-64.so.2 [.] _dl_init_paths 0.08% everybit ld-linux-x86-64.so.2 [.] handle_intel.constprop.0 0.08% everybit libc.so.6 [.] __random_r 0.08% everybit libc.so.6 [.] _int_free 0.08% everybit libc.so.6 [.] memmove 发现主要的性能瓶颈在 bit_vector_set 和 bit_vector_get 两个操作，这表明虽然我们的算法本身高效，但是其性能严重依赖这两个效率低下的 API ，这指出了我们的下一步优化方向就是这两个操作本身，任何不绕开这两个函数的优化都是治标不治本。\nSpace-for-Time 既然瓶颈在于逐位操作，那么优化的核心思想必然是用块级操作替代位级操作。因此我们需要放弃之前翻转的做法，因为这必然会涉及到位级操作。\n作为替代，我们很自然有用空间换时间的想法：\n在堆上用 malloc 开辟一块足够大的临时缓冲区 temp_buffer。 将原数组需要旋转的 B 和 A 两部分，依次拷贝到 temp_buffer 中，使其内容直接变成旋转后的 [B|A] 顺序。 将 temp_buffer 的内容一次性拷贝回原数组。 由于操作区间是非字节对齐的，我们不能直接使用 memcpy。因此，问题的关键就变成了实现一个高性能、支持任意比特偏移的 bithack_memcpy 函数。\n按照这个思路优化后的代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 #include \u0026#34;./bit_vector.h\u0026#34; #include \u0026lt;assert.h\u0026gt; #include \u0026lt;stdbool.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; #include \u0026lt;string.h\u0026gt; #include \u0026lt;sys/types.h\u0026gt; // alloca.h is no longer needed for the final version // #include \u0026lt;alloca.h\u0026gt; #include \u0026lt;stdint.h\u0026gt; /** * @brief A highly optimized bit-level memcpy. * * Copies \u0026#39;bit_len\u0026#39; bits from a source buffer at a given bit offset to a * destination buffer at another bit offset. This function is the core of the * performance optimization, using 64-bit word operations for the bulk of the copy. * * @param dst_buf The destination memory buffer. * @param dst_offset The starting bit offset in the destination buffer. * @param src_buf The source memory buffer. * @param src_offset The starting bit offset in the source buffer. * @param bit_len The number of bits to copy. */ static void bithack_memcpy(char* dst_buf, size_t dst_offset, const char* src_buf, size_t src_offset, size_t bit_len) { if (bit_len == 0) { return; } size_t bits_copied = 0; // Handle the head: copy bit by bit until the destination is byte-aligned. int head_bits = (8 - (dst_offset % 8)) % 8; if (head_bits \u0026gt; bit_len) { head_bits = bit_len; } for (int i = 0; i \u0026lt; head_bits; i++) { if ((src_buf[(src_offset + i) / 8] \u0026gt;\u0026gt; ((src_offset + i) % 8)) \u0026amp; 1) dst_buf[(dst_offset + i) / 8] |= (1 \u0026lt;\u0026lt; ((dst_offset + i) % 8)); else dst_buf[(dst_offset + i) / 8] \u0026amp;= ~(1 \u0026lt;\u0026lt; ((dst_offset + i) % 8)); } bits_copied += head_bits; // Handle the middle: use 64-bit word operations for maximum speed. while (bit_len - bits_copied \u0026gt;= 64) { size_t current_src_offset = src_offset + bits_copied; size_t current_dst_offset = dst_offset + bits_copied; uint64_t src_word; memcpy(\u0026amp;src_word, src_buf + current_src_offset / 8, sizeof(src_word)); int bit_shift = current_src_offset % 8; if (bit_shift != 0) { uint8_t next_byte = src_buf[current_src_offset / 8 + 8]; src_word = (src_word \u0026gt;\u0026gt; bit_shift) | (((uint64_t)next_byte) \u0026lt;\u0026lt; (64 - bit_shift)); } memcpy(dst_buf + current_dst_offset / 8, \u0026amp;src_word, sizeof(src_word)); bits_copied += 64; } // Handle the tail: copy the remaining bits one by one. for (size_t i = bits_copied; i \u0026lt; bit_len; i++) { if ((src_buf[(src_offset + i) / 8] \u0026gt;\u0026gt; ((src_offset + i) % 8)) \u0026amp; 1) dst_buf[(dst_offset + i) / 8] |= (1 \u0026lt;\u0026lt; ((dst_offset + i) % 8)); else dst_buf[(dst_offset + i) / 8] \u0026amp;= ~(1 \u0026lt;\u0026lt; ((dst_offset + i) % 8)); } } static size_t modulo(const ssize_t n, const size_t m) { const ssize_t signed_m = (ssize_t)m; assert(signed_m \u0026gt; 0); const ssize_t result = ((n % signed_m) + signed_m) % signed_m; assert(result \u0026gt;= 0); return (size_t)result; } void rotate_the_bit_vector(bit_vector_t* const bit_vector, const size_t bit_offset, const size_t bit_length, const ssize_t bit_right_amount) { assert(bit_offset + bit_length \u0026lt;= bit_vector_get_bit_sz(bit_vector)); if (bit_length \u0026lt;= 1) { return; } size_t left_shift = modulo(-bit_right_amount, bit_length); if (left_shift == 0) { return; } size_t buf_byte_size = (bit_length + 7) / 8; char* temp_buffer = (char*)malloc(buf_byte_size); if (temp_buffer == NULL) { exit(1); } size_t first_part_len = bit_length - left_shift; size_t second_part_len = left_shift; bithack_memcpy(temp_buffer, 0, bit_vector-\u0026gt;buf, bit_offset + left_shift, first_part_len); bithack_memcpy(temp_buffer, first_part_len, bit_vector-\u0026gt;buf, bit_offset, second_part_len); bithack_memcpy(bit_vector-\u0026gt;buf, bit_offset, temp_buffer, 0, bit_length); free(temp_buffer); } 现在可以完美获得满分：\n1 2 3 4 5 6 7 8 9 check result: PASSED performance of -s: 37 performance of -m: 40 performance of -l: 44 ------score-------- -s : 100.00 /100 -m : 100.00 /100 -l : 100.00 /100 total score: 100.00 /100 250918 upd: 稍微优化一下 middle 循环中的除法和取模操作，可以再提高一些性能。\nDetails 最终的满分代码完全围绕 bithack_memcpy 函数构建。其工作原理的关键在于分块处理和对底层硬件原理的理解。\n函数将任意拷贝任务拆分为三段：Head , Middle 和 Tail。Head 部分通过逐位拷贝，其唯一目的是让接下来的目标地址实现字节对齐。Tail 部分则处理最后剩下的、不足一个块的零散比特。\n性能优化的核心在 Middle 部分，它以 64 位（8 字节）为单位进行块拷贝。其中处理非对齐源数据的逻辑是精髓所在：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 uint64_t src_word; // 1. 预读取：从源地址的字节边界开始，安全地读取8个字节。 // 这导致我们拿到的数据相对于真正的起始点有一个偏移。 memcpy(\u0026amp;src_word, src_buf + current_src_offset / 8, sizeof(src_word)); int bit_shift = current_src_offset % 8; if (bit_shift != 0) { // 2. 抓取：读取紧邻的下一个字节，它包含了我们缺失的数据。 uint8_t next_byte = src_buf[current_src_offset / 8 + 8]; // 3. 移位与拼接： // a. (src_word \u0026gt;\u0026gt; bit_shift): 将预读取的数据右移，丢弃头部多余的比特。 // b. (((uint64_t)next_byte) \u0026lt;\u0026lt; (64 - bit_shift)): // 将下一个字节左移，使其恰好能填充右移后在高位留下的空缺。 // c. | : 通过或运算，将两部分拼接，重组出我们真正需要的64个比特。 src_word = (src_word \u0026gt;\u0026gt; bit_shift) | (((uint64_t)next_byte) \u0026lt;\u0026lt; (64 - bit_shift)); } // 4. 写入：因为目标地址已对齐，所以可以高效地将重组好的 64 位数据写入。 memcpy(dst_buf + current_dst_offset / 8, \u0026amp;src_word, sizeof(src_word)); 其高性能的根源在于两个核心的底层原理：内存对齐 (Data Alignment) 与 数据局部性 (Data Locality)。\nData Alignment：CPU 访问内存以“字”（Word，64 位 CPU 即 8 字节）为单位。如果数据地址是其大小的倍数，CPU 就能一次内存事务完成读写，这叫对齐访问。非对齐访问则可能需要两次内存事务和内部拼接，性能大幅下降。bithack_memcpy 的“头部处理”阶段，其唯一目的就是实现目标地址的字节对齐，确保占主导地位的中部循环可以执行最高效的对齐写入操作。\nMemory Locality \u0026amp; Caching：CPU 内部有多级 Cache，速度远快于 RAM。当 CPU 访问某块内存时，会把其邻近的一整个 Cache Line 都预加载到缓存中。这就是空间局部性原理 (Principle of Spatial Locality)。我们的 bithack_memcpy 函数利用了这一点，无论是从原数组读，还是在临时缓冲区里读写，操作的都是连续的大块内存。当循环处理第一个 64 位字时，CPU 很可能已经将后面几百个字节的数据预加载到了的 L1 Cache 中，后续迭代无需访问慢速的内存，缓存命中率 (Cache Hit Rate) 极高。相比之下，最初的三步翻转法在内存中“来回跳跃”地访问单个比特，破坏了空间局部性，导致缓存命中率极低，性能自然不佳。\n在开辟缓冲区的选择上面，笔者一开始选择了 alloc ，相比于堆内存，栈内存更快且不需要手动释放，但是发现在测试到一定的层数之后就会由于数据量过大而出现 Segment Falut ，因此最后还是选择了使用 malloc 来分配缓冲区。\n","permalink":"https://diefish1024.github.io/posts/solutions/xflops2024-bithack/","summary":"\u003cp\u003e去年超算队招新唯一没有解决的一道题，今在 Gemini 老师的帮助下成功解决，决定重写一份题解报告。\u003c/p\u003e\n\u003ch2 id=\"description\"\u003eDescription\u003c/h2\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/HPC-SJTU/Xflops2024_1st_exam/tree/main/Bithack\"\u003e题目传送门\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e题目要求参赛者优化一个 C 语言函数 \u003ccode\u003erotate_the_bit_vector\u003c/code\u003e，函数功能是对一个 bit vector 中的一个指定子区间进行\u003cstrong\u003e循环旋转\u003c/strong\u003e操作。\u003c/p\u003e\n\u003cp\u003e具体而言，题目给的 \u003ccode\u003ebit_vector\u003c/code\u003e 是一种内存紧凑的数据结构，将 8 个 bit 打包存储到一个字节中。参赛者需要在只修改 \u003ccode\u003esubmit_func.c\u003c/code\u003e 一个文件的前提下重写其中的 \u003ccode\u003erotate_the_bit_vector\u003c/code\u003e 函数，使其在大规模数据时尽可能快。\u003c/p\u003e\n\u003cp\u003e最后评分程序会通过三个不同的 benchmark (\u003ccode\u003e-s\u003c/code\u003e, \u003ccode\u003e-m\u003c/code\u003e, \u003ccode\u003e-l\u003c/code\u003e) 来衡量，每个测试中的数据规模会随着层数的增加而几何级增长，最终的得分取决于规定时间内能到达的“层数”，层数越高。说明性能越好，最终分数也越高。\u003c/p\u003e\n\u003ch2 id=\"analysis\"\u003eAnalysis\u003c/h2\u003e\n\u003ch3 id=\"three-reversal-algorithm\"\u003eThree-Reversal Algorithm\u003c/h3\u003e\n\u003cp\u003e假设要移动的区间长度为 $ n $ ，需要移动 $ k $ 位；由于向右旋转 $ k $ 位可以等效于向左旋转 $ n-k $ 位，因此只讨论向左的移动。\u003c/p\u003e\n\u003cp\u003e题目提供了一个初始的性能极差的实现，通过逐位移动 $ k $ 次来实现 $ k $ 位循环旋转，复杂度为 $ O(n^{2}) $。根据这个原始实现很容易想到一个初步的优化方案：\u003c/p\u003e\n\u003cp\u003e问题的核心是把数组 \u003ccode\u003e[A|B]\u003c/code\u003e 变成 \u003ccode\u003e[B|A]\u003c/code\u003e ，一个经典的算法是\u003cstrong\u003e三步翻转法\u003c/strong\u003e：如果我们把翻转操作记为 \u003ccode\u003e'\u003c/code\u003e ，\u003ccode\u003eA'\u003c/code\u003e 表示数组 \u003ccode\u003eA\u003c/code\u003e 前后反转，那么可以发现原问题的操作实际上等价于三次翻转操作：\u003ccode\u003e[A'|B']' = [B|A]\u003c/code\u003e ，复杂度为 $ O(n) $ ，代码如下：\u003c/p\u003e","title":"Xflops2024-Bithack"},{"content":"1. What is SIMD? SIMD，即 Single Instruction Multiple Data ，是一种并行计算的模式。传统的单指令单数据模型，也就是一条指令 CPU 只能处理一份数据，这在科学计算和图像渲染等大量数据密集的任务中是非常低效的。\nSIMD 的核心思想是用一条指令同时对多个数据进行操作，现代的 CPU 为此设计了特殊的硬件单元，包括宽位（比如 128、256 或 512 位）的向量寄存器 (Vector Registers) 和能够操作这些寄存器的向量指令 (Vector Instructions)。一个向量操作可以同时完成多个标量操作，从而实现数据并行 (Data Parallelism)，提高效率。假设一个 256 位的向量寄存器可以容纳 8 个 32 位浮点数，一条向量加法指令就可以一次性完成 8 个浮点数的加法，理论上将这部分计算的吞吐量提升至原来的 8 倍；并且相比于执行 8 条独立的标量加法指令，CPU 只需要获取并解码一条向量加法指令，这降低了指令流水线的压力。\n2. How SIMD Works 要理解 SIMD 的工作原理，需要了解两个核心概念：向量寄存器和向量指令。\n2.1. Vector Registers 向量寄存器是 CPU 内部的特殊存储单元，其宽度远大于通用寄存器。不同的 Instruction Set Architecture (ISA, 指令集架构) 提供了不同宽度和名称的向量寄存器。\nSSE (Streaming SIMD Extensions)：提供了 128 位的 XMM 寄存器。\nAVX (Advanced Vector Extensions)：提供了 256 位的 YMM 寄存器。\nAVX-512：提供了 512 位的 ZMM 寄存器。\nARM NEON：主要用于移动设备，提供 128 位的向量寄存器。\n比如一个 YMM 寄存器可以同时存放 8 个单精度浮点数（8 * 32 位 = 256 位）或 4 个双精度浮点数（4 * 64 位 = 256 位）。\n2.2. Vector Instructions 向量指令是专门用来操作向量寄存器中数据的指令。这些指令通常与标量指令功能对应，但作用于整个向量。\n算术运算：向量加、减、乘、除。\n逻辑运算：向量与、或、异或。\n数据加载/存储：将内存中的连续数据块加载到向量寄存器，或将寄存器中的数据存回内存。\n数据重排 (Shuffle/Permute)：在向量寄存器内部重新排列数据元素，这是许多高级算法优化的关键。\n3. SIMD Programming Models 实际编程中，主要通过两种凡是来利用 SIMD：自动向量化和手动向量化。\n3.1 Automatic Vectorization Automatic Vectorization (自动向量化) 是指编译器自动分析代码（通常是循环），并将其转换为 SIMD 指令的过程。这是最简单、最直接的优化方式。\n要让编译器成功进行自动向量化，代码需要满足一些条件：\n循环结构简单: 循环体内部没有复杂的分支判断。\n无数据依赖: 循环的每次迭代之间没有依赖关系。例如，a[i] = a[i-1] + 1 这样的代码就存在数据依赖，无法被直接向量化。\n内存访问连续: 对数组的访问是连续的，例如 row-major order (行主序) 访问。\n一个能被自动向量化的简单例子：\n1 2 3 4 5 6 7 void vector_add(float* a, float* b, float* c, int n) { for (int i = 0; i \u0026lt; n; ++i) { // 每次迭代之间没有数据依赖 // 内存访问也是连续的 c[i] = a[i] + b[i]; } } 现代的编译器（比如 Clang, GCC）在开启优化选项时会默认尝试自动向量化。\n3.2 Manual Vectorization with Intrinsics 当自动向量化不能满足性能要求，或者循环逻辑太复杂导致编译器无法分析时，就需要进行手动向量化。最常用的方法是使用 Intrinsics (内建函数)。\nIntrinsics 是编译器提供的、与特定汇编指令一一对应的函数。我们可以和调用普通函数一样使用，而编译器会直接将其翻译成对应的 SIMD 指令。\n这种方式的优点是：\n可以精准控制使用哪条 SIMD 指令，实现最大程度的优化。 可以实现自动向量化无法完成的复杂逻辑。 缺点是：\n代码可移植性差，和特定的架构强相关，基于特定 ISA 编写的代码不能在不支持该指令集的 CPU 上运行（除非使用 qemu ）。 需要学习特定指令集对应的函数，非常繁琐。 3.3 An Example 可以通过一个实例来对比普通实现和使用 AVX Intrinsics 的手动向量化实现。\n普通实现：\n1 2 3 4 5 6 // 传统的标量实现 void scalar_add(float* a, float* b, float* c, int n) { for (int i = 0; i \u0026lt; n; ++i) { c[i] = a[i] + b[i]; } } 手动向量化：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 // 引入AVX头文件 #include \u0026lt;immintrin.h\u0026gt; void avx_add(float* a, float* b, float* c, int n) { // 假设 n 是8的倍数，便于演示 for (int i = 0; i \u0026lt; n; i += 8) { // 1. 从内存加载8个浮点数到 YMM 寄存器 __m256 vec_a = _mm256_load_ps(\u0026amp;a[i]); __m256 vec_b = _mm256_load_ps(\u0026amp;b[i]); // 2. 执行向量加法，一条指令完成8个浮点数相加 __m256 vec_c = _mm256_add_ps(vec_a, vec_b); // 3. 将计算结果从 YMM 寄存器存回内存 _mm256_store_ps(\u0026amp;c[i], vec_c); } } __m256 是 AVX 中的数据类型，代表一个 256 位的向量。 _mm256_load_ps 从内存加载数据到向量寄存器。 _mm256_add_ps 执行单精度浮点数的向量加法。 _mm256_store_ps 将结果存回内存。 通过这种方式，循环迭代次数减少为原来的 1/8，并且每次迭代处理的数据量是原来的 8 倍，理论上性能提升巨大，但是由于这个入水平有限，写的 benchmark 没打过编译器自动优化✋😭🤚可能需要复杂一点的任务才能明显体现性能的优越性。\nSummary SIMD 是一种利用 Data Parallelism (数据并行) 提升性能的关键技术。\n其核心是通过 Vector Registers (向量寄存器) 和 Vector Instructions (向量指令)，实现单指令处理多数据的目标。\nAutomatic Vectorization (自动向量化) 是最便捷的 SIMD 优化方法，依赖于编译器的能力。\n当需要极致性能和精确控制时，可以使用 Intrinsics (内建函数) 进行手动向量化。\nReferences 向量化 - HPC入门指南 lect19 - NJU OS 2025 ","permalink":"https://diefish1024.github.io/posts/hpc/simd-%E5%85%A5%E9%97%A8/","summary":"\u003ch2 id=\"1-what-is-simd\"\u003e1. What is SIMD?\u003c/h2\u003e\n\u003cp\u003eSIMD，即 \u003cstrong\u003eSingle Instruction Multiple Data\u003c/strong\u003e ，是一种并行计算的模式。传统的单指令单数据模型，也就是一条指令 CPU 只能处理一份数据，这在科学计算和图像渲染等大量数据密集的任务中是非常低效的。\u003c/p\u003e\n\u003cp\u003eSIMD 的核心思想是\u003cstrong\u003e用一条指令同时对多个数据进行操作\u003c/strong\u003e，现代的 CPU 为此设计了特殊的硬件单元，包括宽位（比如 128、256 或 512 位）的\u003cstrong\u003e向量寄存器 (Vector Registers)\u003c/strong\u003e 和能够操作这些寄存器的\u003cstrong\u003e向量指令 (Vector Instructions)\u003c/strong\u003e。一个向量操作可以同时完成多个标量操作，从而实现\u003cstrong\u003e数据并行 (Data Parallelism)\u003c/strong\u003e，提高效率。假设一个 256 位的向量寄存器可以容纳 8 个 32 位浮点数，一条向量加法指令就可以一次性完成 8 个浮点数的加法，理论上将这部分计算的吞吐量提升至原来的 8 倍；并且相比于执行 8 条独立的标量加法指令，CPU 只需要获取并解码一条向量加法指令，这降低了指令流水线的压力。\u003c/p\u003e\n\u003ch2 id=\"2-how-simd-works\"\u003e2. How SIMD Works\u003c/h2\u003e\n\u003cp\u003e要理解 SIMD 的工作原理，需要了解两个核心概念：向量寄存器和向量指令。\u003c/p\u003e\n\u003ch3 id=\"21-vector-registers\"\u003e2.1. Vector Registers\u003c/h3\u003e\n\u003cp\u003e向量寄存器是 CPU 内部的特殊存储单元，其宽度远大于通用寄存器。不同的 \u003cstrong\u003eInstruction Set Architecture (ISA, 指令集架构)\u003c/strong\u003e 提供了不同宽度和名称的向量寄存器。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eSSE (Streaming SIMD Extensions)\u003c/strong\u003e：提供了 128 位的 \u003ccode\u003eXMM\u003c/code\u003e 寄存器。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eAVX (Advanced Vector Extensions)\u003c/strong\u003e：提供了 256 位的 \u003ccode\u003eYMM\u003c/code\u003e 寄存器。\u003c/p\u003e","title":"SIMD 入门"},{"content":"针对 CUMCM-2025 开始学习 COPT 求解器的使用，学习如何应用 COPT 的 Python API (coptpy) 来建模并求解数学建模中常见的离散优化问题。\nBasic API 本节将介绍 COPT 求解器 Python API (coptpy) 的核心组件和常用方法。\nEnvr Class Envr 类用于创建一个 COPT 环境。它是所有模型操作的起点。\nCreating Environment and Model:\n1 2 3 4 5 import coptpy as cp from coptpy import COPT env = cp.Envr() # 创建一个 COPT 环境实例 model = env.createModel(name=\u0026#39;YourModelName\u0026#39;) # 在环境中创建一个模型 name：模型的名称，此为可选参数。 Model Class Properties and Methods Model 类是 COPT 的核心，代表了优化模型，包含了所有变量、约束和目标函数。\nBasic Properties 在模型求解后，可以通过以下属性获取其基本信息：\nmodel.status：模型解的状态。此属性指示模型是否找到了最优解、无可行解等。例如，COPT.OPTIMAL 表示已找到最优解。 model.objval：目标函数值。此属性存储模型的最优目标函数值。 Adding Variables 可以通过 addVar() 和 addVars() 方法向模型中添加决策变量。\nAdding a Single Variable:\n使用 model.addVar() 方法向模型中添加一个单独的决策变量。\n1 x = model.addVar(lb=0.0, ub=cp.COPT.INFINITY, vtype=cp.COPT.CONTINUOUS, name=\u0026#39;x_var\u0026#39;) lb：变量的下界（默认为 $ 0.0 $）。 ub：变量的上界（默认为 COPT.INFINITY，表示正无穷）。 vtype：变量的类型，可以是： cp.COPT.CONTINUOUS (连续变量) cp.COPT.INTEGER (整数变量) cp.COPT.BINARY (二进制变量，即 $ 0 $ 或 $ 1 $) name：变量的名称。 Adding Multiple Variables:\n使用 model.addVars() 方法一次性添加一组变量。该方法返回一个 tupledict 对象，其键为变量的下标，值为相应的 Var 对象。\n1 model.addVars(*indices, lb=0.0, ub=cp.COPT.INFINITY, obj=0.0, vtype=cp.COPT.CONTINUOUS, nameprefix=\u0026#34;\u0026#34;) *indices：用于定义变量下标的参数。 lb/ub/vtype：含义与 addVar 相同。 obj：变量在目标函数中的系数，默认为 $ 0.0 $。 nameprefix：变量名称的前缀。 Form 1: Using Integer Parameters to Define Dimensions:\n这将创建一个具有给定维度和连续整数下标的变量组。\n1 2 3 4 # 添加一个 2x3 的整数变量 x，共计 6 个变量，下标从 (0,0) 到 (1,2) x = model.addVars(2, 3, vtype=COPT.INTEGER, nameprefix=\u0026#39;x\u0026#39;) print(x.select()) 输出：\n1 [\u0026lt;coptpy.Var: x(0,0)\u0026gt;, \u0026lt;coptpy.Var: x(0,1)\u0026gt;, \u0026lt;coptpy.Var: x(0,2)\u0026gt;, \u0026lt;coptpy.Var: x(1,0)\u0026gt;, \u0026lt;coptpy.Var: x(1,1)\u0026gt;, \u0026lt;coptpy.Var: x(1,2)\u0026gt;] 可以通过下标访问这些变量：\n1 2 3 for i in range(2): for j in range(3): print(x[i,j].name, end=\u0026#39; \u0026#39;) 输出：\n1 x(0,0) x(0,1) x(0,2) x(1,0) x(1,1) x(1,2) 可以看到 $ x $ 实际上是一个 tupledict 对象，其键是变量下标（如 (0,0)），值是 Var 对象。\nForm 2: Using tuplelist for Non-contiguous Indices:\n当变量下标不是连续整数时，可以使用 coptpy.tuplelist 来明确指定需要创建的变量。\n1 2 3 4 t = cp.tuplelist([(0, 1), (1, 2)]) x = model.addVars(t, nameprefix=\u0026#34;t\u0026#34;) print(x.select()) 输出：\n1 [\u0026lt;coptpy.Var: t(0,1)\u0026gt;, \u0026lt;coptpy.Var: t(1,2)\u0026gt;] Form 3: Using Multiple Lists for Cartesian Product:\n*indices 可以是多个列表，addVars 会自动生成这些列表的笛卡尔积作为变量的下标。\n1 2 3 4 5 t = [\u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;] # 创建 x[\u0026#39;a\u0026#39;,0,0], x[\u0026#39;a\u0026#39;,0,1], ..., x[\u0026#39;b\u0026#39;,1,2] 等变量 x = model.addVars(t, range(2), range(3)) print(x.select()) 输出：\n1 [\u0026lt;coptpy.Var: C(a,0,0)\u0026gt;, \u0026lt;coptpy.Var: C(a,0,1)\u0026gt;, \u0026lt;coptpy.Var: C(a,0,2)\u0026gt;, \u0026lt;coptpy.Var: C(a,1,0)\u0026gt;, \u0026lt;coptpy.Var: C(a,1,1)\u0026gt;, \u0026lt;coptpy.Var: C(a,1,2)\u0026gt;, \u0026lt;coptpy.Var: C(b,0,0)\u0026gt;, \u0026lt;coptpy.Var: C(b,0,1)\u0026gt;, \u0026lt;coptpy.Var: C(b,0,2)\u0026gt;, \u0026lt;coptpy.Var: C(b,1,0)\u0026gt;, \u0026lt;coptpy.Var: C(b,1,1)\u0026gt;, \u0026lt;coptpy.Var: C(b,1,2)\u0026gt;] 从此示例可以看出，变量的下标也可以是字符串类型。\nAdding Constraints 可以通过 addConstr() 和 addConstrs() 方法向模型中添加约束。\nAdding a Single Constraint:\n使用 model.addConstr() 添加一个约束。\n1 model.addConstr(lhs, sense=None, rhs=None, name=\u0026#34;\u0026#34;) lhs：约束的左侧表达式。对于线性约束，可以是 Var 对象、LinExpr 对象或 ConstrBuilder 对象。 sense：约束的类型，可以是： cp.COPT.LESS_EQUAL (\u0026lt;=) cp.COPT.EQUAL (==) cp.COPT.GREATER_EQUAL (\u0026gt;=) rhs：约束的右侧值。 name：约束的名称。 例子：\n1 2 3 # 假设 x 和 y 都是模型中的变量 # 添加一个线性约束 x + y \u0026lt;= 10 model.addConstr(x + y \u0026lt;= 10, name=\u0026#34;total_limit\u0026#34;) Adding Multiple Constraints:\n使用 model.addConstrs() 方法添加一组类似的约束，通常通过生成器表达式来完成。\n1 2 3 # 假设 x 和 y 是通过 addVars 生成的变量组 # 添加 10 个线性约束，每个约束形如：x[i] + y[i] \u0026gt;= 2.0 model.addConstrs(x[i] + y[i] \u0026gt;= 2.0 for i in range(10), nameprefix=\u0026#34;pairwise_sum\u0026#34;) nameprefix：约束名称的前缀，COPT 会自动在其后添加下标。 Adding Indicator Constraints:\n指示约束是一种特殊类型的约束，它在一个二值变量取特定值时激活一个线性约束。\n1 model.addGenConstrIndicator(binvar, binval, lhs, sense=None, rhs=None) binvar：作为指示器功能的二进制变量。 binval：binvar 的目标值（True 或 False / $ 1 $ 或 $ 0 $），当 binvar 取此值时，线性约束被激活。 lhs/sense/rhs：定义被激活的线性约束（与 addConstr 类似）。 例子：\n1 2 3 # 假设 x 是一个二进制变量，y 和 z 是模型中的变量 # 添加一个 Indicator 约束：当 x 为 True (即 x=1) 时，线性约束 y + 2*z \u0026gt;= 3 成立 model.addGenConstrIndicator(x, True, y + 2*z \u0026gt;= 3, name=\u0026#34;indicator_constr\u0026#34;) Setting the Objective Function 使用 model.setObjective() 方法定义模型的优化目标。\n1 model.setObjective(expr, sense=None) expr：目标函数表达式，通常是一个 LinExpr 对象。 sense：目标的优化方向，可以是 cp.COPT.MAXIMIZE 或 cp.COPT.MINIMIZE。 例子：\n1 2 # 假设 profit 是一个线性表达式 model.setObjective(profit, COPT.MAXIMIZE) Retrieving Model Information 以下方法用于获取模型求解后的各种信息。\nGetting All Variables:\n1 vars = model.getVars() 返回一个 VarArray 对象，包含模型中的所有变量。 Getting LP Analysis Results:\n1 values, slacks, duals, redcosts = model.getLpSolution() 仅适用于线性规划 (LP) 模型。 返回一个四元组，其中每个元素都是一个列表： values：变量的取值。 slacks：松弛变量的取值。 duals：约束的对偶变量取值。 redcosts：变量的 Reduced Cost。 Getting Specific Model Information:\n1 model.getInfo(infoname, args) infoname：待获取信息的名称（如 COPT.Info.VarPrimal 获取变量值，COPT.Info.ConDual 获取对偶值等）。 args：指定要获取信息的变量或约束。 若 args 为单个 Var 或 Constraint 对象，则返回其信息值常量。 若 args 为列表、VarArray 或 ConstrArray 对象，则返回信息值组成的列表。 若 args 为字典或 tupledict 对象，则返回键为指定变量/约束的下标，值为其信息值的 tupledict 对象。 Cloning a Model 1 mcopy = model.clone() 创建模型的深拷贝，mcopy 是一个与原模型独立的新模型实例。 Var Class Var 类表示模型中的一个单独决策变量。\nAttributes 在模型求解后，可以通过以下属性获取变量的相应信息。\nvar.x 或 var.Value：变量的当前取值。 var.name：变量的名称。 var.Slack：松弛变量的取值（对于约束，此属性在变量层面通常不直接使用）。 var.Dual：对偶变量的取值（与约束的对偶值相关，在变量层面通常不直接使用）。 var.LB：变量的下界。 var.UB：变量的上界。 Methods varname = v.getName()：获取变量 v 的名称。 v.setName('new_name')：设置变量 v 的名称。 x.remove()：从模型中删除变量 x。 VarArray Class VarArray 类是一个特殊的容器，用于存储一组 Var 对象。例如，model.getVars() 的返回值就是 VarArray 类型。\nMethods var = vararr.getVar(idx)：根据变量在 VarArray 对象中的下标获取相应的变量，返回一个 Var 对象。 varall = vararr.getAll()：获取 VarArray 对象中的所有变量，返回一个列表。 arrsize = vararr.getSize()：获取 vararr 中变量的个数。 Important Data Structures coptpy 库提供了一些特殊的数据结构，以方便处理变量和约束的集合，特别是多维情况。\nmultidict multidict 函数可以将输入字典拆分为多个平行字典。当有一个字典，其值是列表或元组，并且希望将每个子元素作为单独的字典时，它非常有用。\n1 2 3 4 5 6 7 8 9 10 11 import coptpy as cp # 将输入的字典对象拆分为键与多个字典对象并返回 keys, dict1, dict2 = cp.multidict({ \u0026#34;hello\u0026#34;: [0, 1], \u0026#34;world\u0026#34;: [2, 3] }) print(f\u0026#34;keys: {keys}\u0026#34;) print(f\u0026#34;dict1: {dict1}\u0026#34;) print(f\u0026#34;dict2: {dict2}\u0026#34;) 输出：\n1 2 3 keys: [\u0026#39;hello\u0026#39;, \u0026#39;world\u0026#39;] dict1: {\u0026#39;hello\u0026#39;: 0, \u0026#39;world\u0026#39;: 2} dict2: {\u0026#39;hello\u0026#39;: 1, \u0026#39;world\u0026#39;: 3} multidict 返回一个元组，第一个元素是原始字典的所有键组成的列表，随后的元素是根据原始字典值中对应位置元素生成的字典。\ntupledict tupledict 是 Python 内置 dict 的子类，专为使用元组作为键的字典进行了优化。它继承了 dict 的所有方法，并额外提供了 select、sum 和 prod 等方便的集合操作。model.addVars() 的返回值就是一个 tupledict。\nCreating a tupledict:\n1 2 d = cp.tupledict([((1,1),\u0026#39;a\u0026#39;), ((1,2),\u0026#39;b\u0026#39;),((2,1),\u0026#39;c\u0026#39;),((2,2),\u0026#39;d\u0026#39;)]) print(d) 输出：\n1 {(1, 1): \u0026#39;a\u0026#39;, (1, 2): \u0026#39;b\u0026#39;, (2, 1): \u0026#39;c\u0026#39;, (2, 2): \u0026#39;d\u0026#39;} 可以使用下标访问 tupledict 中的元素，如同访问普通字典一样：\n1 2 3 for i in range(1, 3): for j in range(1, 3): print(d[i,j], end=\u0026#39; \u0026#39;) 输出：\n1 a b c d select Method:\ntupledict.select(pattern) 方法根据指定的模式筛选出符合条件的项，返回包含所有符合条件的值的列表。pattern 中的 * 代表通配符。注意，pattern 匹配的是 tupledict 的键。\n1 2 3 4 5 d = cp.tupledict([((1,1),\u0026#39;a\u0026#39;), ((1,2),\u0026#39;b\u0026#39;),((2,1),\u0026#39;c\u0026#39;),((2,2),\u0026#39;d\u0026#39;)]) print(d.select(2,\u0026#39;*\u0026#39;)) # 筛选第一个键为 2 的项 print(d.select(1,2)) # 筛选精确键为 (1,2) 的项 print(d.select()) # 筛选所有项 输出：\n1 2 3 [\u0026#39;c\u0026#39;, \u0026#39;d\u0026#39;] [\u0026#39;b\u0026#39;] [\u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;, \u0026#39;c\u0026#39;, \u0026#39;d\u0026#39;] sum Method:\nexpr = tupledict.sum(pattern) 方法根据指定的模式筛选并累加项，返回一个 LinExpr 对象（如果 tupledict 中的值是数字）。这里的 pattern 用法与 select 方法完全相同。\n1 2 d = cp.tupledict([((1,1),1), ((1,2),2),((2,1),3),((2,2),4)]) print(d.sum(\u0026#39;*\u0026#39;, 2)) # 匹配第二个键为 2 的项，即 d[(1,2)] 和 d[(2,2)]，并求和 输出：\n1 6.0 prod Method:\nexpr = d.prod(coeff, pattern) 方法根据指定的模式筛选，并与乘积系数累乘项，返回一个 LinExpr 对象。coeff 是一个字典或 tupledict 类型，其键需要与 d 的键对应。pattern 的含义与 select 相同。本质上，prod 方法执行的是点积操作。\n1 2 3 4 5 6 d = cp.tupledict([((1,1),1), ((1,2),2),((2,1),3),((2,2),4)]) coef = cp.tupledict([((1,1),2), ((1,2),2),((2,1),3),((2,2),3)]) # 匹配第二个键为 2 的项，即 d[(1,2)] 和 d[(2,2)] # 计算 (d[(1,2)] * coeff[(1,2)]) + (d[(2,2)] * coeff[(2,2)]) # 即 (2 * 2) + (4 * 3) = 4 + 12 = 16 print(d.prod(coef, \u0026#39;*\u0026#39;, 2)) 输出：\n1 16.0 tuplelist tuplelist 是 Python 内置 list 的子类，专门用于存储元组列表。它继承了 list 的所有方法，并增强了 select 和 add 等功能。\nCreating a tuplelist:\n1 2 3 4 5 tl1 = cp.tuplelist([(0, 1), (1, 2)]) tl2 = cp.tuplelist([(\u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;), (\u0026#39;b\u0026#39;, \u0026#39;c\u0026#39;)]) print(tl1) print(tl2) 输出：\n1 2 [(0, 1), (1, 2)] [(\u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;), (\u0026#39;b\u0026#39;, \u0026#39;c\u0026#39;)] 可以直接用索引访问列表的成员。\nadd Method:\ntl.add((2, 3)) 方法用于向 tuplelist 中添加成员，功能类似于 list.append()。\n1 2 3 tl = cp.tuplelist([(0, 1), (1, 2)]) tl.add((2, 3)) print(tl) 输出：\n1 [(0, 1), (1, 2), (2, 3)] select Method:\nselect 方法的思想与 tupledict 中的 select 相同，根据指定的模式筛选符合条件的元组。\n1 2 tl = cp.tuplelist([(0, 1), (1, 2)]) print(tl.select(0,\u0026#39;*\u0026#39;)) # 筛选第一个元素为 0 的元组 输出：\n1 [(0, 1)] Mixed-Integer Programming (MIP) 离散优化的核心工具是混合整数规划 (Mixed-Integer Programming, MIP)。一个标准的 MIP 模型包含三个核心要素：\n决策变量 (Decision Variables)：模型中需要求解的未知数。在离散优化中，这些变量通常被约束为整数（例如，工人数、产品件数）或 0-1 二进制变量（例如，某个决策是否执行）。\n目标函数 (Objective Function)：一个关于决策变量的线性表达式，我们需要将其最大化（如利润、效率）或最小化（如成本、距离）。\n约束条件 (Constraints)：一系列关于决策变量的线性等式或不等式，用于定义问题的可行域。\n我们的任务就是将一个具体问题用这三个要素清晰地表达出来，然后交给 COPT 进行求解。\n0-1 Knapsack Problem 对于 0-1 背包问题，定义 $ N $ 为物品总数，$ w_{i},v_{i} $ 分别为物品 $ i $ 的重量和价值，$ C $ 为背包的容量。那么就可以列出这个问题的三个要素：\n决策变量：定义二进制串 $ x_{i} $ 表示是否选取。 $$ x_i \\in \\{0, 1\\}, \\quad \\forall i \\in \\{1, ..., N\\} $$ 目标函数：最大化背包内物品的总价值。 $$ \\max \\sum_{i=1}^{N} v_i x_i $$ 约束条件：装入背包的物品总重量不能超过背包容量。 $$ \\text{s.t.} \\quad \\sum_{i=1}^{N} w_i x_i \\leq C $$ 那么就可以得到 COPT 的求解代码： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 import coptpy as cp from coptpy import COPT # 1. 创建环境和模型 env = cp.Envr() model = env.createModel(\u0026#34;Knapsack\u0026#34;) # 2. 定义数据 weights = [4, 5, 2, 6, 3] # 重量 values = [10, 12, 5, 15, 7] # 价值 capacity = 12 # 背包容量 n = len(weights) # 3. 创建决策变量 # x[i] = 1 if item i is selected, 0 otherwise x = model.addVars(n, vtype=COPT.BINARY, nameprefix=\u0026#34;x\u0026#34;) # 4. 设置目标函数 model.setObjective(cp.quicksum(values[i] * x[i] for i in range(n)), COPT.MAXIMIZE) # 5. 添加约束条件 model.addConstr(cp.quicksum(weights[i] * x[i] for i in range(n)) \u0026lt;= capacity) # 6. 求解模型 model.solve() # 7. 打印结果 if model.status == COPT.OPTIMAL: print(\u0026#34;Optimal solution found.\u0026#34;) print(f\u0026#34;Total value: {model.objval:.2f}\u0026#34;) selected_items = [i for i in range(n) if x[i].x \u0026gt; 0.5] print(f\u0026#34;Selected items (indices): {selected_items}\u0026#34;) else: print(\u0026#34;No optimal solution found.\u0026#34;) Traveling Salesperson Problem (TSP) 旅行商问题。给定一系列城市和每对城市之间的距离，求解访问每一座城市一次并最终回到起始城市的最短可能路径。此问题的一个经典 MIP 模型是 Miller-Tucker-Zemlin (MTZ) 公式。\n定义 $ N $ 为城市总数量，$ d_{i,j} $ 为城市 $ i $ 到城市 $ j $ 的距离，那么可以得到：\n决策变量： 二进制变量 $ x_{i,j} $ ，表示是否经过 $ i $ 到 $ j $ 之间路径。 $$ x_{ij} \\in \\{0, 1\\}, \\quad \\forall i, j \\in \\{0, ..., N-1\\}, i \\neq j $$ 辅助连续变量 $ u_{i} $ 用于消除子回路 $$ u_i \\ge 0, \\quad \\forall i \\in \\{0, ..., N-1\\} $$ 目标函数：最小化总路程。 $$ \\min \\sum_{i=0}^{N-1} \\sum_{j=0, j\\neq i}^{N-1} d_{i,j} x_{i,j} $$ 约束条件： 每个城市必须且只能进入一次。 $$ \\sum_{i=0, i\\neq j}^{N-1} x_{i,j} = 1, \\quad \\forall j \\in \\{0, ..., N-1\\} $$ 每个城市必须且只能离开一次。 $$ \\sum_{j=0, j\\neq i}^{N-1} x_{ij} = 1, \\quad \\forall i \\in \\{0, ..., N-1\\} $$ 消除子回路约束。 $$ u_i - u_j + N \\cdot x_{ij} \\le N-1, \\quad \\forall i, j \\in \\{1, ..., N-1\\}, i \\neq j $$ 那么就可以得到代码： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 import coptpy as cp from coptpy import COPT import random # 1. 创建环境和模型 env = cp.Envr() model = env.createModel(\u0026#34;TSP\u0026#34;) # 2. 定义数据 n_cities = 10 # 生成随机城市坐标 coords = {i: (random.randint(0, 100), random.randint(0, 100)) for i in range(n_cities)} # 计算距离矩阵 distances = {(i, j): ((coords[i][0] - coords[j][0])**2 + (coords[i][1] - coords[j][1])**2)**0.5 for i in range(n_cities) for j in range(n_cities) if i != j} # 3. 创建决策变量 # x[i, j] = 1 if path from city i to j is taken, 0 otherwise x = model.addVars(distances.keys(), vtype=COPT.BINARY, nameprefix=\u0026#34;x\u0026#34;) # 辅助变量用于消除子回路 u = model.addVars(n_cities, vtype=COPT.CONTINUOUS, nameprefix=\u0026#34;u\u0026#34;) # 4. 设置目标函数 model.setObjective(x.prod(distances), COPT.MINIMIZE) # 5. 添加约束条件 # 每个城市必须离开一次 model.addConstrs((cp.quicksum(x[i, j] for j in range(n_cities) if i != j) == 1 for i in range(n_cities)), nameprefix=\u0026#34;leave\u0026#34;) # 每个城市必须进入一次 model.addConstrs((cp.quicksum(x[i, j] for i in range(n_cities) if i != j) == 1 for j in range(n_cities)), nameprefix=\u0026#34;enter\u0026#34;) # 消除子回路 (MTZ) model.addConstrs((u[i] - u[j] + n_cities * x[i, j] \u0026lt;= n_cities - 1 for i in range(1, n_cities) for j in range(1, n_cities) if i != j), nameprefix=\u0026#34;subtour\u0026#34;) # 6. 求解模型 # 为复杂问题设置时间限制 model.setParam(COPT.Param.TimeLimit, 60) model.solve() # 7. 打印结果 if model.status == COPT.OPTIMAL: print(f\u0026#34;Optimal solution found with total distance: {model.objval:.2f}\u0026#34;) path = [] current_city = 0 while len(path) \u0026lt; n_cities: path.append(current_city) for j in range(n_cities): if current_city != j and x[current_city, j].x \u0026gt; 0.5: current_city = j break print(f\u0026#34;Path: {path}\u0026#34;) 其余问题方法均类似，在此不再赘述，总之解决问题的流程就是定义决策变量，构建目标函数，构建约束三步。\nAdvanced Tips 在比赛中需要高效的建模和调试。\nDebugging Infeasible Models 当模型没有可行解时 (model.status == COPT.INFEASIBLE)，意味着约束条件之间存在冲突。找出问题所在非常困难。COPT 提供了不可约不一致子系统 (Irreducible Inconsistent Subsystem, IIS) 工具来定位问题。IIS 是原始模型约束的一个最小子集，其本身是不可行的。\n使用流程：\n首先调用 model.solve() 并确认模型状态为不可行。 调用 model.computeIIS() 来计算 IIS。 遍历模型的约束，通过检查其 IISConstr 属性，找出属于 IIS 的约束。这些约束就是导致模型不可行的元凶。 1 2 3 4 5 6 7 8 9 # (在模型求解后) if model.status == COPT.INFEASIBLE: print(\u0026#34;Model is infeasible. Computing IIS...\u0026#34;) model.computeIIS() print(\u0026#34;The following constraints are in the IIS:\u0026#34;) for constr in model.getConstrs(): if constr.IISConstr: print(f\u0026#34;- {constr.name}\u0026#34;) Parameter Tuning for Performance 对于大规模或复杂的 MIP 问题，默认参数可能无法在有限时间内找到好的解。可以使用 COPT 的参数调优工具 (Tuner) 自动寻找最佳参数组合。\n在 Python 中，可以通过 model.tune() 方法来启动调优器。它会尝试不同的参数设置，并在调优过程结束后，将最优参数应用到模型上。\n1 2 3 4 5 6 7 # 在调用 solve() 之前，可以先调用 tune() print(\u0026#34;Starting parameter tuning...\u0026#34;) model.tune() # 调优后，可以直接求解模型 print(\u0026#34;Tuning finished. Solving with best parameters...\u0026#34;) model.solve() References Python接口 - 杉树求解器用户指南 copt求解器的使用\u0026mdash;-常见api（知乎） ","permalink":"https://diefish1024.github.io/posts/misc/copt-%E6%B1%82%E8%A7%A3%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/","summary":"\u003cp\u003e针对 CUMCM-2025 开始学习 COPT 求解器的使用，学习如何应用 COPT 的 Python API (\u003ccode\u003ecoptpy\u003c/code\u003e) 来建模并求解数学建模中常见的离散优化问题。\u003c/p\u003e\n\u003ch2 id=\"basic-api\"\u003eBasic API\u003c/h2\u003e\n\u003cp\u003e本节将介绍 \u003ccode\u003eCOPT\u003c/code\u003e 求解器 \u003ccode\u003ePython API (coptpy)\u003c/code\u003e 的核心组件和常用方法。\u003c/p\u003e\n\u003ch3 id=\"envr-class\"\u003eEnvr Class\u003c/h3\u003e\n\u003cp\u003e\u003ccode\u003eEnvr\u003c/code\u003e 类用于创建一个 \u003ccode\u003eCOPT\u003c/code\u003e 环境。它是所有模型操作的起点。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eCreating Environment and Model:\u003c/strong\u003e\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cdiv class=\"chroma\"\u003e\n\u003ctable class=\"lntable\"\u003e\u003ctr\u003e\u003ctd class=\"lntd\"\u003e\n\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode\u003e\u003cspan class=\"lnt\"\u003e1\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e2\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e3\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e4\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e5\n\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\n\u003ctd class=\"lntd\"\u003e\n\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-python\" data-lang=\"python\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"nn\"\u003ecoptpy\u003c/span\u003e \u003cspan class=\"k\"\u003eas\u003c/span\u003e \u003cspan class=\"nn\"\u003ecp\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"kn\"\u003efrom\u003c/span\u003e \u003cspan class=\"nn\"\u003ecoptpy\u003c/span\u003e \u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"n\"\u003eCOPT\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003eenv\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003ecp\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eEnvr\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e  \u003cspan class=\"c1\"\u003e# 创建一个 COPT 环境实例\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003emodel\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eenv\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ecreateModel\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ename\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s1\"\u003e\u0026#39;YourModelName\u0026#39;\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e  \u003cspan class=\"c1\"\u003e# 在环境中创建一个模型\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\u003c/tr\u003e\u003c/table\u003e\n\u003c/div\u003e\n\u003c/div\u003e\u003cul\u003e\n\u003cli\u003e\u003ccode\u003ename\u003c/code\u003e：模型的名称，此为可选参数。\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"model-class-properties-and-methods\"\u003eModel Class Properties and Methods\u003c/h3\u003e\n\u003cp\u003e\u003ccode\u003eModel\u003c/code\u003e 类是 \u003ccode\u003eCOPT\u003c/code\u003e 的核心，代表了优化模型，包含了所有变量、约束和目标函数。\u003c/p\u003e\n\u003ch4 id=\"basic-properties\"\u003eBasic Properties\u003c/h4\u003e\n\u003cp\u003e在模型求解后，可以通过以下属性获取其基本信息：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003emodel.status\u003c/code\u003e：\u003cstrong\u003e模型解的状态\u003c/strong\u003e。此属性指示模型是否找到了最优解、无可行解等。例如，\u003ccode\u003eCOPT.OPTIMAL\u003c/code\u003e 表示已找到最优解。\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003emodel.objval\u003c/code\u003e：\u003cstrong\u003e目标函数值\u003c/strong\u003e。此属性存储模型的最优目标函数值。\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4 id=\"adding-variables\"\u003eAdding Variables\u003c/h4\u003e\n\u003cp\u003e可以通过 \u003ccode\u003eaddVar()\u003c/code\u003e 和 \u003ccode\u003eaddVars()\u003c/code\u003e 方法向模型中添加决策变量。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eAdding a Single Variable:\u003c/strong\u003e\u003c/p\u003e","title":"COPT 求解器学习笔记"},{"content":"File Allocation Table 要设计并实现一个文件系统，我们首先需要关注并解决存储媒介带来的两大核心挑战：\n读写放大 (Read/Write Amplification)：现代存储设备（无论是机械硬盘还是固态硬盘）的物理特性决定了，它们最高效的读写方式是操作连续的大块数据区域，我们称之为一个块 (Block)。如果需要修改一个块中哪怕一个字节的数据，也必须将整个块读入内存、修改、再完整写回。这种“操作少量数据却导致整块数据被读写”的现象就是读写放大，它会严重影响性能。\n局部性 (Locality)：程序的内存访问行为通常具有局部性原理 (Principle of Locality)，即在一段时间内，访问的地址会集中在某个区域。文件系统可以通过合理的数据排布，让物理上相邻的数据块在逻辑上也相关联（例如，属于同一个文件），从而在读取一块数据时，可以利用预读机制将后续可能被访问的数据也加载到内存缓存中，提高效率。\n在软盘上实现文件系统 我们的需求是为一个存储容量很小的设备（如软盘）设计一个文件系统。在这种场景下，使用复杂的树形数据结构（如 B+ 树）会因为元数据本身占用过多空间而显得浪费。因此，一个简单的链式结构是更合适的选择。\n目录的实现\n在简单的文件系统中，目录本身可以被实现为一个普通的文件。这个文件的特殊之处在于，它的内容遵循一种固定格式，即一个目录项数组。\n1 2 3 4 5 6 // 一个简单的目录项 (dentry) 结构 struct dentry { char filename[256]; // 文件名 unsigned int start_block; // 文件数据起始块的编号 unsigned int size; // 文件大小 (以字节为单位) }; 当我们需要打开一个目录时，文件系统只需读取这个文件的内容，并将其解析为一个 struct dentry 数组即可。\n文件数据的存储\n用链表来组织一个文件的所有数据块，主要有两种实现思路。\n方法一：在每个数据块后放置指针\n这种方法非常直观。每个数据块的末尾都留出一小块空间，用于存放下一个数据块的地址或编号。\n优点：实现简单，逻辑清晰。\n缺点：\n极差的随机访问性能：要访问文件的第 N 个数据块，必须从第一个块开始，依次读入前 N-1 个块来找到第 N 块的指针。这需要 N-1 次磁盘 I/O，对于大文件而言是毁灭性的。\n空间浪费：每个数据块都不能被 100% 用来存储文件内容，必须牺牲一部分空间给指针。\n方法二：将指针集中存放在文件系统的某个区域\n为了解决上述问题，我们可以将所有数据块的“链表指针”抽离出来，集中存放在一个被称为文件分配表 (File Allocation Table, FAT) 的核心数据结构中。\nFAT 本质上是一个大数组。数组的下标与磁盘上的数据块编号一一对应。数组中存储的值则是该文件链表中的下一个数据块的编号。\n它是如何工作的？\n一个文件的起始块号记录在它的目录项 (dentry) 中。\n假设文件从第 100 号块开始，我们查询 FAT[100]，如果值为 105，那么 105 号块就是文件的第二个数据块。\n接着我们查询 FAT[105]，得到下一个块号，如此往复，直到遇到一个特殊的文件结尾标记。\n优点：\n大幅改善的随机访问：虽然仍然需要遍历链表，但这个遍历过程发生在 FAT 表内部。因为 FAT 表相比整个磁盘要小得多，可以被完整加载到内存中缓存。要访问第 N 个数据块，只需要在内存中进行 N-1 次数组查询，这比 N-1 次磁盘 I/O 快了几个数量级。\n数据块纯净：数据块可以 100% 用于存储文件内容，没有元数据混入。\n写回策略：对文件结构的修改（如新增/删除数据块）可以先在内存中的 FAT 缓存上进行，然后利用延迟写回 (Write-back Caching) 机制，在稍后的某个时刻一次性将更新后的 FAT 表写回磁盘，合并了多次 I/O 操作，提升了性能。\nUnix 文件系统 FAT 文件系统虽然巧妙，但仍有其局限性，无法满足现代操作系统的复杂需求：\n支持链接：我们希望多个文件名可以指向同一个文件实体。\n支持高效的任意大小文件随机访问：对于非常大的文件，在 FAT 表中线性扫描仍然耗时。我们需要一种能实现 O(1) 或 O(logN) 复杂度查找的数据结构。\n为了解决这些问题，Unix 文件系统引入了一个核心概念：inode (索引节点)。\ninode 是一个独立于文件名的元数据结构，它存储了除文件名之外的、关于一个文件的所有信息，例如：\n文件模式（权限位） 所有者和用户组 ID 文件大小 时间戳（创建、修改、访问时间） 用于索引文件数据块的数据结构 inode 的引入将文件名和文件元数据彻底分离。目录项 (dentry) 的作用被简化为只维护 文件名 -\u0026gt; inode 编号 的映射关系。这天然地支持了硬链接 (Hard Link)：多个不同的目录项可以包含相同的 inode 编号，指向同一个文件实体。\n为了解决高效随机访问问题，ext2 文件系统的 inode 采用了一种非常经典的多级索引结构：\n1 2 3 4 5 6 7 8 // ext2 inode 结构示意 struct ext2_inode { // ... 其他元数据 ... unsigned int direct_blocks[12]; // 12个直接指针 unsigned int singly_indirect_block; // 1个一级间接指针 unsigned int doubly_indirect_block; // 1个二级间接指针 unsigned int triply_indirect_block; // 1个三级间接指针 }; 直接指针 (Direct Pointers)： inode 中直接包含 12 个指针，每个指针指向一个数据块。对于小文件（小于 12 个块），只需读取 inode 就可以获得所有数据块的位置，访问速度极快。\n一级间接指针 (Singly Indirect Pointer)： 如果文件大于 12 个块，文件系统会启用这个指针。它指向一个“指针块”，这个块里不存数据，而是存满了指向数据块的指针。假设一个块能存 1024 个指针，这一级就能多索引 1024 个数据块。\n二级/三级间接指针 (Doubly/Triply Indirect Pointers)： 以此类推，二级间接指针指向一个存储着一级间接指针块地址的块。这种树状的索引结构，仅需极少的几次磁盘读取（最多 4 次，inode -\u0026gt; 三级 -\u0026gt; 二级 -\u0026gt; 一级 -\u0026gt; 数据块），就能定位超大文件中任意一个数据块的位置，实现了真正高效的随机访问 (Random Access)。\n存储器上的数据结构 传统上，文件系统的所有逻辑都实现在操作系统的内核 (Kernel) 中，因为它需要直接管理硬件并保证系统安全与性能。\n然而，现代操作系统提供了一些机制，允许在用户空间 (User Space) 实现文件系统，最著名的就是 FUSE (Filesystem in Userspace)。\nFUSE 的工作原理是，内核提供一个通用的文件系统驱动，当有文件操作请求时，该驱动会将请求转发给一个在用户空间运行的守护进程。这个进程负责实现所有的文件系统逻辑（如何解析路径、读取数据等），然后将结果返回给内核。\n优点：开发、调试和测试变得极为方便，无需修改和重新编译内核。一个用户态文件系统的崩溃也不会影响整个系统的稳定性。这催生了大量创新的文件系统，如 sshfs（将远程服务器目录挂载到本地）、s3fs（将云存储挂载到本地）等。\n缺点：每次文件操作都需要在内核态和用户态之间进行上下文切换 (Context Switch)，带来了额外的性能开销，通常不适用于对性能要求极致的场景。\n","permalink":"https://diefish1024.github.io/posts/class-notes/nju-os-2025/23-%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%9A%84%E5%AE%9E%E7%8E%B0/","summary":"\u003ch2 id=\"file-allocation-table\"\u003eFile Allocation Table\u003c/h2\u003e\n\u003cp\u003e要设计并实现一个文件系统，我们首先需要关注并解决存储媒介带来的两大核心挑战：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e读写放大 (Read/Write Amplification)\u003c/strong\u003e：现代存储设备（无论是机械硬盘还是固态硬盘）的物理特性决定了，它们最高效的读写方式是操作连续的大块数据区域，我们称之为一个\u003cstrong\u003e块 (Block)\u003c/strong\u003e。如果需要修改一个块中哪怕一个字节的数据，也必须将整个块读入内存、修改、再完整写回。这种“操作少量数据却导致整块数据被读写”的现象就是读写放大，它会严重影响性能。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e局部性 (Locality)\u003c/strong\u003e：程序的内存访问行为通常具有\u003cstrong\u003e局部性原理 (Principle of Locality)\u003c/strong\u003e，即在一段时间内，访问的地址会集中在某个区域。文件系统可以通过合理的数据排布，让物理上相邻的数据块在逻辑上也相关联（例如，属于同一个文件），从而在读取一块数据时，可以利用预读机制将后续可能被访问的数据也加载到内存缓存中，提高效率。\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"在软盘上实现文件系统\"\u003e在软盘上实现文件系统\u003c/h3\u003e\n\u003cp\u003e我们的需求是为一个存储容量很小的设备（如软盘）设计一个文件系统。在这种场景下，使用复杂的树形数据结构（如 B+ 树）会因为元数据本身占用过多空间而显得浪费。因此，一个简单的链式结构是更合适的选择。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e目录的实现\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e在简单的文件系统中，目录本身可以被实现为一个普通的文件。这个文件的特殊之处在于，它的内容遵循一种固定格式，即一个目录项数组。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cdiv class=\"chroma\"\u003e\n\u003ctable class=\"lntable\"\u003e\u003ctr\u003e\u003ctd class=\"lntd\"\u003e\n\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode\u003e\u003cspan class=\"lnt\"\u003e1\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e2\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e3\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e4\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e5\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e6\n\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\n\u003ctd class=\"lntd\"\u003e\n\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-c\" data-lang=\"c\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e// 一个简单的目录项 (dentry) 结构\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"k\"\u003estruct\u003c/span\u003e \u003cspan class=\"n\"\u003edentry\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"kt\"\u003echar\u003c/span\u003e \u003cspan class=\"n\"\u003efilename\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"mi\"\u003e256\u003c/span\u003e\u003cspan class=\"p\"\u003e];\u003c/span\u003e        \u003cspan class=\"c1\"\u003e// 文件名\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"kt\"\u003eunsigned\u003c/span\u003e \u003cspan class=\"kt\"\u003eint\u003c/span\u003e \u003cspan class=\"n\"\u003estart_block\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e  \u003cspan class=\"c1\"\u003e// 文件数据起始块的编号\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"kt\"\u003eunsigned\u003c/span\u003e \u003cspan class=\"kt\"\u003eint\u003c/span\u003e \u003cspan class=\"n\"\u003esize\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e         \u003cspan class=\"c1\"\u003e// 文件大小 (以字节为单位)\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"p\"\u003e};\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\u003c/tr\u003e\u003c/table\u003e\n\u003c/div\u003e\n\u003c/div\u003e\u003cp\u003e当我们需要打开一个目录时，文件系统只需读取这个文件的内容，并将其解析为一个 \u003ccode\u003estruct dentry\u003c/code\u003e 数组即可。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e文件数据的存储\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e用链表来组织一个文件的所有数据块，主要有两种实现思路。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e方法一：在每个数据块后放置指针\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e这种方法非常直观。每个数据块的末尾都留出一小块空间，用于存放下一个数据块的地址或编号。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e优点\u003c/strong\u003e：实现简单，逻辑清晰。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e缺点\u003c/strong\u003e：\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e极差的随机访问性能\u003c/strong\u003e：要访问文件的第 N 个数据块，必须从第一个块开始，依次读入前 N-1 个块来找到第 N 块的指针。这需要 N-1 次磁盘 I/O，对于大文件而言是毁灭性的。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e空间浪费\u003c/strong\u003e：每个数据块都不能被 100% 用来存储文件内容，必须牺牲一部分空间给指针。\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e方法二：将指针集中存放在文件系统的某个区域\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e为了解决上述问题，我们可以将所有数据块的“链表指针”抽离出来，集中存放在一个被称为\u003cstrong\u003e文件分配表 (File Allocation Table, FAT)\u003c/strong\u003e 的核心数据结构中。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eFAT\u003c/strong\u003e 本质上是一个大数组。数组的\u003cstrong\u003e下标\u003c/strong\u003e与磁盘上的数据块编号一一对应。数组中存储的\u003cstrong\u003e值\u003c/strong\u003e则是该文件链表中的\u003cstrong\u003e下一个数据块的编号\u003c/strong\u003e。\u003c/p\u003e","title":"23. 文件系统的实现"},{"content":"1. Why Memory Performance Matters in HPC? 在 HPC 领域，我们常常关注 CPU 的浮点运算能力 (FLOPS)，但真正的性能瓶颈往往不在于计算本身，而在于数据访问。现代 CPU 的计算速度远超于内存的访问速度，这种差距被称为内存墙 (Memory Wall)。程序的大部分时间可能都消耗在等待数据从内存加载到 CPU 寄存器的过程中。因此，优化内存访问模式，最大限度地利用 Cache，是提升 C/C++ 程序性能至关重要的一环。\n2. Memory Alignment 内存对齐是指一个数据对象的内存地址是其自身大小或特定字节数（通常是 2 的幂）的整数倍。例如一个 4 字节的 int 类型变量，如果其内存地址是 4 的倍数（如 0x...00, 0x...04, 0x...08），那么它就是内存对齐的。\n2.2 Why is Alignment Important? CPU 并不是逐字节地从内存中读取数据，而是以块（通常是缓存行 (Cache Line)，例如 64 字节）为单位进行读取。\n性能提升：如果一个数据跨越了两个缓存行，CPU 就需要执行两次内存读取操作才能获取这一个数据，这会浪费一倍的时间。如果数据是对齐的，就可以保证它完整地落在一个缓存行内，CPU 只需一次读取操作。\n硬件要求：许多现代 CPU 指令集，尤其是用于并行计算的 SIMD 指令强制要求操作的数据必须是内存对齐的，对未对齐的数据执行这些指令可能会导致程序崩溃或性能急剧下降。\n2.3 How to Achieve Alignment in C/C++? C++11 alignas：这是 Modern C++ 的标准方式，可以指定变量或类型的对齐要求。 1 2 3 4 5 6 7 8 // 声明一个按 64 字节对齐的数组 alignas(64) float aligned_array[1024]; // 定义一个结构体，使其每个实例都按 32 字节对齐 struct alignas(32) MyData { float a; int b; }; GCC/Clang __attribute__((aligned(N)))：特定于编译器的扩展。 1 2 // 声明一个按 64 字节对齐的数组 float aligned_array[1024] __attribute__((aligned(64))); 动态内存对齐：标准的 malloc 不保证特定的对齐方式（通常只保证基本类型的对齐）。需要使用专用函数。 1 2 3 4 5 6 #include \u0026lt;stdlib.h\u0026gt; // C11 标准 // 分配 1024 个 float，并按 64 字节对齐 float* dynamic_array = (float*)aligned_alloc(64, 1024 * sizeof(float)); free(dynamic_array); // 必须用 free 释放 3. Data Locality 数据局部性是缓存工作的基本原理，也是性能优化的核心。描述了 CPU 访问内存地址的集中程度。\n3.1 Temporal and Spatial Locality 时间局部性 (Temporal Locality)：如果一个数据项被访问，那么在不久的将来它很可能再次被访问。\n空间局部性 (Spatial Locality)：如果一个数据项被访问，那么与它地址相近的数据项很可能在不久的将来被访问。\n当 CPU 访问一个内存地址时，它会将包含该地址的整个缓存行加载到缓存中。充分利用这两个局部性原则，可以极大地提高缓存命中率 (Cache Hit Rate)，减少访问主内存的次数。\n3.2 Optimizing Storage Layout 数据在内存中的布局方式直接影响空间局部性，尤其是在处理大量对象时。\nAoS (Array of Structures)：结构体数组。这是最直观的存储方式。 1 2 3 4 struct Point { float x, y, z; }; Point points[N]; 内存布局：[x0, y0, z0, x1, y1, z1, ...]\n在这种布局下当我们想要访问一个点的坐标时空间局部性较好；然后相对所有点的 x 坐标进行操作时，y 和 z 也会被一同加载到缓存中，污染了缓存，造成性能浪费。\nSoA (Structure of Arrays)：数组结构体。 1 2 3 4 5 6 struct Points { float x[N]; float y[N]; float z[N]; }; Points points; 内存布局：[x0, x1, ..., xN-1, y0, y1, ..., yN-1, ...]\n在这种布局下当我们需要对所有点的 x 坐标进行操作时，因为所有 x 的数据在内存中是连续的，空间局部性好，有利于 SIMD 向量化；然而当需要访问一个点的所有坐标时，需要三次内存访问，导致局部性较差。\n在 HPC 中，大量的计算通常是针对某一特定属性的，因此 SoA 布局往往能带来更好的性能，尤其是在需要向量化优化时。\n3.3 Optimizing Access Patterns 一旦数据在内存中完成布局，程序访问它的顺序就成为影响性能的下一个关键因素。以符合其存储顺序并最大化缓存利用率的方式访问数据，是挖掘数据局部性潜力的基础。\n遍历顺序 (Row-Major Order) C/C++ 中的多维数组默认是行主序 (Row-Major) 存储的。这意味着二维数组 A[M][N] 在内存中是按行连续存放的。\n内存布局: A[0][0], A[0][1], ..., A[0][N-1], A[1][0], ...\n为了保证最佳的空间局部性，内层循环应该遍历最右边的索引。\n高效的访问方式 (cache-firendly)： 1 2 3 4 5 for (int i = 0; i \u0026lt; M; i++) { for (int j = 0; j \u0026lt; N; j++) { A[i][j] = ...; // 访问模式与存储模式一致，顺序访问 } } 低效的访问方式 (cache-disaster)： 1 2 3 4 5 for (int j = 0; j \u0026lt; N; j++) { for (int i = 0; i \u0026lt; M; i++) { A[i][j] = ...; // 跨行跳跃访问，每次访问都可能导致缓存未命中 } } 循环分块 (Loop Tiling / Blocking)\n对于大型矩阵运算（如矩阵乘法），即使访问顺序正确，数据量太大也无法全部装入缓存。循环分块是一种将计算分解为适合缓存大小的子问题的方法，可以同时提升时间和空间局部性。\n未优化的矩阵乘法： 1 2 3 4 5 6 7 8 for (int i = 0; i \u0026lt; N; i++) { for (int j = 0; j \u0026lt; N; j++) { for (int k = 0; k \u0026lt; N; k++) { C[i][j] += A[i][k] * B[k][j]; } } } // B[k][j] 的访问是列访问，效率低下。 使用循环分块优化： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 int block_size = 16; // 块大小需根据缓存大小调整 for (int i0 = 0; i0 \u0026lt; N; i0 += block_size) { for (int j0 = 0; j0 \u0026lt; N; j0 += block_size) { for (int k0 = 0; k0 \u0026lt; N; k0 += block_size) { // 在缓存中计算一个子矩阵块 for (int i = i0; i \u0026lt; i0 + block_size; i++) { for (int j = j0; j \u0026lt; j0 + block_size; j++) { for (int k = k0; k \u0026lt; k0 + block_size; k++) { C[i][j] += A[i][k] * B[k][j]; } } } } } } 通过分块，程序可以把一小块数据加载到缓存中并充分复用，然后再处理下一块，大大提高了缓存命中率。\n4. False Sharing in Parallel Computing 在多核并行编程（如 OpenMP, pthreads）中，一个非常隐蔽的性能杀手是伪共享。\n原理：缓存不仅仅在 CPU 和主存之间工作，还在多个核心之间保持数据一致性 (Coherence)。当一个核心修改了其缓存中的数据，该缓存行会被标记为“dirty”，一致性协议会使其他核心中相同的缓存行失效。\n伪共享：如果两个核心上的线程频繁修改不同的变量，但这些变量碰巧位于同一个缓存行中，那么每次修改都会导致对方的缓存行失效并需要重新从主存加载。这种由不相关的变量共享同一个缓存行而导致的性能下降，就是伪共享。\n1 2 3 4 5 6 7 8 int results[NUM_THREADS]; // 假设 NUM_THREADS=2 #pragma omp parallel { int tid = omp_get_thread_num(); results[tid] = some_calculation(); } // 如果 results[0] 和 results[1] 在同一个缓存行， // 线程 0 修改 results[0] 会使线程 1 的缓存行失效，反之亦然。 解决方案：手动进行内存填充 (Padding)，确保每个线程操作的数据位于不同的缓存行。 1 2 3 4 5 struct PaddedResult { int value; char padding[64 - sizeof(int)]; // 假设缓存行大小为 64 字节 }; PaddedResult results[NUM_THREADS]; Summary 内存对齐是利用硬件特性的基础，确保单次操作的效率和 SIMD 的可行性。\n数据局部性是核心优化思想，通过优化存储布局 (AoS vs SoA) 和访问模式 (遍历顺序、循环分块) 来最大化缓存利用率。\n在并行环境中，必须警惕伪共享等陷阱，通过合理的内存布局避免多核间的性能干扰。\nReferences HPC 中的 C/C++ - HPC 入门指南 ","permalink":"https://diefish1024.github.io/posts/hpc/hpc-%E4%B8%AD%E7%9A%84-c-%E5%92%8C-c/","summary":"\u003ch2 id=\"1-why-memory-performance-matters-in-hpc\"\u003e1. Why Memory Performance Matters in HPC?\u003c/h2\u003e\n\u003cp\u003e在 HPC 领域，我们常常关注 CPU 的浮点运算能力 (FLOPS)，但真正的性能瓶颈往往不在于计算本身，而在于\u003cstrong\u003e数据访问\u003c/strong\u003e。现代 CPU 的计算速度远超于内存的访问速度，这种差距被称为\u003cstrong\u003e内存墙 (Memory Wall)\u003c/strong\u003e。程序的大部分时间可能都消耗在等待数据从内存加载到 CPU 寄存器的过程中。因此，优化内存访问模式，最大限度地利用 Cache，是提升 C/C++ 程序性能至关重要的一环。\u003c/p\u003e\n\u003ch2 id=\"2-memory-alignment\"\u003e2. Memory Alignment\u003c/h2\u003e\n\u003cp\u003e内存对齐是指一个数据对象的内存地址是其自身大小或特定字节数（通常是 2 的幂）的整数倍。例如一个 4 字节的 \u003ccode\u003eint\u003c/code\u003e 类型变量，如果其内存地址是 4 的倍数（如 \u003ccode\u003e0x...00\u003c/code\u003e, \u003ccode\u003e0x...04\u003c/code\u003e, \u003ccode\u003e0x...08\u003c/code\u003e），那么它就是内存对齐的。\u003c/p\u003e\n\u003ch3 id=\"22-why-is-alignment-important\"\u003e2.2 Why is Alignment Important?\u003c/h3\u003e\n\u003cp\u003eCPU 并不是逐字节地从内存中读取数据，而是以块（通常是\u003cstrong\u003e缓存行 (Cache Line)\u003c/strong\u003e，例如 64 字节）为单位进行读取。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e性能提升\u003c/strong\u003e：如果一个数据跨越了两个缓存行，CPU 就需要执行两次内存读取操作才能获取这一个数据，这会浪费一倍的时间。如果数据是对齐的，就可以保证它完整地落在一个缓存行内，CPU 只需一次读取操作。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e硬件要求\u003c/strong\u003e：许多现代 CPU 指令集，尤其是用于并行计算的 \u003cstrong\u003eSIMD\u003c/strong\u003e 指令强制要求操作的数据必须是内存对齐的，对未对齐的数据执行这些指令可能会导致程序崩溃或性能急剧下降。\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"23-how-to-achieve-alignment-in-cc\"\u003e2.3 How to Achieve Alignment in C/C++?\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eC++11 \u003ccode\u003ealignas\u003c/code\u003e\u003c/strong\u003e：这是 Modern C++ 的标准方式，可以指定变量或类型的对齐要求。\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cdiv class=\"chroma\"\u003e\n\u003ctable class=\"lntable\"\u003e\u003ctr\u003e\u003ctd class=\"lntd\"\u003e\n\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode\u003e\u003cspan class=\"lnt\"\u003e1\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e2\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e3\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e4\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e5\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e6\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e7\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e8\n\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\n\u003ctd class=\"lntd\"\u003e\n\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-c++\" data-lang=\"c++\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e// 声明一个按 64 字节对齐的数组\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"k\"\u003ealignas\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"mi\"\u003e64\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"kt\"\u003efloat\u003c/span\u003e \u003cspan class=\"n\"\u003ealigned_array\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"mi\"\u003e1024\u003c/span\u003e\u003cspan class=\"p\"\u003e];\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e// 定义一个结构体，使其每个实例都按 32 字节对齐\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"k\"\u003estruct\u003c/span\u003e \u003cspan class=\"nf\"\u003ealignas\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"mi\"\u003e32\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"n\"\u003eMyData\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"kt\"\u003efloat\u003c/span\u003e \u003cspan class=\"n\"\u003ea\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"kt\"\u003eint\u003c/span\u003e \u003cspan class=\"n\"\u003eb\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"p\"\u003e};\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\u003c/tr\u003e\u003c/table\u003e\n\u003c/div\u003e\n\u003c/div\u003e\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eGCC/Clang \u003ccode\u003e__attribute__((aligned(N)))\u003c/code\u003e\u003c/strong\u003e：特定于编译器的扩展。\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cdiv class=\"chroma\"\u003e\n\u003ctable class=\"lntable\"\u003e\u003ctr\u003e\u003ctd class=\"lntd\"\u003e\n\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode\u003e\u003cspan class=\"lnt\"\u003e1\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e2\n\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\n\u003ctd class=\"lntd\"\u003e\n\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-c\" data-lang=\"c\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e// 声明一个按 64 字节对齐的数组\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"kt\"\u003efloat\u003c/span\u003e \u003cspan class=\"n\"\u003ealigned_array\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"mi\"\u003e1024\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e \u003cspan class=\"nf\"\u003e__attribute__\u003c/span\u003e\u003cspan class=\"p\"\u003e((\u003c/span\u003e\u003cspan class=\"nf\"\u003ealigned\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"mi\"\u003e64\u003c/span\u003e\u003cspan class=\"p\"\u003e)));\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\u003c/tr\u003e\u003c/table\u003e\n\u003c/div\u003e\n\u003c/div\u003e\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e动态内存对齐\u003c/strong\u003e：标准的 \u003ccode\u003emalloc\u003c/code\u003e 不保证特定的对齐方式（通常只保证基本类型的对齐）。需要使用专用函数。\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cdiv class=\"chroma\"\u003e\n\u003ctable class=\"lntable\"\u003e\u003ctr\u003e\u003ctd class=\"lntd\"\u003e\n\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode\u003e\u003cspan class=\"lnt\"\u003e1\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e2\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e3\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e4\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e5\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e6\n\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\n\u003ctd class=\"lntd\"\u003e\n\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-c\" data-lang=\"c\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"cp\"\u003e#include\u003c/span\u003e \u003cspan class=\"cpf\"\u003e\u0026lt;stdlib.h\u0026gt;\u003c/span\u003e\u003cspan class=\"cp\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e// C11 标准\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e// 分配 1024 个 float，并按 64 字节对齐\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"kt\"\u003efloat\u003c/span\u003e\u003cspan class=\"o\"\u003e*\u003c/span\u003e \u003cspan class=\"n\"\u003edynamic_array\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"kt\"\u003efloat\u003c/span\u003e\u003cspan class=\"o\"\u003e*\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\u003cspan class=\"nf\"\u003ealigned_alloc\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"mi\"\u003e64\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"mi\"\u003e1024\u003c/span\u003e \u003cspan class=\"o\"\u003e*\u003c/span\u003e \u003cspan class=\"k\"\u003esizeof\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"kt\"\u003efloat\u003c/span\u003e\u003cspan class=\"p\"\u003e));\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"nf\"\u003efree\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003edynamic_array\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e \u003cspan class=\"c1\"\u003e// 必须用 free 释放\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\u003c/tr\u003e\u003c/table\u003e\n\u003c/div\u003e\n\u003c/div\u003e\u003ch2 id=\"3-data-locality\"\u003e3. Data Locality\u003c/h2\u003e\n\u003cp\u003e数据局部性是缓存工作的基本原理，也是性能优化的核心。描述了 CPU 访问内存地址的集中程度。\u003c/p\u003e","title":"HPC 中的 C 和 C++"},{"content":"Abstract 现有 TTA 方法在处理图数据时，对节点属性偏移有效，但是对图结构偏移（同质性、节点度的变化）效果很差。原因是结构偏移会严重破坏节点表示的质量，使不同类别的节点在特征空间中混在一起。为此论文提出了 Matcha 框架，通过在测试的时候自适应地调整 GNN 的“跳数聚合参数 (hop-aggregation parameters)”，并且引入了新的预测感知的聚类损失函数来表示恢复节点表示的质量，从而有效应对结构偏移，并能和现有 TTA 方法相结合，进一步提高性能。\nIntroduction GNN 的脆弱性：GNNs 在各类图任务上的表现依赖于训练数据和测试数据分布相同的假设，然而在现实世界中，图的分布常常会发生变化（分布偏移），分为：\n属性偏移 (Attribute Shift)：节点的特征发生变化。例如不同社交平台，即使用户一样，其账号的内容也会因为平台差异而不同。\n结构偏移 (Structure Shift)：节点的连接方式发生变化。比如工作平台用户倾向于连接同事，生活平台用户倾向于连接家人朋友。这种连接模式的变化就是结构偏移，具体表现为同质性 (Homophily) 和 节点度 (Degree) 的变化。\nTTA 的局限性：TTA 允许一个预训练好的模型在不访问原始训练数据的情况下，利用无标签的测试数据进行自适应调整 。目前 TTA 在计算机视觉领域处理图像损坏、风格变化等属性偏移问题上很成功 。然而为图像处理设计的 TTA 方法直接应用到图上时，其在处理图结构偏移时的性能提升非常有限，几乎失效。\nAnalysis 两种偏移方式对 GNN 的影响存在本质不同。\nPerliminaries 论文聚焦于 GTTA 任务。一个 GNN 模型可以被看成两个部分的组合，一个特征提取器 $ f_{S} $ ，一个分类器 $ g_{S} $ ，通常是一个线性层。\n两种偏移的正式定义：\n属性偏移：源图和目标图中，节点的条件概率分布不同 $ \\mathbb{P}^{S}_{x | y} \\neq \\mathbb{P}^{T}_{x | y} $ 。 结构偏移：图的邻接矩阵和标签的联合分布不同，即 $ \\mathbb{P}^{S}_{A \\times Y} \\neq \\mathbb{P}^{T}_{A \\times Y} $ 。论文主要关注两种具体的结构偏移： 度偏移：源图和目标图的平均节点度数不同。 同质性偏移：源图和目标图的同质性水平不同。其中图的所有节点同质性的平均值 $ h(\\mathcal{G}) = \\dfrac{1}{N}\\sum_{i}h_{i} $ ，单个节点 $ v_{i} $ 的同质性计算公式为： $$ h_{i} = \\dfrac{\\left| \\{ v_{j} \\in \\mathbb{N}(v_{i}): y_{j} = y_{i} \\} \\right|}{d_{i}} $$ 其中 $ y $ 表示节点标签，$ d $ 表示节点度数。 Impact of Distribution Shifts 通过数学建模来显示两种偏移的不同影响机制。\n分析工具\nCSBM (上下文随机块模型)：广泛用于 GNN 分析的随机图生成器。参数 $ \\mu_{+},\\mu_{-} $ 编码节点属性，而 $ d,h $ 参数编码图的结构。\n单层 GCN：为了简化分析，使用了一个单层的 GCN 模型，其节点表示 $ z_{i} $ 的计算公式为： $$ z_{i} = x_{i} + \\gamma \\cdot \\dfrac{1}{d_{i}} \\sum_{v_{j} \\in \\mathbb{N}(v_{i})}x_{j} $$ 其中 $ \\gamma $ 是一个关键的跳数聚合参数，控制节点自身特征和邻居平均特征的混合比例。\n推论 3.1\n在 CSBM 图上，一个节点的最终表示 $ z_{i} $ 服从一个正态分布，其均值取决于节点的真实类别、图的同质性 $ h_{i} $ 以及 $ \\gamma $ 参数，而方差取决于节点度数 $ d_{i} $ 和 $ \\gamma $ 参数 $$ z_{i} \\sim \\mathcal{N}\\left( (1 + \\gamma h_{i})\\mu_{+} + \\gamma(1-h_{i})\\mu_{-}, \\left( 1 + \\dfrac{\\gamma^{2}}{d_{i}} \\right)I \\right) $$\n推论 3.2\n基于 3.1 直接给出了模型预期准确率的公式 $$ \\text{Acc} = \\varPhi\\left( \\sqrt{ \\dfrac{d}{d+\\gamma^{2}} } \\cdot \\left| 1 + \\gamma(2h - 1) \\right| \\cdot \\| \\mu \\|_{2} \\right) $$ 根据这个公式，只需要输入图的度数，同质性和 $ \\gamma $ 参数就能直接计算出模型的理论最高准确率，从而让定量分析成为可能。\n准确率差距分解\n论文指出当模型性能下降时，可能的原因有两种：\n表示退化 $ \\Delta_{f} $：GNN 的特征提取器出现了问题，其生成的节点表示本身质量就很差，无法区分不同类型的节点。\n分类器偏移 $ \\Delta_{g} $：指特征提取器本身没有问题，但是分类器出现了问题。\n命题 3.3 (属性偏移的影响)\n理论证明，在属性偏移下，性能损失完全来自于分类器偏移 $ \\Delta_{g} $ ，而表示退化 $ \\Delta_{f} $ 为零 。 $$ \\Delta_{f} = 0, \\Delta_{g} = \\Theta (\\| \\Delta \\mu \\| _{2}^{2}) $$\n这解释了为什么现有的 TTA 方法（主要调整分类器）在处理属性偏移时有效 。\n命题 3.4 (结构偏移的影响)\n理论证明，在结构偏移下，情况恰恰相反 。性能损失完全来自于表示退化 $ \\Delta_{f} $，而分类器偏移 $ \\Delta_{g} $ 为零 。 $$ \\Delta_{f} = \\Theta(\\Delta h + \\Delta g),\\Delta_{g} = 0 $$\n这是论文的核心发现，揭示了现有 TTA 方法在结构偏移下失效的根本原因：它们没有修复问题的根源——已经退化了的节点表示 。\n命题 3.5 (调整跳聚数参数)\n既然结构偏移的病根在于表示退化，那么治疗方案就必须调整特征提取器 。\n论文证明调整跳数聚合参数 $ \\gamma $ 是一个有效的方法，可以缓解表示退化问题 。\n其关键在于，最优的 $ \\gamma $ 值本身就依赖于图的度和同质性 $ \\gamma_{T} = d_{T}(2h_{T} - 1) $。因此，通过在测试时将 $ \\gamma $ 调整到适应目标图的新值，就可以提升模型的准确率 。这为后续 Matcha 框架的提出提供了理论基础。\nAdapting Hop-Aggregation Parameters 根据前面的分析，解决结构偏移的影响关键在于调整特征提取器 $ f_{S} $ 来恢复节点表示的质量。\n命题 3.5 (调整 $ \\gamma $ 的有效性)\n论文进一步证明调整跳数聚合参数 $ \\gamma $ 是一个有效的方法。命题指出，最优的 $ \\gamma $ 依赖于图的度和同质性（即 $ \\gamma_{T}^{*} = d_{T}(2h_{T} - 1) $ ），当图从源图变为目标图时，最优的 $ \\gamma $ 也会改变。因此在测试时把 $ \\gamma $ 调整到目标图的最优值就可以显著缓解表示退化，提升模型准确率。\nProposed Framework 基于以上洞察，论文设计了 Matcha 框架，旨在解决两个挑战：1. 在没有标签的情况下，如何更新跳数聚合参数以应对结构偏移？ 2. 如何确保算法与现有的 TTA 算法兼容，以同时解决结构和属性偏移？\nPrediction-Informed Clustering Loss 传统的 TTA 方法主要采用熵（entropy）作为代理损失函数，但论文发现熵最小化在提升表示质量方面效果有限，因为它对 logits 的尺度敏感，容易导致平凡解。\n为了解决这个问题，论文提出了一种新颖的预测感知聚类损失 (Prediction-Informed Clustering, PIC) 损失，其核心思想是：一个好的节点表示应该使得同类节点在特征空间中紧密聚集，而不同类节点则相互远离。\n其计算过程如下：\n计算质心：利用模型当前的软预测结果 $ \\hat{Y} $ 作为“伪类别”信息，计算每个伪类别 $ c $ 的质心 $ \\mu_c $ 和所有节点的总质心 $ \\mu_* $。$$ \\mu_{c} = \\frac{\\sum_{i=1}^{N}\\hat{Y}_{i,c}z_{i}}{\\sum_{i=1}^{N}\\hat{Y}_{i,c}}, \\quad \\mu_{*} = \\frac{1}{N}\\sum_{i=1}^{N}z_{i} $$ 计算方差：计算类内方差 $ \\sigma_{intra}^2 $（希望它小）和类间方差 $ \\sigma_{inter}^2 $（希望它大）。$$ \\sigma_{intra}^{2} = \\sum_{i=1}^{N}\\sum_{c=1}^{C}\\hat{Y}_{i,c}||z_{i}-\\mu_{c}||_{2}^{2} $$ $$ \\sigma_{inter}^{2} = \\sum_{c=1}^{C}(\\sum_{i=1}^{N}\\hat{Y}_{i,c})||\\mu_{c}-\\mu_{*}||_{2}^{2} $$ PIC 损失函数：最终的 PIC 损失被定义为类内方差占总方差的比例。$$ \\mathcal{L}_{PIC} = \\frac{\\sigma_{intra}^{2}}{\\sigma_{intra}^{2} + \\sigma_{inter}^{2}} $$ 通过最小化这个损失，模型会调整 $ \\gamma $ 来优化节点表示 $ Z $，使得类内尽可能紧凑，类间尽可能分离。这种比率形式对表示的尺度不敏感，可以有效避免平凡解。 Integration of Generic TTA Methods Matcha 框架可以和任何现有的 TTA 方法（论文中称为 BaseTTA）无缝集成。\n应用通用 TTA：使用 BaseTTA（如 Tent, T3A）对当前模型进行调整，得到一个初步的软预测 $ \\hat{Y} $ 。这一步主要处理属性偏移。\n更新跳数聚合参数：将 $ \\hat{Y} $ 作为伪标签，计算 $ \\mathcal{L}_{PIC} $ 损失，并根据该损失的梯度只更新跳数聚合参数 $ \\gamma $ 。这一步专门应对结构偏移，以恢复表示质量。\n这个过程形成了一种协同效应：通过调整 $ \\gamma $ 得到的更好表示，为 BaseTTA 提供了更高质量的输入，使其能做出更准的预测；而更准的预测又为 $ \\mathcal{L}_{PIC} $ 提供了更可靠的伪标签，从而更好地指导 $ \\gamma $ 的更新。\nExperiments 论文在合成数据集（CSBM）和多个真实世界数据集（如 Syn-Cora, Syn-Products 等）上进行了广泛的实验，以验证 Matcha 的有效性。\nMatcha Handles Various Structure Shifts 主要结果：\n与不进行自适应的模型（ERM）相比，单独使用 Matcha（ERM+Matcha）可以显著提升模型性能，在真实世界数据集上最高提升 31.95%。 与其他基线方法相比，Matcha 在大多数情况下取得了最佳性能，最高超出 40.61%。 Matcha 与基线 TTA 方法结合时，能进一步提升它们的性能，最高可达 22.72%（合成数据）和 39.31%（真实数据）。这些结果有力地证明了 Matcha 的有效性。 Matcha Restores The Representation Quality 除了性能提升，论文还通过 t-SNE 可视化方法，验证了 Matcha 是否成功恢复了节点表示的质量。\n在结构偏移下（b），原始模型的节点表示变得混乱不堪。在使用其他损失函数（c, d, e）后，表示质量虽有改善但仍不理想。而使用 Matcha 的 PIC 损失后（f），节点表示重新形成了非常清晰的聚类结构，证明其成功恢复了表示质量。\nConclusion 本文的贡献可以总结为：\n理论分析：首次从理论上揭示了属性偏移和结构偏移对 GNN 有着截然不同的影响模式，解释了为何通用 TTA 方法在结构偏移下会失效。 提出框架：提出了一个即插即用的 TTA 框架 Matcha，通过一种新颖的预测感知聚类损失（PIC Loss） 来指导跳数聚合参数的自适应调整，从而恢复因结构偏移而退化的节点表示质量。 实验验证：在多种数据集和场景下的广泛实验，一致且显著地证明了 Matcha 框架的有效性、高效性和通用性。 ","permalink":"https://diefish1024.github.io/posts/literature-notes/matcha/","summary":"\u003ch2 id=\"abstract\"\u003eAbstract\u003c/h2\u003e\n\u003cp\u003e现有 TTA 方法在处理图数据时，对\u003cstrong\u003e节点属性偏移\u003c/strong\u003e有效，但是对\u003cstrong\u003e图结构偏移\u003c/strong\u003e（同质性、节点度的变化）效果很差。原因是\u003cstrong\u003e结构偏移会严重破坏节点表示的质量\u003c/strong\u003e，使不同类别的节点在特征空间中混在一起。为此论文提出了 Matcha 框架，通过在测试的时候\u003cstrong\u003e自适应地调整 GNN 的“跳数聚合参数 (hop-aggregation parameters)”\u003c/strong\u003e，并且引入了新的\u003cstrong\u003e预测感知的聚类损失函数\u003c/strong\u003e来表示恢复节点表示的质量，从而有效应对结构偏移，并能和现有 TTA 方法相结合，进一步提高性能。\u003c/p\u003e\n\u003ch2 id=\"introduction\"\u003eIntroduction\u003c/h2\u003e\n\u003cp\u003e\u003cstrong\u003eGNN 的脆弱性\u003c/strong\u003e：GNNs 在各类图任务上的表现依赖于训练数据和测试数据分布相同的假设，然而在现实世界中，图的分布常常会发生变化（分布偏移），分为：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e属性偏移 (Attribute Shift)\u003c/strong\u003e：节点的特征发生变化。例如不同社交平台，即使用户一样，其账号的内容也会因为平台差异而不同。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e结构偏移 (Structure Shift)\u003c/strong\u003e：节点的连接方式发生变化。比如工作平台用户倾向于连接同事，生活平台用户倾向于连接家人朋友。这种连接模式的变化就是结构偏移，具体表现为\u003cstrong\u003e同质性 (Homophily)\u003c/strong\u003e 和 \u003cstrong\u003e节点度 (Degree)\u003c/strong\u003e 的变化。\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003eTTA 的局限性\u003c/strong\u003e：TTA 允许一个预训练好的模型在不访问原始训练数据的情况下，利用无标签的测试数据进行自适应调整 。目前 TTA 在计算机视觉领域处理图像损坏、风格变化等属性偏移问题上很成功 。然而为图像处理设计的 TTA 方法直接应用到图上时，其在处理图结构偏移时的性能提升非常有限，几乎失效。\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"400\" loading=\"lazy\" src=\"/images/matcha/pasted-image-20250828111414.png\"\u003e\u003c/p\u003e\n\u003ch2 id=\"analysis\"\u003eAnalysis\u003c/h2\u003e\n\u003cp\u003e两种偏移方式对 GNN 的影响存在本质不同。\u003c/p\u003e\n\u003ch3 id=\"perliminaries\"\u003ePerliminaries\u003c/h3\u003e\n\u003cp\u003e论文聚焦于 GTTA 任务。一个 GNN 模型可以被看成两个部分的组合，一个\u003cstrong\u003e特征提取器 $ f_{S} $\u003c/strong\u003e ，一个\u003cstrong\u003e分类器 $ g_{S} $\u003c/strong\u003e ，通常是一个线性层。\u003c/p\u003e\n\u003cp\u003e两种偏移的正式定义：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e属性偏移\u003c/strong\u003e：源图和目标图中，节点的条件概率分布不同 $ \\mathbb{P}^{S}_{x | y} \\neq \\mathbb{P}^{T}_{x | y} $ 。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e结构偏移\u003c/strong\u003e：图的邻接矩阵和标签的联合分布不同，即 $ \\mathbb{P}^{S}_{A \\times Y} \\neq \\mathbb{P}^{T}_{A \\times Y} $ 。论文主要关注两种具体的结构偏移：\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e度偏移\u003c/strong\u003e：源图和目标图的平均节点度数不同。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e同质性偏移\u003c/strong\u003e：源图和目标图的同质性水平不同。其中图的所有节点同质性的平均值 $ h(\\mathcal{G}) = \\dfrac{1}{N}\\sum_{i}h_{i} $ ，单个节点 $ v_{i} $ 的同质性计算公式为： $$ \n h_{i} = \\dfrac{\\left| \\{ v_{j} \\in \\mathbb{N}(v_{i}): y_{j} = y_{i} \\} \\right|}{d_{i}}  \n $$ 其中 $ y $ 表示节点标签，$ d $ 表示节点度数。\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"impact-of-distribution-shifts\"\u003eImpact of Distribution Shifts\u003c/h3\u003e\n\u003cp\u003e通过数学建模来显示两种偏移的不同影响机制。\u003c/p\u003e","title":"Matcha"},{"content":"HPC 领域中，除了基于共享内存的 OpenMP, 还有一种更广泛应用于分布式内存系统的并行编程范式——消息传递接口 (MPI)。MPI 不依赖于共享内存，而是通过进程间的显式消息传递来实现数据交换和同步，从而能支持更大规模的集群计算，是构建大规模 HPC 集群不可或缺的工具。\n1. What is MPI? MPI (Message Passing Interface) 是一种用于分布式内存系统并行编程的标准化通信协议和库函数规范。它定义了一套可移植的函数接口，允许在并行计算环境中独立运行的进程之间进行消息传递，从而实现数据交换和协同工作。MPI 不指定如何启动进程，也不要求所有进程在同一台机器上，这使得它非常适合用于集群或多节点环境中的大规模并行计算。\n2. The MPI Programming Model 分布式内存模型\n在分布式内存模型中，各个处理节点可以独立运行自己的进程，使用自己的本地内存来存储和处理数据。每个进程的内存是私有的，其他进程无法直接访问它们。如果一个进程需要访问另一个进程的数据，就必须通过显式的消息传递机制将数据从一个进程发送到另一个进程。同一个节点（服务器）内部需要借助高速数据总线等硬件实现，而跨节点的通信通常由网络连接来实现，比如通过高速以太网、IB（InfiniBand）等。\n核心概念\n进程 (Process)：一个 MPI 程序由一个或多个独立的进程组成。这些进程通过调用 MPI 库函数来进行通信。\n通信子 (Communicator)：一个通信子（MPI_Comm）定义了一个可以互相通信的进程组。最常用的通信子是 MPI_COMM_WORLD，它包含了程序启动时的所有进程。\n秩 (Rank)：在同一个通信子内，每个进程都被赋予一个唯一的整数标识，称为秩。秩的范围是从 0 到 进程总数 - 1。\n消息传递 (Message Passing)：进程间通信的核心机制，分为两大类：\n点对点通信 (Point-to-Point)：在两个指定的进程之间进行。 集体通信 (Collective)：在一个通信子内的所有进程共同参与的通信。 通信协议：MPI 提供了多种通信协议，如阻塞通信（Blocking）、非阻塞通信（Non-blocking）、同步通信（Synchronous）等。\n3. Basic Functions and Concepts 一个基础的 MPI 程序总是包含初始化、执行并行代码和结束这几个部分。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 #include \u0026lt;mpi.h\u0026gt; #include \u0026lt;stdio.h\u0026gt; int main(int argc, char** argv) { // 1. 初始化 MPI 环境 MPI_Init(\u0026amp;argc, \u0026amp;argv); int world_size; int world_rank; char processor_name[MPI_MAX_PROCESSOR_NAME]; int name_len; // 2. 获取通信子信息 MPI_Comm_size(MPI_COMM_WORLD, \u0026amp;world_size); // 获取总进程数 MPI_Comm_rank(MPI_COMM_WORLD, \u0026amp;world_rank); // 获取当前进程的秩 // 获取处理器名称 (可选) MPI_Get_processor_name(processor_name, \u0026amp;name_len); // 3. 基于秩执行不同的代码 printf(\u0026#34;Hello world from processor %s, rank %d out of %d processors\\n\u0026#34;, processor_name, world_rank, world_size); // 4. 结束 MPI 环境 MPI_Finalize(); return 0; } MPI_Init()：初始化 MPI 执行环境，必须是第一个被调用的 MPI 函数。 MPI_Comm_size()：获取指定通信子（这里是 MPI_COMM_WORLD）中的总进程数。 MPI_Comm_rank()：获取当前进程在指定通信子中的秩。 MPI_Finalize()：清理并结束 MPI 环境，必须是最后一个被调用的 MPI 函数。 4. Point-to-Point Communication 点对点通信是 MPI 中最基本的通信模式，用于在一个进程向另一个进程发送数据。核心操作是 Send 和 Recv。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 #include \u0026lt;mpi.h\u0026gt; #include \u0026lt;stdio.h\u0026gt; int main(int argc, char** argv) { MPI_Init(\u0026amp;argc, \u0026amp;argv); int world_rank, world_size; MPI_Comm_rank(MPI_COMM_WORLD, \u0026amp;world_rank); MPI_Comm_size(MPI_COMM_WORLD, \u0026amp;world_size); if (world_size \u0026lt; 2) { if (world_rank == 0) printf(\u0026#34;This program requires at least 2 processes.\\n\u0026#34;); MPI_Finalize(); return 1; } int number; if (world_rank == 0) { // 进程 0 发送数据给进程 1 number = 42; MPI_Send(\u0026amp;number, 1, MPI_INT, 1, 0, MPI_COMM_WORLD); printf(\u0026#34;Process 0 sent number %d to process 1\\n\u0026#34;, number); } else if (world_rank == 1) { // 进程 1 接收来自进程 0 的数据 MPI_Recv(\u0026amp;number, 1, MPI_INT, 0, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE); printf(\u0026#34;Process 1 received number %d from process 0\\n\u0026#34;, number); } MPI_Finalize(); return 0; } MPI_Send(void* data, int count, MPI_Datatype datatype, int dest, int tag, MPI_Comm comm):\ndata：发送缓冲区指针。 count：发送的数据元素个数。 datatype：发送的数据类型 (如 MPI_INT, MPI_FLOAT)。 dest：目标进程的秩。 tag：消息标签，用于区分不同的消息。 comm：使用的通信子。 MPI_Recv(void* data, int count, MPI_Datatype datatype, int source, int tag, MPI_Comm comm, MPI_Status* status):\ndata：接收缓冲区指针。 source：源进程的秩。 status：返回消息的状态信息 (可填 MPI_STATUS_IGNORE 忽略)。 5. Collective Communication 集体通信是涉及一个通信子中所有进程的通信操作，常用于实现数据分发、结果收集和同步等复杂操作。\n广播 (MPI_Bcast)：将一个进程（根进程）的数据发送给通信子中的所有其他进程。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 #include \u0026lt;mpi.h\u0026gt; #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; int main(int argc, char** argv) { MPI_Init(\u0026amp;argc, \u0026amp;argv); int world_size; int world_rank; MPI_Comm_rank(MPI_COMM_WORLD, \u0026amp;world_rank); MPI_Comm_size(MPI_COMM_WORLD, \u0026amp;world_size); int* data = NULL; int data_size; if (world_rank == 0) { // 主进程初始化数据 data_size = 5; data = (int*)malloc(data_size * sizeof(int)); for (int i = 0; i \u0026lt; data_size; i++) data[i] = i + 1; printf(\u0026#34;进程 0 广播数据：\u0026#34;); for (int i = 0; i \u0026lt; data_size; i++) printf(\u0026#34;%d \u0026#34;, data[i]); printf(\u0026#34;\\n\u0026#34;); } MPI_Bcast(\u0026amp;data_size, 1, MPI_INT, 0, MPI_COMM_WORLD); // 分配缓冲区 if (world_rank != 0) { data = (int*)malloc(data_size * sizeof(int)); } MPI_Bcast(data, data_size, MPI_INT, 0, MPI_COMM_WORLD); printf(\u0026#34;进程 %d 接收到的数据：\u0026#34;, world_rank); for (int i = 0; i \u0026lt; data_size; i++) { printf(\u0026#34;%d \u0026#34;, data[i]); } printf(\u0026#34;\\n\u0026#34;); free(data); MPI_Finalize(); return 0; } 分发 (MPI_Scatter)：将根进程中的一个数组，切分成若干块，然后分发给通信子中的所有进程（包括根进程自己）。\n归约 (MPI_Reduce)：从所有进程中收集数据，并通过指定的操作（如求和、最大值）将它们合并到根进程的变量中。\n下面的例子通过 Scatter 和 Reduce 高效地并行计算了两个向量的点积：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 #include \u0026lt;mpi.h\u0026gt; #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; #include \u0026lt;math.h\u0026gt; #include \u0026lt;time.h\u0026gt; int main(int argc, char** argv) { MPI_Init(\u0026amp;argc, \u0026amp;argv); int rank, size; MPI_Comm_rank(MPI_COMM_WORLD, \u0026amp;rank); MPI_Comm_size(MPI_COMM_WORLD, \u0026amp;size); const int vector_size = 1000000; const int local_size = vector_size / size; float *full_A = NULL; float *full_B = NULL; if (rank == 0) { full_A = (float*)malloc(vector_size * sizeof(float)); full_B = (float*)malloc(vector_size * sizeof(float)); // 使用固定种子初始化完整向量（保证可重复性） srand(12345); for (int i = 0; i \u0026lt; vector_size; i++) { full_A[i] = (float)rand() / RAND_MAX; full_B[i] = (float)rand() / RAND_MAX; } } float *local_A = (float*)malloc(local_size * sizeof(float)); float *local_B = (float*)malloc(local_size * sizeof(float)); //============ 并行计算 ============ float global_dot = 0.0; MPI_Scatter(full_A, local_size, MPI_FLOAT, local_A, local_size, MPI_FLOAT, 0, MPI_COMM_WORLD); MPI_Scatter(full_B, local_size, MPI_FLOAT, local_B, local_size, MPI_FLOAT, 0, MPI_COMM_WORLD); float local_dot = 0.0; for (int i = 0; i \u0026lt; local_size; ++i) { local_dot += (double)local_A[i] * (double)local_B[i]; } MPI_Reduce(\u0026amp;local_dot, \u0026amp;global_dot, 1, MPI_FLOAT, MPI_SUM, 0, MPI_COMM_WORLD); //============串行计算============ if (rank == 0) { double serial_dot = 0.0; for (int i = 0; i \u0026lt; vector_size; i++) { serial_dot += (double)full_A[i] * (double)full_B[i]; } double abs_error = fabs(global_dot - serial_dot); printf(\u0026#34;并行点积：%.16f\\n\u0026#34;, global_dot); printf(\u0026#34;串行点积：%.16f\\n\u0026#34;, serial_dot); printf(\u0026#34;绝对误差：%.6e\\n\u0026#34;, abs_error); free(full_A); free(full_B); } free(local_A); free(local_B); MPI_Finalize(); return 0; } 6. Communication Modes MPI 提供了不同的通信模式，以应对不同的性能需求。\n阻塞通信 (Blocking)：MPI_Send 和 MPI_Recv 都是阻塞的。\nMPI_Send 会一直等待，直到发送缓冲区的数据可以被安全地重用（通常是数据已被拷贝到系统缓冲区或已发送到接收方）。 MPI_Recv 会一直等待，直到消息完全接收到接收缓冲区。 优点：编程简单，逻辑清晰。 缺点：可能导致进程长时间等待，造成性能瓶颈。 非阻塞通信 (Non-blocking)：MPI_Isend 和 MPI_Irecv 是非阻塞的。\n函数会立即返回，允许程序在通信进行的同时执行其他计算任务。 需要配合 MPI_Wait 或 MPI_Test 来检查通信是否完成。 优点：可以实现 计算和通信的重叠，是 MPI 性能优化的关键。 缺点：编程复杂度更高。 核心函数： MPI_Isend: 非阻塞发送。 MPI_Irecv: 非阻塞接收。 MPI_Wait: 等待一个非阻塞操作完成。 7. How to Compile and Run 通常 HPC 集群会预装 MPI 环境。在 Ubuntu/Debian 系统上，可以这样安装：\n1 sudo apt-get install openmpi-bin libopenmpi-dev 编译：使用 mpicc 编译器包装器，它会自动链接 MPI 库。 1 mpicc my_program.c -o my_program 运行：使用 mpirun 或 mpiexec 命令启动程序。-np 参数指定要启动的进程总数。 1 2 # 启动 4 个进程来运行程序 mpirun -np 4 ./my_program Summary MPI 是分布式内存并行编程的基石，它通过一套标准化的函数接口，实现了进程间的显式消息传递。其核心思想是将一个大任务分解给多个独立进程，通过 点对点通信 和 集体通信 协同工作。虽然编程模型比 OpenMP 更复杂，但它摆脱了单机内存的限制，能够扩展到数千个计算节点，是解决超大规模计算问题的首选工具。\nReferences MPI - HPC入门指南 Open MPI 入门笔记 | JinBridge ","permalink":"https://diefish1024.github.io/posts/hpc/mpi-%E5%85%A5%E9%97%A8/","summary":"\u003cp\u003eHPC 领域中，除了基于共享内存的 OpenMP, 还有一种更广泛应用于\u003cstrong\u003e分布式内存\u003c/strong\u003e系统的并行编程范式——\u003cstrong\u003e消息传递接口 (MPI)\u003c/strong\u003e。MPI 不依赖于共享内存，而是通过进程间的显式消息传递来实现数据交换和同步，从而能支持更大规模的集群计算，是构建大规模 HPC 集群不可或缺的工具。\u003c/p\u003e\n\u003ch2 id=\"1-what-is-mpi\"\u003e1. What is MPI?\u003c/h2\u003e\n\u003cp\u003eMPI (Message Passing Interface) 是一种用于\u003cstrong\u003e分布式内存\u003c/strong\u003e系统并行编程的标准化通信协议和库函数规范。它定义了一套可移植的函数接口，允许在并行计算环境中独立运行的进程之间进行\u003cstrong\u003e消息传递\u003c/strong\u003e，从而实现数据交换和协同工作。MPI 不指定如何启动进程，也不要求所有进程在同一台机器上，这使得它非常适合用于\u003cstrong\u003e集群或多节点环境\u003c/strong\u003e中的大规模并行计算。\u003c/p\u003e\n\u003ch2 id=\"2-the-mpi-programming-model\"\u003e2. The MPI Programming Model\u003c/h2\u003e\n\u003cp\u003e\u003cstrong\u003e分布式内存模型\u003c/strong\u003e\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e在分布式内存模型中，各个处理节点可以独立运行自己的进程，使用自己的本地内存来存储和处理数据。每个进程的内存是私有的，其他进程无法直接访问它们。如果一个进程需要访问另一个进程的数据，就必须通过显式的消息传递机制将数据从一个进程发送到另一个进程。同一个节点（服务器）内部需要借助高速数据总线等硬件实现，而跨节点的通信通常由网络连接来实现，比如通过高速以太网、IB（InfiniBand）等。\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e\u003cstrong\u003e核心概念\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e进程 (Process)\u003c/strong\u003e：一个 MPI 程序由一个或多个独立的进程组成。这些进程通过调用 MPI 库函数来进行通信。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e通信子 (Communicator)\u003c/strong\u003e：一个通信子（\u003ccode\u003eMPI_Comm\u003c/code\u003e）定义了一个可以互相通信的进程组。最常用的通信子是 \u003ccode\u003eMPI_COMM_WORLD\u003c/code\u003e，它包含了程序启动时的所有进程。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e秩 (Rank)\u003c/strong\u003e：在同一个通信子内，每个进程都被赋予一个唯一的整数标识，称为秩。秩的范围是从 \u003ccode\u003e0\u003c/code\u003e 到 \u003ccode\u003e进程总数 - 1\u003c/code\u003e。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e消息传递 (Message Passing)\u003c/strong\u003e：进程间通信的核心机制，分为两大类：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e点对点通信 (Point-to-Point)\u003c/strong\u003e：在两个指定的进程之间进行。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e集体通信 (Collective)\u003c/strong\u003e：在一个通信子内的所有进程共同参与的通信。\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e通信协议\u003c/strong\u003e：MPI 提供了多种通信协议，如阻塞通信（Blocking）、非阻塞通信（Non-blocking）、同步通信（Synchronous）等。\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"3-basic-functions-and-concepts\"\u003e3. Basic Functions and Concepts\u003c/h2\u003e\n\u003cp\u003e一个基础的 MPI 程序总是包含初始化、执行并行代码和结束这几个部分。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cdiv class=\"chroma\"\u003e\n\u003ctable class=\"lntable\"\u003e\u003ctr\u003e\u003ctd class=\"lntd\"\u003e\n\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode\u003e\u003cspan class=\"lnt\"\u003e 1\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 2\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 3\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 4\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 5\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 6\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 7\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 8\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 9\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e10\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e11\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e12\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e13\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e14\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e15\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e16\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e17\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e18\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e19\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e20\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e21\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e22\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e23\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e24\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e25\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e26\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e27\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e28\n\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\n\u003ctd class=\"lntd\"\u003e\n\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-c\" data-lang=\"c\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"cp\"\u003e#include\u003c/span\u003e \u003cspan class=\"cpf\"\u003e\u0026lt;mpi.h\u0026gt;\u003c/span\u003e\u003cspan class=\"cp\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"cp\"\u003e#include\u003c/span\u003e \u003cspan class=\"cpf\"\u003e\u0026lt;stdio.h\u0026gt;\u003c/span\u003e\u003cspan class=\"cp\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"kt\"\u003eint\u003c/span\u003e \u003cspan class=\"nf\"\u003emain\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"kt\"\u003eint\u003c/span\u003e \u003cspan class=\"n\"\u003eargc\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"kt\"\u003echar\u003c/span\u003e\u003cspan class=\"o\"\u003e**\u003c/span\u003e \u003cspan class=\"n\"\u003eargv\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"c1\"\u003e// 1. 初始化 MPI 环境\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"nf\"\u003eMPI_Init\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"o\"\u003e\u0026amp;\u003c/span\u003e\u003cspan class=\"n\"\u003eargc\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"o\"\u003e\u0026amp;\u003c/span\u003e\u003cspan class=\"n\"\u003eargv\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"kt\"\u003eint\u003c/span\u003e \u003cspan class=\"n\"\u003eworld_size\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"kt\"\u003eint\u003c/span\u003e \u003cspan class=\"n\"\u003eworld_rank\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"kt\"\u003echar\u003c/span\u003e \u003cspan class=\"n\"\u003eprocessor_name\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"n\"\u003eMPI_MAX_PROCESSOR_NAME\u003c/span\u003e\u003cspan class=\"p\"\u003e];\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"kt\"\u003eint\u003c/span\u003e \u003cspan class=\"n\"\u003ename_len\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"c1\"\u003e// 2. 获取通信子信息\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"nf\"\u003eMPI_Comm_size\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eMPI_COMM_WORLD\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"o\"\u003e\u0026amp;\u003c/span\u003e\u003cspan class=\"n\"\u003eworld_size\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e \u003cspan class=\"c1\"\u003e// 获取总进程数\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"nf\"\u003eMPI_Comm_rank\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eMPI_COMM_WORLD\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"o\"\u003e\u0026amp;\u003c/span\u003e\u003cspan class=\"n\"\u003eworld_rank\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e \u003cspan class=\"c1\"\u003e// 获取当前进程的秩\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"c1\"\u003e// 获取处理器名称 (可选)\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"nf\"\u003eMPI_Get_processor_name\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eprocessor_name\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"o\"\u003e\u0026amp;\u003c/span\u003e\u003cspan class=\"n\"\u003ename_len\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"c1\"\u003e// 3. 基于秩执行不同的代码\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"nf\"\u003eprintf\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;Hello world from processor %s, rank %d out of %d processors\u003c/span\u003e\u003cspan class=\"se\"\u003e\\n\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e           \u003cspan class=\"n\"\u003eprocessor_name\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eworld_rank\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eworld_size\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"c1\"\u003e// 4. 结束 MPI 环境\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"nf\"\u003eMPI_Finalize\u003c/span\u003e\u003cspan class=\"p\"\u003e();\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"mi\"\u003e0\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\u003c/tr\u003e\u003c/table\u003e\n\u003c/div\u003e\n\u003c/div\u003e\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e\u003ccode\u003eMPI_Init()\u003c/code\u003e\u003c/strong\u003e：初始化 MPI 执行环境，必须是第一个被调用的 MPI 函数。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e\u003ccode\u003eMPI_Comm_size()\u003c/code\u003e\u003c/strong\u003e：获取指定通信子（这里是 \u003ccode\u003eMPI_COMM_WORLD\u003c/code\u003e）中的总进程数。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e\u003ccode\u003eMPI_Comm_rank()\u003c/code\u003e\u003c/strong\u003e：获取当前进程在指定通信子中的秩。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e\u003ccode\u003eMPI_Finalize()\u003c/code\u003e\u003c/strong\u003e：清理并结束 MPI 环境，必须是最后一个被调用的 MPI 函数。\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"4-point-to-point-communication\"\u003e4. Point-to-Point Communication\u003c/h2\u003e\n\u003cp\u003e点对点通信是 MPI 中最基本的通信模式，用于在一个进程向另一个进程发送数据。核心操作是 \u003ccode\u003eSend\u003c/code\u003e 和 \u003ccode\u003eRecv\u003c/code\u003e。\u003c/p\u003e","title":"MPI 入门"},{"content":"由于高性能计算场景下的并行编程任务的特性，OpenMP 可以通过简单受限的语法极大地化简了并行编程的复杂性，在普通的串行代码中添加一些指令就能够实现高效并行化。\n1. What is OpenMP? OpenMP (Open Multi-Processing) 是一种用于共享内存多处理器系统并行编程的 API。它通过在 C, C++, 或 Fortran 代码中添加 #pragma 的方式，让开发者可以轻松地将串行代码并行化，而无需手动管理复杂的线程创建、同步和销毁过程。\n2. The OpenMP Programming Model 共享内存模型：所有线程在同一个地址空间中共享数据。这意味着不同线程可以访问相同的内存位置，并且可以共享变量的值。\n共享变量：在并行区域中，默认情况下，大多数变量是共享的，即所有线程都可以访问和修改这些变量的值。\n私有变量：某些情况下，我们可能希望每个线程拥有变量的私有副本，这样不同线程之间不会相互干扰。OpenMP 通过 private 指令指定这些变量。\n数据竞争（Race Condition）：由于多个线程同时访问和修改共享变量，可能会导致数据竞争问题。为了避免这种情况，OpenMP 提供了同步机制，如 critical 和 atomic 等。\n并行区域（Parallel Region）：是 OpenMP 编程的核心概念。它是由编译器指令 #pragma omp parallel 指定的一段代码，告诉 OpenMP 在这段代码中创建多个线程并行执行。\nFork-Join 执行模型：从单线程开始执行，进入并行区域开始并行执行，在并行区域结尾进行同步和结束线程。\n3. Core Directives and Constructs OpenMP 的功能主要是通过编译指令（Directives）和相关的子句（Clauses）来实现的。\nparallel：用于创建一个并行区域。 1 2 3 4 5 #pragma omp parallel { // 这部分代码将由多个线程同时执行 printf(\u0026#34;Hello from thread %d\\n\u0026#34;, omp_get_thread_num()); } for：用于并行化 for 循环，必须与 parallel 结合使用。它会自动将循环迭代分配给不同的线程，这是 OpenMP 最常用、最高效的指令之一。 1 2 3 4 #pragma omp parallel for for (int i = 0; i \u0026lt; n; i++) { // 循环的 n 次迭代会被分配给不同线程 } sections：用于将不同的、独立的任务代码块分配给不同线程。适用于任务并行而不是数据并行。 1 2 3 4 5 6 7 #pragma omp parallel sections { #pragma omp section { /* task A */ } #pragma omp section { /* task B */ } } 4. Data Scoping 数据作用域定义了并行区域中变量如何被线程共享或者私有，OpenMP 通过子句 clauses 来控制变量属性。\nshared(list)：变量在所有线程间共享同一份内存，这是大多数变量的默认设置。读写共享变量通常需要同步。 1 2 3 4 5 int a; #pragma omp parallel for shared(a) for (int i = 0; i \u0026lt; n; i++) { // a为公有变量 } private(list)：每个线程在并行区域中有自己独立的变量副本，线程之间相互独立，互不干扰。并行区域内申明的变量默认为私有的，并行区域外申明的变量需要显式申明 private。 firstprivate(list)：是 private 的一种特殊情况。私有副本会用主线程中原始变量的值进行 初始化。 lastprivate(list)：是 private 的另一种特殊情况。当并行结束后，循环中最后一次迭代（或 sections 中最后一个 section）的线程会将其私有副本的值拷贝回主线程的原始变量。 1 2 3 4 5 6 int a; #pragma omp parallel for private(a) for (int i = 0; i \u0026lt; n; i++) { int b; //a,b均为私有变量 } reduction(operator:list)：用于解决并行计算中的归约操作（如求和、求积）。每个线程会计算一个局部结果，并行区结束后，所有局部结果会通过指定的操作符 (+, *, - 等) 合并到主线程的全局变量中，从而避免了竞争。 （规约的运算符规则） 1 2 3 4 5 int sum = 0; #pragma omp parallel for reduction(+:sum) for (int i = 0; i \u0026lt; 10; i++) { sum += i; } 5. Loop Scheduling 当使用 omp for 时，OpenMP 需要决定如何将循环的迭代次数分配给线程。这通过 schedule 子句控制，其选择会影响负载均衡 (Load Balancing) 和开销 (Overhead)。\nschedule(static, [chunk_size])：静态调度。在编译时就将迭代平均分配好。开销最小，适用于每次迭代计算量都相等的循环。 1 2 3 4 #pragma omp parallel for schedule(static, 3) for (int i = 0; i \u0026lt; n; i++) { // 每个线程执行3个连续的迭代 } schedule(dynamic, [chunk_size])：动态调度。线程每次完成一个（或 chunk_size 个）迭代后，动态地去任务队列领取新的任务。开销较大，但适用于每次迭代计算量不均匀的场景。\nschedule(guided, [chunk_size])：引导式调度。动态调度的一种优化。开始时分配大块任务，随着任务剩余量减少，分配的任务块也越来越小。是 static 和 dynamic 的一种折中。\nauto：自动调度将调度策略的选择权交给编译器或运行时库，由它们决定最佳的调度方式。\nschedule(runtime)：由环境变量 OMP_SCHEDULE 决定使用哪种调度策略，增加了灵活性。\n6. Synchronization Control 同步是用来协调线程间的执行顺序和保证对共享数据访问的正确性。\ncritical：定义一个临界区，同一时间只允许一个线程进入该代码块，开销较大。\natomic：针对单条内存更新语句（如 x++, x = x + 1）提供原子操作。比 critical 更轻量，是保护简单更新的首选。\nbarrier：一个同步点。所有线程必须执行到 barrier 处才会继续向下执行，没有任何线程可以提前。在并行区域末尾会有一个隐式的 barrier。\nmaster：指定一块代码只由主线程执行。\nsingle：指定一块代码只由线程组中第一个到达的线程执行。\n7. Environment Variables OpenMP 允许通过环境变量在运行时控制并行行为，而无需重新编译代码。\nOMP_NUM_THREADS：设置并行区默认使用的线程数，这是最常用的环境变量。\nOMP_SCHEDULE：当代码中使用 schedule(runtime) 时，该变量用于设定循环调度策略和块大小，例如：\u0026quot;dynamic,4\u0026quot;。\nOMP_PROC_BIND：控制线程与处理器核心的亲和性（绑定关系），对性能优化非常重要。\n8. How to Compile and Run 编译 C/C++ 代码时，需要添加一个特定的编译器标志来启用 OpenMP 支持。\nGCC / G++： 1 g++ -fopenmp my_program.cpp -o my_program Reference HPC 入门指南 OpenMP 入门笔记 | JinBridge ","permalink":"https://diefish1024.github.io/posts/hpc/openmp-%E5%85%A5%E9%97%A8/","summary":"\u003cp\u003e由于高性能计算场景下的并行编程任务的特性，OpenMP 可以通过简单受限的语法极大地化简了并行编程的复杂性，在普通的串行代码中添加一些指令就能够实现高效并行化。\u003c/p\u003e\n\u003ch2 id=\"1-what-is-openmp\"\u003e1. What is OpenMP?\u003c/h2\u003e\n\u003cp\u003eOpenMP (Open Multi-Processing) 是一种用于\u003cstrong\u003e共享内存\u003c/strong\u003e多处理器系统并行编程的 API。它通过在 C, C++, 或 Fortran 代码中添加 \u003ccode\u003e#pragma\u003c/code\u003e 的方式，让开发者可以轻松地将串行代码并行化，而无需手动管理复杂的线程创建、同步和销毁过程。\u003c/p\u003e\n\u003ch2 id=\"2-the-openmp-programming-model\"\u003e2. The OpenMP Programming Model\u003c/h2\u003e\n\u003cp\u003e\u003cstrong\u003e共享内存模型\u003c/strong\u003e：所有线程在同一个地址空间中共享数据。这意味着不同线程可以访问相同的内存位置，并且可以共享变量的值。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e共享变量\u003c/strong\u003e：在并行区域中，默认情况下，大多数变量是共享的，即所有线程都可以访问和修改这些变量的值。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e私有变量\u003c/strong\u003e：某些情况下，我们可能希望每个线程拥有变量的私有副本，这样不同线程之间不会相互干扰。OpenMP 通过 \u003ccode\u003eprivate\u003c/code\u003e 指令指定这些变量。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e数据竞争（Race Condition）\u003c/strong\u003e：由于多个线程同时访问和修改共享变量，可能会导致数据竞争问题。为了避免这种情况，OpenMP 提供了同步机制，如 \u003ccode\u003ecritical\u003c/code\u003e 和 \u003ccode\u003eatomic\u003c/code\u003e 等。\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e并行区域（Parallel Region）\u003c/strong\u003e：是 OpenMP 编程的核心概念。它是由编译器指令 \u003ccode\u003e#pragma omp parallel\u003c/code\u003e 指定的一段代码，告诉 OpenMP 在这段代码中创建多个线程并行执行。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eFork-Join 执行模型\u003c/strong\u003e：从单线程开始执行，进入并行区域开始并行执行，在并行区域结尾进行同步和结束线程。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/images/openmp-%E5%85%A5%E9%97%A8/pasted-image-20250827105206.png\"\u003e\u003c/p\u003e\n\u003ch2 id=\"3-core-directives-and-constructs\"\u003e3. Core Directives and Constructs\u003c/h2\u003e\n\u003cp\u003eOpenMP 的功能主要是通过编译指令（Directives）和相关的子句（Clauses）来实现的。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e\u003ccode\u003eparallel\u003c/code\u003e\u003c/strong\u003e：用于创建一个并行区域。\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cdiv class=\"chroma\"\u003e\n\u003ctable class=\"lntable\"\u003e\u003ctr\u003e\u003ctd class=\"lntd\"\u003e\n\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode\u003e\u003cspan class=\"lnt\"\u003e1\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e2\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e3\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e4\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e5\n\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\n\u003ctd class=\"lntd\"\u003e\n\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-c\" data-lang=\"c\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"cp\"\u003e#pragma omp parallel\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"p\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"c1\"\u003e// 这部分代码将由多个线程同时执行\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"nf\"\u003eprintf\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;Hello from thread %d\u003c/span\u003e\u003cspan class=\"se\"\u003e\\n\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"nf\"\u003eomp_get_thread_num\u003c/span\u003e\u003cspan class=\"p\"\u003e());\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\u003c/tr\u003e\u003c/table\u003e\n\u003c/div\u003e\n\u003c/div\u003e\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e\u003ccode\u003efor\u003c/code\u003e\u003c/strong\u003e：用于并行化 \u003ccode\u003efor\u003c/code\u003e 循环，必须与 \u003ccode\u003eparallel\u003c/code\u003e 结合使用。它会自动将循环迭代分配给不同的线程，这是 OpenMP 最常用、最高效的指令之一。\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cdiv class=\"chroma\"\u003e\n\u003ctable class=\"lntable\"\u003e\u003ctr\u003e\u003ctd class=\"lntd\"\u003e\n\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode\u003e\u003cspan class=\"lnt\"\u003e1\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e2\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e3\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e4\n\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\n\u003ctd class=\"lntd\"\u003e\n\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-c\" data-lang=\"c\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"cp\"\u003e#pragma omp parallel for\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"k\"\u003efor\u003c/span\u003e \u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"kt\"\u003eint\u003c/span\u003e \u003cspan class=\"n\"\u003ei\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"mi\"\u003e0\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e \u003cspan class=\"n\"\u003ei\u003c/span\u003e \u003cspan class=\"o\"\u003e\u0026lt;\u003c/span\u003e \u003cspan class=\"n\"\u003en\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e \u003cspan class=\"n\"\u003ei\u003c/span\u003e\u003cspan class=\"o\"\u003e++\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"c1\"\u003e// 循环的 n 次迭代会被分配给不同线程\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\u003c/tr\u003e\u003c/table\u003e\n\u003c/div\u003e\n\u003c/div\u003e\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e\u003ccode\u003esections\u003c/code\u003e\u003c/strong\u003e：用于将不同的、独立的任务代码块分配给不同线程。适用于任务并行而不是数据并行。\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cdiv class=\"chroma\"\u003e\n\u003ctable class=\"lntable\"\u003e\u003ctr\u003e\u003ctd class=\"lntd\"\u003e\n\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode\u003e\u003cspan class=\"lnt\"\u003e1\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e2\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e3\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e4\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e5\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e6\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e7\n\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\n\u003ctd class=\"lntd\"\u003e\n\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-c\" data-lang=\"c\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"cp\"\u003e#pragma omp parallel sections\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"p\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"cp\"\u003e#pragma omp section\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"p\"\u003e{\u003c/span\u003e \u003cspan class=\"cm\"\u003e/* task A */\u003c/span\u003e \u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"cp\"\u003e#pragma omp section\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"p\"\u003e{\u003c/span\u003e \u003cspan class=\"cm\"\u003e/* task B */\u003c/span\u003e \u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\u003c/tr\u003e\u003c/table\u003e\n\u003c/div\u003e\n\u003c/div\u003e\u003ch2 id=\"4-data-scoping\"\u003e4. Data Scoping\u003c/h2\u003e\n\u003cp\u003e数据作用域定义了并行区域中变量如何被线程共享或者私有，OpenMP 通过子句 clauses 来控制变量属性。\u003c/p\u003e","title":"OpenMP 入门"},{"content":"目录树 文件的抽象 操作系统将物理存储设备（如磁盘）的复杂性隐藏起来，提供了一个简单、统一的抽象——文件\n文件可以看作是一个虚拟的磁盘，即一个命名的、一维的字节序列，支持 read, write, lseek 等操作\n这种抽象使得上层应用无需关心数据在物理磁盘上的具体位置和存储方式\n目录的引入 当文件数量增多时，需要一种方式来组织和管理它们\n操作系统引入了目录 (Directory) 的概念，它是一种特殊的文件，其内容是其他文件或目录的列表\n通过将文件和目录组织成一个层次化的树状结构，即目录树，可以方便地对文件进行分类、查找和管理\n多数类 Unix 系统遵循 FHS (Filesystem Hierarchy Standard) 的目录结构约定，为软件和用户预测文件位置提供了便利\n目录操作 API 操作系统提供了一系列系统调用来操作目录树，核心操作围绕“增删改查”\nmkdir: 创建一个新的目录 rmdir: 删除一个空的目录 getdents: 读取目录中的条目 (directory entries) link / unlink: 创建或删除文件的链接 链接 链接是文件系统的一个重要特性，它允许一个文件拥有多个名字或存在于目录树的多个位置\n链接主要分为两种类型：硬链接和软链接（符号链接）\n硬链接 Hard Link 定义：硬链接是让多个目录条目（文件名）直接指向磁盘上同一个文件索引节点 (inode)\n每个文件在文件系统中都有一个唯一的 inode，它包含了文件的元数据（如权限、大小、数据块位置等）和数据本身\n创建一个硬链接，相当于为同一个 inode 增加了一个新的入口点（文件名）\n特性：\n所有指向同一个 inode 的硬链接地位平等，没有主次之分 inode 内部维护一个链接计数 (reference count), 只有当这个计数减到 0 时，文件系统才会真正删除该 inode 和对应的数据块，这也是 unlink 系统调用的由来 限制：\n不能为目录创建硬链接，以防止在目录树中产生循环 不能跨越不同的文件系统（因为 inode 号只在当前文件系统内唯一） 软链接 Symbolic Link 定义：软链接，也称符号链接 (symlink)，是一个特殊的文件，它的内容是另一个文件或目录的路径\n软链接本身拥有自己独立的 inode 和数据块，其数据块中存储的是一个文本字符串，即目标对象的路径名，当访问软链接时，操作系统会解析其内容，并将访问请求重定向到它所指向的路径\n特性：\n极其灵活，因为它本质上只是一个路径的“快捷方式” 可以链接到目录 可以跨越不同的文件系统 可以创建一个“悬空”的链接 (dangling link)，即它指向的目标路径当前并不存在 删除软链接本身，对它指向的原始文件没有任何影响 应用:\n常用于管理软件版本，例如让一个通用的命令（如 python）指向一个具体的版本文件（如 /usr/bin/python3.9） 被 NixOS 等系统用来构建高度可复现和隔离的环境，通过大量使用软链接将不同版本的软件包组合成一个虚拟的文件系统结构 文件的元数据 基本元数据 文件作为操作系统中的对象，拥有一系列的属性 (attributes)，这些属性就是元数据 (metadata), 你可以通过 ls -l 命令查看文件的主要元数据，这包括文件的类型、所有者、大小、修改时间等关键信息\n其中，模式 (Mode) 字段定义了文件的访问权限，它分为三组，分别对应所有者 (owner)、所属组 (group) 和其他用户 (other)，每组都包含读 (r)、写 (w)、执行 (x) 三种权限\n一个常见的权限例子是 755，这是一个八进制数，常用于程序或目录\n第一个 7 代表所有者权限, 7=4+2+1, 意味着读、写、执行 (rwx) 权限全开 第二个 5 代表所属组权限, 5=4+0+1, 意味着读、执行 (r-x) 权限 第三个 5 代表其他用户权限, 5=4+0+1, 同样是读、执行 (r-x) 权限 Extended Attributes (xattr) 扩展属性 xattr 是现代文件系统提供的一项强大功能，它允许为文件附加一个灵活的 key-value 键值对字典，用于存储标准元数据无法覆盖的任意信息，操作系统提供了 fsetxattr 和 fgetxattr 等系统调用来操作这些属性\n应用：\nmacOS 的安全隔离机制就是一个典型例子，当从网络下载文件后，系统会自动添加 com.apple.quarantine 属性，记录下载来源（URL）和时间，首次打开时，系统会检查此属性并向用户发出安全警告\n文件内容元信息: 应用程序可以利用 xattr 存储与文件内容相关的元信息，例如，图片浏览器可以存储照片的 EXIF 数据副本，或者音乐播放器可以存储歌曲的演唱者和专辑信息，便于管理和搜索；相比于文件目录只能按照文件标题索引，这种以内容作为索引才是现代文件系统更合理的做法\n缺陷：虽然 xattr 功能强大，但它“好用不火”的原因在于其固有的缺陷\n缺乏标准化与兼容性: xattr 的键名没有统一标准，不同应用和系统间随意定义，导致数据难以互通，例如，com.apple.quarantine 属性在 Linux 或 Windows 上没有意义 工具支持不完善: 许多经典的命令行工具，如 cp, mv, tar, rsync 等，默认不会处理扩展属性，在执行文件复制或打包时，这些重要的元数据可能会被静默丢弃，用户必须显式使用特定参数（如 cp --preserve=xattr, rsync -X）才能保留它们，这对依赖 xattr 的系统（如使用了 SELinux）可能是灾难性的 可见性低: 扩展属性对于普通用户是不可见的，ls -l 命令并不会显示它们，需要使用 getfattr 或 xattr -l 等专用工具才能查看，这使得问题排查变得更加困难 Access Control List (ACL) 传统的 user/group/other 权限模型在处理复杂的共享需求时显得力不从心，例如需要让用户 bob 访问 alice 的一个文件，但 bob 不在 alice 的用户组里，而又不想把文件权限开放给所有“其他用户”，ACL 就是为了解决这类问题而生的\nACL 提供了比传统模型更精细、更灵活的访问控制机制，它允许你为任意指定的用户或用户组设置独立的权限\n文件系统级 API 与针对单个文件或目录的操作不同，文件系统还提供了一系列“系统级”的 API，用于管理整个文件系统的结构和行为\n挂载 Mount 在类 Unix 系统中，所有的文件和目录都组织在一棵以根目录 / 为起点的巨大目录树下，而在 Windows 中，文件系统则分散在不同的“盘符”下（C:、D: 等）\n挂载 (mount) 是构建这棵统一目录树的核心机制, 它的作用是将一个文件系统（通常来自一个独立的存储设备，如硬盘分区、U 盘或光盘）“附加”到现有目录树的一个挂载点 (mount point) 上, 挂载点是一个已存在的空目录\n例如，命令 mount /dev/sdb1 /mnt/data 就将 /dev/sdb1 这个分区上的文件系统挂载到了 /mnt/data 目录, 此后，对 /mnt/data 目录内容的访问，实际上就是对 /dev/sdb1 分区根目录的访问, 整个 Linux 系统的根目录 / 本身也是在系统启动时挂载的第一个文件系统\n回环设备 Loopback Device mount 命令通常操作的是块设备 (block device)，但有时我们需要挂载一个存在于文件中的文件系统镜像（例如一个 .iso 光盘镜像文件）, 文件不是块设备，所以无法直接挂载\n为了解决这个问题，Linux 提供了回环设备 (loopback device), 这是一个虚拟的块设备，它不对应任何物理硬件，而是将一个普通文件作为其后端存储\n它的工作流程可以想象成一个适配器：\n将文件镜像与一个回环设备（如 /dev/loop0）关联起来, 这时，操作系统看待 /dev/loop0 就像看待一个真实的物理磁盘一样 对这个回环设备执行 mount 操作，将其挂载到指定目录 这个过程的底层是通过 ioctl 系统调用实现的，它向 loop 驱动发送 LOOP_SET_FD 等命令，将文件描述符与一个空闲的 loop 设备进行绑定\n联合文件系统 OverlayFS OverlayFS 是一种强大的联合文件系统 (UnionFS)，它允许将多个不同的目录（称为层）“堆叠”起来，对外提供一个统一的、合并后的视图\n我们可以用一个非常形象的比喻来理解它的工作原理：\n底层 (lowerdir): 想象一张已经印刷好的、不可修改的原始画稿, 这就是只读的底层, 它可以有很多张，层层叠放 上层 (upperdir)：在原始画稿上覆盖一张透明的塑料薄膜, 这就是可写的上层 合并视图 (merged view)：你透过这张透明薄膜看到的最终景象，就是 OverlayFS 呈现给你的目录 基于这个模型，所有操作都变得非常直观：\n读取文件: 当你读取一个文件时，相当于透过透明薄膜看画稿, 如果文件只存在于底层，你会直接看到它, 如果文件在上层也存在，那么上层的版本会“遮盖”住底层的版本\n修改文件：你不能直接修改原始画稿（lowerdir），当你第一次尝试修改一个来自底层的文件时，系统会启动写时复制 (Copy-on-Write) 机制，先把这个文件从底层复制一份到上层的透明薄膜上，然后你所有的修改都发生在这份复制品上\n创建文件：这就像直接在透明薄膜上画新的内容，完全不影响下面的原始画稿\n删除文件：你无法擦除原始画稿的内容, 当你删除一个来自底层的文件时，系统会在上层创建一个特殊的“白点”文件 (whiteout)，像贴了一张不透明的小贴纸，刚好遮住底层的文件，让它看起来像是被删除了\n这种分层和写时复制的机制是 Docker 等容器技术的核心, 容器镜像就是只读的 lowerdir，而每个运行的容器都有自己专属的可写 upperdir，这使得成百上千个容器可以共享同一个基础镜像，同时保持各自的隔离性，极大地节省了存储空间和部署时间\n文件系统快照 Snapshot 一些高级的文件系统（如 Btrfs, ZFS）或逻辑卷管理器（LVM）支持快照 (snapshot) 功能，它可以在瞬间“冻结”并创建一个文件系统在某个时间点的完整副本\n快照的实现也常常依赖于写时复制技术，创建快照时，并不会立即复制所有数据，而只是创建了一个指向当前数据块的指针集合, 当之后有数据块被修改时，文件系统不会覆盖旧的数据块，而是将修改写入新的位置，并让旧的快照指针继续指向未修改的旧数据块\n这个功能对于系统备份、快速回滚和创建安全的测试环境非常有用\n","permalink":"https://diefish1024.github.io/posts/class-notes/nju-os-2025/22-%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F-api/","summary":"\u003ch2 id=\"目录树\"\u003e目录树\u003c/h2\u003e\n\u003ch3 id=\"文件的抽象\"\u003e文件的抽象\u003c/h3\u003e\n\u003cp\u003e操作系统将物理存储设备（如磁盘）的复杂性隐藏起来，提供了一个简单、统一的抽象——\u003cstrong\u003e文件\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e文件可以看作是一个\u003cstrong\u003e虚拟的磁盘\u003c/strong\u003e，即一个命名的、一维的\u003cstrong\u003e字节序列\u003c/strong\u003e，支持 \u003ccode\u003eread\u003c/code\u003e, \u003ccode\u003ewrite\u003c/code\u003e, \u003ccode\u003elseek\u003c/code\u003e 等操作\u003c/p\u003e\n\u003cp\u003e这种抽象使得上层应用无需关心数据在物理磁盘上的具体位置和存储方式\u003c/p\u003e\n\u003ch3 id=\"目录的引入\"\u003e目录的引入\u003c/h3\u003e\n\u003cp\u003e当文件数量增多时，需要一种方式来组织和管理它们\u003c/p\u003e\n\u003cp\u003e操作系统引入了\u003cstrong\u003e目录 (Directory)\u003c/strong\u003e 的概念，它是一种特殊的文件，其内容是其他文件或目录的列表\u003c/p\u003e\n\u003cp\u003e通过将文件和目录组织成一个层次化的\u003cstrong\u003e树状结构\u003c/strong\u003e，即\u003cstrong\u003e目录树\u003c/strong\u003e，可以方便地对文件进行分类、查找和管理\u003c/p\u003e\n\u003cp\u003e多数类 Unix 系统遵循 \u003cstrong\u003eFHS (Filesystem Hierarchy Standard)\u003c/strong\u003e 的目录结构约定，为软件和用户预测文件位置提供了便利\u003c/p\u003e\n\u003ch3 id=\"目录操作-api\"\u003e目录操作 API\u003c/h3\u003e\n\u003cp\u003e操作系统提供了一系列系统调用来操作目录树，核心操作围绕“增删改查”\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003emkdir\u003c/code\u003e: 创建一个新的目录\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003ermdir\u003c/code\u003e: 删除一个空的目录\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003egetdents\u003c/code\u003e: 读取目录中的条目 (\u003cstrong\u003ed\u003c/strong\u003eirectory \u003cstrong\u003eent\u003c/strong\u003erie\u003cstrong\u003es\u003c/strong\u003e)\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003elink\u003c/code\u003e / \u003ccode\u003eunlink\u003c/code\u003e: 创建或删除文件的链接\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"链接\"\u003e链接\u003c/h3\u003e\n\u003cp\u003e链接是文件系统的一个重要特性，它允许一个文件拥有多个名字或存在于目录树的多个位置\u003c/p\u003e\n\u003cp\u003e链接主要分为两种类型：\u003cstrong\u003e硬链接\u003c/strong\u003e和\u003cstrong\u003e软链接（符号链接）\u003c/strong\u003e\u003c/p\u003e\n\u003ch4 id=\"硬链接-hard-link\"\u003e硬链接 Hard Link\u003c/h4\u003e\n\u003cp\u003e\u003cstrong\u003e定义\u003c/strong\u003e：\u003cstrong\u003e硬链接\u003c/strong\u003e是让多个目录条目（文件名）直接指向磁盘上同一个\u003cstrong\u003e文件索引节点 (inode)\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e每个文件在文件系统中都有一个唯一的 \u003ccode\u003einode\u003c/code\u003e，它包含了文件的元数据（如权限、大小、数据块位置等）和数据本身\u003c/p\u003e\n\u003cp\u003e创建一个硬链接，相当于为同一个 \u003ccode\u003einode\u003c/code\u003e 增加了一个新的入口点（文件名）\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e特性\u003c/strong\u003e：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e所有指向同一个 \u003ccode\u003einode\u003c/code\u003e 的硬链接地位平等，没有主次之分\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003einode\u003c/code\u003e 内部维护一个\u003cstrong\u003e链接计数 (reference count)\u003c/strong\u003e, 只有当这个计数减到 0 时，文件系统才会真正删除该 \u003ccode\u003einode\u003c/code\u003e 和对应的数据块，这也是 \u003ccode\u003eunlink\u003c/code\u003e 系统调用的由来\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e限制\u003c/strong\u003e：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e不能为目录创建硬链接，以防止在目录树中产生循环\u003c/li\u003e\n\u003cli\u003e不能跨越不同的文件系统（因为 \u003ccode\u003einode\u003c/code\u003e 号只在当前文件系统内唯一）\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4 id=\"软链接-symbolic-link\"\u003e软链接 Symbolic Link\u003c/h4\u003e\n\u003cp\u003e\u003cstrong\u003e定义\u003c/strong\u003e：\u003cstrong\u003e软链接\u003c/strong\u003e，也称\u003cstrong\u003e符号链接 (symlink)\u003c/strong\u003e，是一个\u003cstrong\u003e特殊的文件\u003c/strong\u003e，它的内容是另一个文件或目录的\u003cstrong\u003e路径\u003c/strong\u003e\u003c/p\u003e","title":"22. 文件系统 API"},{"content":"科普性质，简单记录一下\n1-Bit 的存储：磁铁 要实现“持久化”存储，核心是要找到一个能反复改写的状态，很容易想到能够利用磁的特性，这就有了磁带的初步想法：\n一个长条的带子上面均匀有磁性物质 定位到特定位置之后通过放大感应电流读取 用电磁铁改变磁化方向来写入数据 为了提高存储密度，可以把这样的带子给卷起来，于是就得到了磁带\n这样的存储方式主要缺点是几乎不能随机读写（比如磁带收音机需要倒带），一般用于冷数据的存档和备份\n为了解决这个缺点，可以想到用旋转的二维平面来替代卷起来的带子，这样读写延迟就不会超过旋转的周期，这就得到了磁鼓：\n再在磁鼓的基础上进一步内卷，把用圆盘代替柱面，从而可以堆叠起来，进一步提高了存储密度，这就得到了磁盘：\n磁盘作为存储设备的随机读写性能虽然相比磁带有了很大的改善，但是还是需要等待定位到正确的位置，性能仍然不够优秀，为了读写定位到一个扇区通常需要花费几个毫秒的时间，这一点可以通过缓存和调度算法来缓解，让数据尽可能连续存储\n当我们在磁盘的基础上把读写头和盘片本体分开，我们就实现了数据的移动，这也就得到了软盘，这是上个数据数据发行的主要方式，虽然性能和可靠性都比较低，但是胜在了便捷、可移动\n1-Bit 的存储：挖坑 古人实现持久化存储的方式是在石头上刻字，也就是通过挖坑来存储信息，这种方式可以跨越非常长的时间\n而现代工业使我们可以挖出更加精细的坑，从而可以存储更高密度的信息\n为了读取这样的信息，我们可以从光学的角度考虑：在反射平面上挖粗糙坑，激光扫过表面，在平面会反射回来，在坑里会发生漫反射，于是我们只要检测是否收到反射光就可以识别是坑还是表面，这也就是光盘\n光盘最有趣的特性是容易复制，我们要制造光盘可以先仔细地制造一张反转的盘片，坑的位置对应其表面的突起，之后只需要直接用这个盘片压制加热的塑料再镀上反射膜就可以得到一张光盘，这种方式可以达到极高的写入速度\n当然这种挖坑方式的一个重要特性就是不能修改已经写入的内容的，很难填上一个已经挖了的坑（当然通过特殊的制造材料和工艺也是可以做到的），这也就是说里面存储的数据是 append only 的，想要修改之前的内容可以采用可持久化二叉树的结构\n光盘作为存储设备，价格低的同时容量和可靠性都比较高，同时顺序读性能一般，随机读性能低并且很难写入，一个重要的应用常见就是数字时代的内容分发\n现代这种挖坑的存储方式还有一种应用方式是回归古人石碑的形式，把信息刻在很稳定的材料上来做到永久存储\n1-Bit 的存储：电荷 前两种存储介质都存在比较大的缺陷：\n磁：依赖机械部件，从而无法避免 ms 级别的延迟 坑（光）：挖坑效率低，同时填坑很困难 而电荷则是一种非常理想的存储介质：电子的密度极高，并且电路的速度极快（还天然并行）\n在电路中实现 1-bit 的持久存储，一个想法是我们可以挖一个坑，两种状态分别是：\n在坑里填入电子 从坑里放跑电子 而这就得到了闪存 (Flash Memory) ： 其作为存储设备，价格低，容量和可靠性高，而且读写性能极高（由于电路天然并行，所以容量越大，速度越快）\n然而，闪存的物理原理也带来了其固有的缺陷，即会磨损 (wear out)\n每次放电 (erase) 操作都无法 100% 将电子放干净，这会对存储单元造成微小的、不可逆的损伤 在经历数千或数万次擦写循环后，一些存储单元会因为累积的损伤而失效，无法再可靠地存储数据，这被称为 “死单元 (Dead Cell)” 为了解决闪存的磨损问题，并将其更好地呈现给操作系统，现代固态存储设备（如 SSD、U 盘、SD 卡）内部实际上都集成了一个微型计算机系统\n这个系统运行着一层被称为 FTL (Flash Translation Layer) 的固件，它的核心功能之一是 磨损均衡 (Wear Leveling)\nFTL 会记录每个物理块的擦写次数，当操作系统请求写入某个逻辑地址时，FTL 会避免总是写入同一个物理块，而是将写入请求重定向到一个较少被使用的物理块上，这种机制类似于操作系统中的虚拟内存，通过引入一个间接层（逻辑地址到物理地址的映射）来隐藏底层硬件的复杂性并优化其使用寿命\n这也意味着，即便是便宜的 U 盘 或 SD 卡，其内部也可能包含一个 ARM 芯片来运行 FTL，而高性能的 SSD 则拥有更强大的处理器、缓存和更复杂的 FTL 算法，从而提供更长的寿命和更高的性能\n这也解释了为什么我们不应该购买过于廉价的 U 盘，因为它们可能会在 FTL 上偷工减料，甚至伪造容量和厂商信息，导致数据丢失\n存储设备与操作系统 块设备抽象 无论是旋转的磁盘还是闪存芯片，它们都不适合以单个字节为单位进行寻址，因为定位和元数据（如扇区头、ECC 校验码）的开销太大\n因此，存储设备将它们的存储空间划分为固定大小的块 (Block)，并以块为单位进行读写，这大大摊销了单次 I/O 操作的开销，这些设备在操作系统中被称为块设备 (Block Devices)\n操作系统看到的是一个线性的、从 0 开始编号的块数组 struct block disk[NUM_BLOCKS]，应用程序可以直接像读写文件一样读写块设备（例如 /dev/sda），但这样做的效率很低，如果随机读写一个字节，操作系统和设备硬件最终可能会读取或写入整个块，导致读/写放大 (read/write amplification) 的问题，因此，上层的文件系统被设计为能够感知“块”的存在，并以块为单位来组织和管理数据\n为了高效地管理对块设备的访问，操作系统提供了一个专门的 I/O 栈\n在 Linux 中，上层文件系统或应用程序通过块 I/O (Bio) 层提交请求，Bio 层提供了一个请求/响应接口，它将上层的读写请求封装成 struct bio 结构体，这些请求被放入队列中，等待 I/O 调度器 (I/O Scheduler) 进行处理，调度器会根据策略（例如合并相邻的请求、排序请求以减少磁头寻道时间）来优化队列\n现代 Linux 内核使用多队列块 I/O (Multi-queue block I/O, blk-mq) 机制，为每个 CPU 核心 分配独立的请求队列，充分利用了现代多核处理器和高速 SSD 的并行性\n最终，由设备驱动程序将处理好的请求发送给硬件执行\n","permalink":"https://diefish1024.github.io/posts/class-notes/nju-os-2025/21-%E5%AD%98%E5%82%A8%E8%AE%BE%E5%A4%87%E5%8E%9F%E7%90%86/","summary":"\u003cp\u003e科普性质，简单记录一下\u003c/p\u003e\n\u003ch2 id=\"1-bit-的存储磁铁\"\u003e1-Bit 的存储：磁铁\u003c/h2\u003e\n\u003cp\u003e要实现“持久化”存储，核心是要找到一个能反复改写的状态，很容易想到能够利用磁的特性，这就有了磁带的初步想法：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e一个长条的带子上面均匀有磁性物质\u003c/li\u003e\n\u003cli\u003e定位到特定位置之后通过放大感应电流读取\u003c/li\u003e\n\u003cli\u003e用电磁铁改变磁化方向来写入数据\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e为了提高存储密度，可以把这样的带子给卷起来，于是就得到了磁带\u003c/p\u003e\n\u003cp\u003e这样的存储方式主要缺点是\u003cstrong\u003e几乎不能随机读写\u003c/strong\u003e（比如磁带收音机需要倒带），一般用于冷数据的存档和备份\u003c/p\u003e\n\u003cp\u003e为了解决这个缺点，可以想到用旋转的二维平面来替代卷起来的带子，这样读写延迟就不会超过旋转的周期，这就得到了\u003cstrong\u003e磁鼓\u003c/strong\u003e：\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/images/21-%E5%AD%98%E5%82%A8%E8%AE%BE%E5%A4%87%E5%8E%9F%E7%90%86/pasted-image-20250805012735.png\"\u003e\u003c/p\u003e\n\u003cp\u003e再在磁鼓的基础上进一步内卷，把用圆盘代替柱面，从而可以堆叠起来，进一步提高了存储密度，这就得到了\u003cstrong\u003e磁盘\u003c/strong\u003e：\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/images/21-%E5%AD%98%E5%82%A8%E8%AE%BE%E5%A4%87%E5%8E%9F%E7%90%86/pasted-image-20250805012958.png\"\u003e\u003c/p\u003e\n\u003cp\u003e磁盘作为存储设备的随机读写性能虽然相比磁带有了很大的改善，但是还是需要等待定位到正确的位置，性能仍然不够优秀，为了读写定位到一个扇区通常需要花费几个毫秒的时间，这一点可以通过缓存和调度算法来缓解，让数据尽可能连续存储\u003c/p\u003e\n\u003cp\u003e当我们在磁盘的基础上把读写头和盘片本体分开，我们就实现了数据的移动，这也就得到了\u003cstrong\u003e软盘\u003c/strong\u003e，这是上个数据数据发行的主要方式，虽然性能和可靠性都比较低，但是胜在了便捷、可移动\u003c/p\u003e\n\u003ch2 id=\"1-bit-的存储挖坑\"\u003e1-Bit 的存储：挖坑\u003c/h2\u003e\n\u003cp\u003e古人实现持久化存储的方式是在石头上刻字，也就是通过挖坑来存储信息，这种方式可以跨越非常长的时间\u003c/p\u003e\n\u003cp\u003e而现代工业使我们可以挖出更加精细的坑，从而可以存储更高密度的信息\u003c/p\u003e\n\u003cp\u003e为了读取这样的信息，我们可以从光学的角度考虑：在反射平面上挖粗糙坑，激光扫过表面，在平面会反射回来，在坑里会发生漫反射，于是我们只要检测是否收到反射光就可以识别是坑还是表面，这也就是\u003cstrong\u003e光盘\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e光盘最有趣的特性是容易复制，我们要制造光盘可以先仔细地制造一张反转的盘片，坑的位置对应其表面的突起，之后只需要直接用这个盘片压制加热的塑料再镀上反射膜就可以得到一张光盘，这种方式可以达到极高的写入速度\u003c/p\u003e\n\u003cp\u003e当然这种挖坑方式的一个重要特性就是不能修改已经写入的内容的，很难填上一个已经挖了的坑（当然通过特殊的制造材料和工艺也是可以做到的），这也就是说里面存储的数据是 append only 的，想要修改之前的内容可以采用可持久化二叉树的结构\u003c/p\u003e\n\u003cp\u003e光盘作为存储设备，价格低的同时容量和可靠性都比较高，同时顺序读性能一般，随机读性能低并且很难写入，一个重要的应用常见就是数字时代的内容分发\u003c/p\u003e\n\u003cp\u003e现代这种挖坑的存储方式还有一种应用方式是回归古人石碑的形式，把信息刻在很稳定的材料上来做到永久存储\u003c/p\u003e\n\u003ch2 id=\"1-bit-的存储电荷\"\u003e1-Bit 的存储：电荷\u003c/h2\u003e\n\u003cp\u003e前两种存储介质都存在比较大的缺陷：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e磁：依赖机械部件，从而无法避免 ms 级别的延迟\u003c/li\u003e\n\u003cli\u003e坑（光）：挖坑效率低，同时填坑很困难\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e而电荷则是一种非常理想的存储介质：电子的密度极高，并且电路的速度极快（还天然并行）\u003c/p\u003e\n\u003cp\u003e在电路中实现 1-bit 的持久存储，一个想法是我们可以挖一个坑，两种状态分别是：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e在坑里填入电子\u003c/li\u003e\n\u003cli\u003e从坑里放跑电子\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e而这就得到了\u003cstrong\u003e闪存 (Flash Memory)\u003c/strong\u003e ：\n\u003cimg loading=\"lazy\" src=\"/images/21-%E5%AD%98%E5%82%A8%E8%AE%BE%E5%A4%87%E5%8E%9F%E7%90%86/pasted-image-20250805112704.png\"\u003e\n其作为存储设备，价格低，容量和可靠性高，而且读写性能极高（由于电路天然并行，所以容量越大，速度越快）\u003c/p\u003e\n\u003cp\u003e然而，闪存的物理原理也带来了其固有的缺陷，即\u003cstrong\u003e会磨损 (wear out)\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e每次放电 (erase) 操作都无法 100% 将电子放干净，这会对存储单元造成微小的、不可逆的损伤\u003c/li\u003e\n\u003cli\u003e在经历数千或数万次擦写循环后，一些存储单元会因为累积的损伤而失效，无法再可靠地存储数据，这被称为 “\u003cstrong\u003e死单元 (Dead Cell)\u003c/strong\u003e”\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e为了解决闪存的磨损问题，并将其更好地呈现给操作系统，现代固态存储设备（如 SSD、U 盘、SD 卡）内部实际上都集成了一个微型计算机系统\u003c/p\u003e\n\u003cp\u003e这个系统运行着一层被称为 \u003cstrong\u003eFTL (Flash Translation Layer)\u003c/strong\u003e 的固件，它的核心功能之一是 \u003cstrong\u003e磨损均衡 (Wear Leveling)\u003c/strong\u003e\u003c/p\u003e","title":"21. 存储设备原理"},{"content":"输入输出设备 Everything is a File 在 Unix-like 系统中，与外部设备交互的核心思想是 Everything is a File\n文件描述符 (File Descriptor)：操作系统为上层软件提供了一个统一的抽象，即文件描述符，它是一个指向内核中任何 I/O 对象的“指针”或句柄\n统一接口：无论是普通文件、硬件设备（如终端、磁盘）、还是网络连接，都可以通过 open 获得一个文件描述符，然后使用相同的 read/write 等系统调用来进行操作，这极大地简化了应用程序的编写\n设备控制器与 MMIO “文件”这个美好的抽象背后，是具体的硬件工作原理\n设备控制器 (Device Controller)：每个 I/O 设备都有一个控制器，它是一个包含 CPU、内存和寄存器的微型计算机，作为 CPU 和物理设备之间的桥梁\n设备寄存器：控制器通过一组寄存器与 CPU 通信，通常包括：\n状态寄存器：用于表示设备当前是否繁忙、是否准备好等 指令寄存器：CPU 写入指令，告诉设备要做什么 数据寄存器：用于在 CPU 和设备之间传输数据 内存映射 I/O (MMIO)：为了让 CPU 能访问这些寄存器，现代系统普遍采用 MMIO (Memory-Mapped I/O)，操作系统会将设备的寄存器映射到物理内存地址空间中的特定区域，这样一来，CPU 就可以像访问普通内存一样，使用标准的 load/store 指令来读写设备寄存器，从而实现对设备的控制\nGPIO GPIO (General-Purpose Input/Output) 是理解 I/O 设备原理最直观的例子，GPIO 就是一个物理引脚，可以通过编程设置为输入或输出模式\n通过 MMIO，一个 GPIO 引脚的电平状态被映射到一个特定的内存地址，当 CPU 向这个地址写入 1 时，引脚就变为高电平；写入 0 时，则变为低电平，这个过程将一条内存写指令直接转化为了一个物理世界的动作（比如点亮一个 LED）\n输入输出设备案例 串口与键盘 经典的 I/O 设备，展示了最基础的设备交互方式\n端口 I/O：它们通常使用端口 I/O (Port I/O) 与 CPU 通信，设备寄存器被映射到专用的 I/O 端口地址（而非内存地址），CPU 需要使用特殊的 in/out 指令来读写这些端口\n向指定端口写入不同的数值，相当于向设备发送不同的指令（如设置波特率、控制键盘 LED 灯），而从指定端口读取数据则是接收设备的状态或输入（如串口收到的字符、键盘按键的扫描码）\n磁盘控制器与 PIO 早期的磁盘控制器（如 ATA/IDE）展示了一种更复杂但效率较低的交互模式：PIO 协议：全称为Programmed I/O，在这种模式下，数据的传输完全由 CPU 控制\n工作流程：\nCPU 向磁盘控制器的指令寄存器写入命令（如“读取第 N 个扇区”） CPU 进入轮询 (Polling) 状态，反复读取状态寄存器，直到设备报告“数据准备就绪” CPU 在一个循环中，逐个字节或字地将数据从磁盘的数据寄存器读入 CPU 寄存器，再写入内存 缺点：在轮询和数据传输期间，CPU 被完全占用，无法执行其他任务，效率极其低下\n打印机与 DSL 打印机这类设备，将交互模型提升到了一个新的高度\n领域专用语言 (DSL)：打印机不是简单地接收像素数据，而是作为一个独立的计算机，接收并解释用页面描述语言（如 PostScript 或 PCL）编写的“程序”\nCPU（驱动程序）的角色更像是一个编译器，将应用程序的打印请求（如一个 Word 文档）编译成一串 PostScript 指令流，然后发送给打印机\n打印机内部的处理器负责执行这些指令，将抽象的描述（如“在这里画一条线”、“使用这个字体显示文本”）翻译成打印头的物理动作\n总线与可扩展性 单个计算机系统需要连接多种多样的设备，这就需要一个标准化的扩展机制——总线 (Bus)\n总线是一组共享的电子线路，它定义了一套协议，允许 CPU、内存和多个 I/O 设备之间进行通信，它提供了一种“设备虚拟化”，CPU 只需与总线控制器通信，由总线负责将请求转发到正确的设备\n可扩展性：通过标准的扩展插槽（如早期的 ISA、现代的 PCIe），用户可以向系统中添加无穷无尽的新设备，而无需修改主板或 CPU 的设计 PCIe 总线与 DMA PCIe (PCI Express) 是目前主流的高速总线标准，它引入了一项革命性的技术来解决 PIO 的效率问题：DMA，全称为直接内存访问 (Direct Memory Access)，它允许设备控制器在没有 CPU 干预的情况下，直接与主内存进行数据传输\n工作流程：\nCPU 设置 DMA 控制器，告诉它源地址、目标地址和传输大小 CPU 向设备发出“开始传输”的指令后，就可以去执行其他任务了 DMA 控制器全权负责数据的搬运 传输完成后，DMA 控制器通过中断通知 CPU 优势：DMA 极大地解放了 CPU，使其不需要负责搬运数据，从而显著提升了整个系统的 I/O 吞吐量和效率，是所有现代高性能设备（显卡、NVMe 硬盘、高速网卡）的基础\n设备驱动程序 file_operations 结构体 操作系统内核通过名为 file_operations 的结构体落实“Everything is a File”的思想\n核心机制：这个结构体本质上是一个函数指针列表，定义了一系列标准的文件操作，如 read, write, open, llseek, ioctl 等\n驱动的本质：一个设备驱动程序 (Device Driver) 的核心，就是为特定的硬件或虚拟设备，提供一套具体的 file_operations 实现，当一个设备被注册到系统中时，内核就会将这个设备的“文件”与这套操作函数关联起来\n驱动的翻译职责 设备驱动程序的核心职责，就是翻译应用程序和物理硬件之间的交互\n翻译过程：当一个用户程序对文件描述符执行系统调用时（例如 read(fd, buf, size)），内核会：\n通过 fd 找到对应的内核文件对象 从文件对象中找到关联的 file_operations 结构体 调用其中的 .read 函数指针，并将系统调用的参数传递过去 驱动的实现：驱动程序中的 .read 函数则负责执行设备相关的底层操作，比如通过 MMIO 或 PIO 向设备控制器发送指令，等待数据就绪，然后将数据从设备寄存器中读出，最后复制到用户空间的 buf 中\n虚拟设备：这个模型同样适用于虚拟设备，例如对 /dev/null 的 write 操作，其驱动实现仅仅是直接返回写入的字节数，而什么也不做，对 /proc/stat 的 read 操作，则是读取内核中的统计数据并格式化成字符串返回\nioctl 万能接口 对于读写数据流之外的设备控制和配置需求（如设置键盘重复率、获取磁盘健康信息、配置网络参数等），read/write 模型显然不能满足，为此，Unix 系统提供了一个通用的 ioctl (I/O Control) 系统调用\nioctl 是一个高度灵活的接口，它的具体行为完全由设备驱动程序定义，应用程序通过传递一个设备专属的命令码和参数，来执行特定的控制功能\n虽然强大，但 ioctl 也带来了巨大的复杂性，因为每个设备的命令集都不同，形成了一系列隐藏的、非标准的协议，应用程序需要知道这些细节才能与设备深度交互（是巨大的屎山💩）\n实际案例：\nlibc 缓冲：libc 库通过对文件描述符 1 (stdout) 执行一个 tty 设备专属的 ioctl 命令（如 TCGETS），来判断输出目标是否为一个交互式终端，从而决定是采用行缓冲还是全缓冲\nKVM 虚拟化：KVM 就是一个通过 ioctl 暴露全部功能的复杂设备，用户程序打开 /dev/kvm 后，通过一系列 ioctl 命令（如 KVM_CREATE_VM, KVM_SET_REGS, KVM_RUN）来创建虚拟机、设定 CPU 状态并运行虚拟机，直到发生 VM Exit 事件返回到用户态\n","permalink":"https://diefish1024.github.io/posts/class-notes/nju-os-2025/20-%E8%AE%BE%E5%A4%87%E5%92%8C%E9%A9%B1%E5%8A%A8%E7%A8%8B%E5%BA%8F/","summary":"\u003ch2 id=\"输入输出设备\"\u003e输入输出设备\u003c/h2\u003e\n\u003ch3 id=\"everything-is-a-file\"\u003eEverything is a File\u003c/h3\u003e\n\u003cp\u003e在 Unix-like 系统中，与外部设备交互的核心思想是 \u003cstrong\u003eEverything is a File\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e文件描述符 (File Descriptor)\u003c/strong\u003e：操作系统为上层软件提供了一个统一的抽象，即文件描述符，它是一个指向内核中任何 I/O 对象的“指针”或句柄\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e统一接口\u003c/strong\u003e：无论是普通文件、硬件设备（如终端、磁盘）、还是网络连接，都可以通过 \u003ccode\u003eopen\u003c/code\u003e 获得一个文件描述符，然后使用相同的 \u003ccode\u003eread\u003c/code\u003e/\u003ccode\u003ewrite\u003c/code\u003e 等系统调用来进行操作，这极大地简化了应用程序的编写\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"设备控制器与-mmio\"\u003e设备控制器与 MMIO\u003c/h3\u003e\n\u003cp\u003e“文件”这个美好的抽象背后，是具体的硬件工作原理\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e设备控制器 (Device Controller)\u003c/strong\u003e：每个 I/O 设备都有一个控制器，它是一个包含 CPU、内存和寄存器的微型计算机，作为 CPU 和物理设备之间的桥梁\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e设备寄存器\u003c/strong\u003e：控制器通过一组\u003cstrong\u003e寄存器\u003c/strong\u003e与 CPU 通信，通常包括：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e状态寄存器\u003c/strong\u003e：用于表示设备当前是否繁忙、是否准备好等\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e指令寄存器\u003c/strong\u003e：CPU 写入指令，告诉设备要做什么\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e数据寄存器\u003c/strong\u003e：用于在 CPU 和设备之间传输数据\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e内存映射 I/O (MMIO)\u003c/strong\u003e：为了让 CPU 能访问这些寄存器，现代系统普遍采用 \u003cstrong\u003eMMIO (Memory-Mapped I/O)\u003c/strong\u003e，操作系统会将设备的寄存器映射到物理内存地址空间中的特定区域，这样一来，CPU 就可以像访问普通内存一样，使用标准的 \u003ccode\u003eload\u003c/code\u003e/\u003ccode\u003estore\u003c/code\u003e 指令来读写设备寄存器，从而实现对设备的控制\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"gpio\"\u003eGPIO\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003eGPIO (General-Purpose Input/Output)\u003c/strong\u003e 是理解 I/O 设备原理最直观的例子，GPIO 就是一个物理引脚，可以通过编程设置为输入或输出模式\u003c/p\u003e\n\u003cp\u003e通过 MMIO，一个 GPIO 引脚的电平状态被映射到一个特定的内存地址，当 CPU 向这个地址写入 \u003ccode\u003e1\u003c/code\u003e 时，引脚就变为高电平；写入 \u003ccode\u003e0\u003c/code\u003e 时，则变为低电平，这个过程将一条内存写指令直接转化为了一个物理世界的动作（比如点亮一个 LED）\u003c/p\u003e","title":"20. 设备和驱动程序"},{"content":"CPU 内的并行编程 CPU 的功耗 $ P=C\\cdot V^{2}\\cdot f $ 导致纵使有更大的电路，热功耗限制了性能上限，从而有一堵“功耗墙”限制了 CPU 的性能，为此需要考虑如何在降低 $ V $ 和 $ f $ 的同时用面积换性能\n有两个思路：\n让一条指令能处理更多的数据：SIMD (Single Instruction, Multiple Data)\n“一条指令” 浪费的能量大致是定数 处理的数据越多，浪费越少 用更多更简单的处理器：多处理器系统、异构多处理器\n同等面积，处理器越简单，数量越多 异构计算：最经典的例子是大小核架构（如 Apple M1） SIMD SIMD 的核心思想是在硬件层面实现数据级并行，它通过引入专门的硬件单元来达成这个目标：\n宽位寄存器 (Wide Registers)：CPU 内部增加了比通用寄存器宽很多的专用寄存器\nIntel 的 SSE 指令集引入了 128 位的 XMM 寄存器，而最新的 AVX-512 拥有 512 位的 ZMM 寄存器 这些宽位寄存器可以一次性装入多个数据元素，比如一个 128 位的寄存器可以同时容纳 4 个 32 位的浮点数，或者 16 个 8 位的整数 这些被打包在一起的数据被称为 Vector 向量处理单元 (Vector ALU)：CPU 内部也配备了能够对整个向量进行并行计算的 ALU\n当执行一条 SIMD 指令时，这个特殊的 ALU 会在同一个时钟周期内，同时对寄存器中的 4 对浮点数分别执行操作 例子：假设我们要计算两个数组 A 和 B 的和，存入数组 C，每个数组都有 4 个元素。\nTraditional：\nload A[0] load B[0] add -\u0026gt; store C[0] load A[1] load B[1] add -\u0026gt; store C[1] \u0026hellip; 重复 4 次，需要执行 4 轮独立的“load-compute-store”指令 SIMD：\nLOAD：将数组 A 的 4 个元素一次性加载到一个 128 位的 XMM 寄存器中 LOAD：将数组 B 的 4 个元素加载到另一个 XMM 寄存器中 VADDPS：CPU 的向量处理单元对这两个寄存器中的 4 对元素 同时 进行加法运算 STORE：将计算结果寄存器中的 4 个和值一次性存回内存中的数组 C 通过这种方式，原来需要循环多次的计算被压缩成了几条高效的向量指令，极大地提升了吞吐率，尤其是在图像处理、视频编解码、科学计算和人工智能等需要大量重复性计算的领域，效果非常显著\nGPU 和 GPGPU 第二种克服“功耗墙”的思路——使用更多、更简单的处理器——直接催生了 GPU (Graphics Processing Unit) 的发展，它最初为图形渲染这种高度并行的任务而设计，其架构被证明非常有效，最终演变成了一个通用计算的强大引擎\n从 PPU 到 GPU 对专用图形硬件的需求在早期游戏机中就很明显：CPU 在渲染方面效率极低，计算屏幕上每个像素的颜色，每秒重复 60 次，这种“大规模并行”任务会完全压垮为串行任务设计的 CPU\n早期方案 - PPU：早期系统将图形任务交给 PPU (Picture Processing Unit) 处理，这是一种领域专用硬件，它操作的是高级图形对象，如 tiles (8x8 像素块) 和 sprites (可移动的前景角色)，而非单个像素，CPU 的工作被简化为告诉 PPU 该画 哪个 图块以及画在 哪里\n固定功能 Pipeline：随着 3D 图形的出现，简单的 PPU 模型演变为更复杂但仍然固化的 “固定功能管线” (Fixed-Function Pipeline)，它有一系列硬件实现的固定阶段，虽然功能强大，但除了调整预设参数外，几乎没有创造性空间\n随后开发者为了自定义视觉效果，把图形管线中的关键部分被替换为可编程单元，发展出了可编程的特性\n这种可编程性赋予了开发者前所未有的控制力，也标志着现代 GPU 的诞生\nGPGPU 人们很快意识到，一个为像素并行执行数百万个简单程序的芯片，用途远不止于图形\n早期的 hack ：最初的 GPGPU (General-Purpose computing on GPU) 是开发者将一个科学问题（如矩阵乘法）伪装成一个图形任务，例如将矩阵作为“纹理”加载，然后编写一个“片元着色器”来进行乘法计算，最后将结果“颜色”写出 演变为计算平台：这种强大但繁琐的方法证明了其可行性，硬件厂商（比如 Nvidia）随即推出了专用的编程框架（CUDA）和开放标准（OpenCL），这些平台彻底剥离了图形接口，将 GPU 强大的并行计算能力直接暴露给开发者 AI 时代的并行编程 随着 GPGPU 平台的成熟，可编程的 Shader 模型也演变成了更通用的线程模型，最终在 AI 时代大放异彩\nSIMT：单指令，多线程 CUDA 编程模型的核心是 SIMT (Single Instruction, Multiple Threads)，这是对 SIMD 思想的扩展\nGPU 程序中每个像素执行一次的“着色器”，在 CUDA 被看作是一个 Kernel 函数，会被成千上万甚至数百万个 线程 并行执行\nSIMT 的魔法在于，GPU 会将线程分组（通常 32 个线程为一个 Warp），一个 Warp 内的所有线程共享同一个程序计数器 (PC)，在硬件层面，它们在同一时刻执行完全相同的指令\n这实际上创造了一种类似巨型 SIMD 的效果，每个线程虽然有自己独立的寄存器和数据（通过 threadIdx 等内置变量区分），但它们的执行流被捆绑在一起，这使得控制单元的设计可以极其简化，从而在芯片上集成海量的计算核心\nChallenges SIMT 架构在带来巨大并行优势的同时，也给带来了挑战：\n内存合并 (Memory Coalescing)：当一个 Warp 中的多个线程连续访问内存时，GPU 硬件能将这 32 个独立的访问请求合并成一笔或几笔大的内存事务，这是 CUDA 性能优化的关键\n分支发散 (Branch Divergence)：SIMT 最大的难点在于处理分支，如果一个 Warp 内的线程在 if-else 语句上做出不同选择，由于它们共享同一个 PC，硬件必须串行地执行 if 路径和 else 路径，并在执行每个路径时，将另一部分线程暂时屏蔽，这会使 Warp 的执行速度取决于内部执行最慢的线程\n共享内存 (Shared Memory)：虽然 CUDA 线程可以访问共享内存，但如何避免访问冲突 (Bank Conflict)，如何组织数据以最大化并行加载，都会增加 CUDA 程序的编写难度\n尽管编写高效的 CUDA 程序充满挑战，但其回报是巨大的，尤其对于那些计算密集、模式固定的任务，例如深度学习中的矩阵乘法和卷积运算，GPU 能提供比 CPU 高出数个数量级的性能和能效比\n","permalink":"https://diefish1024.github.io/posts/class-notes/nju-os-2025/19-%E7%9C%9F%E5%AE%9E%E4%B8%96%E7%95%8C%E7%9A%84%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B-2/","summary":"\u003ch2 id=\"cpu-内的并行编程\"\u003eCPU 内的并行编程\u003c/h2\u003e\n\u003cp\u003eCPU 的功耗 $ P=C\\cdot V^{2}\\cdot f $ 导致纵使有更大的电路，热功耗限制了性能上限，从而有一堵“功耗墙”限制了 CPU 的性能，为此需要考虑如何在降低 $ V $ 和 $ f $ 的同时用面积换性能\u003c/p\u003e\n\u003cp\u003e有两个思路：\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e让一条指令能处理更多的数据\u003c/strong\u003e：SIMD (Single Instruction, Multiple Data)\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e“一条指令” 浪费的能量大致是定数\u003c/li\u003e\n\u003cli\u003e处理的数据越多，浪费越少\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e用更多更简单的处理器\u003c/strong\u003e：多处理器系统、异构多处理器\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e同等面积，处理器越简单，数量越多\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e异构计算\u003c/strong\u003e：最经典的例子是\u003cstrong\u003e大小核架构\u003c/strong\u003e（如 Apple M1）\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch3 id=\"simd\"\u003eSIMD\u003c/h3\u003e\n\u003cp\u003eSIMD 的核心思想是在硬件层面实现数据级并行，它通过引入专门的硬件单元来达成这个目标：\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e宽位寄存器 (Wide Registers)\u003c/strong\u003e：CPU 内部增加了比通用寄存器宽很多的专用寄存器\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eIntel 的 SSE 指令集引入了 128 位的 XMM 寄存器，而最新的 AVX-512 拥有 512 位的 ZMM 寄存器\u003c/li\u003e\n\u003cli\u003e这些宽位寄存器可以一次性装入多个数据元素，比如一个 128 位的寄存器可以同时容纳 4 个 32 位的浮点数，或者 16 个 8 位的整数\u003c/li\u003e\n\u003cli\u003e这些被打包在一起的数据被称为 Vector\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e向量处理单元 (Vector ALU)\u003c/strong\u003e：CPU 内部也配备了能够对整个向量进行并行计算的 ALU\u003c/p\u003e","title":"19. 真实世界的并发编程 (2)"},{"content":"并发编程的核心抽象是实现一个计算图，计算发生在节点上，边表示节点之间的依赖关系，同时计算图在运行时可能是动态变化的\n使用条件变量、锁、信号量等 api 去实现计算图并不是一个优雅的实现方式，因为这样会在代码中引入众多干扰代码，也可能导致一些问题\n为此可以增加一些功能受限的语法，可以在同样描述计算图的功能下减少了许多潜在的问题\n高性能计算中的并行编程 在高性能计算中，计算图通常易于静态切分，尤其适用于物理模拟的网格划分，为此 HPC 发展出多种高效的并行编程模型，具体学习可以参考 SJTU HPC 学习手册\nMPI: 分布式内存并行 每个 MPI 进程有独立的内存空间，进程间通过显式消息传递（发送/接收）交换数据\nOpenMP: 共享内存并行 多个线程在同一地址空间中并行执行，所有线程可以直接访问相同的数据，使用 #pragma omp 指令实现并行化\n对非计算机专业来说非常友好，只需要在正常的代码上面加上编译指令即可，能轻松实现高效的并行优化\nCUDA: GPU 异构并行 CPU 调度，GPU 执行大规模并行计算\n概念：\n核函数 (Kernel) ：在 GPU 上并行执行的函数 线程层次：线程 (threadIdx) 组成线程块 (blockIdx)，线程块组成网格 (gridDim) 内存层次：寄存器、共享内存（块内高速）、全局内存（所有线程可访问） 我们身边的并发编程 从 Web 1.0 到 Web 2.0 在 Web 时代用的最广泛的是 Javascript\nAsynchronous JavaScript and XML (Ajax; ~1999) 允许网页实现“后台刷新” jQuery $ (2006): A DOM Query Language (编程抽象) Web 2.0 时代的并发编程 线程开销大，并且大多数 Web 开发者难以进行并发编程\n从而有了event-based concurrency (动态计算图) 的机制：禁止任何计算节点并行（和高性能计算的选择不同）\n允许网络请求、sleep 在后台进行（这才是主要开销），执行完之后产生新的计算节点 事件可以在浏览器里看到 直接用这样的方式描述计算图会产生大量屎山代码 (Callback hell) ，现代的选择是动态描述计算图\n数据中心的并发编程 数据中心以海量分布式数据为中心，需要处理的需求有：\n实时的“小数据”处理：内容分发、弹幕…… 离线的“大数据”处理：内容索引、数据挖掘…… 为 AI 提供支持 数据中心里的并发编程需要满足高吞吐量和低延迟的特点，难点在于：\n处理事件可能需要读写持久存储或请求网络上的服务，从而导致延迟不确定 线程维护和上下文切换都会带来开销 在数据中心进行并发编程时，传统的通过手动管理线程、锁等低级并发原语的方式变得越来越复杂且难以扩展，因此今天的解决方案是无服务器计算 (Serverless Computing) ，特别是函数即服务 (Function as a Service, FaaS) ，其优势在于\n开发人员不再需要直接处理底层的并发问题 FaaS 函数通常是短暂的、无状态的，并且每个请求通常触发一个独立的函数实例，不同的函数实例之间通常不共享内存，这从根本上规避了传统多线程编程中由于共享内存问题 这样的范式使得现代存储系统实现高可靠、低延迟的多副本分布式存储和计算变得非常 Challenge ，数据一致性、服务时刻可用和容忍机器离线三个特性不可以兼得 协程 协程是一种程序组件，与线程在概念上有一些相似之处，比如都在进程内部拥有独立的栈帧，并能在运行时维护自己的状态，可以看作是一个共享内存的状态机\n然而，协程与线程最大的不同在于它们的调度方式和上下文切换开销：\n协作式调度：协程的执行是协作式的，会“一直执行” ，直到遇到 yield() 等指令时，才会主动放弃处理器控制权，将执行权交还给调用者或调度器，这与线程的抢占式调度（由操作系统决定何时中断和切换）不同\n操作系统“不感知”的上下文切换：当协程通过 yield() 进行切换时，这仅仅是一个函数调用级别的操作，不需要像线程切换那样，保存和恢复完整的上下文信息，因此这种切换开销非常小，并且是操作系统完全不感知\n阻塞 I/O 的局限性：由于协程是协作式执行的，如果在一个协程内部执行了阻塞性操作（如耗时的 I/O 操作或 sleep()），那么当前所在的整个操作系统线程都会被卡住，这意味着所有在该线程上运行的协程都将停止执行，从而失去了并行\n示例\n1 2 3 4 5 6 7 8 9 10 11 import random def T_worker(name): i = 0 while (i := i + 1): print(f\u0026#39;[{name}] i = {i}\u0026#39;) yield() threads = [T_worker(i) for i in range(1000000)] while True: random.choice(threads).send(None) 这个例子很好地阐释了协程的特点：\n在同一个操作系统线程中执行：虽然创建了非常多个 T_worker 对象，但它们都运行在程序的同一个操作系统线程中，开销远小于创建相同数量个操作系统线程 由程序控制调度：while True: random.choice(threads).send(None) 这段代码是自定义的简单调度器，它随机选择一个协程并激活它，使其执行直到遇到 yield() 暂停，然后再选择下一个协程 资源占用极低：由于不涉及操作系统层面的上下文切换，除了协程本身所需要的一小块内存用于保存其栈帧和状态外，协程不占用额外的操作系统资源，因此可以创建海量的协程实例，非常适合高并发的 I/O 密集型任务。 ","permalink":"https://diefish1024.github.io/posts/class-notes/nju-os-2025/18-%E7%9C%9F%E5%AE%9E%E4%B8%96%E7%95%8C%E7%9A%84%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B-1/","summary":"\u003cp\u003e并发编程的核心抽象是实现一个计算图，计算发生在节点上，边表示节点之间的依赖关系，同时计算图在运行时可能是动态变化的\u003c/p\u003e\n\u003cp\u003e使用条件变量、锁、信号量等 api 去实现计算图并不是一个优雅的实现方式，因为这样会在代码中引入众多\u003cstrong\u003e干扰代码\u003c/strong\u003e，也可能导致一些问题\u003c/p\u003e\n\u003cp\u003e为此可以增加一些功能受限的\u003cstrong\u003e语法\u003c/strong\u003e，可以在同样描述计算图的功能下减少了许多潜在的问题\u003c/p\u003e\n\u003ch2 id=\"高性能计算中的并行编程\"\u003e高性能计算中的并行编程\u003c/h2\u003e\n\u003cp\u003e在高性能计算中，计算图通常易于\u003cstrong\u003e静态切分\u003c/strong\u003e，尤其适用于物理模拟的网格划分，为此 HPC 发展出多种高效的并行编程模型，具体学习可以参考 \u003ca href=\"https://xflops.sjtu.edu.cn/hpc-start-guide/parallel-computing/basic/\"\u003eSJTU HPC 学习手册\u003c/a\u003e\u003c/p\u003e\n\u003ch4 id=\"mpi-分布式内存并行\"\u003eMPI: 分布式内存并行\u003c/h4\u003e\n\u003cp\u003e每个 MPI 进程有独立的内存空间，进程间通过\u003cstrong\u003e显式消息传递\u003c/strong\u003e（发送/接收）交换数据\u003c/p\u003e\n\u003ch4 id=\"openmp-共享内存并行\"\u003eOpenMP: 共享内存并行\u003c/h4\u003e\n\u003cp\u003e多个线程在同一地址空间中并行执行，所有线程可以直接访问相同的数据，使用 \u003ccode\u003e#pragma omp\u003c/code\u003e 指令实现并行化\u003c/p\u003e\n\u003cp\u003e对非计算机专业来说非常友好，只需要在正常的代码上面加上编译指令即可，能轻松实现高效的并行优化\u003c/p\u003e\n\u003ch4 id=\"cuda-gpu-异构并行\"\u003eCUDA: GPU 异构并行\u003c/h4\u003e\n\u003cp\u003eCPU 调度，GPU 执行大规模并行计算\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e概念\u003c/strong\u003e：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e核函数 (Kernel)\u003c/strong\u003e ：在 GPU 上并行执行的函数\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e线程层次\u003c/strong\u003e：线程 (\u003ccode\u003ethreadIdx\u003c/code\u003e) 组成线程块 (\u003ccode\u003eblockIdx\u003c/code\u003e)，线程块组成网格 (\u003ccode\u003egridDim\u003c/code\u003e)\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e内存层次\u003c/strong\u003e：寄存器、共享内存（块内高速）、全局内存（所有线程可访问）\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"我们身边的并发编程\"\u003e我们身边的并发编程\u003c/h2\u003e\n\u003ch4 id=\"从-web-10-到-web-20\"\u003e从 Web 1.0 到 Web 2.0\u003c/h4\u003e\n\u003cp\u003e在 Web 时代用的最广泛的是 Javascript\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eAsynchronous JavaScript and XML\u003c/strong\u003e (Ajax; ~1999)\n\u003cul\u003e\n\u003cli\u003e允许网页实现“后台刷新”\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003ejQuery $ (2006): A DOM Query Language\u003c/strong\u003e (编程抽象)\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4 id=\"web-20-时代的并发编程\"\u003eWeb 2.0 时代的并发编程\u003c/h4\u003e\n\u003cp\u003e线程开销大，并且大多数 Web 开发者难以进行并发编程\u003c/p\u003e","title":"18. 真实世界的并发编程 (1)"},{"content":"数据竞争 大多并发 bug 最后都会体现为数据竞争 (Data Race)\n对于顺序程序而言，函数 f() 返回之后就已经完成了所有的状态修改，对于其他部分而言这个修改是立即生效的；如果对于并发程序而言模式的切换也在瞬间完成，那就不会导致并发的问题\n然而实际上模式的切换需要时间，执行的操作在未来一段时间之后才会就绪，但是我们在实际编程时总是容易有“立即生效”的肌肉记忆，这就导致了并发问题的可能性\n不过对于函数式编程而言，操作不存在对外状态的修改，没有副作用（只会操作局部变量），这就不会导致并发问题\nData Race 发生的实质是不同的线程同时访问同一内存，并且至少有一个是写，形象的理解就是不同的内存访问在“赛跑”，跑赢的操作先执行\nNot that easy: 虽然我们将数据竞争形象地比喻为“赛跑”，但实际上，哪一个操作能“跑赢”并没有想象中那么简单和确定，其复杂性主要体现在以下几个方面\n弱内存模型 (Weak memory model)：在现代处理器架构中，为了提升性能，处理器可能会对内存操作进行重排序。这意味着，不同的线程或“观察者”在不同时间点看到共享内存的状态可能是不一致的。一个线程对内存的写入操作，可能不会立即对所有其他线程可见，导致不同线程观察到不同的结果。这种内存模型的一致性问题使得确定哪个操作“先发生”变得非常困难且不确定。\n未定义行为 (Undefined Behavior)：从 C++11 标准开始，数据竞争被明确规定为未定义行为。这意味着，如果你的程序发生了数据竞争，编译器可以自由地产生任何行为，无论是崩溃、产生错误结果，还是看似正常运行但结果不可预测。这使得数据竞争成为非常危险且难以调试的并发错误，因为它的表现可能是不确定、不稳定的。\n多线程与多内存的复杂交互：在实际的并发程序中，通常会有多个线程同时访问多个共享内存位置。这些线程和内存之间存在复杂的读（R）写（W）交互。一个线程对一个内存位置的写入可能影响到其他多个线程对该位置的读取，同时，多个内存位置之间也可能存在复杂的依赖关系和缓存一致性问题。这种错综复杂的交互网络进一步加剧了数据竞争的不可预测性。\n为了消灭数据竞争，我们需要保证程序的 serializability ，可能竞争的内存访问要么互斥，要么同步\n实际编程中遇到的数据竞争 bug 大多属于上错了锁和忘记上锁两种情况的变种\nCase 1: 上错了锁\n1 2 void T_1() { spin_lock(\u0026amp;A); sum++; spin_unlock(\u0026amp;A); } void T_2() { spin_lock(\u0026amp;B); sum++; spin_unlock(\u0026amp;B); } Case 2: 忘记上锁\n1 2 void T_1() { spin_lock(\u0026amp;A); sum++; spin_unlock(\u0026amp;A); } void T_2() { sum++; } 但是实际系统面临的情况比这复杂的多，因为\n内存可以是地址空间的任何内存，比如全局变量、堆内存分配的变量、程序的栈…… 访问可以发生在任何代码，比如自己的代码、框架代码、一行没读到的汇编指令、某条 ret 指令 “一行没读到的汇编指令”造成的访问的情况有编译器优化造成的指令重排、硬件层面弱内存模型的内存访问重排、还有一些高层语言操作的隐式内存访问 实际系统中虽然难以避免，但是会尽可能保证底层的结构对上层尽可能封闭来防止这种错误 死锁 死锁 (Deadlock) 是指一个群体中的每个成员都在等待其他成员（包括自身）采取行动的状态\n死锁有两种：\nAA-Deadlock: 自己等待自己\n1 2 3 4 5 6 7 lock(\u0026amp;lk); // lk-\u0026gt;locked == ✅; proceed ... // Possibly in interrupt handler lock(\u0026amp;lk); // while (lk-\u0026gt;locked == ❌) ; 这样的错误虽然看起来很傻，但是在真实程序复杂的控制流中是可能出现的\nABBA-Deadlock: 两个（多个）锁互相等待\n比如 16. 并发控制：同步信号量 中的哲学家吃饭问题\nHow? 想要消除死锁，可以从死锁产生的必要条件入手，通常称为霍尔德（Holt）条件， 可以形象地把锁看成袋子里的球：\n互斥 (Mutual-exclusion)： 一个口袋一个球，即资源是互斥的，一次只能被一个线程占用 如果资源可以共享（例如，只读文件），则不会发生死锁 请求并保持 (Wait-for)： 得到球的人想要更多的球，即一个线程在持有至少一个资源的同时，又在等待获取其他被占用的资源 如果线程在请求新资源时，必须释放所有已持有的资源，则可以避免死锁 不可抢占 (No-preemption)： 不能抢别人的持有的球，即资源不能被强制从持有者手中抢走，只能由持有者自愿释放 如果系统可以抢占资源（例如，通过中断强制释放），则可以打破此条件 循环等待 (Circular-chain)： 形成循环等待的关系，即存在一个线程链 $ T_1, T_2, \\ldots, T_n $，其中 $ T_1 $ 正在等待 $ T_2 $ 占用的资源，$ T_2 $ 正在等待 $ T_3 $ 占用的资源，依此类推，$ T_n $ 正在等待 $ T_1 $ 占用的资源 这四个条件是死锁发生的必要条件，这意味着只要打破任何一个条件，就不会发生死锁了，理论上，我们可以通过破坏这些条件来预防或避免死锁。\n然而，将这套理论应用于实际复杂系统时，会发现它是一个正确的废话，不能称为一个合理的 argument\n对于玩具系统/模型：可以直接证明系统是 deadlock-free 的，因为其状态空间有限，可以通过穷举或形式化方法进行验证 对于真正的复杂系统：很难判断哪个条件最容易被打破，或者说，在保证系统功能性和性能的前提下，打破某个条件可能带来巨大的复杂性或性能开销 实际编程中通常会采用其他策略来预防死锁：\n一个常见的方法是锁排序，其核心思想是：\n任意时刻系统中的锁都是有限的。 给所有锁编号（或者定义一个全局的获取顺序） 线程在获取多个锁时，严格按照从小数到大的顺序获取锁 这种策略也相对容易检查和验证。 这样在任意时刻总有一个线程获得“编号最大”的锁，于是这个线程总是可以继续运行\n然而这种方法在实践中会遇到问题，代码的文档并不总是可靠，并且对于复杂系统这是难以扩展的；而最好的锁是封装的，并不会暴露出来，这样使用代码的人甚至不需要知道正在使用锁\nSome Methods 为了应对死锁，尤其是 ABBA-Deadlock，一些工具被开发出来，例如 Linux 内核中的 LockDep\n一个简单的想法：\n每次 acquire/release 锁时，都打印一个日志 如果任何线程存在 $ A\\to B $ 和 $ B\\to A $ 的依赖关系，就报告死锁 这可能导致 false positives ，比如存在同步机制 ($ A\\to B\\to \\mathrm{spawn}\\to B\\to A $) 通过优化这个方法可以得到一个相对高效的实现：动态维护“锁依赖图“并检测环路\n原子性和顺序违反 并发编程是本质困难的，我们只能用 sequential 的方式来理解并发：把程序分成若干的块，每一块的操作都是原子的，无法被打断\n并发的机制可以分成两类：\n互斥锁实现原子性 忘记上锁会导致原子性违反 (Atomicity Violation, AV) 条件变量/信号量实现先后顺序同步 忘记同步会导致顺序违反 (Order Violation, OV) 并发的机制完全是“后果自负”的，这也导致了 Threads cannot be implemented as a library ，因为？\n有研究统计了很多真是系统存在的并发 bug，发现 97% 的非死锁并发 bug 都是原子性或顺序错误\nAtomic Violation 代码被别的线程“强行插入”，即使分别上锁消除了数据竞争，还是会导致 AV\n比如图中的例子：\n如果在 Thread 1 结束判断进入 if 之后 Thread 2 再执行，就导致了错误\n并且注意到操作系统的状态也是共享状态，利用一样的原理还可能产生更难发现的 bug\n攻击者在 check 之后马上替换文件为符号链接，就可以造成权限问题等严重安全漏洞\nOrder Violation 事件没有按照预定的顺序发生，就会导致 OV ，比如 如果 Thread 2 中的 S4 发生在了条件变量的初始化之前，那么相当于全局的广播被吞掉了，就可能会导致 Thread 1 可能无法被唤醒\nHowever 我们可以使用加强版的 LockDep 来解决这些问题，比如直接分析程序的日志，检查有没有不相交的锁，事件的 happens-before 关系是否正确……甚至也可以直接用启发式（或者 LLM ）来分析日志是否正确\n然而即使这样也不能解决真实世界的所有并发问题，比如这个 GhostRace 的例子\n实现了正确的互斥、正确的同步 $ \\text{use}\\to\\text{free} $ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 void T_A() { lock(\u0026amp;obj-\u0026gt;lock); free(obj-\u0026gt;something); obj-\u0026gt;something = NULL; unlock(\u0026amp;obj-\u0026gt;lock); } void T_B() { lock(\u0026amp;obj-\u0026gt;lock); if (obj-\u0026gt;something) { // changes cache on speculative execution } unlock(\u0026amp;obj-\u0026gt;lock); } 实际上导致问题的是现代 CPU 的推测执行的特性，为了提高效率会提前通过分治预测器预判执行的方向，提前执行指令\n这段代码中线程 $ T_{B} $ 的 CPU 会在正式获得锁并判断 NULL 之前就提前推测性执行 if 块内部的代码，如果此时 $ T_{A} $ 恰好释放了 obj-something 指向的内存，那么 $ T_{B} $ 中就会访问到一块已经被释放的内存，从而通过缓存等方式泄露信息（虽然错误执行的语句已经回滚了，但是被加载到缓存中的数据等不会回滚），通过这种方式就有可能访问到程序本来没有权限访问的内存，从而产生安全漏洞\n这种并发 bug 的根源在于软件层面的同步无法约束硬件层面的行为\n","permalink":"https://diefish1024.github.io/posts/class-notes/nju-os-2025/17-%E5%B9%B6%E5%8F%91-bugs/","summary":"\u003ch2 id=\"数据竞争\"\u003e数据竞争\u003c/h2\u003e\n\u003cp\u003e大多并发 bug 最后都会体现为\u003cstrong\u003e数据竞争 (Data Race)\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e对于顺序程序而言，函数 \u003ccode\u003ef()\u003c/code\u003e 返回之后就已经完成了所有的状态修改，对于其他部分而言这个修改是立即生效的；如果对于并发程序而言模式的切换也在瞬间完成，那就不会导致并发的问题\u003c/p\u003e\n\u003cp\u003e然而实际上模式的切换需要时间，执行的操作在未来一段时间之后才会就绪，但是我们在实际编程时总是容易有“立即生效”的肌肉记忆，这就导致了并发问题的可能性\u003c/p\u003e\n\u003cp\u003e不过对于\u003cstrong\u003e函数式编程\u003c/strong\u003e而言，操作不存在对外状态的修改，没有副作用（只会操作局部变量），这就不会导致并发问题\u003c/p\u003e\n\u003cp\u003eData Race 发生的实质是\u003cstrong\u003e不同的线程\u003c/strong\u003e同时访问\u003cstrong\u003e同一内存\u003c/strong\u003e，并且\u003cstrong\u003e至少有一个是写\u003c/strong\u003e，形象的理解就是不同的内存访问在“赛跑”，跑赢的操作先执行\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eNot that easy\u003c/strong\u003e: 虽然我们将数据竞争形象地比喻为“赛跑”，但实际上，哪一个操作能“跑赢”并没有想象中那么简单和确定，其复杂性主要体现在以下几个方面\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e弱内存模型 (Weak memory model)\u003c/strong\u003e：在现代处理器架构中，为了提升性能，处理器可能会对内存操作进行重排序。这意味着，不同的线程或“观察者”在不同时间点看到共享内存的状态可能是不一致的。一个线程对内存的写入操作，可能不会立即对所有其他线程可见，导致不同线程观察到不同的结果。这种\u003cstrong\u003e内存模型的一致性问题\u003c/strong\u003e使得确定哪个操作“先发生”变得非常困难且不确定。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e未定义行为 (Undefined Behavior)\u003c/strong\u003e：从 C++11 标准开始，数据竞争被明确规定为\u003cstrong\u003e未定义行为\u003c/strong\u003e。这意味着，如果你的程序发生了数据竞争，编译器可以自由地产生任何行为，无论是崩溃、产生错误结果，还是看似正常运行但结果不可预测。这使得数据竞争成为非常危险且难以调试的并发错误，因为它的表现可能是不确定、不稳定的。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e多线程与多内存的复杂交互\u003c/strong\u003e：在实际的并发程序中，通常会有多个线程同时访问多个共享内存位置。这些线程和内存之间存在复杂的读（R）写（W）交互。一个线程对一个内存位置的写入可能影响到其他多个线程对该位置的读取，同时，多个内存位置之间也可能存在复杂的依赖关系和缓存一致性问题。这种错综复杂的交互网络进一步加剧了数据竞争的不可预测性。\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e为了消灭数据竞争，我们需要保证程序的 serializability ，\u003cstrong\u003e可能竞争的内存访问要么互斥，要么同步\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e实际编程中遇到的数据竞争 bug 大多属于\u003cstrong\u003e上错了锁\u003c/strong\u003e和\u003cstrong\u003e忘记上锁\u003c/strong\u003e两种情况的变种\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eCase 1: 上错了锁\u003c/strong\u003e\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cdiv class=\"chroma\"\u003e\n\u003ctable class=\"lntable\"\u003e\u003ctr\u003e\u003ctd class=\"lntd\"\u003e\n\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode\u003e\u003cspan class=\"lnt\"\u003e1\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e2\n\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\n\u003ctd class=\"lntd\"\u003e\n\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-c\" data-lang=\"c\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"kt\"\u003evoid\u003c/span\u003e \u003cspan class=\"nf\"\u003eT_1\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e \u003cspan class=\"nf\"\u003espin_lock\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"o\"\u003e\u0026amp;\u003c/span\u003e\u003cspan class=\"n\"\u003eA\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e \u003cspan class=\"n\"\u003esum\u003c/span\u003e\u003cspan class=\"o\"\u003e++\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e \u003cspan class=\"nf\"\u003espin_unlock\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"o\"\u003e\u0026amp;\u003c/span\u003e\u003cspan class=\"n\"\u003eA\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e \u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"kt\"\u003evoid\u003c/span\u003e \u003cspan class=\"nf\"\u003eT_2\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e \u003cspan class=\"nf\"\u003espin_lock\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"o\"\u003e\u0026amp;\u003c/span\u003e\u003cspan class=\"n\"\u003eB\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e \u003cspan class=\"n\"\u003esum\u003c/span\u003e\u003cspan class=\"o\"\u003e++\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e \u003cspan class=\"nf\"\u003espin_unlock\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"o\"\u003e\u0026amp;\u003c/span\u003e\u003cspan class=\"n\"\u003eB\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e \u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\u003c/tr\u003e\u003c/table\u003e\n\u003c/div\u003e\n\u003c/div\u003e\u003cp\u003e\u003cstrong\u003eCase 2: 忘记上锁\u003c/strong\u003e\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cdiv class=\"chroma\"\u003e\n\u003ctable class=\"lntable\"\u003e\u003ctr\u003e\u003ctd class=\"lntd\"\u003e\n\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode\u003e\u003cspan class=\"lnt\"\u003e1\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e2\n\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\n\u003ctd class=\"lntd\"\u003e\n\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-c\" data-lang=\"c\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"kt\"\u003evoid\u003c/span\u003e \u003cspan class=\"nf\"\u003eT_1\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e \u003cspan class=\"nf\"\u003espin_lock\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"o\"\u003e\u0026amp;\u003c/span\u003e\u003cspan class=\"n\"\u003eA\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e \u003cspan class=\"n\"\u003esum\u003c/span\u003e\u003cspan class=\"o\"\u003e++\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e \u003cspan class=\"nf\"\u003espin_unlock\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"o\"\u003e\u0026amp;\u003c/span\u003e\u003cspan class=\"n\"\u003eA\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e \u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"kt\"\u003evoid\u003c/span\u003e \u003cspan class=\"nf\"\u003eT_2\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e \u003cspan class=\"n\"\u003esum\u003c/span\u003e\u003cspan class=\"o\"\u003e++\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e \u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\u003c/tr\u003e\u003c/table\u003e\n\u003c/div\u003e\n\u003c/div\u003e\u003cp\u003e但是实际系统面临的情况比这复杂的多，因为\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e内存可以是地址空间的任何内存，比如全局变量、堆内存分配的变量、程序的栈……\u003c/li\u003e\n\u003cli\u003e访问可以发生在任何代码，比如自己的代码、框架代码、一行没读到的汇编指令、某条 ret 指令\n\u003cul\u003e\n\u003cli\u003e“一行没读到的汇编指令”造成的访问的情况有编译器优化造成的指令重排、硬件层面弱内存模型的内存访问重排、还有一些高层语言操作的隐式内存访问\u003c/li\u003e\n\u003cli\u003e实际系统中虽然难以避免，但是会尽可能保证底层的结构对上层尽可能封闭来防止这种错误\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"死锁\"\u003e死锁\u003c/h2\u003e\n\u003cp\u003e\u003cstrong\u003e死锁 (Deadlock)\u003c/strong\u003e 是指一个群体中的每个成员都在等待其他成员（包括自身）采取行动的状态\u003c/p\u003e\n\u003cp\u003e死锁有两种：\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eAA-Deadlock\u003c/strong\u003e: 自己等待自己\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cdiv class=\"chroma\"\u003e\n\u003ctable class=\"lntable\"\u003e\u003ctr\u003e\u003ctd class=\"lntd\"\u003e\n\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode\u003e\u003cspan class=\"lnt\"\u003e1\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e2\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e3\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e4\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e5\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e6\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e7\n\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\n\u003ctd class=\"lntd\"\u003e\n\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-c\" data-lang=\"c\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"nf\"\u003elock\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"o\"\u003e\u0026amp;\u003c/span\u003e\u003cspan class=\"n\"\u003elk\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e// lk-\u0026gt;locked == ✅; proceed\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"p\"\u003e...\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"c1\"\u003e// Possibly in interrupt handler\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"nf\"\u003elock\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"o\"\u003e\u0026amp;\u003c/span\u003e\u003cspan class=\"n\"\u003elk\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"c1\"\u003e// while (lk-\u0026gt;locked == ❌) ;\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\u003c/tr\u003e\u003c/table\u003e\n\u003c/div\u003e\n\u003c/div\u003e\u003cp\u003e这样的错误虽然看起来很傻，但是在真实程序复杂的控制流中是可能出现的\u003c/p\u003e","title":"17. 并发 Bugs"},{"content":"推理效率对于 llm 是一个至关重要的问题。当模型生成文本时，尤其是以自回归方式逐词生成时，效率瓶颈会变得非常明显。KV Cache 就是为了解决这一问题而诞生的技术。\n1. What is KV Cache? KV Cache，全称 Key-Value Cache，是一种优化技术，用于加速 Transformer 架构在自回归生成过程中的推理速度。它的核心思想是缓存并重用在注意力机制中计算得到的 Key (K) 和 Value (V) 向量。\n2. Transformer Attention Mechanism Review 要理解 KV Cache，首先需要对 Transformer 架构中的自注意力机制有一个基本认识。自注意力机制允许模型在处理序列中的某个词时，考虑序列中所有其他词的重要性。\n每个输入 token（词或子词）在进入注意力层时，都会被转换成三个不同的向量：\nQ 向量：代表当前 token 的“查询”信息 K 向量：代表所有 token 的“键”信息，用于与 Query 进行匹配 V 向量：代表所有 token 的“值”信息，用于加权求和，得到最终的输出 自注意力机制的计算过程为以下步骤：\n计算 Query 与所有 Key 的点积，得到注意力分数 将注意力分数进行缩放，除以 $ \\sqrt{d_k} $（$ d_k $ 是 Key 向量的维度) 对缩放后的分数进行 Softmax，将其转换为注意力权重，表示每个 token 对当前 token 的重要性 将注意力权重与 Value 向量进行加权求和，得到当前 token 的注意力输出 公式为： $$ \\text{Attention}(Q, K, V) = \\text{softmax}\\left(\\frac{QK^T}{\\sqrt{d_k}}\\right)V $$ 其中矩阵 $ Q,K,V \\in \\mathbb{R}^{L \\times d} $ ，$ L $ 为当前上下文长度\n（处于简洁性的考虑，忽略了 Causal Mask ，实际上 $ QK^{T} $ 应该 Mask 成下三角矩阵来强制不能看到序列未来的信息）\n3. The Problem KV Cache Solves 在大型语言模型中，当模型以自回归方式生成文本时（每次生成一个新 token，并将其添加到输入序列中，然后根据整个序列生成下一个 token），会遇到一个效率问题：\n假设我们要生成“中华人民”\n输入：“中” 模型计算“中”的 $ Q, K, V $ 计算 attention ，生成“华” 输入：“中华” 模型再次计算“中”和“华”的 $ Q, K, V $ 计算 attention ，生成“人” 输入：“中华人” 模型再次计算“中”、“华”和“人”的 $ Q, K, V $ 计算 attention ，生成“民” 可以看到，在每一步生成新 token 时，都需要重新计算之前已经处理过的所有 token 的 $ K $ 和 $ V $ 向量。这种重复计算在序列较长时会消耗大量的计算资源和时间，效率低下。\n4. How KV Cache Works 根据上面分析得到的问题，很容易想到 KV Cache 的核心思想：将已经计算过的 Key 和 Value 向量缓存起来，在后续的生成步骤中直接重用，而不是重新计算。\n以生成“中华人民”为例，使用 KV Cache 的流程如下：\n输入：“中” 计算“中”的 $ K_1, V_1 $ 将 $ K_1, V_1 $ 存入 KV Cache 使用 $ Q_1, K_1, V_1 $ 计算 attention ，生成“华” 输入：“华”（当前 token 只有“华”，但注意力要关注整个序列“中华”） 计算“华”的 $ K_2, V_2 $ 将 $ K_2, V_2 $ 添加到 KV Cache。此时 KV Cache 包含 $ [K_1, K_2] $ 和 $ [V_1, V_2] $ 使用当前 $ Q_2 $ 和缓存中的 $ [K_1, K_2], [V_1, V_2] $ 计算 attention ，生成“人” 输入：“人” 计算“人”的 $ K_3, V_3 $ 将 $ K_3, V_3 $ 添加到 KV Cache。此时 KV Cache 包含 $ [K_1, K_2, K_3] $ 和 $ [V_1, V_2, V_3] $ 使用当前 $ Q_3 $ 和缓存中的 $ [K_1, K_2, K_3], [V_1, V_2, V_3] $ 计算 attention ，生成“民” 通过这种方式，每一步只需要计算当前新生成 token 的 $ K, V $ 向量，而无需重新计算之前所有 token 的 $ K, V $。\n5. Why Not QKV Cache? 可能会好奇，既然 K 和 V 都需要缓存，为什么不也缓存 Q 呢？也就是说，为什么是 KV Cache 而不是 QKV Cache？\n原因在于 Q 向量的性质：\nQ 向量是用来“查询”当前 token 与序列中其他 token 的相关性的。在自回归生成过程中，每一步生成一个新的 token，这个新 token 对应的 Query 向量是新的，它基于当前步的隐藏状态计算得出。换句话说，每次生成新 token 时，其对应的 $ Q $ 向量都是独一无二的，并且需要重新计算以反映最新的生成上下文。 K 和 V 向量则代表了序列中每个 token 的“内容”信息。对于已经处理过的 token，它们的 $ K $ 和 $ V $ 向量一旦计算出来，其内容信息就是固定不变的。因此，这些 $ K $ 和 $ V $ 向量可以直接被缓存并反复使用，而无需重新计算。 因此，不缓存 Q 是因为它在每一步都是一个新的计算结果；而缓存 K 和 V 则可以显著减少重复计算，从而提高效率。\n6. KV Cache in Attention Mechanism 在数学上，当使用 KV Cache 进行自回归解码时，注意力公式中的 $ K $ 和 $ V $ 矩阵会随着生成过程的进行而不断增长。\n假设我们正在生成第 $ t $ 个 token。\n当前 token 的 Q 向量是 $ Q_t $ ，这是一个行向量，代表当前第 $ t $ 个 token 的 Query ，维度为 $ 1 \\times d_k $ K 矩阵 $ K_{\\text{cached}} $ 将包含从第一个 token 到第 $ t $ 个 token 的所有 K 向量： $ K_{\\text{cached}} = [K_1^T, K_2^T, \\dots, K_t^T]^T $ ，维度为 $ t \\times d_k $ V 矩阵 $ V_{\\text{cached}} $ 将包含从第一个 token 到第 $ t $ 个 token 的所有 V 向量： $ V_{\\text{cached}} = [V_1^T, V_2^T, \\dots, V_t^T]^T $ 。其维度为 $ t \\times d_v $ 那么，第 $ t $ 个 token 的注意力计算变为： $$ \\text{Attention}_{t}(Q_t, K_{\\text{cached}}, V_{\\text{cached}}) = \\text{softmax}\\left(\\frac{Q_t K_{\\text{cached}}^T}{\\sqrt{d_k}}\\right)V_{\\text{cached}} $$ 其中\n$ Q_t K_{\\text{cached}}^T $ 是一个 $ 1 \\times t $ 的行向量，代表当前 Query 与所有历史 Key 的相关性分数 $ \\text{softmax} $ 操作将这个 $ 1 \\times t $ 的向量转化为注意力权重 这个 $ 1 \\times t $ 的注意力权重向量再与 $ V_{\\text{cached}} $ 矩阵（维度 $ t \\times d_v $）相乘，得到最终的注意力输出，维度是 $ 1 \\times d_v $ 每次生成新的 token $ t+1 $ 时，我们只需要计算新的 $ Q_{t+1} $，将新计算的 $ K_{t+1} $ 和 $ V_{t+1} $ 拼接到 $ K_{\\text{cached}} $ 和 $ V_{\\text{cached}} $ 末尾，形成 $ K'_{\\text{cached}} = \\text{concat}(K_{\\text{cached}}, K_{t+1}) $ 和 $ V'_{\\text{cached}} = \\text{concat}(V_{\\text{cached}}, V_{t+1}) $\n7. Limitations and Considerations 尽管 KV Cache 带来了巨大的性能提升，但也存在一些问题：\n内存占用：KV Cache 需要存储所有已处理 token 的 Key 和 Value 向量。对于大型模型和长上下文序列，这些缓存可能非常大，导致显存（GPU Memory）成为瓶颈。 上下文长度限制：由于内存限制，KV Cache 会限制模型能够处理的最大上下文长度。一旦达到内存上限，就需要采取策略来管理缓存，例如丢弃最早的 Key/Value 对（类似于循环缓冲区），但这可能会影响模型对长距离依赖的理解。 Summary KV Cache 是 Transformer 模型在自回归推理过程中非常重要的一种优化技术。通过缓存并重用已经计算过的 Key 和 Value 向量，它极大地减少了重复计算，从而显著提升了大型语言模型的生成速度。\nReferences KV Cache 原理讲解 （Bilibili） 注意：此视频内容存在部分错误 看图学KV Cache（知乎） 为什么没有Q Cache（知乎） ","permalink":"https://diefish1024.github.io/posts/ai-infra/kv-cache-%E5%85%A5%E9%97%A8/","summary":"\u003cp\u003e推理效率对于 llm 是一个至关重要的问题。当模型生成文本时，尤其是以自回归方式逐词生成时，效率瓶颈会变得非常明显。KV Cache 就是为了解决这一问题而诞生的技术。\u003c/p\u003e\n\u003ch2 id=\"1-what-is-kv-cache\"\u003e1. What is KV Cache?\u003c/h2\u003e\n\u003cp\u003eKV Cache，全称 \u003cstrong\u003eKey-Value Cache\u003c/strong\u003e，是一种优化技术，用于加速 Transformer 架构在自回归生成过程中的推理速度。它的核心思想是\u003cstrong\u003e缓存\u003c/strong\u003e并\u003cstrong\u003e重用\u003c/strong\u003e在注意力机制中计算得到的 \u003cstrong\u003eKey (K)\u003c/strong\u003e 和 \u003cstrong\u003eValue (V)\u003c/strong\u003e 向量。\u003c/p\u003e\n\u003ch2 id=\"2-transformer-attention-mechanism-review\"\u003e2. Transformer Attention Mechanism Review\u003c/h2\u003e\n\u003cp\u003e要理解 KV Cache，首先需要对 Transformer 架构中的自注意力机制有一个基本认识。自注意力机制允许模型在处理序列中的某个词时，考虑序列中所有其他词的重要性。\u003c/p\u003e\n\u003cp\u003e每个输入 token（词或子词）在进入注意力层时，都会被转换成三个不同的向量：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eQ 向量：代表当前 token 的“查询”信息\u003c/li\u003e\n\u003cli\u003eK 向量：代表所有 token 的“键”信息，用于与 Query 进行匹配\u003c/li\u003e\n\u003cli\u003eV 向量：代表所有 token 的“值”信息，用于加权求和，得到最终的输出\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e自注意力机制的计算过程为以下步骤：\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e计算 Query 与所有 Key 的点积，得到\u003cstrong\u003e注意力分数\u003c/strong\u003e\u003c/li\u003e\n\u003cli\u003e将注意力分数进行缩放，除以 $ \\sqrt{d_k} $（$ d_k $ 是 Key 向量的维度)\u003c/li\u003e\n\u003cli\u003e对缩放后的分数进行 Softmax，将其转换为\u003cstrong\u003e注意力权重\u003c/strong\u003e，表示每个 token 对当前 token 的重要性\u003c/li\u003e\n\u003cli\u003e将注意力权重与 Value 向量进行加权求和，得到当前 token 的注意力输出\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e公式为：\n$$ \n\n\\text{Attention}(Q, K, V) = \\text{softmax}\\left(\\frac{QK^T}{\\sqrt{d_k}}\\right)V\n\n $$\n其中矩阵 $ Q,K,V \\in \\mathbb{R}^{L \\times d} $ ，$ L $ 为当前上下文长度\u003c/p\u003e","title":"KV Cache 入门"},{"content":"Abstract 问题：现有 EEG 情绪识别方法对长期上下文信息关注不足，导致跨被试泛化能力减弱 方案：提出 Emotion Transformer (EmT) ，为 Graph-Transformer 混和架构 核心模块： TGC：将 EEG 信号转换为时序图序列 RMPG：使用残差多视图金字塔 GCN，学习动态、多尺度的空间连接模式，生成 token（核心） TCT：使用任务自适应的 Transformer，学习 token 序列上下文（核心） TSO：输出分类/回归结果 成果：在多个公开数据集的广义跨被试任务上面超过了 baseline Introduction \u0026amp; Related Work 为什么 EEG 难以使用跨被试 (cross-subject) 的场景？\n个体差异：不同被试生理结构和认知策略差异，导致 EEG 模式不同 低信噪比：EEG 信号容易受到外源噪声干扰（肌电、眼电……） 目标是学习一种跨被试共享、具有泛化能力的情绪表征\nGpaph Neural Networks 核心思想：EEG 数据具有非欧图结构，适合使用 GNN 来处理 代表工作： ChebyNet：使用切比雪夫多项式近似光谱滤波，EmT 模型中采用其作为 GCN 层 GCN：通过局部一阶聚合近似光谱滤波 DGCNN / RGNN：使用 GNNs 提取 EEG 空间信息；依赖单一的邻接矩阵，忽略时序上下文，具有局限性；而 EmT 通过多视图可学习邻接矩阵和时序图来弥补 Temporal Context Learning 核心理念：情绪是连续认知过程，EEG 信号中嵌入时序上下文信息 代表工作： LSTM / TCN / TESANet / Conformer / AMDET 局限性：这些方法通常从扁平化的 EEG 特征向量学习，可能未能有效学习空间关系；EmT 则通过并行 GCN 和 STA 层更有效地捕捉时空信息 EEG Emotion Recognition 核心理念：EEG 情绪识别面临个体差异大、信噪比低等挑战，需提取光谱、空间、时序特征 代表工作： GCB-Net / TSception 局限性：没有关注长时序上下文信息 Method EmT 是一个端到端的框架，包含四大模块：\nraw EEG -\u0026gt; TGC -\u0026gt; 时序图 -\u0026gt; RMPG -\u0026gt; Tokens -\u0026gt; TCT -\u0026gt; 深层特征 -\u0026gt; TSO -\u0026gt; Result\nEEG-Temporal-Graph Representations (TGC) 目标：将连续的 EEG 信号转化为结构化的时序图序列\n图：每个“图”是指在一个短的窗口内大脑状态的数学表示，图中的每个节点对应一个 EEG 电极通道，节点的特征是该通道在 7 个不同的频段上的 rPSD 时序序列：序列是通过滑动窗口技术截取的一段较长的 EEG 数据里面切分成许多重叠的短的子片段，每个子片段生成的图所形成的序列 双层滑动窗口分段：为了捕捉不同时间尺度上的信息，TGC 采用了一种双层分段策略\n首先将一次完整实验的 (trail) 的 EEG 数据，表示为 $ X \\in \\mathbb{R}^{c \\times L} $ （其中 $ c $ 为通道数，$ L $ 为总采样点数），通过一个较长的滑动窗口（长度为 $ l $ ，步长为 $ s $ ）分割成多个重叠的长片段 $ \\overline{X} \\in \\mathbb{R}^{c \\times l} $ 接着对于每一个长片段 $ \\overline{X} $ 使用一个更短的滑动窗口（长度为 $ l' $ ，步长为 $ s' $ ）将其分割为一系列子片段 $ \\tilde{X} \\in \\mathbb{R}^{c \\times l'} $ 这使得模型能够在一个长片段的标签下，观察到内部更精细的信号动态变化，为后续的 Transformer 模块捕捉时间上下文提供了基础 节点特征提取：对于每一个子片段 $ \\tilde{X} $，需要为其对应的图节点（即 EEG 通道）提取有意义的特征，论文选择了相对功率谱密度 (Relative PSD, rPSD) 作为节点属性\n具体地，使用 welch\u0026rsquo;s method 计算每个 EEG 通道在七个经典频带上的 rPSD 这样，每个子片段 $ \\tilde{X} $ 都对应一个特征矩阵 $ F \\in \\mathbb{R}^{c \\times f} $，其中 $ f=7 $ 最终，一个长片段 $ \\overline{X} $ 被转换成一个按时间顺序排列的图序列 $ G_{T} = \\{\\mathcal{G}^{i}\\} \\in \\mathbb{R}^{seq \\times c \\times f} $，其中 $ seq $ 是子片段的数量。这个时间图序列就是 RMPG 模块的输入\nResidual Multiview Pyramid GCN (RMPG) 核心：解决传统 GNN“单一视角”问题，为时间图序列 $ G_{T} $​ 中的每一个图 $ \\mathcal{G}^i $ 学习一个丰富的、多层次的空间表征，并将其压缩成一个单一的 token ，以供后续的 TCT 模块处理\nRMPG 模块由一个基础的图编码器 $ \\Phi_{g}(\\cdot) $ 构成，文中采用了 ChebyNet 作为基础图编码器，对于给定特征输入 $ F^{m-1} $ 和邻接矩阵 $ A $ （通过拉普拉斯算子 $ \\hat{L} $ 转换） $$ \\Phi_{g}(F^{m}, A) = \\sigma\\left( \\sum_{k=0}^{K-1}\\theta_{k}^{m}T_{k}(\\hat{L})F^{m-1} - b^{m}\\right) $$ 其中 $ m $ 为 GCN 层的索引，$ \\sigma $ 为 ReLU 激活函数，$ \\theta $ 为参数，$ T_{k} $ 为 $ k $ 阶 Chebyshev 多项式\n多视图学习 (Multiview Learning) ：为了模拟情绪背后多种认知子过程驱动的不同大脑连接模式，RMPG 并非使用单一的图卷积网络，而是并行地使用了多个 GCN 分支，$ \\{ \\Phi_{g}^{0}(\\cdot), \\Phi_{g}^{1}(\\cdot), \\dots, \\Phi_{g}^{i}(\\cdot) \\} $\n每个分支都拥有一个独立的可学习邻接矩阵 $ A^{i} \\in \\mathbb{R}^{c \\times c} $ ，能在模型训练过程中通过梯度反向传播进行端到端的优化 这意味着每个 GCN 分支都能从数据中学习到一种独特的大脑功能连接“视图” 金字塔学习 (Pyramid Learning) ：为了捕捉不同尺度的空间信息，并行的 GCN 分支被设计成具有不同的深度（即 GCN 层数）\n较浅的 GCN 能够有效地聚合全局的、跨脑区的功能连接信息，聚合远距离节点的信息而不过度平滑 较深的 GCN 能够更好地聚合局部邻域内的信息，在脑区内部形成一致的表征 GCN 的深度越深，其输出所代表的特征金字塔层级越高。 残差连接 (Residual) ：除了并行的 GCN 分支外，RMPG 还包含一个并行的线性残差分支。该分支直接对原始的时序图 $ G $ （或者对应的特征矩阵 $ F $ ）进行线性投影，不经过任何图卷积，从而保留最原始的节点信息，作为特征金字塔的“基座”\n线性投影层 $ LP(\\cdot) $ 将扁平化的图表示投影到隐藏嵌入 $ H_{g}^{i} \\in \\mathbb{R}^{d_{g}} $ 堆叠来自不同层的 GCN 的并行输出，得到多金字塔视图嵌入 $$ \\{ H_{g}^{i} \\} = \\{ LP^{i}(\\Gamma(\\Phi_{g}^{i}(F, A^{i}))) \\} $$ 其中 $ \\Gamma(\\cdot) $ 是扁平操作，$ \\{ \\cdot \\} $ 是堆叠操作 特征融合与 Token 生成：最终，对于图序列中的每一个图 $ G_{i} $，其所有 GCN 视图的输出 $ \\{ H_{i}^{g} \\} $ 和残差基座 $ H_{g-\\text{base}} $​ 通过一个 mean fusion 操作合并成当前时间步 $ i $ 的最终 token $ s_{i} $ $$ s_{i} = \\text{mean}(\\{ H_{g-\\text{base}}, H_{g}^{0}, H_{g}^{1}, \\dots, H_{g}^{i} \\}) $$\n通过 RMPG 模块，输入的图序列 $ G_{T} $ 被高效地转化为一个 token 序列 $ S_{T}=\\{ s^{i} \\} \\in \\mathbb{R}^{seq \\times d_{g}} $ ，这个序列既蕴含了每个时刻丰富的多视图、多层次空间信息，又具备了适合 Transformer 处理的格式\nTemporal Contextual Transformer (TCT) 核心：接受由 RMPG 生成的 token 序列 $ S_{T} $ ，并利用 Transformer 的结构来高效捕捉这些 token 之间的时间依赖关系；与标准的 Transformer 不同，TCT 引入了两种为 EEG 情绪识别任务定制的 Token Mixer，分别用于分类和回归任务\nTCT 模块由多个堆叠的 Transformer Block 组成，对于输入 token 序列 $ Z^{m} $ （ $ Z^{0} = S_{T} $ ），每个 Block 的计算过程为 $$ Z^{m'} = \\text{TokenMixer}(\\text{Norm}(Z^{m})) + Z^{m} $$ $$ Z^{m+1} = \\text{MLP}(\\text{Norm}(Z^{m'})) + Z^{m'} $$ 其中 $ m $ 是层的索引，MLP 是带 ReLU 激活函数的两层感知机\n$ \\text{TokenMixer}_{\\text{clas}} $ for Classification Tasks 旨在捕捉随时间变化的长短时序上下文信息\n多头自注意力 (Multi-head Self-Attention, MSA) ：用于全局地关注序列中与整体情绪状态高度相关的部分 $$ \\text{Attn}(Q,K,V) = \\text{softmax}\\left( \\frac{QK^{T}}{\\sqrt{ d }} \\right)V $$\n并行应用多个注意力头（每个头有独立的 $ LP_h(\\cdot) $ 来生成 $ Q, K, V $），然后将所有头的输出拼接：$$ \\text{MSA}(S_{T}) = \\text{Concat}(\\text{Attn}(LP_0(S_{T})), ..., \\text{Attn}(LP_{n_{\\text{head}}-1}(S_{T}))) $$ 其中 $ S_{T} $ 是 token 序列，$ n_{\\text{head}} $ 是注意力头的数量 短期聚合层 (Short-Time Aggregation, STA) ：\n基于“情绪短期连续而长期变化”的先验知识，STA 在 MSA 之后应用来学习短期的上下文信息 首先对 MSA 的输出 $ H_{\\text{attn}} \\in \\mathbb{R}^{n_{\\text{head}} \\times \\text{seq} \\times d_{\\text{head}}} $ 应用一个带有比例因子 $ \\alpha $ 的 Dropout 层 $ \\text{dp}(\\alpha) $ 接着，通过 Conv2D 聚合 $ n_{\\text{anchor}} $ 个时序近邻 Conv2D 的卷积核 $ K_{\\text{cnn}} $ 的尺寸为 $ (n_{\\text{anchor}}, 1) $，步长为 $ (1,1) $ 最后，卷积的输出会被 Reshape 并进行线性投影（$ W_{\\text{sta}} $） 可以描述为 $$ \\text{STA}(H_{\\text{attn}}) = \\text{Reshape}(\\text{Conv2D}(\\text{dp}(H_{\\text{attn}}), K_{\\text{cnn}})) W_{\\text{sta}} $$ $ \\text{Reshape}(\\cdot) $ 将维度从 $ (n_{\\text{head}},\\text{seq},d_{\\text{head}}) $ 转换为 $ (\\text{seq}, n_{\\text{head}} \\cdot d_{\\text{head}}) $ ， $ W_{\\text{sta}} \\in \\mathbb{R}^{n_{\\text{head}} \\cdot d_{\\text{head}} \\times d_g} $ 是投影权重矩阵 $ \\text{TokenMixer}_{\\text{Clas}} $ 最终由上述两个模块串联构成 $$ \\text{TokenMixer}_{\\text{clas}}(S_{T}) = \\text{STA}(\\text{MSA}(S_{T})) $$\n$ \\text{TokenMixer}_{\\text{regr}} $ for Regression Tasks 旨在预测序列中情绪状态的连续变化\n不同于分类任务：分类任务的目标通常是从整个序列中提取几个核心特征来判断整体情绪状态，这通过 MSA 聚焦于重要部分是有效的；然而回归任务需要模型对序列中每个时步的连续情绪变化进行预测，因此不使用全局的 MSA，而是采用了一种基于 RNN 的混合器（ RNN family ）\nRNN Mixer ：\nRNN 结构天然适合处理连续序列的演变过程，能够更好地建模情绪值的平滑变化 经验性选择的两层双向 GRU (bi-directional GRU) 作为 $ \\text{TokenMixer}_{\\text{regr}} $ ，输出长度为 $ 2 \\times d_{\\text{head}} $ 计算过程为 $$ \\text{TokenMixer}_{\\text{regr}}(S_T) = \\text{RNNs}(\\text{LP}(S_T)) $$ 其中 $ LP(S_{T}) = S_{T}W_{v} $ ，把 token 序列投影为 $ V $ 值\nTSO Module 头部接收来自不同 Token Mixer 的输出：用于分类的 $ S_{\\text{clas}} $ 和用于回归的 $ S_{\\text{regr}} $\n分类任务：对所有 token 进行 mean fusion ，再通过线性层得到最终 logits $$ \\hat{Y}_{\\text{clas}} = \\text{mean}(S_{\\text{clas}})W_{\\text{clas}} + b_{\\text{clas}} $$ 其中 $ S_{\\text{clas}} \\in \\mathbb{R}^{\\text{seq} \\times d_{\\text{head}}} $ ，$ W_{\\text{clas}} \\in \\mathbb{R}^{d_{\\text{head}} \\times d_{\\text{class}}} $ ，$ b_{\\text{clas}} \\in \\mathbb{R}^{n_{\\text{class}}} $\n回归任务：直接将每个时间步的 token 特征通过线性层，得到对应每个时刻的回归值 $$ \\hat{Y}_{\\text{regr}} = S_{\\text{regr}}W_{\\text{regr}} + b_{\\text{regr}} $$ 其中 $ S_{\\text{regr}} \\in \\mathbb{R}^{\\text{seq} \\times 2\\cdot d_{\\text{head}}} $ （双向），$ W_{\\text{regr}} \\in \\mathbb{R}^{2\\cdot d_{\\text{head}} \\times 1} $ ，$ b_{\\text{regr}} \\in \\mathbb{R} $\nExperiment Datasets 使用 SEED, THU-EP, FACED, MAHNOB-HCI 四个公开数据集\n其中 SEED 数据集使用了 0.3-50 Hz 的带通滤波\nEEG-Temporal-Graph 长片段：窗口长度 $ l=20\\,\\mathrm{s} $ （即 $ 20 \\times f_{s} $ ），步长 $ s=4\\,\\mathrm{s} $ 子片段： 对于 SEED 和 THU-EP： $ l'=2\\,\\mathrm{s},s'=0.5\\,\\mathrm{s} $ 对于 FACED： $ l'=4\\,\\mathrm{s},s'=1\\,\\mathrm{s} $ Settings 数据划分： SEED：采用留一被试交叉验证，每次迭代一个被试的数据作为测试集，剩余数据中 80% 作为训练集，20% 作为验证集 THU-EP 和 FACED：采用留 $ n $ 被试交叉验证，其中 $ n_{\\text{THU-EP}}=8,n_{\\text{FACED}}=12 $ ，训练数据中 10% 作为验证集 分类任务：对 SEED、THU-EP 和 FACED 进行积极/消极情绪的二分类，THU-EP 和 FACED 的效价分数通过阈值 3.0 划分为高/低效价 回归任务：MAHNOB-HCI 并进行 LOSO 验证 Evaluation Metrics Classfication Accuracy：$$ \\text{Accuracy} = \\frac{\\text{TP + TN}}{\\text{TP + FP + TN + FN}} $$ F1 Score：$$ \\text{F1} = 2 \\times \\frac{\\text{Precision} \\times \\text{Recall}}{\\text{Precision + Recall}} = \\frac{\\text{TP}}{\\text{TP} + \\frac{1}{2}(\\text{FP} + \\text{FN})} $$ 其中 $ \\text{TP} $ 表示真阳性，$ \\text{TN} $ 表示真阴性，$ \\text{FP} $ 表示假阳性，$ \\text{FN} $ 表示假阴性\nRegression 给定预测值 $ \\hat{y} $ 和连续标签 $ y $ ：\n均方根误差 (RMSE) ：$$ \\text{RMSE} = \\sqrt{\\frac{1}{N} \\sum_{i=0}^{N-1} (\\hat{y}_i - y_i)^2} $$ 皮尔逊相关系数 (PCC) ：$$ \\text{PCC} = \\frac{\\sigma_{\\hat{y}y}}{\\sigma_{\\hat{y}} \\sigma_y} = \\frac{\\sum_{i=0}^{N-1} (\\hat{y}_i - \\mu_{\\hat{y}})(\\hat{y}_i - \\mu_y)}{\\sqrt{\\sum_{i=0}^{N-1} (\\hat{y}_i - \\mu_{\\hat{y}})^2} \\sqrt{\\sum_{i=0}^{N-1} (y_i - \\mu_y)^2}} $$ 一致性相关系数 (CCC) ：$$ \\text{CCC} = \\frac{2\\sigma_{\\hat{y}y}}{\\sigma^2_{\\hat{y}} + \\sigma^2_y + (\\mu_{\\hat{y}} - \\mu_y)^2} $$ 其中 $ N $ 是向量中的元素数量，$ \\sigma_{\\hat{y}y} $ 是协方差，$ \\sigma_{\\hat{y}} $ 和 $ \\sigma_y $ 是标准差，$ \\mu_{\\hat{y}} $ 和 $ \\mu_y $ 是均值\nImplementation Details 模型的三种变体： Analyses Classification SEED： EmT-D 表现最佳，EmT-B 和 EmT-S 表现也良好，RGNN 表现第二佳 使用特征作为输入的模型通常优于直接使用 EEG 信号作为输入的模型，从时序特征而非直接特征学习通常能取得更好的性能（RGNN 除外），这表明了学习时序上下文信息的有效性，EmT 借助基于 GCN 的模块，能更好地学习空间信息 THU-EP / FACED： THU-EP：EmT-B 取得了最佳 F1 分数，Conformer 取得了最佳 ACC FACED：EmT-B 取得了第二佳 ACC 和最佳 F1 分数 由于类不平衡，F1 分数比 ACC 更重要，EmT-B 在这两个数据集上均取得了最高 F1 分数 与 SEED 不同，直接使用 EEG 作为输入的 baseline 模型表现更好，这可能因为这两个数据集的被试人数更多 Features： SEED (62 channels，15 subjects) ：EmT-D (8 层) 表现最佳，说明 Transformer 层数越多，学到的空间信息越丰富 THU-EP 和 FACED (32 channels，more subjects) ：EmT-B (4 层) 表现更好，通道数少且被试间变异性大时，更深的模型（EmT-D）容易过拟合 Regression 在 MAHNOB-HCI 数据集上，EmT-Regr (LP+LSTM) 取得了最低的 RMSE，而 EmT-Regr (LP+GRU) 取得了最佳的 PCC 和 CCC 使用 MSA 作为 Token Mixer 时，模型性能急剧下降，甚至低于所有基线模型 这表明对于回归任务，融合所有片段的信息至关重要，而 RNN 的顺序信息融合能力比 MSA 更适合建模连续的情绪变化 Ablation Study Effect of EEG Features Effect of The Depth and Width of GCNs in RMPG Depth：增加 GCN 层的数量会导致性能显著下降，这与更深 GCN 中存在的过平滑问题一致 Width：宽度从 8 增加到 32 时，性能呈正相关；当宽度进一步增加时，性能下降，这可能是由更大的模型尺寸导致的过拟合 Effect of The Number of TCT Blocks Classfication (SEED) ：TCT 块的数量从 2 增加到 8 时，ACC 和 F1 分数均显著提高，这表明增加 TCT 块数能增强模型捕捉时序上下文信息的能力，从而提升分类性能 Regression (MAHNOB-HCI) ：TCT 块的数量对性能指标几乎没有影响 Visualization Learned Connections 在 SEED 数据集上学习到的两种不同连接模式的可视化证据 在 SEED 数据集上，两个可学习的邻接矩阵揭示了情绪认知过程中不同的连接模式：\n(a) 中主要关注额叶、顶叶和颞叶区域之间的连接，这些区域与心理注意力密切相关 (b) 中则包括额叶、颞叶和顶叶区域之间的互动（与情绪相关），以及枕叶和顶叶区域的互动（与视觉过程相关，因为刺激为视频） Learned Temporal Contextual Information Classfication (FACED) Regression 分类任务在 TCT 块之前，特征随时间变化，TCT 块之后，激活变得更加一致；这可能是因为自注意力机制关注与整体情绪状态高度相关的部分，而 STA 层通过聚合邻近的时序信息来平滑波动 回归任务：特征空间也显示出时序变化；与分类不同，回归特征并非简单平滑，形成了更复杂的表示 总结：TCT 块处理分类和回归任务的方式不同：分类中，特征被平滑以增强可分离性；回归中，RNN Token Mixer 保留了时序变化，从而实现连续情绪预测 ","permalink":"https://diefish1024.github.io/posts/literature-notes/emt/","summary":"\u003ch2 id=\"abstract\"\u003eAbstract\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e问题\u003c/strong\u003e：现有 EEG 情绪识别方法对长期上下文信息关注不足，导致跨被试泛化能力减弱\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e方案\u003c/strong\u003e：提出 \u003cstrong\u003eEmotion Transformer (EmT)\u003c/strong\u003e ，为 Graph-Transformer 混和架构\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e核心模块\u003c/strong\u003e：\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003eTGC\u003c/strong\u003e：将 EEG 信号转换为时序图序列\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eRMPG\u003c/strong\u003e：使用残差多视图金字塔 GCN，学习动态、多尺度的空间连接模式，生成 token（核心）\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eTCT\u003c/strong\u003e：使用任务自适应的 Transformer，学习 token 序列上下文（核心）\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eTSO\u003c/strong\u003e：输出分类/回归结果\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e成果\u003c/strong\u003e：在多个公开数据集的广义跨被试任务上面超过了 baseline\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"introduction--related-work\"\u003eIntroduction \u0026amp; Related Work\u003c/h2\u003e\n\u003cp\u003e为什么 EEG 难以使用跨被试 (cross-subject) 的场景？\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e个体差异\u003c/strong\u003e：不同被试生理结构和认知策略差异，导致 EEG 模式不同\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e低信噪比\u003c/strong\u003e：EEG 信号容易受到外源噪声干扰（肌电、眼电……）\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e目标是学习一种\u003cstrong\u003e跨被试共享\u003c/strong\u003e、具有\u003cstrong\u003e泛化能力\u003c/strong\u003e的情绪表征\u003c/p\u003e\n\u003ch3 id=\"gpaph-neural-networks\"\u003eGpaph Neural Networks\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e核心思想\u003c/strong\u003e：EEG 数据具有非欧图结构，适合使用 GNN 来处理\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e代表工作\u003c/strong\u003e：\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eChebyNet\u003c/strong\u003e：使用切比雪夫多项式近似光谱滤波，EmT 模型中采用其作为 GCN 层\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eGCN\u003c/strong\u003e：通过局部一阶聚合近似光谱滤波\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eDGCNN / RGNN\u003c/strong\u003e：使用 GNNs 提取 EEG 空间信息；依赖单一的邻接矩阵，忽略时序上下文，具有\u003cstrong\u003e局限性\u003c/strong\u003e；而 EmT 通过\u003cstrong\u003e多视图可学习邻接矩阵\u003c/strong\u003e和\u003cstrong\u003e时序图\u003c/strong\u003e来弥补\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"temporal-context-learning\"\u003eTemporal Context Learning\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e核心理念\u003c/strong\u003e：情绪是连续认知过程，EEG 信号中嵌入时序上下文信息\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e代表工作\u003c/strong\u003e：\n\u003cul\u003e\n\u003cli\u003eLSTM / TCN / TESANet / Conformer / AMDET\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e局限性\u003c/strong\u003e：这些方法通常从扁平化的 EEG 特征向量学习，可能\u003cstrong\u003e未能有效学习空间关系\u003c/strong\u003e；EmT 则通过并行 GCN 和 STA 层更有效地捕捉时空信息\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"eeg-emotion-recognition\"\u003eEEG Emotion Recognition\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e核心理念\u003c/strong\u003e：EEG 情绪识别面临个体差异大、信噪比低等挑战，需提取光谱、空间、时序特征\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e代表工作\u003c/strong\u003e：\n\u003cul\u003e\n\u003cli\u003eGCB-Net / TSception\u003c/li\u003e\n\u003cli\u003e局限性：没有关注长时序上下文信息\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"method\"\u003eMethod\u003c/h2\u003e\n\u003cp\u003eEmT 是一个端到端的框架，包含四大模块：\u003c/p\u003e","title":"EmT"},{"content":"Introduction TTA 在回归任务上的局限：为分类任务设计，一般基于熵最小化和特征对齐；熵最小化不适用，回归模型产生单一值，不产生概率分布；简单特征对齐对回归模型效果不佳，可能反而会稀释需要学习的特征\nProblem Setting 考虑一个回归模型 $ f_\\theta: \\mathcal{X} \\to \\mathbb{R} $，可以进一步分解为特征提取器 $ g_\\phi: \\mathcal{X} \\to \\mathbb{R}^D $（从输入 $ \\mathcal{X} $ 提取 $ D $ 维特征 $ z $）和线性回归器 $ h_\\psi(z) = w^T z + b $（或者 $ h_{\\psi}(z)=Wz+b $）\n$ f_\\theta $ 首先在一个有标签的源数据集 $ S = \\{(x_i, y_i)\\}_{i=1}^{N_s} $ 上进行预训练，数据从源域分布 $ p_s $ 中采样\n目标是使用一个无标签的目标数据集 $ T = \\{x_j\\}_{j=1}^{N_t} $ 来适应预训练好的模型 $ f_\\theta $ 到目标域\n我们假设存在 covariate shift ，这意味着：\n输入数据的分布在源域和目标域之间是不同的：$ p_s(x) \\neq p_t(x) $ 但给定输入后，输出的条件分布是相同的：$ p_s(y|x) = p_t(y|x) $ Test-time Adaptation for Regression Basic Idea: Feature Alignment 朴素实现：\n计算源域特征统计量：在源域训练后，计算源域特征的均值 $ \\mu^s $ 和元素级方差 $ \\sigma^{s2} $ $$ \\mu^s = \\frac{1}{N_s} \\sum_{i=1}^{N_s} z_i^s, \\quad \\sigma^{s2} = \\frac{1}{N_s} \\sum_{i=1}^{N_s} (z_i^s - \\mu^s) \\odot (z_i^s - \\mu^s) \\quad \\text{(1)} $$ 其中 $ z_i^s = g_\\phi(x_i) $ 是源特征，$ N_s $ 是源数据样本数，$ \\odot $ 表示元素级乘积\n目标域特征统计量：在目标域，对每个迷你批次（mini-batch）$ B = \\{x_j\\}_{j=1}^{N_B} $，计算其特征均值 $ \\hat{\\mu}^t $ 和方差 $ \\hat{\\sigma}^{t2} $，计算方式与公式 (1) 类似\n对齐损失函数：使用 KL 散度来衡量两个对角高斯分布 $ N(\\mu^s, \\sigma^{s2}) $ 和 $ N(\\hat{\\mu}^t, \\hat{\\sigma}^{t2}) $ 之间的差异，并最小化该差异。 $$ L_{TTA} (\\phi) = \\frac{1}{2} \\sum_{d=1}^D \\left\\{ D_{KL} (N(\\mu^s_d, \\sigma^s_{d}{}^2)||N(\\hat{\\mu}^t_d, \\hat{\\sigma}^t_{d}{}^2)) + D_{KL} (N(\\hat{\\mu}^t_d, \\hat{\\sigma}^t_{d}{}^2)||N(\\mu^s_d, \\sigma^s_{d}{}^2)) \\right\\} \\quad \\text{(2)} $$ 这里的 $ d $ 表示向量的第 $ d $ 个元素。之所以使用双向的 KL 散度，是为了经验上获得更好的结果\n一维高斯 KL 散度公式： $$ D_{KL} (N(\\mu_1, \\sigma_1^2)||N(\\mu_2, \\sigma_2^2)) = \\dfrac{\\left[ \\log(\\sigma_2^2/\\sigma_1^2) + \\dfrac{(\\mu_1 - \\mu_2)^2 + \\sigma_1^2}{\\sigma_2^2} - 1 \\right]}{2} \\quad \\text{(3)} $$\n朴素对齐的问题：\n回归模型特征倾向于分布在一个小型的子空间中，许多特征维度方差为零或接近零 公式 (3) 中涉及到方差在分母上，使得这种朴素对齐在面对零方差维度时变得不稳定 对所有维度“一视同仁”地对齐不适用于回归任务的特性，因为许多维度对最终输出影响很小 Significant-subspace Alignment SSA 的三个步骤：\n子空间检测 (Subspace detection)：\n在源数据集 $ S $ 上进行训练后，检测源特征分布所在的子空间。不计算每个维度的方差，而是计算协方差矩阵： $$ \\Sigma^s = \\frac{1}{N_s} \\sum_{i=1}^{N_s} (z_i^s - \\mu^s) (z_i^s - \\mu^s)^T \\quad \\text{(4)} $$ 其中 $ \\mu^s $ 是源特征的均值向量（同理 (1)） 基于 PCA 的思想，通过对 $ \\Sigma^s $ 进行特征分解，得到特征向量 $ v_d^s $ 和对应的特征值 $ \\lambda_d^s $ 选取前 K 个最大的特征值 $ \\lambda_1^s, \\dots, \\lambda_K^s $ 及其对应的源基向量 $ v_1^s, \\dots, v_K^s $ 来定义源子空间，这些基向量张成的子空间代表了源特征数据最有代表性和最重要的变化方向 维度加权 (Dimension weighting)：\n考虑到回归模型 $ h_\\psi(z)=w^T z + b $，子空间维度 $ v_d^s $ 对最终输出的影响由 $ w^T v_d^s $ 决定（即特征向量与回归器权重向量的点积） 为了优先对齐那些对输出影响更大的子空间维度，为每个子空间维度 $ d $ 定义权重 $ a_d $： $$ a_d = 1 + |w^T v_d^s| \\quad \\text{(5)} $$ 这个权重 $ a_d $ 会在对应的子空间基方向对输出有较大影响时值更大（最小为 1）。 特征对齐 (Feature alignment)：\n这一步在目标域进行。对于目标域的迷你批次 $ B $，首先将目标特征 $ z^t = g_\\phi(x^t) $ 投影到源子空间。 $$ \\tilde{z}^t = V_s^T (z^t - \\mu^s) \\quad \\text{(6)} $$ 其中 $ V_s = [v_1^s, \\dots, v_K^s] \\in \\mathbb{R}^{D \\times K} $ 是由前 K 个源基向量构成的矩阵，$ \\tilde{z}^t \\in \\mathbb{R}^K $ 是投影后的目标特征。 然后，计算投影后目标特征的迷你批次均值 $ \\tilde{\\mu}^t $ 和方差 $ \\tilde{\\sigma}^{t2} $ （同理公式 (1) ） 最后，使用结合子空间检测和维度加权的新损失函数来最小化目标特征分布与源特征分布在子空间中的差异。源域投影后的均值是 0，方差是其特征值 $ \\Lambda^s = [\\lambda_1^s, \\dots, \\lambda_K^s] $。 $$ \\begin{align}L_{TTA}(\\phi) = \u0026 \\frac{1}{2} \\sum_{d=1}^K a_d \\left\\{ D_{KL} (N(0, \\lambda^s_d)||N(\\tilde{\\mu}^t_d, \\tilde{\\sigma}^t_{d}{}^2)) + D_{KL} (N(\\tilde{\\mu}^t_d, \\tilde{\\sigma}^t_{d}{}^2)||N(0, \\lambda^s_d)) \\right\\} \\\\ = \u0026 \\sum_{d=1}^K a_d \\left\\{ \\frac{(\\tilde{\\mu}^t_d)^2 + \\lambda^s_d}{2\\tilde{\\sigma}^t_{d}{}^2} + \\frac{(\\tilde{\\mu}^t_d)^2 + \\tilde{\\sigma}^t_{d}{}^2}{2\\lambda^s_d} - 1 \\right\\} \\quad \\text{(7)} \\end{align} $$ 其中 $ a_d $ 是维度权重，$ \\lambda_d^s $ 是源域子空间的第 $ d $ 个特征值，$ \\tilde{\\mu}_d^t $ 和 $ \\tilde{\\sigma}_{d}{}^2 $ 是投影后的目标特征在第 $ d $ 个维度上的均值和方差 伪代码：\n输入：预训练好的源模型 $ f_\\theta $、源基向量 $ V_s $、源均值 $ \\mu^s $、源方差 $ \\Lambda^s $、目标数据集 $ T $ 输出：适应后的模型 $ f_\\phi^t $ 步骤： 计算源子空间中每个维度的权重 $ a_d $ 对于目标数据集 $ T $ 中的每个 mini batch $ \\{x\\}_i^B $： 提取目标特征 $ z = g_\\phi(x) $。 将目标特征投影到源子空间 $ \\tilde{z} $ 计算投影后目标特征的均值 $ \\tilde{\\mu}^t $ 和方差 $ \\tilde{\\sigma}^{t2} $ 更新特征提取器 $ g_\\phi $ 以最小化损失函数 $ L_{TTA}(\\phi) $ 重复直到收敛。 对角高斯分布的合理性 为什么假设特征分布为对角高斯分布是合理的：\n中心极限定理：当特征被投影到子空间后，如果原始特征维度 $ D $ 足够大，根据中心极限定理，投影后的特征分布会倾向于高斯分布。 PCA 的去相关性：由于子空间检测使用了 PCA，投影到主成分上的特征是去相关的，这意味着不同维度之间是独立的，这使得对角高斯分布的假设（即各维度独立）变得合理。 Appendix A. LIMITATION：SSA 假设是协变量偏移，即 $ p(y|x) $ 不变，未来工作将考虑 $ p(y|x) $ 变化的情况\nB. EVALUATION METRIC：R²接近 1 表示模型拟合效果好 $$ R^2 = 1 - \\frac{\\sum_{i=1}^N (y_i - \\hat{y}_i)^2}{\\sum_{i=1}^N (y_i - \\bar{y})^2} \\quad \\text{(10)} $$ 其中 $ \\hat{y}_i $ 是预测值，$ y_i $ 是真实值，$ \\bar{y} $ 是真实值的平均值。\nD. ADDITIONAL EXPERIMENTAL RESULTS：\nD.1 特征对齐的度量：比较了 KL 散度、2WD 和 L1 范数作为特征对齐损失的效果，结果显示 KL 散度结合子空间检测（SSA）表现最佳。 公式 (11)：2-Wasserstein Distance for Gaussians $$ W_2^2 (N(\\mu_1, \\sigma_1^2), N(\\mu_2, \\sigma_2^2)) = (\\mu_1 - \\mu_2)^2 + (\\sigma_1 - \\sigma_2)^2 $$ 公式 (12)：L1 Norm of Statistics $$ L_1 (N(\\mu_1, \\sigma_1^2), N(\\mu_2, \\sigma_2^2)) = |\\mu_1 - \\mu_2| + |\\sigma_1 - \\sigma_2| $$ 公式 (13)：SSA Loss with 2WD $$ L_{TTA-2WD} = \\sum_{d=1}^K a_d \\left\\{ (\\tilde{\\mu}^t_d)^2 + (\\tilde{\\sigma}^t_d - \\sqrt{\\lambda^s_d})^2 \\right\\} $$ 公式 (14)：SSA Loss with L1 Norm $$ L_{TTA-L1} = \\sum_{d=1}^K a_d \\left\\{ |\\tilde{\\mu}^t_d| + |\\tilde{\\sigma}^t_d - \\sqrt{\\lambda^s_d}| \\right\\} $$ D.2 特征可视化：通过 PCA 和 UMAP 等降维技术可视化了源域和目标域特征分布（图 4-5），直观地展示了 SSA 如何成功地将目标特征分布拉近源域。 D.3 原始特征维度对子空间的影响：分析了原始特征维度对子空间的重要性。 公式 (15)：Gradient Norm $ s_d $ $$ s_d = ||\\frac{\\partial \\tilde{z}}{\\partial z_d}||_2 = ||(V_s^T)_d||_2 = ||[v_{1,d}^s, \\dots, v_{K,d}^s]||_2, $$ 其中 $ (V_s^T)_d $ 是 $ V_s^T $ 的第 $ d $ 行。 发现：回归模型的特征子空间确实受许多原始特征维度影响很小（图 6），这进一步确认了子空间检测的必要性。 D.4 附加消融实验：进一步证实了子空间检测对于 SSA 性能的重要性（表 13-14）。 D.5 Vision Transformer 实验：在 Vision Transformer 上验证了 SSA 的有效性（表 15-16），表明该方法对不同模型架构也适用。 D.6 多任务回归模型：将 SSA 应用于多任务回归，模型同时输出多个预测值（如头部姿态的俯仰、偏航、滚转角度），结果表明 SSA 同样有效（表 17）。 D.7 与分类 TTA 结合：探索了 SSA 与分类 TTA 结合的可能性（表 18-20）。 D.8 超参数敏感性：分析了学习率和批次大小等超参数对 SSA 性能的影响（表 21-26），发现 SSA 在典型参数范围内表现稳定。 D.9 额外结果：提供了 MAE 等其他指标的性能数据（表 27-28）。 D.10 在线设置：SSA 在分批在线（batched online）设置下也表现出色（表 29-31）。 ","permalink":"https://diefish1024.github.io/posts/literature-notes/ssa/","summary":"\u003ch2 id=\"introduction\"\u003eIntroduction\u003c/h2\u003e\n\u003cp\u003eTTA 在回归任务上的局限：为分类任务设计，一般基于熵最小化和特征对齐；熵最小化不适用，回归模型产生单一值，不产生概率分布；简单特征对齐对回归模型效果不佳，可能反而会稀释需要学习的特征\u003c/p\u003e\n\u003ch2 id=\"problem-setting\"\u003eProblem Setting\u003c/h2\u003e\n\u003cp\u003e考虑一个回归模型 $ f_\\theta: \\mathcal{X} \\to \\mathbb{R} $，可以进一步分解为\u003cstrong\u003e特征提取器\u003c/strong\u003e $ g_\\phi: \\mathcal{X} \\to \\mathbb{R}^D $（从输入 $ \\mathcal{X} $ 提取 $ D $ 维特征 $ z $）和\u003cstrong\u003e线性回归器\u003c/strong\u003e $ h_\\psi(z) = w^T z + b $（或者 $ h_{\\psi}(z)=Wz+b $）\u003c/p\u003e\n\u003cp\u003e$ f_\\theta $ 首先在一个有标签的\u003cstrong\u003e源数据集\u003c/strong\u003e $ S = \\{(x_i, y_i)\\}_{i=1}^{N_s} $ 上进行预训练，数据从源域分布 $ p_s $ 中采样\u003c/p\u003e\n\u003cp\u003e目标是使用一个\u003cstrong\u003e无标签的\u003c/strong\u003e目标数据集 $ T = \\{x_j\\}_{j=1}^{N_t} $ 来适应预训练好的模型 $ f_\\theta $ 到目标域\u003c/p\u003e\n\u003cp\u003e我们假设存在 \u003cstrong\u003ecovariate shift\u003c/strong\u003e ，这意味着：\u003c/p\u003e","title":"SSA"},{"content":"Method Problem Set EEG 数据 $ \\{ X_{s,l}^{i},y_{s,l}^{i} \\}_{i=1}^{n_{s,l}} $ ，进行无监督在线 K 分类\nSource Model Training 对源数据做 Euclidean alignment (EA) 数据对齐，减少不同个体 EEG 信号差异\nEA 计算每个个体所有 EEG 试次协方差矩阵的算术平均值 $$ R_{s,l} = \\dfrac{1}{n}\\sum_{i=1}^{n} X_{i}(X_{i})^{T} \\implies \\bar{X}_{i} = R_{s,l}^{-1/2}X_{i} $$ 之后再整合经过对齐的受试者数据，形成“源域”\n在整合后的数据上独立训练 $ M $ 个模型\nIncremental EA on Target Data 对新数据增量式更新协方差矩阵，再用新的矩阵更新所有测试数据\nTarget Label Prediction 用训练好的 $ M $ 模型初始化用于适应目标域的 $ M $ 个 TTA 模型 $ f_{m} $\n新的 $ X_{a} $ 经过 IEA 被变换为 $ X_{a}' $ 后被输入到每个模型 $ f_{m} $ 中进行分类，输出概率向量 $ f_{m}(X_{a}') $\n之后结合这 $ M $ 个概率向量来获得最终的预测标签 $ \\hat{y}_{a} $\n$ a\\leq M $ 数据量较少：直接对所有模型的预测向量平均 $ a\u003eM $ 数据量较多：使用谱元学习器对各个模型进行加权平均，根据历史表现（预测的协方差矩阵）分配不同的权重 Target Model Update 在数据量足够以后（$ a\u003eB $）使用一个滑动批次的数据更新模型，在此之前模型不变\n组合损失函数： $$ L_{M} = L_{CEM}(f_{m};\\{ X'_{i} \\}_{i=a-B+1}^{a}) + L_{MDR}(f_{m};\\{ X'_{i} \\}_{i=a-B+1}^{a}) $$ 有两个部分\n1) Conditional Entropy Minimization 条件熵最小化\n使分类边界更加清晰 通过最小化每个预测的条件熵（使用温度缩放因子 $ T $ 进行校准），使模型倾向于输出接近 0 或 1 的概率 2) Adaptive Marginal Distribution Regularization 自适应边缘分布正则化\n防止出现所有数据都在单类别和对错误结果过于自信的不良结果 计算当前批次每个类别的平均预测概率 $ p_{k} $ 通过设置阈值得到伪标签，估计目标域的类别评论 $ z_{k} $ 校准平均预测概率 $ q'_{k} $ $$ q_{k} = \\dfrac{p_{k}}{c+z_{k}},\\quad q'_{k} = \\dfrac{q_{k}}{\\sum q} $$ $ L_{MDR} = \\sum_{k=1}^{K}q'_{k}\\log q'_{k} $ （采用负熵的形式） Complete T-TIME Algorithm 先预测，后台并行地更新模型\nExperiment 使用三个运动想象数据集\n每次把一个受试者的数据作为目标域，其余作为源域\nClassification Accuracies on Balanced Classes 过于复杂的算法由于数据不足，性能反而下降 基于熵的方法普遍表现良好，MCC 在离线迁移学习中表现最好 T-TIME 在所有在线迁移学习算法中表现最佳，并且其性能与表现最佳的离线迁移学习方法相当 Classification Performance Under Class-Imbalance 使用随机移除数据来创建不平衡数据集\n传统方法表现较弱 T-TIME 表现突出 ","permalink":"https://diefish1024.github.io/posts/literature-notes/t-time/","summary":"\u003ch1 id=\"method\"\u003eMethod\u003c/h1\u003e\n\u003ch3 id=\"problem-set\"\u003eProblem Set\u003c/h3\u003e\n\u003cp\u003eEEG 数据 $ \\{ X_{s,l}^{i},y_{s,l}^{i} \\}_{i=1}^{n_{s,l}} $ ，进行无监督在线 K 分类\u003c/p\u003e\n\u003ch3 id=\"source-model-training\"\u003eSource Model Training\u003c/h3\u003e\n\u003cp\u003e对源数据做 Euclidean alignment (EA) 数据对齐，减少不同个体 EEG 信号差异\u003c/p\u003e\n\u003cp\u003eEA 计算每个个体所有 EEG 试次协方差矩阵的算术平均值\n$$ \n\nR_{s,l} = \\dfrac{1}{n}\\sum_{i=1}^{n} X_{i}(X_{i})^{T} \\implies \\bar{X}_{i} = R_{s,l}^{-1/2}X_{i}\n\n $$\n之后再整合经过对齐的受试者数据，形成“源域”\u003c/p\u003e\n\u003cp\u003e在整合后的数据上独立训练 $ M $ 个模型\u003c/p\u003e\n\u003ch3 id=\"incremental-ea-on-target-data\"\u003eIncremental EA on Target Data\u003c/h3\u003e\n\u003cp\u003e对新数据增量式更新协方差矩阵，再用新的矩阵更新所有测试数据\u003c/p\u003e\n\u003ch3 id=\"target-label-prediction\"\u003eTarget Label Prediction\u003c/h3\u003e\n\u003cp\u003e用训练好的 $ M $ 模型初始化用于适应目标域的 $ M $ 个 TTA 模型 $ f_{m} $\u003c/p\u003e\n\u003cp\u003e新的 $ X_{a} $ 经过 IEA 被变换为 $ X_{a}' $ 后被输入到每个模型 $ f_{m} $ 中进行分类，输出概率向量 $ f_{m}(X_{a}') $\u003c/p\u003e","title":"T-TIME"},{"content":"Setting Fully Test-Time Adaptation 是一种独特的模型适应设定。在此设定下，模型 $ f_\\theta(x) $ 在训练阶段已通过源数据 $ x^s $ 和标签 $ y^s $ 完成训练，获得参数 $ \\theta $。但在测试阶段，模型将遇到与源数据分布不同的无标签目标数据 $ x^t $。\nFTT-Adaptation 与以下方法不同：\nFine-tuning：需要目标标签进行重新训练。 Domain Adaptation：需要源数据和目标数据进行联合训练。 Test-Time Training (TTT)：需要修改训练过程并共同优化有监督及自监督损失。 相比之下，FTT-Adaptation 仅能利用预训练模型 $ f_\\theta $ 和无标签目标数据 $ x^t $ 进行适应，不依赖源数据或额外的监督信息。\nMethod 论文的核心贡献是提出了 Tent 方法，其核心思想是通过最小化测试熵（Test Entropy Minimization）来适应模型预测，旨在使模型对测试数据的预测结果更“有信心”。\nEntropy Objective Tent 的测试时目标函数是最小化模型预测 $ \\hat{y} = f_\\theta(x^t) $ 的熵 $ H(\\hat{y}) $。论文中使用的香农熵计算公式如下：\n$$ H(\\hat{y}) = - \\sum_c p(\\hat{y}_c) \\log p(\\hat{y}_c) $$ 其中， $ p(\\hat{y}_c) $ 表示模型预测目标数据 $ x^t $ 属于类别 $ c $ 的概率。\n最小化熵促使模型输出更“尖锐”或更“确定”的预测分布。 优势：熵是一种无监督目标，仅依赖于模型预测，不需要真实标签。最小化熵与减少预测误差和数据漂移之间存在内在联系，因为更确定的预测通常意味着更正确的预测。 Modulation Parameters Tent 不直接修改原始模型的全部参数 $ \\theta $。相反，它仅更新模型内部归一化层（如Batch Normalization layers）中的线性且低维度的仿射变换参数：尺度参数 $ \\gamma $ 和偏移参数 $ \\beta $。\n这一选择的理由是：这些参数只占模型总参数的极小部分（\u0026lt;1%），优化效率高且稳定。 特征调制过程包含两个步骤： 1.Normalization (标准化)：根据当前批次测试数据的均值 $ \\mu $ 和标准差 $ \\sigma $ 来标准化特征 $ x $，即 $ \\hat{x} = (x - \\mu)/\\sigma $。这里的 $ \\mu, \\sigma $ 是在测试时从当前批次数据中估计的。 2.Transformation (仿射变换)：对标准化后的特征 $ \\hat{x} $ 应用仿射变换，即 $ x' = \\gamma \\hat{x} + \\beta $。参数 $ \\gamma $ 和 $ \\beta $ 通过最小化熵目标函数进行优化。 Algorithm Tent 算法的流程如下：\nInitialization： 加载预训练好的源模型参数 $ \\theta $。 固定所有非仿射变换的参数。 丢弃源数据中估计的归一化统计量。 优化器收集所有归一化层的通道级仿射变换参数 $ \\{\\gamma_{l,k}, \\beta_{l,k}\\} $。 Iteration：在线处理数据批次。 Forward Pass：对每个数据批次，逐层估计该批次数据的归一化统计量 ($ \\mu, \\sigma $)。 Backward Pass：计算预测熵 $ H(\\hat{y}) $ 相对于仿射变换参数 $ \\gamma, \\beta $ 的梯度 $ \\nabla H(\\hat{y}) $。 Update：使用梯度更新 $ \\gamma, \\beta $ 参数。Tent 采用高效的在线更新策略，每次更新只影响下一个批次的数据处理。 Termination：对于在线适应，适应过程只要有测试数据就持续进行。对于离线适应，模型会先进行更新，然后重复推断，适应可以持续多个Epochs。 Experiments 论文在多种计算机视觉任务和数据集上对 Tent 进行了全面评估。\nRobustness To Corruptions 在图像分类的鲁棒性基准测试中，使用受损版本的 CIFAR-10/100-C 和 ImageNet-C 数据集（15 种损坏类型，不同严重程度）。\n主要发现： Tent 在 ImageNet-C 上达到了 44.0% 的最低错误率，优于 SOTA 鲁棒性训练方法（如Adversarial Noise Training (ANT) 的 50.2%）和Test-Time Normalization (BN) 基线（49.9%）。 在 CIFAR-10/100-C 上，Tent 也显著优于其他 TTA baseline（BN, Pseudo-Labeling (PL)）以及需要联合训练源域和目标域的Domain Adaptation（RG, UDA-SS）和Test-Time Training (TTT) 方法。 这些改进仅通过一次Epoch的测试时优化实现，且未改变原始模型训练。 Source-Free Domain Adaptation 评估 Tent 在无源域适应场景下的性能，包括数字识别（从 SVHN 到 MNIST/MNIST-M/USPS）和语义分割（从 GTA 到 Cityscapes）。\n主要发现： 在数字识别任务中，Tent 大多数情况下错误率低于源模型和BN，部分情况甚至优于需要源数据的Domain Adaptation方法（RG, UDA-SS）。 语义分割任务中，Tent 将Intersection-Over-Union (IOU) 分数从源模型的 28.8% 提高到 35.8%，显著优于 BN 的 31.4%。 Analysis 论文通过多项分析实验探究了 Tent 的工作原理和特性：\nTent 降低熵和误差：实验证实，Tent 成功降低了预测的熵值和任务损失（如Softmax Cross-Entropy），印证了熵最小化与误差减少之间的正相关性。 Tent 需要特征调制：不更新归一化统计量或不优化仿射变换参数会显著降低 Tent 性能，说明这些特征调制步骤对于适应不可或缺。 Tent 泛化到不同的目标数据：适应过程对未用于更新的其他测试数据点同样有效，表明其学习到的调制是通用的。 Tent 调制与归一化不同：对比分析显示，Tent 的特征调制使特征更接近在目标标签上优化的Oracle模型（理想模型），而非仅像Batch Normalization那样接近原始参考分布。 Tent 适应其他网络架构：Tent 在基于Self-Attention 和Equilibrium Solving (MDEQ) 的模型上也能有效降低误差，展现了其普适性。 Related Work 论文回顾了与 Tent 相关的现有工作：\nTrain-Time Adaptation 方法：传统的Domain Adaptation、Test-Time Training (TTT) 等，通常需要源数据或训练阶段修改模型。 Source-Free Adaptation 方法：近期一些不依赖源数据的方法，但通常需要更复杂的设计、离线优化或修改训练过程。Tent 的优势在于其在线、高效且不改变训练过程。 Entropy Minimization：熵最小化已被广泛用于Semi-Supervised Learning和Domain Adaptation的正则化项，但 Tent 首次将其作为Fully Test-Time Adaptation中唯一的无监督损失来驱动模型适应。 Feature Modulation：归一化层和仿射变换已被用于各种任务的特征调制，但 Tent 将其作为在测试时通过无监督目标进行优化的核心机制。 Discussion Tent 通过Test Entropy Minimization实现了在数据漂移情况下的泛化误差降低。其核心在于模型的自监督自我改进，即依据自身的预测反馈进行调整。\n优势总结： 高效：仅通过在线优化少数参数（$ \\gamma, \\beta $）实现。 实用：无需源数据访问，不改变模型训练过程。 通用：适用于多种数据漂移类型和不同网络架构。 尽管 Tent 在广泛的场景中表现出色，但仍存在挑战，例如在特定困难的数据漂移（如 SVHN 到 MNIST-M/USPS）上仍有提升空间。未来研究方向可探索更全面的参数调整、更通用的Test-Time Adaptation Loss以及进一步提升效率的方法。总而言之，Tent 为Fully Test-Time Adaptation 提供了一个创新且实用的范式，使得模型能够在部署后，在面对未知且无标签的测试数据时，具备强大的自我适应能力。\n","permalink":"https://diefish1024.github.io/posts/literature-notes/tent/","summary":"\u003ch1 id=\"setting\"\u003eSetting\u003c/h1\u003e\n\u003cp\u003e\u003cstrong\u003eFully Test-Time Adaptation\u003c/strong\u003e 是一种独特的模型适应设定。在此设定下，模型 $ f_\\theta(x) $ 在训练阶段已通过源数据 $ x^s $ 和标签 $ y^s $ 完成训练，获得参数 $ \\theta $。但在测试阶段，模型将遇到与源数据分布不同的无标签目标数据 $ x^t $。\u003c/p\u003e\n\u003cp\u003eFTT-Adaptation 与以下方法不同：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eFine-tuning\u003c/strong\u003e：需要目标标签进行重新训练。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eDomain Adaptation\u003c/strong\u003e：需要源数据和目标数据进行联合训练。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eTest-Time Training (TTT)\u003c/strong\u003e：需要修改训练过程并共同优化有监督及自监督损失。\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e相比之下，FTT-Adaptation 仅能利用预训练模型 $ f_\\theta $ 和无标签目标数据 $ x^t $ 进行适应，不依赖源数据或额外的监督信息。\u003c/p\u003e\n\u003ch2 id=\"method\"\u003eMethod\u003c/h2\u003e\n\u003cp\u003e论文的核心贡献是提出了 \u003cstrong\u003eTent\u003c/strong\u003e 方法，其核心思想是通过\u003cstrong\u003e最小化测试熵\u003c/strong\u003e（\u003cstrong\u003eTest Entropy Minimization\u003c/strong\u003e）来适应模型预测，旨在使模型对测试数据的预测结果更“有信心”。\u003c/p\u003e\n\u003ch3 id=\"entropy-objective\"\u003eEntropy Objective\u003c/h3\u003e\n\u003cp\u003eTent 的测试时目标函数是最小化模型预测 $ \\hat{y} = f_\\theta(x^t) $ 的\u003cstrong\u003e熵 $ H(\\hat{y}) $\u003c/strong\u003e。论文中使用的\u003cstrong\u003e香农熵\u003c/strong\u003e计算公式如下：\u003c/p\u003e\n$$ \n\nH(\\hat{y}) = - \\sum_c p(\\hat{y}_c) \\log p(\\hat{y}_c)\n\n $$\n\u003cp\u003e其中， $ p(\\hat{y}_c) $ 表示模型预测目标数据 $ x^t $ 属于类别 $ c $ 的概率。\u003c/p\u003e","title":"Tent"},{"content":"Setting Continual Test-Time Domain Adaptation 是一种更具挑战性的模型适应设定。在此设定下，一个在源数据上预训练好的模型，在测试时会遇到一个非平稳且持续变化的目标环境 。\nCoTTA 与以下方法不同：\nStandard Domain Adaptation：需要同时访问源数据和（静态的）目标数据进行训练。 Standard Test-Time Adaptation / Fully Test-Time Adaptation：通常假设目标域是固定的或静态的，而 CoTTA 关注的是持续变化的目标域。 Test-Time Training (TTT)：需要修改源模型的训练过程以加入辅助任务，因此无法使用任意的“开箱即用”预训练模型。 相比之下，CoTTA 专门解决在无源数据的条件下，模型如何在线适应一个持续变化的数据流，同时克服现有方法中常见的错误累积和灾难性遗忘问题。\nMethod 论文的核心贡献是提出了CoTTA (Continual Test-Time Adaptation) 方法，旨在通过减少错误累积和避免灾难性遗忘，实现模型在非平稳环境下的长期稳定适应，主要有两个关键部分。\n1. 减少错误累积 (Reducing Error Accumulation) 为了生成更可靠的自训练信号，CoTTA 采用了平均化的伪标签策略，该策略结合了权重平均和数据增强平均。\n权重平均伪标签 (Weight-Averaged Pseudo-Labels) 该方法采用一个教师 - 学生 (teacher-student) 框架。学生模型 (student model) 在线进行学习和更新。 教师模型 (teacher model) 的权重是学生模型权重的指数移动平均 (Exponential Moving Average, EMA)。 由于教师模型的更新更平滑，其预测结果通常比学生模型更准确，因此用它来生成伪标签，可以有效减少错误累积。学生模型通过最小化与教师伪标签的一致性损失 (consistency loss) 来进行更新。 数据增强平均伪标签 (Augmentation-Averaged Pseudo-Labels) 为了进一步提升伪标签在遇到较大域偏移时的质量，CoTTA 会有条件地使用数据增强。 它首先使用原始预训练模型评估当前测试数据的预测置信度，以此来近似域差异的大小。 条件性应用： 如果置信度高（域差异小），则直接使用教师模型的预测作为伪标签。 如果置信度低（域差异大），则对输入数据进行 N 次随机增强，并将教师模型对这些增强样本的平均预测结果作为伪标签。这可以进一步提高伪标签的鲁棒性。 2. 避免灾难性遗忘 (Avoiding Catastrophic Forgetting) 为了在长期适应过程中保留从源域学到的知识，CoTTA 引入了随机恢复 (Stochastic Restoration) 机制。\n核心思想：在每次模型更新后，以一个很小的概率 p，将模型中的一小部分权重参数随机地恢复到其原始的、预训练时的状态。 优势： 这种机制可以看作一种特殊的 Dropout。它能有效防止模型在适应新数据时“漂移”得离源模型太远，从而显式地保留了源知识，避免了灾难性遗忘。 通过保留源知识，CoTTA 能够安全地更新网络中的所有参数，而不仅仅是归一化层，这为模型适应提供了更大的容量。 Algorithm CoTTA 算法的在线流程如下：\nInitialization (初始化)： 加载一个“开箱即用”的预训练源模型 $ f_{\\theta_{0}} $ 用源模型权重初始化教师模型 $ f_{\\theta'_{0}} $ Iteration (迭代)：对于在线输入的每个测试数据 $ x_{t} $​： 生成伪标签：使用教师模型 $ f_{\\theta'_{t}} $​​，并结合条件性数据增强，生成权重和增强平均的伪标签。 更新学生模型：通过一致性损失更新学生模型 $ f_{\\theta_{t}} $ 更新教师模型：使用 EMA 更新教师模型的权重 $ f_{\\theta'_{t+1}} $ 随机恢复：对学生模型的权重进行随机恢复 Output (输出)：使用教师模型 $ f_{\\theta'_{t}} $​​ 进行在线预测，并传递更新后的学生和教师模型到下一个时间步。 Experiments 论文在多个图像分类和语义分割任务上对 CoTTA 进行了评估，特别是在一个持续变化的测试环境中。\nContinual Adaptation on Corrupted Images 在 CIFAR10-C、CIFAR100-C 和 ImageNet-C 数据集上，模型被顺序输入 15 种不同类型的损坏图像。\n主要发现： 在 CIFAR10-C 上，CoTTA 的平均错误率仅为 16.2%，显著优于 Source-only 基线 (43.5%) 和 TENT-continual (20.7%)。 在更难的 CIFAR100-C 上，TENT 等方法因错误累积导致性能随时间推移而急剧下降（错误率从 37.2% 恶化到 90.4%），而 CoTTA 表现稳定，平均错误率仅为 32.5% 。 实验表明，TENT 在持续适应的后期会因错误累积而性能崩溃，而 CoTTA 的随机恢复机制成功避免了这一点。 Continual Adaptation on Semantic Segmentation 在一个从 Cityscapes (晴天) 到 ACDC (雾、夜、雨、雪等恶劣天气) 的持续语义分割任务中，模型会循环经历这四种天气条件 10 次，以测试其长期适应和遗忘情况。\n主要发现： CoTTA 将平均 mIoU 提升至 58.6%，优于源模型 (56.7%) 和其他适应方法。 TENT 在此任务上表现不佳，因为其依赖的批量归一化 (Batch Normalization) 层在 Transformer 架构 (Segformer) 中很少。 CoTTA 不依赖于特定层，因此在基于 Transformer 的架构上同样有效，展现了其通用性。 Analysis 通过消融实验验证了 CoTTA 各个组件的有效性。\n权重平均的作用：仅使用权重平均的伪标签，就将错误率从 20.7% (TENT-continual) 降至 18.3%，证明了教师模型伪标签的优越性。 数据增强平均的作用：在权重平均的基础上再加入条件性数据增强，错误率进一步降至 17.4%。 随机恢复的作用：最后加入随机恢复机制，错误率最终降至 16.2%，并且解决了长期适应中的性能衰退问题，证明了其在避免灾难性遗忘中的关键作用。 Related Work 论文回顾了与 CoTTA 相关的领域：\nTest-Time Adaptation (TTA)：现有工作大多关注静态目标域，在持续变化的环境中，基于熵最小化或伪标签的方法容易因伪标签噪声而累积错误。 Continuous Domain Adaptation：与 CoTTA 目标相似，但现有方法通常需要访问源数据来对齐分布。 Continual Learning：CoTTA 借鉴了该领域的思想来解决灾难性遗忘问题，但将其应用在了一个无监督、测试时适应的独特场景中。 Source-Free Domain Adaptation：CoTTA 属于此范畴，其新颖之处在于它专为在线和持续变化的环境设计，而这是先前工作很少考虑的。 Discussion CoTTA 成功地解决了在无源数据、非平稳环境下进行持续测试时适应的挑战。它通过创新的机制同时解决了错误累积和灾难性遗忘这两个核心难题。\n优势总结： 稳定与长效：通过随机恢复机制，CoTTA 实现了在长期持续适应过程中的性能稳定，避免了性能崩溃。 实用与通用：无需访问源数据，也无需修改模型训练过程，可直接用于各类“开箱即用”的预训练模型（包括 CNN 和 Transformer） 。 高效：整个适应过程在线进行，模型根据当前数据流即时更新和预测。 总而言之，CoTTA 为模型在真实世界中部署后的持续自我进化提供了一个强大且实用的框架，使模型能够鲁棒地适应不断变化的操作环境。\n","permalink":"https://diefish1024.github.io/posts/literature-notes/cotta/","summary":"\u003ch1 id=\"setting\"\u003eSetting\u003c/h1\u003e\n\u003cp\u003e\u003cstrong\u003eContinual Test-Time Domain Adaptation\u003c/strong\u003e 是一种更具挑战性的模型适应设定。在此设定下，一个在源数据上预训练好的模型，在测试时会遇到一个\u003cstrong\u003e非平稳\u003c/strong\u003e且\u003cstrong\u003e持续变化\u003c/strong\u003e的目标环境 。\u003c/p\u003e\n\u003cp\u003eCoTTA 与以下方法不同：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eStandard Domain Adaptation\u003c/strong\u003e：需要同时访问源数据和（静态的）目标数据进行训练。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eStandard Test-Time Adaptation / Fully Test-Time Adaptation\u003c/strong\u003e：通常假设目标域是固定的或静态的，而 CoTTA 关注的是持续变化的目标域。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eTest-Time Training (TTT)\u003c/strong\u003e：需要修改源模型的训练过程以加入辅助任务，因此无法使用任意的“开箱即用”预训练模型。\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e相比之下，CoTTA 专门解决在\u003cstrong\u003e无源数据\u003c/strong\u003e的条件下，模型如何在线适应一个\u003cstrong\u003e持续变化的\u003c/strong\u003e数据流，同时克服现有方法中常见的\u003cstrong\u003e错误累积\u003c/strong\u003e和\u003cstrong\u003e灾难性遗忘\u003c/strong\u003e问题。\u003c/p\u003e\n\u003ch2 id=\"method\"\u003eMethod\u003c/h2\u003e\n\u003cp\u003e论文的核心贡献是提出了\u003cstrong\u003eCoTTA (Continual Test-Time Adaptation)\u003c/strong\u003e 方法，旨在通过\u003cstrong\u003e减少错误累积\u003c/strong\u003e和\u003cstrong\u003e避免灾难性遗忘\u003c/strong\u003e，实现模型在非平稳环境下的长期稳定适应，主要有两个关键部分。\u003c/p\u003e\n\u003ch3 id=\"1-减少错误累积-reducing-error-accumulation\"\u003e1. 减少错误累积 (Reducing Error Accumulation)\u003c/h3\u003e\n\u003cp\u003e为了生成更可靠的自训练信号，CoTTA 采用了平均化的伪标签策略，该策略结合了权重平均和数据增强平均。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e权重平均伪标签 (Weight-Averaged Pseudo-Labels)\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003e该方法采用一个\u003cstrong\u003e教师 - 学生 (teacher-student)\u003c/strong\u003e 框架。学生模型 (student model) 在线进行学习和更新。\u003c/li\u003e\n\u003cli\u003e教师模型 (teacher model) 的权重是学生模型权重的\u003cstrong\u003e指数移动平均 (Exponential Moving Average, EMA)\u003c/strong\u003e。\u003c/li\u003e\n\u003cli\u003e由于教师模型的更新更平滑，其预测结果通常比学生模型更准确，因此用它来生成伪标签，可以有效减少错误累积。学生模型通过最小化与教师伪标签的\u003cstrong\u003e一致性损失\u003c/strong\u003e (consistency loss) 来进行更新。\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e数据增强平均伪标签 (Augmentation-Averaged Pseudo-Labels)\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003e为了进一步提升伪标签在遇到较大域偏移时的质量，CoTTA 会有条件地使用数据增强。\u003c/li\u003e\n\u003cli\u003e它首先使用\u003cstrong\u003e原始预训练模型\u003c/strong\u003e评估当前测试数据的\u003cstrong\u003e预测置信度\u003c/strong\u003e，以此来近似域差异的大小。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e条件性应用\u003c/strong\u003e：\n\u003cul\u003e\n\u003cli\u003e如果置信度\u003cstrong\u003e高\u003c/strong\u003e（域差异小），则直接使用教师模型的预测作为伪标签。\u003c/li\u003e\n\u003cli\u003e如果置信度\u003cstrong\u003e低\u003c/strong\u003e（域差异大），则对输入数据进行 N 次随机增强，并将教师模型对这些增强样本的平均预测结果作为伪标签。这可以进一步提高伪标签的鲁棒性。\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"2-避免灾难性遗忘-avoiding-catastrophic-forgetting\"\u003e2. 避免灾难性遗忘 (Avoiding Catastrophic Forgetting)\u003c/h3\u003e\n\u003cp\u003e为了在长期适应过程中保留从源域学到的知识，CoTTA 引入了\u003cstrong\u003e随机恢复 (Stochastic Restoration)\u003c/strong\u003e 机制。\u003c/p\u003e","title":"CoTTA"},{"content":"Introduction 类似 GAN 的对抗训练思想\nDomain Adaptation 给定源域 $ D_{S} $ （有标签）和目标域 $ D_{T} $ （无标签），目标是训练一个分类器 $ \\eta: X\\to Y $ 使其在目标域上的目标风险 $$ R_{D_{T}}(\\eta) = \\underset{(\\mathbf{x},y)\\sim D_{T}}{\\mathrm{Pr}}(\\eta(\\mathbf{x}) \\neq y) $$ 最小\nDomain Divergence 需要量化两个领域的“相似度”，从而引出了 H- 散度 的概念： $$ d_{\\mathcal{H}}(D_S, D_T) = 2 \\sup_{\\eta \\in \\mathcal{H}} \\left| \\Pr_{x \\sim D_S}[\\eta(x) = 1] - \\Pr_{x \\sim D_T}[\\eta(x) = 1] \\right| $$ 含义是最优的分类器将目标域和源域判定为 1 的可能性之差，当 H- 散度非常小时，说明两个领域很难被区分，也就说明学习的特征实现了领域不变性的效果\n由于理论 H 散度是理想数据分布上的定义，实际中只有有限的样本集 $ S $ 和 $ T $ ，因此需要一定的近似，于是需要经验 H- 散度 $$ \\hat{d}_{\\mathcal{H}}(S, T) = 2 \\left(1 - \\min_{\\eta \\in \\mathcal{H}} \\left[ \\dfrac{1}{n}\\sum_{i=1}^n \\mathcal{I}[\\eta(x_i) = 0] + \\dfrac{1}{n'}\\sum_{i=n+1}^N \\mathcal{I}[\\eta(x_i) = 1] \\right] \\right) $$ 其中 $ \\mathcal{I}[\\cdot] $ 表示条件为真时为 1，否则为 0\nProxy Distance 经验 H- 散度也需要直接遍历所有的 $ \\eta $ ，在计算上不现实，需要一个进一步的近似方法，因此考虑 Proxy A-distance (PAD)\n构造用于领域分类的数据集 $$ U = \\{ (\\mathbf{x}_{i},0) \\}_{i=1}^{n} \\cup \\{ (\\mathbf{x}_{i},1) \\}_{i=n+1}^{N} $$ 用这个数据集训练分类器，设 $ \\epsilon $ 为在数据集 $ U $ 上训练出的最优领域分类器所达到的最小错误率，那么可以用 $$ \\hat{d}_{\\mathcal{A}} = 2(1-2\\epsilon) $$ 来近似 H- 散度\nGeneralization Bound on the Target Risk 有效性证明\n理论研究说明模型的目标风险可以通过源风险和两个领域的散度来限制，主要思想是 $$ R_{D_T}(\\eta) \\le R_S(\\eta) + \\text{Domain Divergence Terms} + \\text{Complexity Terms} + \\beta $$ 其中 $ \\text{Domain Divergence Terms}\\approx d_{\\mathcal{H}}(S, T) $ ，可以用上面的 $ \\hat{d}_{\\mathcal{A}} $ 近似；$ \\text{Complexity Terms} $ 是一个比较小的常数项，和模型本身训练有关（原公式没看懂。。）；$ \\beta $ 是一个理想化的项，表示最好情况下在目标域和源域上同时取得的最低错误率\nDANN 优化目标： $$ E(\\theta_f, \\theta_y, \\theta_d) = \\frac{1}{n} \\sum_{i=1}^n \\mathcal{L}_y(\\theta_f, \\theta_y) - \\lambda \\left( \\frac{1}{n} \\sum_{i=1}^n \\mathcal{L}_d(\\theta_f, \\theta_d) + \\frac{1}{n'} \\sum_{i=n+1}^N \\mathcal{L}_d(\\theta_f, \\theta_d) \\right) $$ 核心是 Saddle Point Problem ，找到需要找到鞍点而非最小值\n如何实现对抗：\n标签预测参数： $$ \\theta_{y} \\leftarrow \\theta_{y} - \\mu \\dfrac{ \\partial \\mathcal{L}_{y} }{ \\partial \\theta_{y} } $$ 领域分类参数： $$ \\theta_{d} \\leftarrow \\theta_{d} - \\mu \\lambda \\dfrac{ \\partial \\mathcal{L}_{d} }{ \\partial \\theta_{d} } $$ 特征提取参数： $$ \\theta_{f} \\leftarrow \\theta_{f} - \\mu\\left( \\dfrac{ \\partial \\mathcal{L}_{y} }{ \\partial \\theta_{f} } - \\lambda \\dfrac{ \\partial \\mathcal{L}_{d} }{ \\partial \\theta_{f} } \\right) $$ 核心需要最大化 $ \\mathcal{L}_{d} $ ，因此需要沿着梯度的正向优化 Gradient Reversal Layer (GRL) 是实现对抗的核心组件，具体原理是在前向传播时表现为 $ R(x)=x $ ，但是反向传播时 $ \\dfrac{\\mathrm{d} R}{\\mathrm{d}x}=-I $ ，这样可以直接利用内置的自动微分优雅实现对抗\n","permalink":"https://diefish1024.github.io/posts/literature-notes/dann/","summary":"\u003ch2 id=\"introduction\"\u003eIntroduction\u003c/h2\u003e\n\u003cp\u003e类似 GAN 的对抗训练思想\u003c/p\u003e\n\u003ch2 id=\"domain-adaptation\"\u003eDomain Adaptation\u003c/h2\u003e\n\u003cp\u003e给定源域 $ D_{S} $ （有标签）和目标域 $ D_{T} $ （无标签），目标是训练一个分类器 $ \\eta: X\\to Y $ 使其在目标域上的目标风险\n$$ \n\nR_{D_{T}}(\\eta) = \\underset{(\\mathbf{x},y)\\sim D_{T}}{\\mathrm{Pr}}(\\eta(\\mathbf{x}) \\neq y)\n\n $$\n最小\u003c/p\u003e\n\u003ch4 id=\"domain-divergence\"\u003eDomain Divergence\u003c/h4\u003e\n\u003cp\u003e需要量化两个领域的“相似度”，从而引出了 \u003cstrong\u003eH- 散度\u003c/strong\u003e 的概念：\n$$ \n\nd_{\\mathcal{H}}(D_S, D_T) = 2 \\sup_{\\eta \\in \\mathcal{H}} \\left| \\Pr_{x \\sim D_S}[\\eta(x) = 1] - \\Pr_{x \\sim D_T}[\\eta(x) = 1] \\right|\n\n $$\n含义是最优的分类器将目标域和源域判定为 1 的可能性之差，当 H- 散度非常小时，说明两个领域很难被区分，也就说明学习的特征实现了领域不变性的效果\u003c/p\u003e\n\u003cp\u003e由于理论 H 散度是理想数据分布上的定义，实际中只有有限的样本集 $ S $ 和 $ T $ ，因此需要一定的近似，于是需要经验 H- 散度\n$$ \n\n\\hat{d}_{\\mathcal{H}}(S, T) = 2 \\left(1 - \\min_{\\eta \\in \\mathcal{H}} \\left[ \\dfrac{1}{n}\\sum_{i=1}^n \\mathcal{I}[\\eta(x_i) = 0] + \\dfrac{1}{n'}\\sum_{i=n+1}^N \\mathcal{I}[\\eta(x_i) = 1] \\right] \\right)\n\n $$\n其中 $ \\mathcal{I}[\\cdot] $ 表示条件为真时为 1，否则为 0\u003c/p\u003e","title":"DANN"},{"content":"A General Paradigm of Test-Time Adaptation 根据测试数据接收方式和适应过程，TTA 分为三种主要范式：\nTest-Time Batch Adaptation (TTBA) 测试时间批次适应： 数据以小批次形式到达。模型会针对每个到来的小批次进行适应，并立即提供预测。 Online Test-Time Adaptation (OTTA) 在线测试时间适应： 数据以序列化的方式（小批次）到达。模型进行增量更新，并且过去的适应经验会影响未来的预测。 Test-Time Domain Adaptation (TTDA) 测试时间域适应： 整个目标域的数据（所有测试数据）可在预测前一次性用于适应。 Datasets for Evaluation 论文使用了两种不同类型的分布偏移数据集进行评估：\nCorruption Datasets 损坏数据集： 原始数据集（CIFAR-10，ImageNet）经过人为损坏处理后得到的，通过添加不同类型的噪声、模糊等，模拟不同严重程度的分布偏移。 Natural-shift Datasets 自然偏移数据集： 这些数据集代表数据分布中自然发生的变化，收集自不同的真实世界来源或条件（Office-Home，DomainNet，其中图像可能是不同风格的艺术作品、剪贴画、真实世界照片或草图）。 Results on Natural Shift Datasets TTA 方法在自然偏移数据集上的表现与在损坏数据集上的表现有所不同。 PredBN 在损坏数据集上有效，但在自然偏移数据集上表现不佳，有时甚至比源模型更差。这可能是因为自然偏移对数据分布的影响与人工损坏不同。 T3A 在 OTTA 范式下的自然偏移数据集上表现优于其他 OTTA 算法。这归因于其特征生成方式及其分类器优化能力。 对于自然偏移数据集，TTDA 算法 持续取得了最高的性能。一些 OTTA 方法的多轮次也能达到可比的成果。 ","permalink":"https://diefish1024.github.io/posts/literature-notes/benchmarking-tta/","summary":"\u003ch3 id=\"a-general-paradigm-of-test-time-adaptation\"\u003eA General Paradigm of Test-Time Adaptation\u003c/h3\u003e\n\u003cp\u003e根据测试数据接收方式和适应过程，TTA 分为三种主要范式：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eTest-Time Batch Adaptation (TTBA) 测试时间批次适应：\u003c/strong\u003e 数据以小批次形式到达。模型会针对每个到来的小批次进行适应，并立即提供预测。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eOnline Test-Time Adaptation (OTTA) 在线测试时间适应：\u003c/strong\u003e 数据以序列化的方式（小批次）到达。模型进行增量更新，并且过去的适应经验会影响未来的预测。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eTest-Time Domain Adaptation (TTDA) 测试时间域适应：\u003c/strong\u003e 整个目标域的数据（所有测试数据）可在预测前一次性用于适应。\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"datasets-for-evaluation\"\u003eDatasets for Evaluation\u003c/h3\u003e\n\u003cp\u003e论文使用了两种不同类型的分布偏移数据集进行评估：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eCorruption Datasets 损坏数据集：\u003c/strong\u003e 原始数据集（CIFAR-10，ImageNet）经过\u003cstrong\u003e人为损坏处理\u003c/strong\u003e后得到的，通过添加不同类型的噪声、模糊等，模拟不同严重程度的分布偏移。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eNatural-shift Datasets 自然偏移数据集：\u003c/strong\u003e 这些数据集代表数据分布中\u003cstrong\u003e自然发生的变化\u003c/strong\u003e，收集自不同的真实世界来源或条件（Office-Home，DomainNet，其中图像可能是不同风格的艺术作品、剪贴画、真实世界照片或草图）。\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"results-on-natural-shift-datasets\"\u003eResults on Natural Shift Datasets\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eTTA 方法在自然偏移数据集上的表现与在损坏数据集上的表现有所不同。\u003c/li\u003e\n\u003cli\u003ePredBN 在损坏数据集上有效，但在自然偏移数据集上表现不佳，有时甚至比源模型更差。这可能是因为自然偏移对数据分布的影响与人工损坏不同。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eT3A\u003c/strong\u003e 在 OTTA 范式下的自然偏移数据集上表现优于其他 OTTA 算法。这归因于其特征生成方式及其分类器优化能力。\u003c/li\u003e\n\u003cli\u003e对于自然偏移数据集，\u003cstrong\u003eTTDA 算法\u003c/strong\u003e 持续取得了最高的性能。一些 OTTA 方法的多轮次也能达到可比的成果。\u003c/li\u003e\n\u003c/ul\u003e","title":"Benchmarking TTA"},{"content":"信号量 互斥锁在某种意义上也可以认为实现了 \u0026ldquo;happens-before\u0026rdquo; 的依赖关系—— release 必然发生在 acquire 之前。我们可以试着利用这种依赖关系来实现计算图的调度：为每条边分配一个互斥锁，代表数据或前置任务的完成；一个节点必须获得所有入边对应的互斥锁才能开始计算，计算完成后，就释放所有出边对应的互斥锁，通知下游节点输出就绪（但是这种直接使用互斥锁作为边状态信号的方式是 undefined behavior，因为互斥锁主要用于保护临界区，其释放通常要求由持有它的线程完成，若释放未曾获取的锁，则行为未定义）\n我们可以从这种想法中抽象出其本质，也就是用一个“信号”去获取资源的许可，类似餐厅的取号吃饭\n这种信号的思想很适合用来管理计数类型的同类资源，比如停车场的空位，为了实现这种 producer-customer 的问题，用 条件变量 可以轻易解决，进入的条件就是存在空位 count \u0026lt; capacity ，那我们从减少变量的角度出发，这实际上也就是剩余空位的数量大于零，我们停车相当于消耗了一个车位，离开相当于创造了一个车位，这也就得到了所谓“信号量”的机制\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 void P(sem_t *sem) { // Prolaag - try + decrease/down/wait/acquire mutex_lock(\u0026amp;sem-\u0026gt;lk); while (!(sem-\u0026gt;count \u0026gt; 0)) { cond_wait(\u0026amp;sem-\u0026gt;cv, \u0026amp;sem-\u0026gt;lk); } sem-\u0026gt;count--; // 消耗一个信号 (车位) mutex_unlock(\u0026amp;sem-\u0026gt;lk); } void V(sem_t *sem) { // Verhoog - increase/up/post/signal/release mutex_lock(\u0026amp;sem-\u0026gt;lk); sem-\u0026gt;count++; // 创建一个信号 (车位) cond_broadcast(\u0026amp;sem-\u0026gt;cv); mutex_unlock(\u0026amp;sem-\u0026gt;lk); } 根据这个一路推出信号量的思路，或许可以认为这是互斥锁的扩展\n信号量：应用 信号量有两种典型的应用：\n实现一个临时的 happens-before：$ A\\to V(s)\\to P(s)\\to B $ 管理计数资源：停车场、餐厅…… 可以利用信号量优雅地实现 producer-customer 的模型：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 sem_t empty = SEM_INIT(depth); sem_t fill = SEM_INIT(0); void T_produce() { P(\u0026amp;empty); printf(\u0026#34;(\u0026#34;); V(\u0026amp;fill); } void T_consume() { P(\u0026amp;fill); printf(\u0026#34;)\u0026#34;); V(\u0026amp;empty); } 信号量、条件变量与同步 信号量对比条件变量：\n信号量：更加干净优雅，但是不一定能很好地表示同步条件（用更 hack 的方式解决问题） 条件变量：更加万能，但是代码比较丑陋（用更标准化的方式解决问题） 尝试用信号量解决更复杂的同步问题：哲学家吃饭，一张圆桌围坐 $ n $ 个哲学家，每两个人之间有一把叉子（筷子更加合适？？），每个哲学家（线程）有时思考有时吃饭，思考时什么也不用做，吃饭时同时需要左手右手的叉子\n用条件变量解决这个问题只需要无脑设置同步条件即可，用信号量解决这个问题有一个初步的想法是 P(\u0026amp;sem[lhs]) \u0026amp;\u0026amp; P(\u0026amp;sem[rhs]) ，乍一看没什么问题，但是实际上这个条件在所有人都同时举起了同一边的叉子时会陷入死锁（所以并发编程一定要仔细再仔细！），所以为了排除这种方案，有两种解决方案：\n从桌子赶走一个人：为上桌吃饭人数设置一个信号量，限制不让所有人同时上桌即可（显然不可能所有人同时吃上饭） 为叉子编号，总是先拿起编号小的一把（最后一个人的顺序会和其他人反过来） 但是这样的解决方案是不够优雅不够通用的，因此更多时候条件变量是一个更好的选择，可以总结为信号量在适合的适合很好用，但不总是很好用\n","permalink":"https://diefish1024.github.io/posts/class-notes/nju-os-2025/16-%E5%B9%B6%E5%8F%91%E6%8E%A7%E5%88%B6%E5%90%8C%E6%AD%A5%E4%BF%A1%E5%8F%B7%E9%87%8F/","summary":"\u003ch2 id=\"信号量\"\u003e信号量\u003c/h2\u003e\n\u003cp\u003e互斥锁在某种意义上也可以认为实现了 \u0026ldquo;happens-before\u0026rdquo; 的依赖关系—— release 必然发生在 acquire 之前。我们可以试着利用这种依赖关系来实现计算图的调度：为每条边分配一个互斥锁，代表数据或前置任务的完成；一个节点必须获得所有入边对应的互斥锁才能开始计算，计算完成后，就释放所有出边对应的互斥锁，通知下游节点输出就绪（但是这种直接使用互斥锁作为边状态信号的方式是 undefined behavior，因为互斥锁主要用于保护临界区，其释放通常要求由持有它的线程完成，若释放未曾获取的锁，则行为未定义）\u003c/p\u003e\n\u003cp\u003e我们可以从这种想法中抽象出其本质，也就是用一个“\u003cstrong\u003e信号\u003c/strong\u003e”去获取资源的许可，类似餐厅的取号吃饭\u003c/p\u003e\n\u003cp\u003e这种\u003cstrong\u003e信号\u003c/strong\u003e的思想很适合用来管理\u003cstrong\u003e计数类型的同类资源\u003c/strong\u003e，比如停车场的空位，为了实现这种 producer-customer 的问题，用 \u003ca href=\"15.%20%E5%B9%B6%E5%8F%91%E6%8E%A7%E5%88%B6%EF%BC%9A%E5%90%8C%E6%AD%A5%E6%9D%A1%E4%BB%B6%E5%8F%98%E9%87%8F.md\"\u003e条件变量\u003c/a\u003e 可以轻易解决，进入的条件就是存在空位 \u003ccode\u003ecount \u0026lt; capacity\u003c/code\u003e ，那我们从减少变量的角度出发，这实际上也就是剩余空位的数量大于零，我们停车相当于\u003cstrong\u003e消耗\u003c/strong\u003e了一个车位，离开相当于\u003cstrong\u003e创造\u003c/strong\u003e了一个车位，这也就得到了所谓“\u003cstrong\u003e信号量\u003c/strong\u003e”的机制\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cdiv class=\"chroma\"\u003e\n\u003ctable class=\"lntable\"\u003e\u003ctr\u003e\u003ctd class=\"lntd\"\u003e\n\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode\u003e\u003cspan class=\"lnt\"\u003e 1\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 2\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 3\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 4\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 5\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 6\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 7\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 8\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 9\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e10\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e11\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e12\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e13\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e14\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e15\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e16\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e17\n\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\n\u003ctd class=\"lntd\"\u003e\n\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-c\" data-lang=\"c\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"kt\"\u003evoid\u003c/span\u003e \u003cspan class=\"nf\"\u003eP\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"kt\"\u003esem_t\u003c/span\u003e \u003cspan class=\"o\"\u003e*\u003c/span\u003e\u003cspan class=\"n\"\u003esem\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"c1\"\u003e// Prolaag - try + decrease/down/wait/acquire\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"nf\"\u003emutex_lock\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"o\"\u003e\u0026amp;\u003c/span\u003e\u003cspan class=\"n\"\u003esem\u003c/span\u003e\u003cspan class=\"o\"\u003e-\u0026gt;\u003c/span\u003e\u003cspan class=\"n\"\u003elk\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"k\"\u003ewhile\u003c/span\u003e \u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"o\"\u003e!\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003esem\u003c/span\u003e\u003cspan class=\"o\"\u003e-\u0026gt;\u003c/span\u003e\u003cspan class=\"n\"\u003ecount\u003c/span\u003e \u003cspan class=\"o\"\u003e\u0026gt;\u003c/span\u003e \u003cspan class=\"mi\"\u003e0\u003c/span\u003e\u003cspan class=\"p\"\u003e))\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"nf\"\u003econd_wait\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"o\"\u003e\u0026amp;\u003c/span\u003e\u003cspan class=\"n\"\u003esem\u003c/span\u003e\u003cspan class=\"o\"\u003e-\u0026gt;\u003c/span\u003e\u003cspan class=\"n\"\u003ecv\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"o\"\u003e\u0026amp;\u003c/span\u003e\u003cspan class=\"n\"\u003esem\u003c/span\u003e\u003cspan class=\"o\"\u003e-\u0026gt;\u003c/span\u003e\u003cspan class=\"n\"\u003elk\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"n\"\u003esem\u003c/span\u003e\u003cspan class=\"o\"\u003e-\u0026gt;\u003c/span\u003e\u003cspan class=\"n\"\u003ecount\u003c/span\u003e\u003cspan class=\"o\"\u003e--\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e  \u003cspan class=\"c1\"\u003e// 消耗一个信号 (车位)\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"nf\"\u003emutex_unlock\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"o\"\u003e\u0026amp;\u003c/span\u003e\u003cspan class=\"n\"\u003esem\u003c/span\u003e\u003cspan class=\"o\"\u003e-\u0026gt;\u003c/span\u003e\u003cspan class=\"n\"\u003elk\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"kt\"\u003evoid\u003c/span\u003e \u003cspan class=\"nf\"\u003eV\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"kt\"\u003esem_t\u003c/span\u003e \u003cspan class=\"o\"\u003e*\u003c/span\u003e\u003cspan class=\"n\"\u003esem\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"c1\"\u003e// Verhoog - increase/up/post/signal/release\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"nf\"\u003emutex_lock\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"o\"\u003e\u0026amp;\u003c/span\u003e\u003cspan class=\"n\"\u003esem\u003c/span\u003e\u003cspan class=\"o\"\u003e-\u0026gt;\u003c/span\u003e\u003cspan class=\"n\"\u003elk\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"n\"\u003esem\u003c/span\u003e\u003cspan class=\"o\"\u003e-\u0026gt;\u003c/span\u003e\u003cspan class=\"n\"\u003ecount\u003c/span\u003e\u003cspan class=\"o\"\u003e++\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e  \u003cspan class=\"c1\"\u003e// 创建一个信号 (车位)\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"nf\"\u003econd_broadcast\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"o\"\u003e\u0026amp;\u003c/span\u003e\u003cspan class=\"n\"\u003esem\u003c/span\u003e\u003cspan class=\"o\"\u003e-\u0026gt;\u003c/span\u003e\u003cspan class=\"n\"\u003ecv\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"nf\"\u003emutex_unlock\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"o\"\u003e\u0026amp;\u003c/span\u003e\u003cspan class=\"n\"\u003esem\u003c/span\u003e\u003cspan class=\"o\"\u003e-\u0026gt;\u003c/span\u003e\u003cspan class=\"n\"\u003elk\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\u003c/tr\u003e\u003c/table\u003e\n\u003c/div\u003e\n\u003c/div\u003e\u003cp\u003e根据这个一路推出信号量的思路，或许可以认为这是互斥锁的扩展\u003c/p\u003e","title":"16. 并发控制：同步信号量"},{"content":"同步和条件变量 互斥实现了原子性，但是无法实现确定性，也就是无法正确实现 \u0026ldquo;happens-before\u0026rdquo; 的关系\n因此需要引入条件变量来实现线程的同步，形成受控制的并发事件的发生顺序（可以用乐团指挥来类比），把一系列不确定的状态在某一个时间点同步到了一个确定的状态，将发散的并发程序状态 “收束”\n实现同步\n实现 $ A\\to B $：\n1 2 3 4 5 6 7 A; can_proceed = true; (signal) while(!can_proceed); B // B: wait until the condition is satisfied 这样的思路大致正确，但是自选的循环有很大的性能问题，因此需要一个更加底层的机制来帮助实现这一点\n最理想的 API 是 wait_until(cond) ，但是过去为了简化设计，变成了\n条件不满足时等待：wait - 直接睡眠等待 条件满足时继续：signal/broadcast - 唤醒所有线程 （小时候的 scratch 编程其实已经有了这样的思想😂）\n在 c++ 代码中我们可以把条件放到 $ \\lambda $ 表达式中：\n1 2 3 4 5 6 7 8 9 10 11 12 std::mutex mtx; std::condition_variable cv; void T_player() { std::unique_lock lk(mtx); cv.wait(lk, []{ return can_proceed; } ); cv.notify_all(); lk.unlock(); } 注意条件变量在等待时需要带着一把锁（需要确保检查和等待是原子操作）\n使用条件变量解决同步问题 大部分的同步问题都可以用经典的生产者 - 消费者问题归纳：\nProducer 和 Consumer 共享一个缓冲区，其中\nProducer 看到缓冲区有空位就会放入，否则等待 Consumer 看到缓冲区有数据就回去走，否则等待 显然一个对象的生产和消费必须满足 \u0026ldquo;happens-before\u0026rdquo; 的关系\n可以等价成打印匹配的括号，并且嵌套深度有上限（缓冲区的深度）\n处理这样的问题首先要想清楚程序继续执行的条件，比如生产的条件是 $ d\u003c n $ ，而消费的条件是 $ d\u003e0 $ ，然后套入固定的模板代码即可：\n1 2 3 4 5 6 mutex_lock(lk); while (!cond) { // cond can be any calculate cond_wait(\u0026amp;cv, lk); } assert(cond); mutex_lock(lk); 1 2 3 4 mutex_lock(lk); cond = true cond_broadcast(\u0026amp;cv); //⚠️ mutex_unlock(lk); 注意：全局广播 cond_broadcast 不能被替换成单独唤醒一个线程 cond_signal ，在这里显然可能会导致所有进程都被锁住无法触发新的同步变量；并发编程很多看起来正确的地方都需要仔细思考\n遇到任何同步问题的核心都是同步条件是什么，比如括号打印可以拓展成打印 \u0026lt;\u0026gt;\u0026lt; 或者 \u0026gt;\u0026lt;\u0026gt; 两种形状，核心也是画出状态机，找到同步条件，再套入模板就解决了问题\n计算图与并发控制 并行计算的模型可以用一个 DAG 计算图去理解，任务之间存在依赖关系，通过拓扑排序的顺序去解决问题，相互不存在 \u0026ldquo;happens-before\u0026rdquo; 依赖关系的任务都可以并发解决\n为了优化效率，我们对计算任务的分配需要保证每个节点计算的消耗是远大于同步和锁的开销的，因此实际上可能是把很多个小的任务聚合成一个大的并发计算节点，交给一个线程去执行\n实现计算图有两种思路，第一种是朴素的为每个节点设置一个线程和条件变量\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 // The dependency edge is u-\u0026gt;v void T_u() { // calculate u mutex_lock(v-\u0026gt;lock); v-\u0026gt;num_done++; cond_signal(v-\u0026gt;cv); // it\u0026#39;s okay mutex_unlock(v-\u0026gt;lock); } void T_v() { mutex_lock(v-\u0026gt;lock); while (!(v-\u0026gt;num_done == v-\u0026gt;num_predecessors)){ cond_wait(v-\u0026gt;cv, v-\u0026gt;lock); } mutex_unlock(v-\u0026gt;lock); // calculate v } 但是这样实际会产生过多的线程，造成不必要的性能开销（比如产生了多余 CPU 的 core 数量的线程），实际上更优的办法是创建一个任务调度器线程 $ T_{\\text{scheduler}} $ 来专门控制产生 $ T_{\\text{worker}} $ ：\n1 2 3 4 5 6 7 8 9 10 11 12 13 mutex_lock(lk); while (!(all_done || has_job(tid))) { cond_wait(\u0026amp;worker_cv[tid], lk); } mutex_unlock(lk); if (all_done) { break; } else { process_job(tid); } signal(\u0026amp;sched_cv); ","permalink":"https://diefish1024.github.io/posts/class-notes/nju-os-2025/15-%E5%B9%B6%E5%8F%91%E6%8E%A7%E5%88%B6%E5%90%8C%E6%AD%A5%E6%9D%A1%E4%BB%B6%E5%8F%98%E9%87%8F/","summary":"\u003ch2 id=\"同步和条件变量\"\u003e同步和条件变量\u003c/h2\u003e\n\u003cp\u003e互斥实现了\u003cstrong\u003e原子性\u003c/strong\u003e，但是无法实现\u003cstrong\u003e确定性\u003c/strong\u003e，也就是无法正确实现 \u0026ldquo;happens-before\u0026rdquo; 的关系\u003c/p\u003e\n\u003cp\u003e因此需要引入条件变量来实现线程的同步，形成受控制的并发事件的\u003cstrong\u003e发生顺序\u003c/strong\u003e（可以用乐团指挥来类比），把一系列不确定的状态在某一个时间点同步到了一个确定的状态，将发散的并发程序状态 “收束”\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e实现同步\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e实现 $ A\\to B $：\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cdiv class=\"chroma\"\u003e\n\u003ctable class=\"lntable\"\u003e\u003ctr\u003e\u003ctd class=\"lntd\"\u003e\n\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode\u003e\u003cspan class=\"lnt\"\u003e1\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e2\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e3\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e4\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e5\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e6\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e7\n\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\n\u003ctd class=\"lntd\"\u003e\n\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-gdscript3\" data-lang=\"gdscript3\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003eA\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003ecan_proceed\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"bp\"\u003etrue\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"k\"\u003esignal\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"k\"\u003ewhile\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"o\"\u003e!\u003c/span\u003e\u003cspan class=\"n\"\u003ecan_proceed\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003eB\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"o\"\u003e//\u003c/span\u003e \u003cspan class=\"n\"\u003eB\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"n\"\u003ewait\u003c/span\u003e \u003cspan class=\"n\"\u003euntil\u003c/span\u003e \u003cspan class=\"n\"\u003ethe\u003c/span\u003e \u003cspan class=\"n\"\u003econdition\u003c/span\u003e \u003cspan class=\"n\"\u003eis\u003c/span\u003e \u003cspan class=\"n\"\u003esatisfied\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\u003c/tr\u003e\u003c/table\u003e\n\u003c/div\u003e\n\u003c/div\u003e\u003cp\u003e这样的思路大致正确，但是自选的循环有很大的性能问题，因此需要一个更加底层的机制来帮助实现这一点\u003c/p\u003e\n\u003cp\u003e最理想的 API 是 \u003ccode\u003ewait_until(cond)\u003c/code\u003e ，但是过去为了简化设计，变成了\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e条件不满足时等待：\u003ccode\u003ewait\u003c/code\u003e - 直接睡眠等待\u003c/li\u003e\n\u003cli\u003e条件满足时继续：\u003ccode\u003esignal/broadcast\u003c/code\u003e - 唤醒所有线程\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e（小时候的 scratch 编程其实已经有了这样的思想😂）\u003c/p\u003e\n\u003cp\u003e在 c++ 代码中我们可以把条件放到 $ \\lambda $ 表达式中：\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cdiv class=\"chroma\"\u003e\n\u003ctable class=\"lntable\"\u003e\u003ctr\u003e\u003ctd class=\"lntd\"\u003e\n\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode\u003e\u003cspan class=\"lnt\"\u003e 1\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 2\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 3\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 4\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 5\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 6\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 7\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 8\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 9\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e10\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e11\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e12\n\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\n\u003ctd class=\"lntd\"\u003e\n\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-c++\" data-lang=\"c++\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003estd\u003c/span\u003e\u003cspan class=\"o\"\u003e::\u003c/span\u003e\u003cspan class=\"n\"\u003emutex\u003c/span\u003e \u003cspan class=\"n\"\u003emtx\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003estd\u003c/span\u003e\u003cspan class=\"o\"\u003e::\u003c/span\u003e\u003cspan class=\"n\"\u003econdition_variable\u003c/span\u003e \u003cspan class=\"n\"\u003ecv\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"kt\"\u003evoid\u003c/span\u003e \u003cspan class=\"nf\"\u003eT_player\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\t\u003cspan class=\"n\"\u003estd\u003c/span\u003e\u003cspan class=\"o\"\u003e::\u003c/span\u003e\u003cspan class=\"n\"\u003eunique_lock\u003c/span\u003e \u003cspan class=\"n\"\u003elk\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003emtx\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\t\u003cspan class=\"n\"\u003ecv\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ewait\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003elk\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\t\t\u003cspan class=\"p\"\u003e[]{\u003c/span\u003e \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"n\"\u003ecan_proceed\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e \u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\t\u003cspan class=\"p\"\u003e);\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\t\u003cspan class=\"n\"\u003ecv\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003enotify_all\u003c/span\u003e\u003cspan class=\"p\"\u003e();\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\t\u003cspan class=\"n\"\u003elk\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eunlock\u003c/span\u003e\u003cspan class=\"p\"\u003e();\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\u003c/tr\u003e\u003c/table\u003e\n\u003c/div\u003e\n\u003c/div\u003e\u003cp\u003e注意条件变量在等待时需要带着一把锁（需要确保检查和等待是原子操作）\u003c/p\u003e","title":"15. 并发控制：同步条件变量"}]