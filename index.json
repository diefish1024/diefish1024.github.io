[{"content":"Exercise 1 (Multiplication of block matrices). Consider two block matrices $$ A = \\begin{pmatrix} A_{11} \u0026 \\cdots \u0026 A_{1t} \\\\ \\vdots \u0026 \\ddots \u0026 \\vdots \\\\ A_{p1} \u0026 \\cdots \u0026 A_{pt} \\end{pmatrix} \\quad \\text{and} \\quad B = \\begin{pmatrix} B_{11} \u0026 \\cdots \u0026 B_{1q} \\\\ \\vdots \u0026 \\ddots \u0026 \\vdots \\\\ B_{t1} \u0026 \\cdots \u0026 B_{tq} \\end{pmatrix} $$ Moreover, for every $ i \\in [p] $, $ j \\in [t] $, and $ l \\in [q] $ the number of columns of $ A_{ij} $ is equal to the number of rows of $ B_{jl} $. In particular, $ A_{ij} \\cdot B_{jl} $ is defined. Prove that $$ A \\cdot B = \\begin{pmatrix} C_{11} \u0026 \\cdots \u0026 C_{1q} \\\\ \\vdots \u0026 \\ddots \u0026 \\vdots \\\\ C_{p1} \u0026 \\cdots \u0026 C_{pq} \\end{pmatrix} $$ with $$ C_{il} = \\sum_{j \\in [t]} A_{ij} B_{jl} $$ for any $ i \\in [p] $ and $ l \\in [q] $.\nProof:\nLet $ A = (a_{\\alpha\\beta}) $ and $ B = (b_{\\beta\\gamma}) $. The entry $ (AB)_{\\alpha\\gamma} $ is given by $ (AB)_{\\alpha\\gamma} = \\sum_{\\beta} a_{\\alpha\\beta} b_{\\beta\\gamma} $.\nConsider a specific entry $ (C_{il})_{uv} $ within the block $ C_{il} $ of the product matrix $ AB $. This entry corresponds to a global row index $ \\alpha $ in $ A $\u0026rsquo;s $ i $-th block row (specifically, the $ u $-th row within that block row) and a global column index $ \\gamma $ in $ B $\u0026rsquo;s $ l $-th block column (specifically, the $ v $-th column within that block column).\nThe summation over $ \\beta $ can be partitioned according to the column blocks of $ A $ and the row blocks of $ B $ that correspond to the intermediate index $ j $. Specifically, the range of $ \\beta $ for which $ a_{\\alpha\\beta} $ belongs to $ A_{ij} $ and $ b_{\\beta\\gamma} $ belongs to $ B_{jl} $ forms a segment. Summing these segments yields: $$ (C_{il})_{uv} = \\sum_{\\beta} a_{\\alpha\\beta} b_{\\beta\\gamma} = \\sum_{j=1}^{t} \\left( \\sum_{\\substack{\\beta_j \\in \\text{columns of } A_{ij} \\\\ \\text{and rows of } B_{jl}}} (A_{ij})_{u\\beta_j} (B_{jl})_{\\beta_j v} \\right) $$ The inner sum $ \\sum_{\\beta_j} (A_{ij})_{u\\beta_j} (B_{jl})_{\\beta_j v} $ precisely represents the $ (u,v) $-th entry of the product matrix $ A_{ij} B_{jl} $.\nTherefore, we can write: $$ (C_{il})_{uv} = \\sum_{j=1}^{t} (A_{ij} B_{jl})_{uv} $$ Since this equality holds for every entry $ (u,v) $ in the block $ C_{il} $, it follows that the block matrix equation is true: $$ C_{il} = \\sum_{j \\in [t]} A_{ij} B_{jl} $$\nExercise 2 Let $ P $ be a permutation matrix and consider its column vectors $ p_1, \\ldots, p_n $. (i) Prove that each pair of distinct (i.e., $ i \\neq j $) $ p_i $ and $ p_j $ are perpendicular. (ii) Prove each $ p_i $ is a unit vector. (iii) Using (i) and (ii) prove that $ P^{-1} = P^T $.\n(i)\nFor distinct columns $ p_i $ and $ p_j $ (where $ i \\neq j $), each vector has a single \u0026lsquo;1\u0026rsquo; at different positions.\nWhen computing their dot product $ p_i^T p_j = \\sum_k (p_i)_k (p_j)_k $, for any given $ k $, at least one of $ (p_i)_k $ or $ (p_j)_k $ must be \u0026lsquo;0\u0026rsquo; because their \u0026lsquo;1\u0026rsquo;s are in different rows. Thus, $ (p_i)_k (p_j)_k = 0 $ for all $ k $, which implies $ p_i^T p_j = 0 $. Therefore, $ p_{i} $ and $ p_j $ are perpendicular for $ i \\neq j $.\n(ii)\nA column vector $ p_i $ has exactly one \u0026lsquo;1\u0026rsquo; and all other entries are \u0026lsquo;0\u0026rsquo;, its norm is $ p_i^T p_i = \\sum_k (p_i)_k^2 = 1 $. Therefore, $ \\|p_i\\| = 1 $, proving $ p_i $ is a unit vector.\n(iii)\nConsider the entry $ (P^T P)_{ij} $ of the product $ P^T P $. This entry is the dot product of the $ i $-th column of $ P $ with its $ j $-th column: $ (P^T P)_{ij} = p_i^T p_j $.\nFrom part (i), if $ i \\neq j $, then $ p_i^T p_j = 0 $. From part (ii), if $ i = j $, then $ p_i^T p_i = 1 $. Thus $ P^T P = I $, therefore, $ P^{-1} = P^T $.\nExercise 3 Let $ A = [a_1, \\ldots, a_n] $ be an $ n \\times n $ matrix such that $ A^{-1} = A^T $. Prove: (i) Each pair of distinct column vectors $ a_i $ and $ a_j $ are perpendicular. (ii) Each $ a_i $ is a unit vector. Prove that the same is true for the row vectors of $ A $.\n(i) \u0026amp; (ii) Proof for Column Vectors\nGiven $ A^{-1} = A^T $, it follows that $ A^T A = I $.\nThe entry $ (A^T A)_{kl} $ is the dot product of the $ k $-th column of $ A $ ($ a_k $) and the $ l $-th column of $ A $ ($ a_l $), i.e., $ (A^T A)_{kl} = a_k^T a_l $.\nSince $ A^T A = I $, we have:\nFor $ k \\neq l $: $ a_k^T a_l = 0 $. This proves that distinct column vectors $ a_k $ and $ a_l $ are perpendicular. For $ k = l $: $ a_k^T a_k = 1 $. This proves that $ \\|a_k\\|^2 = 1 $, so each column vector $ a_k $ is a unit vector. Proof for Row Vectors\nLet $ A $ have row vectors $ r_1, \\ldots, r_n $. From $ A^{-1} = A^T $, it also follows that $ A A^T = I $.\nThe entry $ (A A^T)_{kl} $ is the dot product of the $ k $-th row of $ A $ ($ r_k $) and the $ l $-th row of $ A $ ($ r_l $), i.e., $ (A A^T)_{kl} = r_k r_l^T $.\nSince $ A A^T = I $, we have:\nFor $ k \\neq l $: $ r_k r_l^T = 0 $. This proves that distinct row vectors $ r_k $ and $ r_l $ are perpendicular. For $ k = l $: $ r_k r_k^T = 1 $. This proves that $ \\|r_k\\|^2 = 1 $, so each row vector $ r_k $ is a unit vector. Exercise 4 Let $ A $ be a square matrix such that there are $ B $ and $ C $ with $ BA = AC = I $. Note we didn\u0026rsquo;t assume per se $ B = C $. However, prove that $ B = C $. In particular $ A $ is invertible with $ A^{-1} = B = C $.\nProof: $$ \\begin{align*} BA \u0026 = I \\\\ (BA)C \u0026 = IC = C \\\\ B(AC)\u0026 = C \\\\ BI = B \u0026 = C \\end{align*} $$ Thus, $ B $ and $ C $ must be equal. This proves that if both a left inverse and a right inverse exist for a square matrix $ A $, they are unique and identical, defining the inverse $ A^{-1} = B = C $.\nExercise 5 This is intended to repeat what we have learnt in the class. Prove in a vector space: (i) $ 0v = 0 $. (ii) $ (-1)v = -v $. (iii) $ -(v + w) = (-v) + (-w) $. (iv) $ c0 = 0 $. (v) $ c(-v) = (-c)v = -(cv) $.\n(i) $$ 0v = (0+0)v = 2\\cdot0v \\implies 0v = 0 $$ (ii) $$ v + (-1)v = (1 + (-1))v = 0v =0 \\implies (-1)v = -v $$ (iii) $$ (v+w) + ((-v) + (-w)) = (v + (-v)) + (w + (-w)) = 0 \\implies (-v+w) = (-v) + (-w) $$ (iv) $$ c\\cdot \\vec{0} = c\\cdot(\\vec{0} + \\vec{0}) = 2(c \\cdot \\vec{0}) \\implies c\\cdot \\vec{0} = 0 $$ (v) $$ c(-v) = c((-1)v) = (c \\cdot (-1))v = (-c)v $$ $$ cv + (-c)v = (c + (-c))v = 0v = 0 \\implies (-c)v = -(cv) $$\nCombining these, we have $ c(-v) = (-c)v = -(cv) $.\n","permalink":"https://diefish1024.github.io/posts/class-notes/math1205h-linear-algebra/math1205h-hw3/","summary":"\u003ch2 id=\"exercise-1\"\u003eExercise 1\u003c/h2\u003e\n\u003cblockquote\u003e\n\u003cp\u003e(Multiplication of block matrices). Consider two block matrices\n$$ \n\n A = \\begin{pmatrix}\n A_{11} \u0026 \\cdots \u0026 A_{1t} \\\\\n \\vdots \u0026 \\ddots \u0026 \\vdots \\\\\n A_{p1} \u0026 \\cdots \u0026 A_{pt}\n \\end{pmatrix}\n \\quad \\text{and} \\quad\n B = \\begin{pmatrix}\n B_{11} \u0026 \\cdots \u0026 B_{1q} \\\\\n \\vdots \u0026 \\ddots \u0026 \\vdots \\\\\n B_{t1} \u0026 \\cdots \u0026 B_{tq}\n \\end{pmatrix}\n \n $$\nMoreover, for every $ i \\in [p] $, $ j \\in [t] $, and $ l \\in [q] $ the number of columns of $ A_{ij} $ is equal to the number of rows of $ B_{jl} $. In particular, $ A_{ij} \\cdot B_{jl} $ is defined. Prove that\n$$ \n\n A \\cdot B = \\begin{pmatrix}\n C_{11} \u0026 \\cdots \u0026 C_{1q} \\\\\n \\vdots \u0026 \\ddots \u0026 \\vdots \\\\\n C_{p1} \u0026 \\cdots \u0026 C_{pq}\n \\end{pmatrix}\n \n $$\nwith\n$$ \n\n C_{il} = \\sum_{j \\in [t]} A_{ij} B_{jl}\n \n $$\nfor any $ i \\in [p] $ and $ l \\in [q] $.\u003c/p\u003e","title":"MATH1205H HW3"},{"content":"Exercise 1 What rows or columns or matrices do you multiply to find\nthe second column of $ AB $ ? the first row of $ AB $ ? the entry in row $ 3 $, column $ 5 $ of $ AB $ ? the entry in row $ 1 $, column $ 1 $ of $ CDE $ ? To find the second column of $ AB $, we multiply matrix $ A $ by the second column of matrix $ B $.\nMultiply the first row of $ A $ by matrix $ B $.\nMultiply the third row of $ A $ and the fifth column of $ B $.\nMultiply first the first row of $ C $ by $ D $, then product the first column of $ E $.\nExercise 2 Show that $ (A + B)^2 $ is different from $ A^2 + 2AB + B^2 $, when $ A=\\begin{pmatrix} 1 \u0026 2 \\\\ 0 \u0026 0 \\end{pmatrix} $ and $ B=\\begin{pmatrix} 1 \u0026 0 \\\\ 3 \u0026 0 \\end{pmatrix} $.\nWrite down the correct rule for $ (A + B)(A + B) = A^2 + \\_\\_\\_\\_\\_\\_\\_\\_ + B^2 $.\nFirst, we find the sum of matrices $ A $ and $ B $ : $$ A+B = \\begin{pmatrix} 1 \u0026 2 \\\\ 0 \u0026 0 \\end{pmatrix} + \\begin{pmatrix} 1 \u0026 0 \\\\ 3 \u0026 0 \\end{pmatrix} = \\begin{pmatrix} 1+1 \u0026 2+0 \\\\ 0+3 \u0026 0+0 \\end{pmatrix} = \\begin{pmatrix} 2 \u0026 2 \\\\ 3 \u0026 0 \\end{pmatrix} $$ Next, we compute the square of $ (A+B) $ : $$ (A+B)^2 = \\begin{pmatrix} 2 \u0026 2 \\\\ 3 \u0026 0 \\end{pmatrix} \\begin{pmatrix} 2 \u0026 2 \\\\ 3 \u0026 0 \\end{pmatrix} = \\begin{pmatrix} 10 \u0026 4 \\\\ 6 \u0026 6 \\end{pmatrix} $$ Then we need to compute $ A^2 $, $ B^2 $, and $ 2AB $ separately.\n$$ A^2 = \\begin{pmatrix} 1 \u0026 2 \\\\ 0 \u0026 0 \\end{pmatrix} \\begin{pmatrix} 1 \u0026 2 \\\\ 0 \u0026 0 \\end{pmatrix} = \\begin{pmatrix} 1 \u0026 2 \\\\ 0 \u0026 0 \\end{pmatrix}, B^2 = \\begin{pmatrix} 1 \u0026 0 \\\\ 3 \u0026 0 \\end{pmatrix} \\begin{pmatrix} 1 \u0026 0 \\\\ 3 \u0026 0 \\end{pmatrix} = \\begin{pmatrix} 1 \u0026 0 \\\\ 3 \u0026 0 \\end{pmatrix} $$ $$ AB = \\begin{pmatrix} 1 \u0026 2 \\\\ 0 \u0026 0 \\end{pmatrix} \\begin{pmatrix} 1 \u0026 0 \\\\ 3 \u0026 0 \\end{pmatrix} = \\begin{pmatrix} 7 \u0026 0 \\\\ 0 \u0026 0 \\end{pmatrix} $$ Thus, we can calculate the result $$ A^2 + 2AB + B^2 = \\begin{pmatrix} 1 \u0026 2 \\\\ 0 \u0026 0 \\end{pmatrix} + \\begin{pmatrix} 14 \u0026 0 \\\\ 0 \u0026 0 \\end{pmatrix} + \\begin{pmatrix} 1 \u0026 0 \\\\ 3 \u0026 0 \\end{pmatrix} = \\begin{pmatrix} 16 \u0026 2 \\\\ 3 \u0026 0 \\end{pmatrix} $$ We found: $ (A+B)^2 = \\begin{pmatrix} 10 \u0026 4 \\\\ 6 \u0026 6 \\end{pmatrix} ,A^2 + 2AB + B^2 = \\begin{pmatrix} 16 \u0026 2 \\\\ 3 \u0026 0 \\end{pmatrix} $.\nSince $ \\begin{pmatrix} 10 \u0026 4 \\\\ 6 \u0026 6 \\end{pmatrix} \\neq \\begin{pmatrix} 16 \u0026 2 \\\\ 3 \u0026 0 \\end{pmatrix} $, we have shown that $ (A + B)^2 $ is different from $ A^2 + 2AB + B^2 $ for the given matrices. This difference arises because matrix multiplication is generally not commutative ($ AB \\neq BA $).\nThe correct rule for expanding $ (A+B)(A+B) $ for matrices $ A $ and $ B $ is: $ (A + B)(A + B) = A^2 + \\underline{AB+BA} + B^2 $.\nExercise 3 If you do a row operation on $ A $ and then a column operation, the result is the same as if you did the column operation first. Why is this true?\nProof:\nPerforming a row operation on a matrix $ A $ is equivalent to multiplying $ A $ on its left by a corresponding elementary matrix, let\u0026rsquo;s call it $ E_R $. So, the operation results in $ E_R A $. Then, perform the column operation on the result $ E_R A $. This means multiplying $ E_R A $ on the right by $ E_C $, giving the final result $ (E_R A) E_C $.\nPerforming a column operation on a matrix $ A $ is equivalent to multiplying $ A $ on its right by a corresponding elementary matrix, let\u0026rsquo;s call it $ E_C $. So, the operation results in $ A E_C $. Then, perform the row operation on the result $ A E_C $. This means multiplying $ A E_C $ on the left by $ E_R $, giving the final result $ E_R (A E_C) $.\nAccording to the associativity of matrix multiplication, we have $ (E_R A) E_C = E_R (A E_C) $. Therefore, the final matrix result is the same regardless of the order in which the row and column operations are performed.\nExercise 4 Let $ A=\\begin{pmatrix} 2 \u0026 3 \\\\ 1 \u0026 2 \\\\ 7 \u0026 100 \\end{pmatrix} $. Prove that there is no $ 2 \\times 3 $ matrix $ B $ such that $ AB = I $.\n(Please only use the materials we have learnt so far, in particular the geometric interpretation of $ Ab $ is a linear combination of the column vectors of $ A $).\nProof:\nFirstly, if $ AB=I $, $ I $ must be the $ 3 \\times 3 $ identity matrix ($ I_3 $).\nConsidering the column space of matrix $ A $, which has two column vectors: $ A_1 = \\begin{pmatrix} 2 \\\\ 1 \\\\ 7 \\end{pmatrix} $ and $ A_2 = \\begin{pmatrix} 3 \\\\ 2 \\\\ 100 \\end{pmatrix} $. These two vectors are linearly independent, so the column space $ Col(A) $ is a two-dimensional subspace of $ \\mathbb{R}^3 $ (a plane through the origin).\nIf $ AB=I_3 $, then each column of $ I_3 $ must be in the column space of $ A $. That is, for each standard basis vector $ e_j $ (the columns of $ I_3 $), there must exist a column vector $ b_j $ from $ B $ such that $ A b_j = e_j $. This means $ e_j $ must be a linear combination of $ A $\u0026rsquo;s column vectors, and thus $ e_j \\in Col(A) $.\nThe columns of $ I_3 $ are $ e_1=\\begin{pmatrix} 1 \\\\ 0 \\\\ 0 \\end{pmatrix} $, $ e_2=\\begin{pmatrix} 0 \\\\ 1 \\\\ 0 \\end{pmatrix} $, and $ e_3=\\begin{pmatrix} 0 \\\\ 0 \\\\ 1 \\end{pmatrix} $. These three vectors are linearly independent and span the entire $ \\mathbb{R}^3 $. However, $ Col(A) $ is only a two-dimensional subspace. A two-dimensional subspace cannot contain three linearly independent vectors that span a three-dimensional space.\nTherefore, there is no $ 2 \\times 3 $ matrix $ B $ such that $ AB=I $.\nExercise 5 Let $ m, n \\ge 1 $ and $ A, B $ two $ m \\times n $ matrices. Prove that if for all $ x \\in \\mathbb{R}^n $ we have $ Ax = Bx $, then $ A = B $.\nProof:\nWe are given $ Ax = Bx $ for all $ x \\in \\mathbb{R}^n $. This can be rewritten as $ (A-B)x = 0 $ for all $ x \\in \\mathbb{R}^n $. Let . Then the condition becomes for all .\nConsider the standard basis vectors $ e_1, e_2, \\ldots, e_n $ in $ \\mathbb{R}^n $. Since $ Cx=0 $ for all $ x $, it must hold for each $ e_j $. Therefore, implies that every column of is the zero vector.\nIf all columns of matrix $ C $ are the zero vector, then $ C $ must be the zero matrix. Since $ C=A-B $, we have $ A-B=0 $, which implies $ A=B $.\n","permalink":"https://diefish1024.github.io/posts/class-notes/math1205h-linear-algebra/math1205h-hw2/","summary":"\u003ch2 id=\"exercise-1\"\u003eExercise 1\u003c/h2\u003e\n\u003cblockquote\u003e\n\u003cp\u003eWhat rows or columns or matrices do you multiply to find\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003ethe second column of $ AB $ ?\u003c/li\u003e\n\u003cli\u003ethe first row of $ AB $ ?\u003c/li\u003e\n\u003cli\u003ethe entry in row $ 3 $, column $ 5 $ of $ AB $ ?\u003c/li\u003e\n\u003cli\u003ethe entry in row $ 1 $, column $ 1 $ of $ CDE $ ?\u003c/li\u003e\n\u003c/ol\u003e\u003c/blockquote\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003eTo find the second column of $ AB $, we multiply matrix $ A $ by the second column of matrix $ B $.\u003c/p\u003e","title":"MATH1205H HW2"},{"content":"Problem 1 用生成函数求解递推式 $$ a_{n} = 4a_{n-1} - 5a_{n-2} + 2a_{n-3} $$ 初始值为 $ a_{0}=0,a_{1}=3,a_{2}=7 $。\n解：\n设数列 $ \\{ a_{n} \\} $ 的生成函数为 $ F(x) $，那么根据递推式和初值 $ a_{0}=0,a_{1}=3,a_{2}=7 $ 得到 $$ F(x) = 4xF(x) - 5x^{2}F(x) + 2x^{3}F(x) + 3x - 5x^{2} $$ 得到 $$ F(x) = \\dfrac{5x^{2}-3x}{2x^{3}-5x^{2}+4x-1} = \\dfrac{3x-5x^{2}}{(1-x)^{2}(1-2x)} $$ 我们希望分解成 $$ \\dfrac{A}{1-x} + \\dfrac{B}{(1-x)^{2}} + \\dfrac{C}{1-2x} $$ 待定系数可以解得 $$ F(x) = \\dfrac{-3}{1-x} + \\dfrac{2}{(1-x)^{2}} + \\dfrac{1}{1-2x} $$ 展开得到 $$ F(x) = \\sum_{n=0}^{\\infty} (-3+2(n+1)+2^{n})x^{n} $$ 因此 $$ a_{n} = -3+2(n+1)+2^{n} = 2^{n} + 2n - 1 $$\nProblem 2 (1)\n设 $ f(n) $ 为集合 $ [n] $ 中不包含两个连续数字的子集数量，求 $ f(n) $ 的递推关系。\n解：\n容易得到 $ f(0)=1,f(1)=2,f(2)=3,f(3)=\\dots $。考虑集合 $ [n]=\\{ 1,2,\\dots,n \\} $，如果选择的子集中包含 $ n $，那么一定不包含 $ n-1 $，等价于从 $ [n-2] $ 中选择；如果不包含 $ n $，那么等价于从 $ [n-1] $ 中选择，因此 $ f(n)=f(n-1)+f(n-2) $。这样就找出了 $ f(n) $ 的递推关系，进一步同理斐波那契数列，我们考虑求出通项。\n设生成函数 $ F(x)=\\sum_{n=0}^{\\infty}f(n)x^{n} $，满足 $ F(x)=xF(x-1)+x^{2}F(x-2)+1+x $，解出 $$ F(x) = \\dfrac{1+x}{1-x-x^{2}} \\xlongequal{\\phi= \\frac{1+\\sqrt{ 5 }}{2},\\psi= \\frac{1-\\sqrt{ 5 }}{2}} \\dfrac{\\phi^{2} / \\sqrt{ 5 }}{1 - \\phi x} - \\dfrac{\\psi^{2} / \\sqrt{ 5 }}{1 - \\psi x} $$ 展开得到 $$ F(x) = \\sum_{n=0}^{\\infty} \\left( \\dfrac{\\phi^{n+2}- \\psi^{n+2}}{\\sqrt{ 5 }} \\right)x^{n} $$ 于是 $$ f(n) = \\dfrac{\\phi^{n+2} - \\psi^{n+2}}{\\sqrt{ 5 }} = \\dfrac{1}{\\sqrt{ 5 }}\\left( \\left( \\dfrac{1+\\sqrt{ 5 }}{2} \\right)^{n+2} - \\left( \\dfrac{1-\\sqrt{ 5 }}{2} \\right)^{n+2} \\right) $$\n(2)\n设 $ f(n,k) $ 为集合 $ [n] $ 中不包含两个连续数字的 $ k $-子集（大小为 $ k $ 的子集）的数量。求 $ f(n,k) $ 的递推关系，找到一个合适的生成函数，并求出这些数本身。\n解：\n同理先考虑 $ f(n,k) $ 的递推关系。从 $ [n] $ 中选出不包含连续数字的大小为 $ k $ 的子集，如果选出的子集包含 $ n $，那么可以看成从 $ [n-2] $ 中选取有 $ k-1 $ 个元素的子集，否则看成从 $ [n-1] $ 中选出 $ k $ 个元素，得到递推式 $$ f(n,k)=f(n-2,k-1) + f(n-1,k) $$ 边界条件有 $ f(n,0)=1,f(n,k\u003c 0)=f(n,k\u003en)=0,f(1,1)=1 $。\n于是我们定义 $$ F_{k}(x) = \\sum_{n=0}^{\\infty} f(n,k)x^{n} $$ 对于 $ k=0 $， $$ F_{0}(x) = \\sum_{n=0}^{\\infty} x^{n} = \\dfrac{1}{1-x} $$ $ k=1 $ 时 $$ F_{1}(x) = \\sum_{n=0}^{\\infty} nx^{n} = \\dfrac{x}{(1-x)^{2}} $$ $ k\u003e 1 $ 时边界条件不会影响递推 $$ F_{k}(x) = \\sum_{n=k}^{\\infty} f(n,k)x^{n} = \\sum_{n=k}^{\\infty} f(n-1,k)x^{n} + \\sum_{n=k}^{\\infty} f(n-2,k-1)x^{n} = xF_{k}(x) + x^{2}F_{k-1}(x) $$ 于是 $$ F_{k}(x) = \\dfrac{x^{2}}{1-x}F_{k-1}(x) = \\left( \\dfrac{x^{2}}{1-x} \\right)^{k-1}F_{1}(x) = \\dfrac{x^{2k-1}}{(1-x)^{k+1}} $$ 现在需要从这个形式中提取出 $ f(n,k) $。\n根据广义二项式定理 $$ \\dfrac{1}{(1-x)^{k+1}} = \\sum_{n=0}^{\\infty} \\binom{ n+k }{ k } x^{n} $$ 带入即可得到 $$ F_{k} = \\sum_{n=0}^{\\infty} \\binom{ n+k }{ k } x^{n+2k-1} \\xlongequal{m=n+2k-1} \\sum_{m=2k-1}^{\\infty} \\binom{ m-k+1 }{ k } x^{m} $$\n于是 $$ f(n,k)=\\binom{ n-k+1 }{ k } \\quad (n\\geq 2k) $$ （显然 $ n\u003c 2k-1 $ 时不可能找出不含两个连续数字，大小为 $ k $ 的子集，结果符合直觉）\n(3)\n设 $ F_{n} $ 为斐波那契数列的第 $ n $ 项，证明 $$ F_{n+1} = \\sum_{k\\geq 0}\\binom{ k }{ n-k } $$ 证：\n由于斐波那契数列，有 $ F_{n+1}=F_{n}+F_{n-1} $，容易推导出其生成函数为 $ G(x) = \\dfrac{1}{1-x-x^{2}} $。\n现在考虑 $ h_{n}=\\sum_{k\\geq 0}\\binom{ k }{ n-k } $，生成函数为 $ H(x)=\\sum_{n=0}^{\\infty}h_{n}x^{n} $，化简得到 $$ \\begin{align*} H(x) \u0026 = \\sum_{n=0}^{\\infty} \\sum_{k=0 }^{\\infty} \\binom{ k }{ n-k }x^{n} \\\\ \u0026 \\xlongequal{ i=k,j=n-k} \\sum_{i=0}^{\\infty} \\sum_{j=0}^{\\infty} \\binom{ i }{ j } x^{i+j} \\\\ \u0026 = \\sum_{i=0}^{\\infty} x^{i}\\sum_{j=0}^{i} \\binom{ i }{ j } x^{j} \\\\ \u0026 = \\sum_{i=0}^{\\infty} x^{i}\\cdot(1+x)^{i} = \\sum_{i=0}^{\\infty} (x+x^{2})^{i} \\\\ \u0026 = \\dfrac{1}{1-x-x^{2}} = G(x) \\end{align*} $$ 因此 $ F_{n+1}=h_{n} $，证毕！\nProblem 3 (1)\n对于任意正整数 $ n $ 和 $ k $，定义 $ f(n, k) $ 如下：对于将 $ n $ 写成有序的 $ k $ 个非负整数之和的每一种方式，设 $ S $ 为这 $ k $ 个整数的乘积。那么 $ f(n, k) $ 是通过这种方式获得的所有 $ S $ 的总和。请找到 $ f(n, k) $ 的合适生成函数，并求出这些数本身。\n证 1\n设 $ x_{1}+x_{2}+\\dots+x_{k}=n $，我们需要 $ \\prod_{i=1}^{k}x_{i} $。\n对于 $ x_{i} $，它对求和的贡献就是 $ x_{i} $，所以我们考虑生成函数 $ \\sum_{x_{i}=0}^{\\infty}x_{i}z^{x_{i}}=\\frac{z}{(1-z)^{2}} $。$ k $ 个这样的变量叠加可以表示为 $$ \\left( \\sum_{x_{1}=0}^{\\infty} x_{1}z^{x_{1}} \\right)\\left( \\sum_{x_{2}=0}^{\\infty} x_{2}z^{x_{2}} \\right)\\dots\\left( \\sum_{x_{k}=0}^{\\infty} x_{k}z^{x_{k}} \\right) = \\dfrac{z^{k}}{(1-z)^{2k}} $$ 展开以后就可以得到 $$ \\sum_{x_{1},\\dots,x_{n}} \\prod_{i=1}^{k}x_{i}\\cdot z^{\\sum x_{i}} = \\sum_{n=1}^{\\infty} f(n,k)z^{n} = \\dfrac{z^{k}}{(1-z)^{2k}} $$ 因此 $ f(n,k) $ 的生成函数为 $$ H_{k}(x) = \\dfrac{x^{k}}{(1-x)^{2k}} $$ 由于 $$ \\dfrac{1}{(1-x)^{2k}} = \\sum_{n=0}^{\\infty} \\binom{ n+2k-1 }{ 2k-1 } x^{n} $$ 于是 $$ H_{k}(x) = \\sum_{n=0}^{\\infty} \\binom{ n+2k-1 }{ 2k-1 } x^{n+k} \\xlongequal{m=n+k} \\sum_{m=k}^{\\infty} \\binom{ m+k-1 }{ 2k-1 } x^{m} $$ 于是 $$ f(n,k) = \\binom{ n+k-1 }{ 2k-1 } $$\n证 2\n考虑递推关系 $$ f(n,k) = \\begin{cases} 0 \u0026 ,k\\geq n+1 \\\\ n \u0026 ,k = 1 \\\\ \\sum_{r=0}^{n} rf(n-r,k-1) \u0026 ,\\text{others} \\end{cases} $$ 于是设对应的生成函数为 $ H_{k}(x) $。\n首先 $$ H_{1}(x) = \\sum_{n=0}^{\\infty} nx^{n} = \\dfrac{x}{(1-x)^{2}} $$ 之后我们需要对 $ H_{k}(x) $ 建立递推关系： $$ \\begin{align*} H_{k}(x) \u0026 = \\sum_{n=0}^{\\infty} f(n,k)x^{n} = \\sum_{n=0}^{\\infty} \\sum_{r=0}^{n} rf(n-r,k-1)x^{n} \\\\ \u0026 \\xlongequal{i=r,j=n-r} \\sum_{i=0}^{\\infty} \\sum_{j=0}^{\\infty} if(j,k-1)x^{i+j} \\\\ \u0026 = \\sum_{j=0}^{\\infty} f(j,k-1)x^{j}\\left( \\sum_{i=0}^{\\infty} ix^{i} \\right) \\\\ \u0026 = H_{1}(x)\\cdot H_{k-1}(x) \\end{align*} $$ 于是 $$ H_{k}(x) = \\dfrac{x}{(1-x)^{2}}H_{k-1}(x) = \\dfrac{x^{k}}{(1-x)^{2k}} $$ 后续步骤相同。\n(2)\n设 $ f(n, k, c) $ 为将 $ n $ 写成有序的 $ k $ 个整数之和的方式数量，其中每个整数至少为 $ c $。请找到 $ f(n, k, c) $ 的合适生成函数，并求出这些数本身。\n证：\n同理 $ (1) $ ，由于此时需要的是计数，每个值的贡献都是 $ 1 $，因此对于 $ x_{i} $ 的生成函数为 $ \\sum_{x_{i}=c}^{\\infty}z^{x_{i}} = \\dfrac{z^{c}}{1-z} $ 因此 $ k $ 个变量叠加表示为 $$ \\left( \\sum_{x_{1}=c}^{\\infty} z^{x_{1}} \\right)\\left( \\sum_{x_{2}=c}^{\\infty} z^{x_{2}} \\right)\\dots\\left( \\sum_{x_{k}=c}^{\\infty} z^{x_{k}} \\right) = \\dfrac{z^{ck}}{(1-z)^{k}} $$ 同时展开可以得到 $$ H_{c,k}(z) = \\sum_{n=ck}^{\\infty} f(n,c,k)z^{n} = \\dfrac{z^{ck}}{(1-z)^{k}} $$ 这就得到了 $ f(n,c,k) $ 的生成函数。\n下面求出数列通项。根据广义二项式定理 $$ \\dfrac{1}{(1-z)^{k}} = \\sum_{n=0}^{\\infty} \\binom{ n+k-1 }{ k-1 } z^{n} $$ 于是 $$ \\begin{align*} H_{c,k}(z) \u0026 = \\sum_{n=0}^{\\infty} \\binom{ n+k-1 }{ k-1 } z^{n+ck} \\\\ \u0026 \\xlongequal{m = n+ck} \\sum_{m=ck}^{\\infty} \\binom{ m-ck+k-1 }{ k-1 } z^{m} \\end{align*} $$ 得到 $$ f(n,c,k) = \\dbinom{ n-ck+k-1 }{ k-1 } $$\n","permalink":"https://diefish1024.github.io/posts/class-notes/cs0901-combinatorics/cs0901-hw2/","summary":"\u003ch2 id=\"problem-1\"\u003eProblem 1\u003c/h2\u003e\n\u003cp\u003e用生成函数求解递推式\n$$ \n\na_{n} = 4a_{n-1} - 5a_{n-2} + 2a_{n-3}\n\n $$\n初始值为 $ a_{0}=0,a_{1}=3,a_{2}=7 $。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e解\u003c/strong\u003e：\u003c/p\u003e\n\u003cp\u003e设数列 $ \\{ a_{n} \\} $ 的生成函数为 $ F(x) $，那么根据递推式和初值 $ a_{0}=0,a_{1}=3,a_{2}=7 $ 得到\n$$ \n\nF(x) = 4xF(x) - 5x^{2}F(x) + 2x^{3}F(x) + 3x - 5x^{2}\n\n $$\n得到\n$$ \n\nF(x) = \\dfrac{5x^{2}-3x}{2x^{3}-5x^{2}+4x-1} = \\dfrac{3x-5x^{2}}{(1-x)^{2}(1-2x)}\n\n $$\n我们希望分解成\n$$ \n\n\\dfrac{A}{1-x} + \\dfrac{B}{(1-x)^{2}} + \\dfrac{C}{1-2x}\n\n $$\n待定系数可以解得\n$$ \n\nF(x) = \\dfrac{-3}{1-x} + \\dfrac{2}{(1-x)^{2}} + \\dfrac{1}{1-2x}\n\n $$\n展开得到\n$$ \n\nF(x) = \\sum_{n=0}^{\\infty} (-3+2(n+1)+2^{n})x^{n}\n\n $$\n因此\n$$ \n\na_{n} = -3+2(n+1)+2^{n} = 2^{n} + 2n - 1\n\n $$\u003c/p\u003e","title":"CS0901 HW2"},{"content":"Exercise 1 Let $ f:\\mathbb{R}\\to\\mathbb{R} $ be a function. Prove that the following are equivalent: (i) There is a constant $ a\\in\\mathbb{R} $ such that for every$ x\\in\\mathbb{R} $ we have$ f(x)=ax $. (ii) For all $ x_1,x_2,c,x\\in\\mathbb{R} $ we have $ f(x_1+x_2)=f(x_1)+f(x_2) $ and $ f(cx)=c\\,f(x) $.\n(i ⇒ ii)\nAssume there exists $ a\\in\\mathbb{R} $ such that $ f(x)=a x $ for all $ x\\in\\mathbb{R} $ . Then for any $ x_1,x_2,c,x\\in\\mathbb{R} $ ,\n$ f(x_1+x_2)=a(x_1+x_2)=ax_1+ax_2=f(x_1)+f(x_2) $; $ f(cx)=a(cx)=c(ax)=c\\,f(x) $. Hence (ii) holds.\n(ii ⇒ i)\nAssume (ii) hold for all real scalars. Define $ a:=f(1) $. For any $ x\\in\\mathbb{R} $ we can write $ x=x\\cdot 1 $; by homogeneity, we have $ f(x)=f(x\\cdot 1)=x\\,f(1)=a x $.\nThus (i) holds with $ a=f(1) $. Therefore (i) and (ii) are equivalent.\nExercise 2 Describe geometrically (line, plane, or all of $ \\mathbb{R}^3 $) all linear combinations of the given vectors.\n(a) $ \\begin{pmatrix}1\\\\2\\\\3\\end{pmatrix} $ and $ \\begin{pmatrix}3\\\\6\\\\9\\end{pmatrix} $.\nObserve that$ \\begin{pmatrix}3\\\\6\\\\9\\end{pmatrix}=3\\begin{pmatrix}1\\\\2\\\\3\\end{pmatrix} $, so the two vectors are colinear. Hence their span is $ \\mathrm{Span}=\\{\\, t\\begin{pmatrix}1\\\\2\\\\3\\end{pmatrix}\\mid t\\in\\mathbb{R}\\,\\} $, which is a line. (b) $ \\begin{pmatrix}1\\\\0\\\\0\\end{pmatrix} $ and $ \\begin{pmatrix}0\\\\2\\\\3\\end{pmatrix} $.\nThese two vectors are not scalar multiples of each other, hence they are linearly independent. Therefore their span $ \\mathrm{Span}=\\{\\, \\alpha\\begin{pmatrix}1\\\\0\\\\0\\end{pmatrix}+\\beta\\begin{pmatrix}0\\\\2\\\\3\\end{pmatrix}\\mid \\alpha,\\beta\\in\\mathbb{R}\\,\\} $ is a plane. (c) $ \\begin{pmatrix}2\\\\0\\\\0\\end{pmatrix} $, $ \\begin{pmatrix}0\\\\2\\\\2\\end{pmatrix} $ and $ \\begin{pmatrix}2\\\\2\\\\3\\end{pmatrix} $.\nForm the matrix with these as columns and compute the determinant: $$ \\det\\begin{pmatrix} 2 \u0026 0 \u0026 2\\\\ 0 \u0026 2 \u0026 2\\\\ 0 \u0026 2 \u0026 3 \\end{pmatrix} \\neq 0. $$ Since the determinant is nonzero, the three vectors are linearly independent,therefore their span all of $ \\mathbb{R}^3 $. Answers:\n(a) a line. (b) a plane. (c) all of $ \\mathbb{R}^3 $. Exercise 3 Consider $ v=(1,-2,1) $ and $ w=(0,1,-1) $. Find $ c $ and $ d $ such that $ c v+d w=(3,3,-6) $. Why is $ (3,3,6) $ impossible?\nLet $ c v+d w=(3,3,-6) $. Comparing coordinates: $$ \\begin{cases} c = 3 \\\\ -2c+d=9 \\\\ c-d=-6 \\end{cases} $$ It can be solved that $ c=3 $ and $ d=9 $.\nFor $ (3,3,6) $, the first coordinate again forces $ c=3 $, and the second gives $ d=9 $, hence the third would be $ c-d=3-9=-6\\neq 6 $. Therefore it is impossible. Equivalently, every linear combination satisfies $ y+z=-x $ (since $ y=-2c+d $ and $ z=c-d $), but the vector $ (3,3,6) $ has $ y+z=9\\neq -3 $; hence it does not lie in $ \\mathrm{Span}\\{v,w\\} $.\nExercise 4 In the following, tacitly assume that every matrix operation is well-defined. Prove: (i) $ A+B=B+A $. (ii) $ c(A+B)=cA+cB $. (iii) $ A+(B+C)=(A+B)+C $. (iv) $ A(B+C)=AB+AC $. (v) $ (A+B)C=AC+BC $. (vi) $ A(BC)=(AB)C $.\nWrite $ A=(a_{ij}) $, $ B=(b_{ij}) $, $ C=(c_{ij}) $. Use the entrywise definitions of addition and multiplication.\n(i) Commutativity of addition: For all $ i,j $, $ (A+B)_{ij}=a_{ij}+b_{ij}=b_{ij}+a_{ij}=(B+A)_{ij} $. Hence $ A+B=B+A $.\n(ii) Distributivity of scalar multiplication over addition: For all $ i,j $, $ \\big(c(A+B)\\big)_{ij}=c(a_{ij}+b_{ij})=ca_{ij}+cb_{ij}=(cA+cB)_{ij} $.\n(iii) Associativity of addition: For all $ i,j $, $ \\big(A+(B+C)\\big)_{ij}=a_{ij}+(b_{ij}+c_{ij})=(a_{ij}+b_{ij})+c_{ij}=\\big((A+B)+C\\big)_{ij} $.\n(iv) Left distributivity of multiplication: $$ \\big(A(B+C)\\big)_{ij} =\\sum_k a_{ik}(b_{kj}+c_{kj}) =\\sum_k a_{ik}b_{kj}+\\sum_k a_{ik}c_{kj} =(AB)_{ij}+(AC)_{ij} =(AB+AC)_{ij}. $$\n(v) Right distributivity of multiplication: $$ \\big((A+B)C\\big)_{ij} =\\sum_k (a_{ik}+b_{ik})c_{kj} =\\sum_k a_{ik}c_{kj}+\\sum_k b_{ik}c_{kj} =(AC)_{ij}+(BC)_{ij} =(AC+BC)_{ij}. $$\n(vi) Associativity of multiplication: $$ \\big(A(BC)\\big)_{ij} =\\sum_k a_{ik}(BC)_{kj} =\\sum_k a_{ik}\\sum_\\ell b_{k\\ell}c_{\\ell j} =\\sum_\\ell\\Big(\\sum_k a_{ik}b_{k\\ell}\\Big)c_{\\ell j} =\\big((AB)C\\big)_{ij}. $$\nTherefore all properties (i)–(vi) hold.\nExercise 5 Let$ A=\\begin{pmatrix}3\u00261\\\\[2pt] 1\u0026-3\\end{pmatrix} $. Compute $ A^{50} $ and $ A^{51} $.\nFirst compute$ A^2 $: $$ A^2 =\\begin{pmatrix}3\u00261\\\\ 1\u0026-3\\end{pmatrix} \\begin{pmatrix}3\u00261\\\\ 1\u0026-3\\end{pmatrix} =\\begin{pmatrix} 3\\cdot 3+1\\cdot 1 \u0026 3\\cdot 1+1\\cdot(-3)\\\\ 1\\cdot 3+(-3)\\cdot 1 \u0026 1\\cdot 1+(-3)\\cdot(-3) \\end{pmatrix} =\\begin{pmatrix}10\u00260\\\\ 0\u002610\\end{pmatrix} =10\\,I_2. $$ Thus $ A^2=10I_2 $. It follows that for any integer $ n\\ge 1 $,\nif $ n $ is even, $ A^n=(A^2)^{n/2}=10^{n/2}I_2 $; if $ n $ is odd, $ A^n=A\\cdot A^{n-1}=A\\cdot 10^{(n-1)/2}I_2=10^{(n-1)/2}A $. Therefore,\n$ A^{50}=10^{25}I_2 $, $ A^{51}=10^{25}A=10^{25}\\begin{pmatrix}3\u00261\\\\[2pt] 1\u0026-3\\end{pmatrix} $. ","permalink":"https://diefish1024.github.io/posts/class-notes/math1205h-linear-algebra/math1205h-hw1/","summary":"\u003ch2 id=\"exercise-1\"\u003eExercise 1\u003c/h2\u003e\n\u003cblockquote\u003e\n\u003cp\u003eLet $ f:\\mathbb{R}\\to\\mathbb{R} $ be a function. Prove that the following are equivalent:\n(i) There is a constant $ a\\in\\mathbb{R} $ such that for every$ x\\in\\mathbb{R} $ we have$ f(x)=ax $.\n(ii) For all $ x_1,x_2,c,x\\in\\mathbb{R} $ we have $ f(x_1+x_2)=f(x_1)+f(x_2) $ and $ f(cx)=c\\,f(x) $.\u003c/p\u003e\u003c/blockquote\u003e\n\u003cp\u003e\u003cstrong\u003e(i ⇒ ii)\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eAssume there exists $ a\\in\\mathbb{R} $ such that $ f(x)=a x $ for all $ x\\in\\mathbb{R} $ . Then for any $ x_1,x_2,c,x\\in\\mathbb{R} $ ,\u003c/p\u003e","title":"MATH1205H HW1"},{"content":"考虑上一节引入的二项式定理 $$ (1+x)^{n} = \\sum_{k=0}^{n} \\binom{ n }{ k } x^{k} $$ 这可以理解成我们把二项系数转换成了一个函数，这使得我们能更有效地操作和分析序列，这个工具被成为生成函数。\nOrdinary Generating Functions 给定序列 $ \\{ a_{n} \\}_{n\\geq 0} $，由 $ \\{ a_{n} \\} $ 定义的普通生成函数 (OGF) 为： $$ G(x) = \\sum_{n\\geq 0} a_{n}x^{n} $$ 虽然看起来 OGF 并没有被很好的定义，对于和某些数列，这个形式不会收敛，但是实际上生成函数并不能被看成一个真正的函数，它是一个形式幂级数，并且不被要求收敛。\n以下是一些生成函数的基础例子： $$ G(x) = 1+x+x^{2}+x^{3} +\\dots = \\dfrac{1}{1-x} $$ $$ G(x) = 1+ax+a^{2}x^{2} + a^{3}x^{3} + \\dots = \\dfrac{1}{1-ax} $$\n给定一个序列，写出他的生成函数是很容易的。尽管找到他的闭合形式不容易，但是我们一般不需要这样做。相反，我们需要考虑给定一个闭合形式，需要如何知道其对应的序列。\n我们约定 $ [x^{n}]G(x) $ 表示生成函数中 $ x^{n} $ 的系数。\n理论上我们总可以使用泰勒级数来得到 $ [x^{n}]G(x) $。\nNewton’s Generalized Binomial Theorem\n如果 $ x $ 是任何实数并且 $ \\left| x \\right|\u003c1 $，并且 $ r $ 是任何复数，我们有： $$ (1+x)^{r} = \\sum_{n=0}^{\\infty} \\binom{ r }{ n } x^{n} $$ 其中 $$ \\binom{ r }{ n } = \\dfrac{r^{\\underline{n}}}{n!} $$ 例如 $$ \\dfrac{1}{1+x} = (1+x)^{-1} = \\sum_{n=0}^{\\infty} \\binom{ -1 }{ n } x^{n} = 1-x+x^{2}-x^{3}+\\dots $$\nOperations on Generating Functions Convolution 多项式乘法（卷积）在某种意义上编码了乘法原理和加法原理。令 $ F(x)=\\sum_{n=0}^{\\infty}f_{n}x^{n},G(x)=\\sum_{n=0}^{\\infty}g_{n}x^{n} $，那么 $$ [x^{n}](F(x)G(x)) = \\sum_{n=0}^{\\infty} f_{k}g_{n-k} $$ 我们称这为卷积 (convolution) 。这有清晰的组合意义，表示从 $ F\\cup G $ 中选择 $ n $ 个元素。\nExamples Example 1\n假设有 $ 5 $ 个相同蓝色球，$ 3 $ 个相同绿色球，$ 2 $ 个相同红色球，问有几种方式从几种选择 $ 6 $ 个球？\n解：\n我们通过生成函数来解决这个问题，令 $ \\{ b_{n} \\},\\{ g_{n} \\},\\{ r_{n} \\} $ 分别为选择蓝色、绿色、红色球的方案数，显然由于每种颜色的球相同，我们容易得到他们对应的生成函数分别为 $$ \\begin{align*} B(x) \u0026 = 1+x+x^{2}+x^{3}+x^{4}+x^{5} \\\\ G(x) \u0026 = 1+x+x^{2}+x^{3} \\\\ R(x) \u0026 = 1+x+x^{2} \\end{align*} $$ 那么我们就能得到 $ F(x)=B(x)G(x)R(x) $ 为选择三种球方案的生成函数，选择 $ 6 $ 个球的方案数为 $$ [x^{6}]F(x) = \\dots $$\nExample 2 (Multiset Number)\n回顾十二重计数法中的多重集数 $ \\left( \\binom{ m }{ n } \\right) $，表示从 $ [m] $ 中选择大小为 $ n $ 的多重集（允许元素重复）的数量，我们可以用生成函数证明 $$ \\left( \\binom{ m }{ n } \\right) = \\binom{ n+m-1 }{ n } = \\binom{ n+m-1 }{ m-1 } $$ 证：\n设 $ \\left( \\binom{ m }{ n } \\right) $ 的生成函数为 $$ F(x) = \\sum_{n=0}^{\\infty} \\left(\\binom{ m }{ n }\\right) x^{n} $$ 我们考虑对于单个元素 $ i $ 的集合，其被选择 $ k $ 次的方案数显然都为 $ 1 $，所以对应生成函数为 $$ F_{i}(x) = \\sum_{n=0}^{\\infty} x^{n} = \\dfrac{1}{1-x} $$ 于是 $$ F(x) = F_{1}(x)F_{2}(x)\\dots F_{m}(x) = \\dfrac{1}{(1-x)^{m}} $$ 从而 $$ \\left( \\binom{ m }{ n } \\right) = [x^{n}]F(x) = \\binom{ -m }{ n } (-r)^{n} = \\binom{ n+m-1 }{ n } $$ 因此得证。\nExample 3\n对于每个正整数 $ n $，将 $ n $ 分割成若干个奇数之和的方案数等于将 $ n $ 分割成若干个不同的数之和的方案数。\n证：\n令 $ o_{n} $ 为将 $ n $ 分割成奇数的的方案数，$ d_{n} $ 为分割成不同部分的方案数，并且令 $ O_{n} $ 和 $ D_{n} $ 分别为他们对应的生成函数。\n对于奇数，我们有 $$ \\begin{align*} O(x) \u0026 = (1+x+x^{2}+\\dots)(1+x^{3}+(x^{3})^{2} + \\dots)(1+x^{5}+(x^{5})^{2} + \\dots)\\dots \\\\ \u0026 = \\dfrac{1}{1-x}\\cdot \\dfrac{1}{1-x^{3}}\\cdot \\dfrac{1}{1-x^{5}}\\cdot\\dots \\\\ \u0026 = \\prod_{k\\,\\text{mod}\\,2=1} \\dfrac{1}{1-x^{k}} \\end{align*} $$\n对于不同部分，我们有 $$ \\begin{align*} D(x) \u0026 = (1+x)(1+x^{2})(1+x^{3})\\dots \\\\ \u0026 = \\dfrac{1-x^{2}}{1-x}\\cdot \\dfrac{1-x^{4}}{1-x^{2}}\\cdot \\dfrac{1-x^{6}}{1-x^{3}}\\cdot \\dots \\\\ \u0026 = \\prod_{k=1}^{\\infty} \\dfrac{1-x^{2k}}{1-x^{k}} \\\\ \u0026 = \\prod_{k\\,\\text{mod}\\,2=1} \\dfrac{1}{1-x^{k}} \\end{align*} $$ 因此 $ O(x)=D(x) $，从而 $ o_{n}=d_{n} $，方案数相等。\nOperations Solving Recurrence 生成函数最重要的应用之一是解决递推关系并找到闭合形式，现在我们介绍一些例子。\n一个经典例子是求解斐波那契数列，过程可以参考作业解答，此处不再重复。\n另一个例子是卡特兰数。我们已知其递推关系是 $$ C_{0}=1,\\quad C_{n} = \\sum_{k=0}^{n-1} C_{k}C_{n-1-k}\\,,\\forall n\\geq 1 $$ 我们令 $ G(x) $ 为卡特兰数的生成函数。递推关系表明我们应该考虑乘法。 $$ \\begin{align*} G(x) \u0026 = C_{0} + \\sum_{n=1}^{\\infty} \\sum_{k=0}^{n-1} C_{k}C_{n-1-l}x^{n} \\\\ G(x)^{2} \u0026 = \\left( \\sum_{n=0}^{\\infty} C_{n}x^{n} \\right)^{2} = \\sum_{n=0}^{\\infty} \\left( \\sum_{k=0}^{n} C_{k}C_{n-k} \\right)x^{n} \\\\ \\implies xG(x)^{2} \u0026 = \\sum_{n=1}^{\\infty}\\left( \\sum_{k=0}^{n-1} C_{k}C_{n-1-k} \\right)x^{n} \\\\ \\end{align*} $$ 因此我们有 $$ G(x) = 1+ xG(x)^{2} \\implies G(x) = \\dfrac{1\\pm \\sqrt{ 1-4x }}{2x} $$ 这两个解中只有一个是我们需要的生成函数，注意到 $ \\lim_{ x \\to 0 }G(x)=C_{0}=1 $，容易验证 $$ G(x) = \\dfrac{1-\\sqrt{ 1-4x }}{2x} $$ 现在我们通过广义二项式定理展开 $ \\sqrt{ 1-4x }=(1-4x)^{1 / 2} $ ，再带入原式得到 $$ G(x) = \\sum_{n=0}^{\\infty} \\dfrac{1}{n+1}\\binom{ 2n }{ n } x^{n} $$ 这就算出了 $$ C_{n} = \\dfrac{1}{n+1}\\binom{ 2n }{ n } $$\n最后一个例子是第二类斯特林数。其递推关系为 $$ \\left\\{ 0 \\atop 0 \\right\\} = 0,\\quad \\left\\{ n\\atop k \\right\\} = k\\left\\{ n-1 \\atop k \\right\\} + \\left\\{ n-1 \\atop k-1 \\right\\} \\quad \\text{for } (n,k) \\neq (0,0) $$ 由于存在两个索引，所以此时有三个生成函数候选： $$ \\begin{align*} A(x,y) \u0026 = \\sum_{n=0}^{\\infty} \\sum_{k=0}^{\\infty} \\left\\{ n \\atop k \\right\\} x^{n}y^{k} \\\\ B_{k}(x) \u0026 = \\sum_{n=0}^{\\infty} \\left\\{ n\\atop k \\right\\} x^{n} \\\\ C_{n}(y) \u0026 = \\sum_{k=0}^{\\infty} \\left\\{ n \\atop k \\right\\} y^{k} \\end{align*} $$ 然而由于我们并不知道如何处理多元生成函数，因此 $ A(x,y) $ 应该首先被排除。如果选择 $ C_{n}(y) $，那么递推关系中的 $ k\\left\\{ n-1\\atop k \\right\\} $ 无疑会涉及到微分，这会使得操作更加复杂。因此我们使用 $ B_{k}(x) $ 作为生成函数。\n注意到 $$ B_{k}(x) = \\sum_{n=k}^{\\infty} \\left\\{ n \\atop k \\right\\}x^{k} = kxB_{k}(x) + xB_{k-1}(x) \\quad \\text{for } k\\geq 1 $$ 并且 $ B_{0}(x)=1 $。\n于是 $$ B_{k}(x) = \\dfrac{x}{1-kx}B_{k-1}(x) = \\dfrac{x^{k}}{(1-x)(1-2x)\\dots(1-kx)} = \\prod_{i=1}^{k} \\dfrac{x}{1-ix} $$ 我们的目标是找到 $ [x^{n}]B_{k}(x) $ 的显式公式。一个很自然的思路是把 $ B_{k}(x) $ 写成 $$ B_{k}(x) = \\sum_{i=1}^{k} \\dfrac{r_{i}x}{1-ix} $$ 为了找到 $ r_{i} $，我们固定某个 $ j\\in[k] $ 并将两边乘以 $ 1-jx $。这就得到了 $$ \\dfrac{x^{k}}{\\prod_{i\\neq j}(1-ix)} = r_{j}x + \\sum_{i\\neq j} \\dfrac{r_{i}x}{1-ix}(1-jx) $$ 再令 $ x=1 / j $，我们就得到了 $$ \\dfrac{(1 /j)^{k}}{\\prod_{i\\neq j}(1-i / j)} = \\dfrac{r_{j}}{j}\\implies r_{j} = \\dfrac{(-1)^{k-j}}{(j-1)!(k-j)!} $$ 于是就得到了 $$ \\left\\{ n\\atop k \\right\\} = [x^{n}]B_{k}(x) = \\sum_{i=1}^{k} r_{i}i^{n-1} = \\sum_{i=1}^{k} \\dfrac{(-1)^{k-i}}{(i-1)!(k-i)!}i^{n-1} $$\nExponential Generating Function 一般而言，OGF 对于计数子集的数量非常有用，然而它可能不适用于计数置换或者带标签元素。例如 $ [n] $ 上的置换数量的 OGF 是什么，显然有 $$ F(x) = 1+x+2x^{2}+6x^{3}+\\dots=\\sum_{n=0}^{\\infty} n!x^{n} $$ 我们尝试找出它的闭合形式。由于 $ [x^{n}]F(x)=n[x^{n-1}]F(x) $，这提示我们使用微分运算 $$ F(x) = 1+x(xF(x))' = 1+xF(x) + x^{2}F'(x) $$ 然而这类微分方程通常没有闭合形式的解。\n于是这就需要引入指数生成函数 (EGF)，它用于处理置换或者带标签元素的计数。\n对于序列 $ \\{ a_{n} \\}_{n\\geq 0} $，由 $ \\{ a_{n} \\} $ 定义的 EGF 为 $$ G(x) = \\sum_{n=0}^{\\infty} \\dfrac{a_{n}}{n!}x^{n} $$ 置换：容易看出由 $ n! $ 定义的 EGF 为 $ \\dfrac{1}{1-x} $。\n循环置换：圆排列数量为 $ (n-1)! $，容易得到其生成函数为 $ \\sum_{n=1}^{\\infty} \\frac{1}{n}x^{n}=-\\ln(1-x) $。\n为了更好的理解 EGF 的组合含义，我们考虑两个指数生成函数的乘积。设 $ \\hat{F}(x) = \\sum_{n=0}^{\\infty} \\frac{1}{n!}f_{n}x^{n} $，且 $ \\hat{G}(x) = \\sum_{n=0}^{\\infty} \\frac{1}{n!}g_{n}x^{n} $ ，那么容易看出 $$ [x^{n}](\\hat{F}(x)\\hat{G}(x)) = \\sum_{k=0}^{n} \\dfrac{f_{k}}{k!} \\dfrac{g_{n-k}}{(n-k)!} $$ 于是 $ \\hat{F}(x)\\hat{G}(x) $ 对应序列的通项为 $$ h_{n} = n![x^{n}](\\hat{F}(x)\\hat{G}(x)) = \\sum_{k=0}^{n} \\binom{ n }{ k } f_{k}g_{n-k} $$ 这表示我们不仅枚举元素的数量，还枚举他们的位置或者标签。\n现在我们考虑指数生成函数的一个应用。假设有一个 $ 1 \\times n $ 的棋盘，我们想用蓝色、绿色和红色为每个格子着色。要求红色格子的数量必须是偶数，并且至少有一个蓝色格子。我们的目标是确定棋盘着色的方式数量 $ f_n $。 令 $ \\{b_n\\} $、$ \\{g_n\\} $、$ \\{r_n\\} $ 分别为用单一颜色蓝色、绿色和红色为 $ n $ 个格子着色的方式数量序列。那么它们对应的指数生成函数是： $$ \\begin{align*} \u0026 \\hat{B}(x) = \\sum_{n \\ge 1} \\frac{1}{n!} x^n = e^x - 1 \\quad (\\text{至少一个蓝色格子}) \\\\ \u0026 \\hat{G}(x) = \\sum_{n \\ge 0} \\frac{1}{n!} x^n = e^x \\quad (\\text{任意数量的绿色格子}) \\\\ \u0026 \\hat{R}(x) = \\sum_{n \\ge 0, n \\text{ 偶数}} \\frac{1}{n!} x^n = 1 + \\frac{x^2}{2!} + \\frac{x^4}{4!} + \\dots = \\frac{e^x + e^{-x}}{2} \\quad (\\text{偶数个红色格子}) \\end{align*} $$ 因此 $ \\{f_n\\} $ 的指数生成函数是： $$ \\begin{align*} \\hat{F}(x) \u0026 = \\hat{B}(x) \\cdot \\hat{G}(x) \\cdot \\hat{R}(x) \\\\ \u0026 = (e^x - 1)e^x \\frac{e^x + e^{-x}}{2} \\\\ \u0026 = \\frac{e^{2x} - e^x}{2} (e^x + e^{-x}) \\\\ \u0026 = \\frac{e^{3x} + e^x - e^{2x} - 1}{2} \\\\ \u0026 = \\frac{1}{2} \\left( \\sum_{n \\ge 0} \\frac{3^n}{n!} x^n - \\sum_{n \\ge 0} \\frac{2^n}{n!} x^n + \\sum_{n \\ge 0} \\frac{1^n}{n!} x^n - 1 \\right) \\end{align*} $$ 这给出了： $$ f_n = n! \\cdot [x^n]\\hat{F}(x) = \\begin{cases} 0, \u0026 n = 0 \\\\ \\frac{3^n - 2^n + 1}{2}, \u0026 n \\ge 1 \\end{cases} $$\n类似地，回想一下 $ \\left\\{\\substack{n \\\\ k}\\right\\} $ 计算将 $ [n] $ 分割成 $ k $ 个相同非空子集的方式数量，因此 $ k!\\left\\{\\substack{n \\\\ k}\\right\\} $ 具有指数生成函数： $$ \\sum_{n \\ge 0} k!\\left\\{\\substack{n \\\\ k}\\right\\} \\frac{x^n}{n!} = (e^x - 1)^k $$\n","permalink":"https://diefish1024.github.io/posts/class-notes/cs0901-combinatorics/lect2-generating-functions/","summary":"\u003cp\u003e考虑上一节引入的二项式定理\n$$ \n\n(1+x)^{n} = \\sum_{k=0}^{n} \\binom{ n }{ k } x^{k}\n\n $$\n这可以理解成我们把二项系数转换成了一个函数，这使得我们能更有效地操作和分析序列，这个工具被成为\u003cstrong\u003e生成函数\u003c/strong\u003e。\u003c/p\u003e\n\u003ch2 id=\"ordinary-generating-functions\"\u003eOrdinary Generating Functions\u003c/h2\u003e\n\u003cp\u003e给定序列 $ \\{ a_{n} \\}_{n\\geq 0} $，由 $ \\{ a_{n} \\} $ 定义的\u003cstrong\u003e普通生成函数 (OGF)\u003c/strong\u003e 为：\n$$ \n\nG(x) = \\sum_{n\\geq  0} a_{n}x^{n}\n\n $$\n虽然看起来 OGF 并没有被很好的定义，对于和某些数列，这个形式不会收敛，但是实际上生成函数并不能被看成一个真正的函数，它是一个\u003cstrong\u003e形式幂级数\u003c/strong\u003e，并且不被要求收敛。\u003c/p\u003e\n\u003cp\u003e以下是一些生成函数的基础例子：\n$$ \n\nG(x) = 1+x+x^{2}+x^{3} +\\dots = \\dfrac{1}{1-x}\n\n $$\n$$ \n\nG(x) = 1+ax+a^{2}x^{2} + a^{3}x^{3} + \\dots = \\dfrac{1}{1-ax}\n\n $$\u003c/p\u003e\n\u003cp\u003e给定一个序列，写出他的生成函数是很容易的。尽管找到他的闭合形式不容易，但是我们一般不需要这样做。相反，我们需要考虑给定一个闭合形式，需要如何知道其对应的序列。\u003c/p\u003e\n\u003cp\u003e我们约定 $ [x^{n}]G(x) $ 表示生成函数中 $ x^{n} $ 的系数。\u003c/p\u003e","title":"Lect2-Generating Functions"},{"content":"Introduction 条件概率指一个事件在另一个事件发生的条件下发生的概率，用记号 $ \\mathbb{P}(A|B) $ 表示，仅在 $ \\mathbb{P}(B)\u003e0 $ 时有定义： $$ \\mathbb{P}(A|B) = \\dfrac{\\mathbb{P}(A \\cap B)}{P(B)} $$ 可以写成 $$ \\mathbb{P}(A \\cap B) = \\mathbb{P}(B)\\cdot \\mathbb{P}(A|B) $$\n对于 $ n $ 个事件，连续使用上式，即可得到 $$ \\mathbb{P}\\left( \\bigcap_{i=1}^{n}A_{i} \\right) = \\prod_{k=1}^{n} \\mathbb{P}\\left( A_{k}\\bigg|\\bigcap_{i=1}^{k-1}A_{i} \\right) $$ 这个式子被称为 链式法则。\nIndependence 对于事件 $ A,B $，如果 $ \\mathbb{P}(A\\cap B)=\\mathbb{P}(A)\\mathbb{P}(B) $，或者等价地 $ \\mathbb{P}(A|B)=\\mathbb{P}(A) $，那么我们称 $ A $ 和 $ B $ 是独立的。这表明 $ A $ 或 $ B $ 自己是否发生对对方是否发生没有影响。\n推广到 $ n $ 个事件上有：对于事件 $ A_{1},\\dots,A_{n} $，如果他们是相互独立的，说明对于任意的 $ I\\subseteq[n] $ ，有 $$ \\mathbb{P}\\left( \\bigcap_{i\\in I}A_{i} \\right) = \\prod_{i\\in I}\\mathbb{P}(A)_{i} $$ 这个定义非常强，因为它要求对于所有的 $ I\\subseteq[n] $ 都成立。\n如果把定义改成只要求 $ I\\in \\binom{ [n] }{ 2 } $，可以得到两两独立的定义。\n目前这都是关于有限集的定义，对于无穷多个事件 $ \\{ A_{j} \\}_{j\\in J} $（这要求 $ J $ 是可数集，否则概率没有定义），我们说它们是互相独立的，当且仅当对于 $ J $ 的任意一个有限子集 $ I $，$ \\{ A_{i} \\}_{i\\in I} $ 相互独立。\nLaw of Total Probability 假设事件 $ B_{1},B_{2},\\dots,B_{n}\\in \\mathcal{F} $ 构成了样本空间的一个划分，即 $ \\Omega=\\bigcup_{i=1}^{n}B_{i} $ 并且对于 $ i\\neq j $，有 $ B_{i}\\cap B_{j}=\\emptyset $。根据集合论的知识，我们可以推导出对于任意集合 $ A $，$ A\\cap B_{i} $ 也构成了 $ A $ 的一个划分。如果我们取 $ A\\in\\mathcal{F} $，根据概率论公理，我们有 $$ \\mathbb{P}(A) = \\mathbb{P}\\left( \\bigcup_{n\\geq 1}(A\\cap B_{n}) \\right) = \\sum_{n\\geq 1} \\mathbb{P}(A\\cap B_{i}) $$ 这就得到了 全概率公式。写成条件概率的形式，可以得到 $$ \\mathbb{P}(A) = \\sum_{n\\geq 1}\\mathbb{P}(B_{n})\\mathbb{P}(A|B_{n}) $$\nSome Examples 无限悖论 假设有无穷个球，用 $ k=1,2,\\dots $ 来编号，并有一个无穷大的箱子。考察“放球”和“拿球”的过程。\n放球过程表述为：对于 $ n=0,1,2,\\dots $，在 12 点前的 $ 2^{-n} $ 分钟放入编号为 $ 10n+1,10n+2,\\dots,10(n+1) $ 的球。\n我们再使用不同的方式把球拿出来（假设拿和放都在瞬间完成）：\n12 点前 $ 2^{-n} $ 分钟放完球后，从箱子里拿出 $ 10(n+1) $ 号球。\n这种情况下 12 点时箱子里会有无穷的球，因为编号不是 10 的倍数的球都没有被拿出来。\n12 点前 $ 2^{-n} $ 分钟放完球后，从箱子里拿出 $ (n+1) $ 号球。\n此时 12 点时箱子里一个球都没有，因为每个球都能找到一个对应的时刻被拿出来。\n我们可以发现同样是拿一个球，最后的效果居然完全不同。我们现在考虑，如果随机拿出一个球又会怎么样？\n12 点前 $ 2^{-n} $ 分钟放完球后，从箱子里均匀随机地拿出一个球。\n我们计算每个球在 12 点的时候留在箱子里的概率。以 1 号球为例，其余类似。对于每个 $ n $，用事件 $ A_{n} $ 表示在 $ n $ 轮操作后 1 号球还在箱子里这个事件。我们需要关注的是 $$ A_{\\infty} := \\bigcap_{n\\geq 0}A_{n} = \\lim_{ n \\to \\infty } A_{n} $$ 根据上一节中概率测度的连续性，我们有 $ \\mathbb{P}(\\lim_{ n \\to \\infty }A_{n})=\\lim_{ n \\to \\infty }\\mathbb{P}(A_{n}) $。因此只需要计算 $ \\mathbb{P}(A_{n}) $ 即可。我们再定义一个事件 $ B_{n} $ 表示第 $ n $ 轮拿出来的不是 1 号球，则有 $ A_{n}=B_{0}\\cap B_{1}\\cap\\dots \\cap B_{n} $。使用链式法则，就可以得到 $$ \\mathbb{P}(A_{n}) = \\mathbb{P}\\left( \\bigcap_{i=1}^{n}B_{i} \\right) = \\prod_{k=0}^{n}\\mathbb{P}\\left( B_{k}\\bigg|\\bigcap_{i\u003c k}B_{i} \\right) $$ 其中事件 $ B_{k}|\\bigcap_{i\u003c k}B_{i} $ 有非常明显的组合意义，显然这个概率是 $ 1- \\dfrac{1}{9(k+1)+1} $。\n因此 $$ \\mathbb{P}(A_{n}) = \\prod_{k=0}^{n} \\left( 1 - \\dfrac{1}{9(k+1)+1} \\right) \\leq e^{ -\\sum_{k=0}^{n} 1/(9k+10) } $$ 由于级数 $ \\sum_{k=0}^{n} \\frac{1}{9k+10} $ 发散，所以 $ \\lim_{ n \\to \\infty }\\mathbb{P}(A_{n})=0 $，所以 12 点时 1 号球还在箱子里的概率 $ \\mathbb{P}(S_{1}) $ 为 0。类似地，还能得到其他球的概率 $ \\mathbb{P}(S_{n})=0 $。我们现在需要知道 12 点时箱子里还有球的概率，即 $ \\mathbb{P}(\\exists n \\subset \\mathbb{N},S_{n}) $，利用上一届的 union-bound，可以得到 $$ \\mathbb{P}(\\exists n \\subset \\mathbb{N},S_{n}) \\leq \\sum_{n\\geq 1}\\mathbb{P}(S_{n})=0 $$\nKarger 最小割算法 一个经典的问题是求图上的最小割。给定一个连通无向图 $ G(V,E) $，我们说边集 $ C \\subseteq E $ 是一个割，当且仅当删掉 $ C $ 以后剩下的 $ G(V,E\\setminus C) $ 是不连通的。我们需要寻找图上最小的一个割。\n我们在此处考虑用一个随机算法求解这个问题。\n定义图上的缩边操作：给定 $ e=\\{ u,v \\}\\in E $，我们将 $ u,v $ 合并成一个点，并删掉这条边，把缩完之后的图记为 $ G / e $。 Kager 算法的原理非常简单，从 $ G $ 出发，每次随机选择一条边，把它缩掉，重复执行 $ n-2 $ 之后图里面就会只剩下两个点，这时我们再输出所有剩下的边。\n这个算法“有可能”输出省却答案的原理是，由于我们关心的是”最小”的割，那么我们每一步选到割中的边的概率就不会太大。为了谈论这个概率，我们需要选择合适的概率空间。一个自然的想法是选择算法执行过程中所有删除的边的序列作为样本空间。\n设 $ C $ 是一个固定的最小割，并且其大小为 $ k $，我们需要计算最终输出 $ C $ 的概率。这需要我们执行的过程中，每一次都没有选到 $ C $ 中的边。我们用 $ A_{k} $ 来表示第 $ k $ 次执行完缩边操作后，$ C $ 中的任意一条边还没有被删掉的概率。\n为了分析 $ \\mathbb{P}(A_{k}) $，同理上一个例子中的想法，我们定义 $ B_{k} $ 为第 $ k $ 次缩边选择的不是 $ C $ 中的边这一事件，那么显然有 $ A_{k}=\\bigcap_{i=1}^{k}B_{i} $，因此根据链式法则，我们有 $$ \\mathbb{P}(\\text{output}=C) = \\mathbb{P}(A_{n-2}) = \\prod_{i=1}^{n-2}\\mathbb{P}\\left(B_{i}\\bigg| \\bigcap_{j=1}^{i-1}B_{j}\\right) $$ 我们需要找出一个这个概率的下界。我们想要说明每一轮都有比较大的概率选不到 $ C $ 中的边，由于选取是均匀的，所以只需要证明在第 $ i $ 轮，已知前 $ i-1 $ 轮都没有选到 $ C $ 中的边的情况下，图中剩下的边足够多即可。\n一个重要的观察是，此时图中每个点的度数都不小于 $ k $。原因是由于缩边这种操作不会破坏割的性质，如果有点的度数小于 $ k $，在原图中直接取这些边就得到了一个小于 $ k $ 的割。\n有了这个观察，我们就知道在第 $ i-1 $ 轮，剩下 $ n-i+1 $ 个顶点时，至少还有 $ \\frac{k}{2}\\cdot(n-i+1) $ 条边，所以我们就有 $$ \\mathbb{P}\\left( B_{i}\\bigg|\\bigcap_{j=1}^{i-1}B_{j} \\right) \\geq 1 - \\dfrac{k}{\\frac{k}{2} \\cdot (n-i+1)} = \\dfrac{n-i-1}{n-i+1} $$ 这说明 $$ \\mathbb{P}(A_{n-2}) \\geq \\prod_{i=1}^{n-2} \\dfrac{n-i-1}{n-i+1} = \\dfrac{2}{n(n-1)} $$ 因此我们的算法至少有 $ \\frac{2}{n(n-1)} $ 的概率可以输出 $ C $。如果我们重复这个算法 $ N=50n(n-1) $ 次，并且输出这么多次中找到的最小的割，那么这个割是最小割的概率至少有 $$ 1-\\left( 1- \\dfrac{2}{n(n-1)} \\right)^{N} \\geq 1 - e^{ -100 } $$ 使用并查集来维护的话，复杂度大约为 $ O(n^{2}m) $，不过这可以进一步改进成 $ O(n^{2}) $。\n","permalink":"https://diefish1024.github.io/posts/class-notes/math2701-probability-theory/lect3-conditional-probability/","summary":"\u003ch2 id=\"introduction\"\u003eIntroduction\u003c/h2\u003e\n\u003cp\u003e条件概率指一个事件在另一个事件发生的条件下发生的概率，用记号 $ \\mathbb{P}(A|B) $ 表示，仅在 $ \\mathbb{P}(B)\u003e0 $\n时有定义：\n$$ \n\n\\mathbb{P}(A|B) = \\dfrac{\\mathbb{P}(A \\cap B)}{P(B)}\n\n $$\n可以写成\n$$ \n\n\\mathbb{P}(A \\cap B) = \\mathbb{P}(B)\\cdot \\mathbb{P}(A|B)\n\n $$\u003c/p\u003e\n\u003cp\u003e对于 $ n $ 个事件，连续使用上式，即可得到\n$$ \n\n\\mathbb{P}\\left( \\bigcap_{i=1}^{n}A_{i} \\right) = \\prod_{k=1}^{n} \\mathbb{P}\\left( A_{k}\\bigg|\\bigcap_{i=1}^{k-1}A_{i} \\right)\n\n $$\n这个式子被称为 \u003ca href=\"https://en.wikipedia.org/wiki/Chain_rule_(probability)\"\u003e链式法则\u003c/a\u003e。\u003c/p\u003e\n\u003ch2 id=\"independence\"\u003eIndependence\u003c/h2\u003e\n\u003cp\u003e对于事件 $ A,B $，如果 $ \\mathbb{P}(A\\cap B)=\\mathbb{P}(A)\\mathbb{P}(B) $，或者等价地 $ \\mathbb{P}(A|B)=\\mathbb{P}(A) $，那么我们称 $ A $ 和 $ B $ 是独立的。这表明 $ A $ 或 $ B $ 自己是否发生对对方是否发生没有影响。\u003c/p\u003e","title":"Lect3-Conditional Probability"},{"content":"Motivation 例题：在圆上“随机”选一段弧，问弧长大于圆周的 $ \\frac{1}{3} $ 的概率？（Bertrand paradox）\n至少三种自然的“均匀化”模型会给出不同答案：\n对弧长参数均匀（在 $ [0, 2\\pi) $ 上均匀取长度，再随机起点）。 对端点在圆上独立均匀（等价于随机两点确定弧，需指定取较短或较长弧）。 对中心角或几何构造的中间量均匀（如均匀选角度后裁剪）。 核心问题：如何定义“随机”？不同“随机化”方案导致不同答案。\n讨论概率问题必须先明确概率空间（样本空间、事件族与概率测度），否则“概率”无从谈起。\nProbability Space 一个概率空间由三元组 $ (\\Omega, \\mathcal{F}, \\mathbb{P}) $ 构成：\n$ \\Omega $：样本空间（一次随机试验所有可能结果）。 $ \\mathcal{F} \\subseteq 2^{\\Omega} $：事件族（允许讨论与运算的集合）。 $ \\mathbb{P} : \\mathcal{F} \\to [0,1] $：概率测度（赋予事件概率）。 记号说明：\n$ \\Omega $：样本空间。 $ 2^{\\Omega} $：$ \\Omega $ 的幂集（所有子集的集合）。 为什么 $ \\mathbb{P} $ 要定义在 $ \\mathcal{F} $ 上而非直接在 $ \\Omega $ 上？\n离散可数时，取 $ \\mathcal{F} = 2^{\\Omega} $ 可行，且对单点赋值即可确定所有事件的概率。 连续时不同：单点的概率通常为 $ 0 $，但不可数并可有正概率；且 $ 2^{\\Omega} $ 中存在不可测集合，无法一致赋值（见下文 Vitali set 与 Axiom of Choice）。因此需选择一个足够大又可控的 $ \\sigma $- 代数作为事件族。 Sigma-Algebra 要求 $ \\mathcal{F} $ 构成一个 $ \\sigma $- 代数（域）：\n$ \\emptyset \\in \\mathcal{F},\\ \\Omega \\in \\mathcal{F} $。 若 $ A \\in \\mathcal{F} $，则其补集 $ A^{c} \\in \\mathcal{F} $。 若 $ A_{1}, A_{2}, \\dots \\in \\mathcal{F} $，则可数并 $ \\bigcup_{n \\ge 1} A_{n} \\in \\mathcal{F} $。 注：由德摩根律得可数交封闭。 “$ \\sigma $”表示对可数并封闭。\n直觉：这些封闭性保证我们做常见的事件运算不“跑出”可测范围。\nProbability Measure 概率测度 $ \\mathbb{P} : \\mathcal{F} \\to [0,1] $ 满足： 规范化：$ \\mathbb{P}(\\emptyset) = 0,\\ \\mathbb{P}(\\Omega) = 1 $。 补集关系：对任意 $ A \\in \\mathcal{F} $，$ \\mathbb{P}(A) = 1 - \\mathbb{P}(A^{c}) $。 可数可加性（对两两不交）：若 $ A_{i} \\cap A_{j} = \\emptyset $（$ i \\neq j $），则 $$ \\mathbb{P}\\Big( \\bigcup_{n \\ge 1} A_{n} \\Big) = \\sum_{n \\ge 1} \\mathbb{P}(A_{n}) $$ 若 $ \\Omega $ 可数且 $ \\mathcal{F} = 2^{\\Omega} $，记 $ p_{\\omega} := \\mathbb{P}(\\{\\omega\\}) $，则任意 $ A \\subseteq \\Omega $ 满足 $$ \\mathbb{P}(A) = \\sum_{\\omega \\in A} p_{\\omega} $$\nSet Operations and Event Semantics 集合—事件对应：\n$ A $：事件 $ A $ 发生。 $ A \\cup B $：至少一个发生。 $ A \\cap B $：同时发生。 $ A \\setminus B $：$ A $ 且不 $ B $。 $ A \\subseteq B $：$ A $ 蕴含 $ B $。 $ A \\cap B = \\emptyset $：不能同时发生。 $ A \\cup B = \\Omega $：必有一个发生。 这些操作在 $ \\mathcal{F} $ 内封闭（由 $ \\sigma $- 代数性质和德摩根律）。\nInclusion–Exclusion and Union Bound 单调性：若 $ A \\subseteq B $，则 $ \\mathbb{P}(A) \\le \\mathbb{P}(B) $。 证：写 $ B = A \\cup (B \\setminus A) $，并为不交，故 $ \\mathbb{P}(B) = \\mathbb{P}(A) + \\mathbb{P}(B \\setminus A) \\ge \\mathbb{P}(A) $.\n二集合容斥： $$ \\mathbb{P}(A \\cup B) = \\mathbb{P}(A) + \\mathbb{P}(B) - \\mathbb{P}(A \\cap B) $$\n并界（union bound, Boole 不等式）： $$ \\mathbb{P}\\Big( \\bigcup_{n} A_{n} \\Big) \\le \\sum_{n} \\mathbb{P}(A_{n}) $$\nLimits of Events 集合序列的极限： 若 $ A_{1} \\subseteq A_{2} \\subseteq \\cdots $，则 $$ \\lim_{n \\to \\infty} A_{n} = \\bigcup_{n \\ge 1} A_{n} $$ 若 $ A_{1} \\supseteq A_{2} \\supseteq \\cdots $，则 $$ \\lim_{n \\to \\infty} A_{n} = \\bigcap_{n \\ge 1} A_{n} $$ 测度的“连续性”（极限与测度交换）： 若 $ A_{n} \\uparrow $，则 $ \\mathbb{P}(\\lim A_{n}) = \\lim\\limits_{n \\to \\infty} \\mathbb{P}(A_{n}) $。 若 $ A_{n} \\downarrow $，则 $ \\mathbb{P}(\\lim A_{n}) = \\lim\\limits_{n \\to \\infty} \\mathbb{P}(A_{n}) $。 递增情形用不交分解与可数可加性；递减情形用德摩根律转化。 证：\n只证明递增（非降）的情形。\n使用极限的定义，有（类比裂项） $$ \\mathbb{P}(\\lim_{ n \\to \\infty } A_{n}) = \\mathbb{P}\\left( \\bigcup_{n\\geq 1}A_{n} \\right) = \\mathbb{P}\\left( A_{1} \\cup \\bigcup_{n\\geq\t2}(A_{n}\\setminus A_{n-1}) \\right) $$ 于是就把 $ \\lim_{ n \\to \\infty }A_{n} $ 写成了一堆不交集合的并，那么根据 $ \\mathbb{P} $ 的第三条公理，可以得到 $$ \\mathbb{P}(\\lim_{ n \\to \\infty } A_{n}) = \\mathbb{P}(A_{1}) + \\sum_{n\\geq 2}\\mathbb{P}(A_{n}\\setminus A_{n-1}) = \\mathbb{P}(A_{1}) + \\lim_{ N \\to \\infty } \\sum_{n=2}^{N} (\\mathbb{P}(A_{n})- \\mathbb{P}(A_{n-1})) = \\lim_{ n \\to \\infty } \\mathbb{P}(A_{n}) $$\nWhy Not Take All Subsets? 关于前面提到的为什么事件集 $ \\mathcal{F} $ 不能直接等于 $ 2^{\\Omega} $ 的问题，在这里给出一个证明。\n考虑问题，如何在 $ \\Omega = [0,1) $ 上定义“均匀分布” $ \\mathbb{P} $ ？\n直觉要求：\n长度一致性：对区间 $ (a,b) \\subset [0,1) $，$ \\mathbb{P}((a,b)) = b - a $。 平移不变性：对任意 $ I \\subset [0,1) $ 与 $ r \\in [0,1) $，有 $ \\mathbb{P}(I) = \\mathbb{P}(I + r) $，其中 $ I + r = \\{ (x + r) \\bmod 1 : x \\in I \\} $。 Vitali set（使用 Axiom of Choice）表明：若令 $ \\mathcal{F} = 2^{[0,1)} $，并要求上面两条与 $ \\sigma $- 可加性，则产生矛盾：（证明用到有理数集的什么性质？为什么一定要通过有理数？）\n定义等价关系 $ x \\sim y \\iff x - y \\in \\mathbb{Q} $，将 $ [0,1) $ 划分为等价类。 用 Axiom of Choice 从每个等价类选一代表，得集合 $ N $。 对每个 $ r \\in \\mathbb{Q} \\cap [0,1) $，令 $ N_{r} := N + r = \\{ (x+r) \\bmod 1: x \\in N\\} $，可证 $ \\{ N_{r} \\} $ 两两不交（反证法）且并为 $ [0,1) $ 的平移副本覆盖。 可数可加性与平移不变性给出 $$ 1 = \\mathbb{P}([0,1)) = \\sum_{r} \\mathbb{P}(N_{r}) = \\sum_{r} \\mathbb{P}(N) $$ 若 $ \\mathbb{P}(N) = 0 $，右端为 $ 0 $；若 $ \\mathbb{P}(N) \u003e 0 $，右端为 $ +\\infty $，均矛盾。 结论：$ 2^{[0,1)} $ 中存在不可测集合，无法一致赋予概率。 正确做法：取最小且足够的 $ \\sigma $- 代数（Borel $ \\sigma $- 代数）\n令 $ \\mathcal{F} $ 为包含所有开区间的最小 $ \\sigma $- 代数（Borel）。 在该 $ \\mathcal{F} $ 上存在与长度一致且平移不变的测度（勒贝格测度在 $ [0,1) $ 的限制），从而得到期望的“均匀分布”。 Discrete vs Continuous 离散可数： 可取 $ \\mathcal{F} = 2^{\\Omega} $，对单点赋值（质量函数）即可决定所有事件的概率。 连续不可数： 单点概率常为 $ 0 $，但不可数并可得正概率；不可测集合阻止我们将 $ \\mathcal{F} $ 取为 $ 2^{\\Omega} $。必须选取如 Borel（或其完备化）这样的“可测”结构。 Summary 概率论以 $ (\\Omega, \\mathcal{F}, \\mathbb{P}) $ 为基础对象。“随机”的语义由此三元组精确定义。 $ \\sigma $- 代数的可数封闭性与测度的可数可加性是技术与直觉的统一；它们保证常见事件运算与极限操作的可用性。 并界与容斥是估算复杂事件概率的常用工具。 在不可数空间，Axiom of Choice 导致不可测集合的存在，解释了为何不能取 $ \\mathcal{F} = 2^{\\Omega} $. ","permalink":"https://diefish1024.github.io/posts/class-notes/math2701-probability-theory/lect2-probability-space/","summary":"\u003ch2 id=\"motivation\"\u003eMotivation\u003c/h2\u003e\n\u003cp\u003e例题：在圆上“随机”选一段弧，问弧长大于圆周的 $ \\frac{1}{3} $ 的概率？（\u003ca href=\"https://en.wikipedia.org/wiki/Bertrand_paradox_(probability)\"\u003eBertrand paradox\u003c/a\u003e）\u003c/p\u003e\n\u003cp\u003e至少三种自然的“均匀化”模型会给出不同答案：\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e对弧长参数均匀（在 $ [0, 2\\pi) $ 上均匀取长度，再随机起点）。\u003c/li\u003e\n\u003cli\u003e对端点在圆上独立均匀（等价于随机两点确定弧，需指定取较短或较长弧）。\u003c/li\u003e\n\u003cli\u003e对中心角或几何构造的中间量均匀（如均匀选角度后裁剪）。\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e核心问题：如何定义“随机”？不同“随机化”方案导致不同答案。\u003c/p\u003e\n\u003cp\u003e讨论概率问题必须先明确概率空间（样本空间、事件族与概率测度），否则“概率”无从谈起。\u003c/p\u003e\n\u003ch2 id=\"probability-space\"\u003eProbability Space\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e一个概率空间由三元组 $ (\\Omega, \\mathcal{F}, \\mathbb{P}) $ 构成：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e$ \\Omega $：样本空间（一次随机试验所有可能结果）。\u003c/li\u003e\n\u003cli\u003e$ \\mathcal{F} \\subseteq 2^{\\Omega} $：事件族（允许讨论与运算的集合）。\u003c/li\u003e\n\u003cli\u003e$ \\mathbb{P} : \\mathcal{F} \\to [0,1] $：概率测度（赋予事件概率）。\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e记号说明：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e$ \\Omega $：样本空间。\u003c/li\u003e\n\u003cli\u003e$ 2^{\\Omega} $：$ \\Omega $ 的幂集（所有子集的集合）。\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e为什么 $ \\mathbb{P} $ 要定义在 $ \\mathcal{F} $ 上而非直接在 $ \\Omega $ 上？\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e离散可数时，取 $ \\mathcal{F} = 2^{\\Omega} $ 可行，且对单点赋值即可确定所有事件的概率。\u003c/li\u003e\n\u003cli\u003e连续时不同：单点的概率通常为 $ 0 $，但不可数并可有正概率；且 $ 2^{\\Omega} $ 中存在不可测集合，无法一致赋值（见下文 Vitali set 与 Axiom of Choice）。因此需选择一个\u003cstrong\u003e足够大又可控\u003c/strong\u003e的 $ \\sigma $- 代数作为事件族。\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"sigma-algebra\"\u003eSigma-Algebra\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e要求 $ \\mathcal{F} $ 构成一个 $ \\sigma $- 代数（域）：\u003c/p\u003e","title":"Lect2-Probability Space"},{"content":"Problem 1 (1)\n求 $$ \\sum_{k=0}^{n} \\binom{ 2n }{ 2k } $$\n解\n$$ \\begin{align*} \u0026 \\sum_{k=0}^{n} (-1)^{k}\\binom{ n }{ k } = 0 \\\\ \\implies \u0026 \\sum_{k=0}^{2n} (-1)^{k}\\binom{ 2n }{ k } =0 \\\\ \\implies \u0026 \\sum_{k=0}^{2n} \\binom{ 2n }{ 2k } = \\sum_{k=1}^{2n} \\binom{ 2n }{ 2k - 1 } \\end{align*} $$ 同时由于 $$ \\sum_{k=0}^{2n} \\binom{ 2n }{ 2k } + \\sum_{k=1}^{2n} \\binom{ 2n }{ 2k - 1 } = \\sum_{k=0}^{2n} \\binom{ 2n }{ k } = 2^{2n} $$ 得到 $$ \\sum_{k=0}^{2n} \\binom{ 2n }{ 2k } = 2^{2n-1} $$\n(2)\n求 $$ \\sum_{k=0}^{3n} \\binom{ 3n }{ 3k } $$\n解\n同理 (1) 的解法，设 $ z $ 为一个三次单位根，那么根据二项式定理有 $$ \\sum_{k=0}^{n} z^{k}\\binom{ n }{ k } = (1 + z)^{n} $$ 那么设 $ \\sum_{k=0}^{3n}\\binom{ 3n }{ 3k }=A,\\,\\sum_{k=0}^{3n-1}\\binom{ 3n }{ 3k+1 }=B,\\,\\sum_{k=0}^{3n-1}\\binom{ 3n }{ 3k+2 }=C $，就能得到 $$ A + z\\cdot B + z^{2}\\cdot C = (1 + z)^{3n} $$\n设 $ \\omega=e^{ \\frac{2\\pi i}{3} } $ ，则有 $ 1+\\omega+\\omega^{2}=0,\\omega^{3}=1 $. 分别令 $ z \\in \\{ 1,\\omega,\\omega^{2} \\} $ 带入上式，得到 $$ \\begin{cases} A + B + C \u0026 = (1+1)^{3n} \\\\ A + \\omega B + \\omega^{2}C \u0026 = (1+\\omega)^{3n} \\\\ A + \\omega^{2}B + \\omega C \u0026 = (1 + \\omega^{2})^{3n} \\end{cases} $$ 将三式相加并利用 $ 1+\\omega+\\omega^{2}=0 $ 的性质，移项即可得到 $$ A = \\dfrac{2^{3n} + (1+\\omega)^{3n} + (1+\\omega^{2})^{3n}}{3} $$ 带入 $ \\omega=-\\dfrac{1}{2}+\\dfrac{\\sqrt{ 3 }}{2}\\cdot i $ 得到 $ 1+\\omega=e^{ \\frac{\\pi i}{3} },1+\\omega^{2}=e^{ - \\frac{\\pi i}{3} } $ ，带入上式并化简可得 $$ \\sum_{k=0}^{n} \\binom{ 3n }{ 3k } = \\dfrac{2^{3n} + 2(-1)^{n}}{3} $$\nProblem 2 (1) $$ \\binom{ n }{ m } \\binom{ m }{ k } = \\binom{ n }{ k } \\binom{ n-k }{ m-k } $$ 证 1\n考虑左右两边组合意义：\n$ \\binom{ n }{ m }\\binom{ m }{ k } $ 可以表示在 $ n $ 个人中先选出 $ m $ 个人，再在这 $ m $ 个人中选出 $ k $ 个人的概率，本质上是把 $ n $ 个人分成了 $ 3 $ 类，每类分别有 $ n-m,\\,m-k,\\,k $ 个人。\n$ \\binom{ n }{ k }\\binom{ n-k }{ m-k } $ 可以看成在 $ n $ 个人里面选出 $ k $ 个人，再在剩下 $ n-k $ 个人中选出 $ m-k $ 个人，同样也可以看成是分成了分别有 $ n-m,\\,m-k,\\,k $ 个人的三类。\n因此左右表示同一个组合意义，值必然相同。\n证 2 $$ \\binom{ n }{ m } \\binom{ m }{ k } = \\dfrac{n^{\\underline{m}}}{m!}\\cdot \\dfrac{m^{\\underline{k}}}{k!} = \\dfrac{n^{\\underline{k}}}{k!}\\cdot \\dfrac{n^{\\underline{m}}}{n^{\\underline{k}}}\\cdot \\dfrac{m^{\\underline{k}}}{m!} = \\dfrac{n^{\\underline{k}}}{k!}\\cdot \\dfrac{(n-k)^{\\underline{m-k}}}{(m-k)!} = \\binom{ n }{ k } \\binom{ n-k }{ m-k } $$\n(2) $$ \\sum_{k=0}^{r} \\binom{ n+k }{ k } = \\binom{ n+r+1 }{ r } $$ 证 1\n考虑组合意义。\n右式变形为 $ \\binom{ n+r+1 }{ n+1 } $ 可以表示为在 $ n+r+1 $ 个人中选出 $ n+1 $ 个人的方案数。\n左侧变形为 $ \\sum \\binom{ n+k }{ n } $ 可以看成枚举要选的最后一个人是第 $ n+k+1 $ 个人，在前 $ n+k $ 个人中选择 $ n $ 个人，所有情况的和恰好也是在 $ n+r+1 $ 个人中选出 $ n+1 $ 个人的方案数。\n因此左右两次可以表达同一个组合意义，值相同。\n证 2\n考虑等式 $$ \\binom{ n+k }{ k } + \\binom{ n+k }{ k-1 } = \\binom{ n+k+1 }{ k } $$ 移项得到 $$ \\binom{ n+k }{ k } = \\binom{ n+k+1 }{ k } - \\binom{ n+k }{ k-1 } $$ 在求和可得 $$ \\sum_{k=0}^{r} \\binom{ n+k }{ k } = \\sum_{k=0}^{r} \\left[ \\binom{ n+k+1 }{ k } - \\binom{ n+k }{ k-1 } \\right] = \\binom{ n+r+1 }{ r } - \\binom{ n }{ -1 } $$ 认为 $ \\binom{ n }{ k } $ 在 $ k\u003en $ 或者 $ k\u003c 0 $ 时 $ \\binom{ n }{ k }=0 $ ，则可得到 $$ \\sum_{k=0}^{r} \\binom{ n+k }{ k } = \\binom{ n+r+1 }{ r } $$\n(3) $$ \\sum_{k=0}^{n} \\binom{ n }{ k } ^{2}k = n\\binom{ 2n-1 }{ n-1 } $$ 证 1\n考虑组合意义，同样以在班级中选人举例。\n由于 $ 2\\binom{ 2n-1 }{ n-1 }=\\binom{ 2n }{ n } $，右侧变形为 $ \\frac{n}{2}\\binom{ 2n }{ n } $ ，可以表示在 $ 2n $ 个人（男女各一半）的班级中选出 $ n $ 个人当班委，再在这 $ n $ 个人中选出一个男生当班长的方案数。\n左侧变成 $ \\sum_{k=0}^{n}\\binom{ n }{ k }\\binom{ n }{ n-k }k $ ，对于每个 $ k $ 表示 $ n $ 个男生 $ n $ 个女生的班级中，男生选出 $ k $ 个人，女生选出 $ n-k $ 个人，共 $ n $ 个人当班委，再从 $ k $ 个男生班委中选出一个人当班长的方案数。把所有 $ k $ 的情况合起来，同样可以得到在男女各半的 $ 2n $ 个人中选出 $ n $ 个班委和一个男生班长的方案数。\n因此左右两式可以表达同一个组合意义，值相同。\n证 2\n将恒等式 $$ k\\binom{ n }{ k } = n\\binom{ n-1 }{ k-1 } = n\\binom{ n-1 }{ n-k } $$ 带入左式，左右两侧消去 $ n $ 后，只需证 $$ \\sum_{k=0}^{n} \\binom{ n }{ k } \\binom{ n-1 }{ n-k } = \\binom{ 2n-1 }{ n-1 } $$ 根据 Vandermonde 卷积 $$ \\sum_{k=0}^{n} \\binom{ n }{ k } \\binom{ n-1 }{ n-k } = \\binom{ n + n - 1 }{ n } = \\binom{ 2n-1 }{ n } $$ 因此原式得证！\n(4) $$ \\sum_{i=0}^{a} \\binom{ a }{ i } \\binom{ b+i }{ a } = \\sum_{i=0}^{a} \\binom{ a }{ i } \\binom{ b }{ i } 2^{i} $$ 证 1\n从组合意义证明，同样以班级选班委举例。考虑一个班级有 $ a $ 个班委和 $ b $ 个非班委，现进行班委换届。\n左式对于每个 $ i $ ，$ \\binom{ a }{ i }\\binom{ b+i }{ a } $ 表示 $ a $ 个班委中有 $ i $ 个人有意愿再参与下一届的班委选举，在 $ b+i $ 个人中选举产生新的 $ a $ 个班委。每种情况加起来，表示 $ a $ 个原班委自由选择是否参加选举的前提下班委换届的所有方案数。\n右式对于每个 $ i $ ，将 $ \\binom{ a }{ i } $ 变换为 $ \\binom{ a }{ a-i } $ ，$ \\binom{ a }{ a-i }\\binom{ b }{ i } $ 表示新一届班委中有 $ i $ 个来自原先 $ b $ 个非班委的方案数，$ 2^{i} $ 表示剩下没选上、未知竞选意愿的 $ i $ 个原班委所有竞选意愿的可能。将每种情况加起来，也同样可以得到 $ a $ 个原班委自由选择是否参选的前提下班委换届的方案数。\n因此左右两式可以表示相同的组合意义，值相同。\n证 2\n根据 Vandermonde 卷积 $$ \\binom{ b+i }{ a } = \\sum_{j=0}^{i} \\binom{ i }{ j } \\binom{ b }{ a-j } $$ 带入左式得到 $$ \\begin{align*} \\sum_{i=0}^{a} \\binom{ a }{ i } \\binom{ b+i }{ a } \u0026 = \\sum_{i=0}^{a} \\sum_{j=0}^{i} \\binom{ b }{ a-j } \\binom{ a }{ i } \\binom{ i }{ j } \\\\ \u0026 = \\sum_{i=0}^{a} \\sum_{j=0}^{i} \\binom{ b }{ a-j } \\binom{ a }{ j } \\binom{ a-j }{ i-j } \\\\ \u0026 = \\sum_{j=0}^{a} \\binom{ b }{ a-j } \\binom{ a }{ j } \\sum_{i=j}^{a} \\binom{ a-j }{ i-j } \\\\ \u0026 = \\sum_{j=0}^{a} \\binom{ b }{ a-j } \\binom{ a }{ a-j } 2^{a-j} \\\\ \u0026 \\xlongequal{i=a-j} \\sum_{i=0}^{a} \\binom{ b }{ i } \\binom{ a }{ i } 2^{i} \\end{align*} $$\nProblem 3 给定集合 $ A=\\{1,2,\\ldots,n\\} $ 与正整数 $ k $，从 $ A $ 中选出一组按三角阵排列的 $ \\binom{k+1}{2} $ 个子集 $$ \\begin{matrix} S_{1,1} \\\\ S_{2,1} \u0026 S_{2,2} \\\\ \\vdots \u0026 \\vdots \u0026 \\ddots \\\\ S_{k,1} \u0026 S_{k,2} \u0026 \\dots \u0026 S_{k,k} \\end{matrix} $$ 满足每个集合是它左边和上方的集合（如果存在）的子集。需要求出满足这个要求的选择方案数。\n解\n由于每个元素相互独立，具体方案和元素无关，因此可以考虑一个元素的合法出现方式（在哪些集合会包含这个元素）的总数，设为 $ f(k) $ ，那么最后答案即为 $ [f(k)]^{n} $ 。\n现在考虑 $ x\\in A $ ，根据包含关系，不难看出如果 $ x\\in S $ ，那么 $ S $ 左侧和上方（如果存在）的集合都会包含 $ x $。因此出现 $ x $ 的集合在 $ k $ 阶三角形中可以形成一个从 $ (1,1) $ 出发，每次可以向右或者下方通行的有向图。\n考虑某个合法方案，设元素最后一次出现在对角线（$ S_{1,1},\\dots,S_{k,k} $）的位置为 $ S_{r,r} $ ，那么根据包含关系，此时显然 $ x $ 包含于上方的 $ r $ 阶小三角阵中的每一个元素，并且不会出现在下方的 $ k-r $ 阶小三角方阵中（否则必然会再次出现在对角线中）。因此只需要考虑 $ x $ 在余下部分，也就是四个顶点分别为为 $ (r+1,1),(r+1,r),(k,1),(k,r) $ 的长方形区域中的合法方案数即可。\n对于这样的长方形区域，我们可以按行考虑，显然根据包含的规则， $ x $ 在每一行出现的形式必定是从最左侧开始连续的一段，并且上到下每一行 $ x $ 出现的次数是不降的。因此我们可以把这个问题转化为求一个长度为 $ k-r $ ，每个数范围为 $ 0\\sim r $ 的单调不降序列的方案数。设第 $ i $ 个数的值为 $ t_{i} $ ，那么方案数为 $$ \\begin{align*} \\sum_{t_{1}=0}^{r} \\sum_{t_{2}=0}^{t_{1}} \\dots \\sum_{t_{k-r}=0}^{t_{k-r-1}} 1 \u0026 = \\sum_{t_{1}=0}^{r} \\dots \\sum_{t_{k-r-1}=0}^{t_{k-r-2}} (t_{k-r-1} + 1) \\\\ \u0026 = \\sum_{t_{1}=0}^{r} \\dots \\sum_{t_{k-r-1}=0}^{t_{k-r-2}} \\binom{ t_{k-r-1} + 1 }{ 1 } \\\\ \u0026 = \\sum_{t_{1}=0}^{r} \\dots \\sum_{t_{k-r-2}=1}^{t_{k-r-3}} \\binom{ t_{k-r-2}+2 }{ 2 } \\\\ \u0026 \\dots \\\\ \u0026 = \\sum_{t_{1}=0}^{r} \\binom{ t_{1} + k-r-1 }{ k-r-1 } = \\binom{ k }{ k-r } \\end{align*} $$ 因此 $$ f(k) = \\sum_{r=0}^{k} \\binom{ k }{ k-r } = \\sum_{r=0}^{k} \\binom{ k }{ r } = 2^{k} $$ 所以方案数为 $$ [f(k)]^{n} = 2^{nk} $$\nProblem 4 给定一个长度为 $ mn+1 $ 的序列 $ a_{0},a_{1},\\ldots,a_{mn} $，其中每一项只可能取 $ 1 $ 或 $ 1-m $，并且满足总和 $$ \\sum_{i=0}^{mn} a_i = 1 . $$ 在此条件下：\n(1)\n证明：在该序列里，取值为 $ 1 $ 的项共有 $ mn-n+1 $ 个，而取值为 $ 1-m $ 的项共有 $ n $ 个。\n证\n设 $ 1 $ 有 $ a $ 个，$ 1-m $ 有 $ b $ 个，那么得到方程 $$ \\begin{cases} a + b = mn+1 \\\\ a + (1-m)b = 1 \\end{cases} $$ 直接可以解得 $$ \\begin{cases} a = mn-n+1 \\\\ b=n \\end{cases} $$\n(2)\n把序列首尾相接排成一个圆环。考虑所有可能的“起点”选择（即对序列做循环移位）。\n证明：恰好存在唯一一个起点 $ k $，使得从该位置开始依次相加得到的所有部分和都为正，即 $$ a_k,\\ a_k+a_{k+1},\\ \\ldots,\\ a_k+a_{k+1}+\\cdots+a_{k-1} $$ 全部大于 $ 0 $（下标按模 $ mn+1 $ 计算）。\n证\n考虑序列前缀和 $ S_{t} = \\sum_{i=0}^{t}a_{i} $ ，并且 $ S_{-1}=0 $。在序列 $ \\{ S_{-1},S_{0},\\dots,S_{mn} \\} $ 中存在最小值 $ S_{k} $，如果有多个，取其中下标最大的为 $ S_{k} $，显然 $ S_{k} $ 唯一。\n于是 $ \\forall r\\in \\{ k+1,\\dots,mn \\} $ ，有 $ S_{r}\u003eS_{k} $ ，因此从 $ k+1 $ 到 $ r $ 的子段和为 $ \\sum_{i=k+1}^{r}a_{i}=S_{r}-S_{k}\u003e0 $\n并且 $ \\forall l\\in \\{ 0,\\dots,k \\}: S_{l-1}\\leq S_{k} $ ，因此从 $ k+1 $ 开始的一段循环序列中的和为（考虑在原序列中这一段的补集）： $$ \\sum_{i=k+1}^{mn+1+l}a_{i\\bmod (mn+1)}=\\sum_{i=0}^{mn}a_{i} - \\sum_{i=l}^{k}a_{i}=1-(S_{k}-S_{l-1}) = 1+S_{l-1}-S_{k}\\geq 1 \u003e 0 $$\n综上，我们找出了唯一满足从该位置开始左右的部分和都为正的一个位置，证毕。\n(3)\n求满足“所有前缀部分和都为正”的序列 $ a_{0},a_{1},\\ldots,a_{mn} $ 的总数。\n证 1\n不考虑任意前缀和为正的限制，所有的序列总数为 $ \\binom{ mn+1 }{ n } $（总共 $ mn+1 $ 个数，选择 $ n $ 个数为 $ 1-m $）。\n对于任意一个序列，根据 $ (2) $ 的结论，存在唯一的 $ k $ 使得从 $ k $ 开始的所有前缀和为正，因此我们将改序列的下标向左平移 $ k $ 即可得到一个合法的序列。\n这说明每种圆排列都对应唯一一个合法的序列，所以答案为 $$ \\dfrac{1}{mn+1}\\binom{ mn+1 }{ n } $$\n证 2（没证出来😭）\n首先必然有 $ a_{0}=1 $ ，否则 $ a_{0}=1-m\u003c 0 $ 已经不满足条件。因此可以在原序列去掉 $ a_{0} $，问题的约束转化为 $ \\sum_{i=1}^{mn}a_{i}=0 $ ，保证从 $ a_{1} $ 开始的前缀和非负即可。\n将问题转化为在一个二维网格上路径计数的模型：从起点 $ O(0,0) $ 出发，每一步会向上走 $ 1 $ 格或者向右走 $ 1 $ 格，目标走到 $ D(n,n(m-1)) $，其中前缀和非负的约束转化为不能越过直线 $ l:y=(m-1)x $ 。\n我们将向上走的操作记为 $ U $，向右走的操作记为 $ R $，显然最终一个 $ R $ 可以对应 $ (m-1) $ 个 $ U $ 操作。由于一个 $ R $ 操作的跨度过大，使我们难以操作“路径中第一个不合法的点”，因此我们考虑将 $ R $ 拆解成粒度更小 $ (m-1) $ 个连续的 $ r $ 操作，可以看成向右移动 $ \\dfrac{1}{m-1} $ 格的距离。此时一条路径中含有 $ N=n(m-1) $ 个 $ U $ 操作和 $ r $ 操作。\n考虑一条不合法的路径，可以看成一个不合法的操作序列 $ S $，单独找出第一次越过 $ l $ 的 $ r $ 操作，可以将 $ S $ 分解成 $$ S = ArB $$ 其中 $ A $ 的末尾刚好在 $ l $ 上，满足 $ r=U $ （数量），$ B $ 为剩余序列。\n由于 $ A $ 的性质更好，所以参考 Catalan 数的证明，我们考虑将 $ A $ “反射”，将其中的所有 $ r $ 和 $ U $ 操作互换，得到 $ \\overline{A} $，从而构造出 $$ S'=\\overline{A}rB $$ 于是我们得到了一个不合法序列 $ S $ 和某个 $ S' $ 序列的双射。从 $ S' $ 映射会 $ S $ 同样只需要找出第一次到达 $ l $ 的位置找出 $ \\overline{A} $，再进行一次“反射”即可。\n我们再定义一个压缩操作，表示从左到右扫描一个序列，遇到 $ U $ 直接加入新的序列，遇到累计遇到 $ (m-1) $ 个 $ r $ 向新序列中加入一个 $ R $。这样对于任意一个 $ U $ 和 $ r $ 数量均为 $ N $ 的序列，压缩后都会得到一个无约束的 $ U-R $ 序列。我们将这个操作记为 $ C(S) $，$ S $ 表示操作的 $ U-r $ 序列。\n于是现在我们对于一条不合法的路径，将其细化为 $ U-r $ 序列 $ S $ 后再反射为 $ S' $，压缩后得到 $ P=C(S') $，这是一个无约束的 $ U-R $ 序列，含有 $ n $ 个 $ R $。\n// 通过手动计算小数据，可以猜出一个合法序列对应 $ n(m-1) $ 个非法序列的结论。并且注意到有 $ N $ 个 $ U $ 操作，因此希望通过引入某种“标记操作”，来标记某个 $ U $ 操作，来构造出一个 $ \\text{非法序列} \\leftrightarrow (\\text{合法序列},u^{*}) $ 的双射，其中 $ u^{*} $ 表示被标记的 $ U $ 操作。这样说明一个合法序列对应 $ N $ 个非法序列，于是合法序列数量为 $$ \\dfrac{1}{N+1}\\binom{ mn }{ n } = \\dfrac{1}{n(m-1)+1}\\binom{ mn }{ n } = \\dfrac{1}{mn+1}\\binom{ mn+1 }{ n } $$\n","permalink":"https://diefish1024.github.io/posts/class-notes/cs0901-combinatorics/cs0901-hw1/","summary":"\u003ch2 id=\"problem-1\"\u003eProblem 1\u003c/h2\u003e\n\u003cp\u003e\u003cstrong\u003e(1)\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e求\n$$ \n\n\\sum_{k=0}^{n} \\binom{ 2n }{ 2k } \n\n $$\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e解\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e$$ \n\n\\begin{align*}\n \u0026 \\sum_{k=0}^{n} (-1)^{k}\\binom{ n }{ k } = 0 \\\\\n\\implies \u0026 \\sum_{k=0}^{2n} (-1)^{k}\\binom{ 2n }{ k } =0 \\\\\n\\implies \u0026 \\sum_{k=0}^{2n} \\binom{ 2n }{ 2k } = \\sum_{k=1}^{2n} \\binom{ 2n }{ 2k - 1 } \n\\end{align*}\n\n $$\n同时由于\n$$ \n\n\\sum_{k=0}^{2n} \\binom{ 2n }{ 2k } + \\sum_{k=1}^{2n} \\binom{ 2n }{ 2k - 1 } = \\sum_{k=0}^{2n} \\binom{ 2n }{ k } = 2^{2n}\n\n $$\n得到\n$$ \n\n\\sum_{k=0}^{2n} \\binom{ 2n }{ 2k } = 2^{2n-1}\n\n $$\u003c/p\u003e","title":"CS0901 HW1"},{"content":"Product and Sum Principles 加法原理（分类计数） 若一个任务可分解为若干个互斥的子类，第 $ i $ 类有 $ a_i $ 种方案，则总数为 $ \\sum_i a_i $。 解释：互斥保证不重不漏，求和即“或”的计数。\n乘法原理（分步计数） 若一个任务分为若干个有序步骤，步骤 $ i $ 有 $ b_i $ 种选择且相互独立，则总数为 $ \\prod_i b_i $。 解释：有序步骤逐个做决定，“且”的计数对应乘法。\nConstructing Maps 有些组合证明可以依赖于构造映射：\n单射：不同原像映到不同像，用于证明下界或“可嵌入性”。 满射：像覆盖全体，用于证明上界可达或构造覆盖。 双射：建立集合 $ A $ 与 $ B $ 的一一对应，从而数 $ |A|=|B| $；这是“数某一个量 ⇒ 构造双射”的核心思想。 Twelvefoldway 将 $ n $ 个球放入 $ m $ 个盒子，球与盒子可“可区分/不可区分”，以及盒子容量约束“任意/至多 1/至少 1”。\n$ n $ $ m $ 任意 $ \\leq 1 $ $ \\geq 1 $ 不同 不同 $ m^{n} $ $ m^{\\underline{n}} $ $ m!\\left\\{ {n \\atop m} \\right\\} $ 同 不同 $ \\binom{ n+m-1 }{ m-1 } $ $ \\binom{ m }{ n } $ $ \\binom{ n-1 }{ m-1 } $ 不同 同 $ \\sum_{k=0}^{\\min(n,m)} \\left\\{ {n \\atop k} \\right\\} $ $ [n \\leq m] $ $ \\left\\{ {n \\atop m} \\right\\} $ 同 同 $ p_{\\leq m}(n) $ $ [n \\leq m] $ $ p(n,m) $ “把 $ n $ 个不同球分成 $ k $ 个非空无序盒”对应第二类斯特林数 $ \\left\\{ {n \\atop k} \\right\\} $。\nStirling Numbers of the Second Kind 定义：$ \\left\\{ {n \\atop k} \\right\\} $ 表示“将 $ n $ 个不同元素分成 $ k $ 个非空无序块”的方案数。\n基本递推：$$ \\left\\{ {n \\atop k} \\right\\} = \\left\\{ {n-1 \\atop k-1} \\right\\} + k \\left\\{ {n-1 \\atop k} \\right\\}, \\quad \\left\\{ {0 \\atop 0} \\right\\}=1 $$ 从组合意义上理解，元素 $ n $ 要么独自成新块（$ \\left\\{ {n-1 \\atop k-1} \\right\\} $），要么加入已有 $ k $ 个块之一（$ k \\left\\{ {n-1 \\atop k} \\right\\} $）。\n与降阶阶乘的分层展开：$$ m^{n} = \\sum_{k=1}^{n} \\left\\{ {n \\atop k} \\right\\} m^{\\underline{k}} $$ 组合证明：\n将 $ n $ 个不同球先“分组”为 $ k $ 个非空无序块： $ \\left\\{ {n \\atop k} \\right\\} $。 从 $ m $ 个可区分盒中选出并按顺序对应这 $ k $ 个块： $ m^{\\underline{k}} $。 按 $ k $ 分层求和即得全部映射 $ [n] \\to [m] $ 的总数 $ m^n $。 另一恒等式：$$ \\left\\{ {n \\atop m} \\right\\} = \\sum_{k=0}^{n-1} \\binom{ n-1 }{ k } \\left\\{ {n-k-1 \\atop k-1} \\right\\} $$\nVandermonde’s Convolution 范德蒙卷积： $$ \\binom{ r+s }{ n } = \\sum_{k=0}^{n} \\binom{ r }{ k } \\binom{ s }{ n-k } $$\n组合证明：从 $ r+s $ 个元素中选 $ n $ 个。分类：从前 $ r $ 个元素选 $ k $ 个、从后 $ s $ 个元素选 $ n-k $ 个，$ k $ 遍历 $ 0 $ 至 $ n $，互斥且完备，故求和。\n代数证明：用二项式定理展开 $ (1+x)^{r+s} = (1+x)^r (1+x)^s $，比对 $ x^n $ 的系数即得。\nBinomial Coefficients 对称性： $ \\binom{ n }{ k } = \\binom{ n }{ n-k } $ 组合：选 $ k $ 个等价于弃 $ n-k $ 个。\nPascal 恒等式： $ \\binom{ n }{ k } = \\binom{ n-1 }{ k } + \\binom{ n-1 }{ k-1 } $ 组合：考虑是否包含元素 $ n $。\n总和： $ \\sum_{k=0}^{n} \\binom{ n }{ k } = 2^{n} $ 组合：每元素选/不选两种，乘法原理；或代数用 $ (1+1)^n $。\n“曲棍球杆”恒等式： $ \\sum_{i=r}^{n} \\binom{ i }{ r } = \\binom{ n+1 }{ r+1 } $ 组合：给定最大元素，按其值分类累加；或用 Pascal 叠加。\n一阶矩： $ \\sum_{k=0}^{n} k \\binom{ n }{ k } = n 2^{n-1} $ 组合：双计数“选出子集并指定一个已选标记元素”；或代数对 $ (1+x)^n $ 求导令 $ x=1 $。\n二项式定理： $ (x+y)^{n} = \\sum_{k=0}^{n} \\binom{ n }{ k } x^{k} y^{n-k} $ 代数：展开乘法；组合：从 $ n $ 个因子中选 $ k $ 次取 $ x $。\n范德蒙卷积：见上一节。\n凸性与对数凹性：\n对于固定 $ n $，序列 $ \\left( \\binom{ n }{ 0 }, \\binom{ n }{ 1 }, \\dots, \\binom{ n }{ n } \\right) $ 是对称、单峰且对数凹：对所有可行 $ k $，有 $$ \\binom{ n }{ k }^{2} \\ge \\binom{ n }{ k-1 } \\binom{ n }{ k+1 } $$ 计算比值 $$ \\frac{ \\binom{ n }{ k } }{ \\binom{ n }{ k-1 } } = \\frac{ n-k+1 }{ k }, \\quad \\frac{ \\binom{ n }{ k+1 } }{ \\binom{ n }{ k } } = \\frac{ n-k }{ k+1 } $$ 由此得 $$ \\frac{ \\binom{ n }{ k }^{2} }{ \\binom{ n }{ k-1 } \\binom{ n }{ k+1 } } = \\frac{ k (k+1) }{ (n-k+1)(n-k) } \\cdot \\frac{ (n-k+1)(n-k) }{ k (k+1) } = 1 $$ Catalan Numbers 第 $ n $ 个卡特兰数 $$ C_n = \\frac{ 1 }{ n+1 } \\binom{ 2n }{ n } $$\n网格路径模型：从点 $ (0,0) $ 到 $ (n,n) $，每步向右 $ R $ 或向上 $ U $，要求路径始终不越过主对角线 $ y=x $。这等价于计数长度 $ 2n $ 的序列，任意前缀中 $ U $ 的数量不小于 $ R $ 的数量。\n经典反射法证明（Ballot/Reflection）：\n总路径数：不加限制，从 $ 2n $ 步中选出 $ n $ 步为 $ U $，共 $ \\binom{ 2n }{ n } $ 条。 计“坏”路径：越界的路径。设首次越界的时刻为第 $ t $ 步，此时 $ R $ 比 $ U $ 多一。将前 $ t $ 步关于直线 $ y=x $ 反射（交换 $ U $ 与 $ R $），得到一条从 $ (0,0) $ 到 $ (n+1,n-1) $ 的路径；此构造是坏路径与“从 $ (0,0) $ 到 $ (n+1,n-1) $ 的任意路径”之间的双射。因此坏路径数为 $ \\binom{ 2n }{ n-1 } $。 好路径数： $ \\binom{ 2n }{ n } - \\binom{ 2n }{ n-1 } = \\frac{ 1 }{ n+1 } \\binom{ 2n }{ n } $，即 $ C_n $。 本质抽象：两类操作 $ U $ 与 $ R $ 总数相等，且任意时刻“$ U $ 的累计数 ≥ $ R $ 的累计数”。同构到投票/括号配对/堆栈可行序等大量模型。\n","permalink":"https://diefish1024.github.io/posts/class-notes/cs0901-combinatorics/lect1-counting/","summary":"\u003ch2 id=\"product-and-sum-principles\"\u003eProduct and Sum Principles\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e加法原理（分类计数）\u003c/strong\u003e\n若一个任务可分解为若干个互斥的子类，第 $ i $ 类有 $ a_i $ 种方案，则总数为 $ \\sum_i a_i $。\n解释：互斥保证不重不漏，求和即“或”的计数。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e乘法原理（分步计数）\u003c/strong\u003e\n若一个任务分为若干个有序步骤，步骤 $ i $ 有 $ b_i $ 种选择且相互独立，则总数为 $ \\prod_i b_i $。\n解释：有序步骤逐个做决定，“且”的计数对应乘法。\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"constructing-maps\"\u003eConstructing Maps\u003c/h2\u003e\n\u003cp\u003e有些组合证明可以依赖于构造映射：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e单射\u003c/strong\u003e：不同原像映到不同像，用于证明下界或“可嵌入性”。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e满射\u003c/strong\u003e：像覆盖全体，用于证明上界可达或构造覆盖。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e双射\u003c/strong\u003e：建立集合 $ A $ 与 $ B $ 的一一对应，从而数 $ |A|=|B| $；这是“数某一个量 ⇒ 构造双射”的核心思想。\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"twelvefoldway\"\u003e\u003ca href=\"https://en.wikipedia.org/wiki/Twelvefold_way\"\u003eTwelvefoldway\u003c/a\u003e\u003c/h2\u003e\n\u003cp\u003e将 $ n $ 个球放入 $ m $ 个盒子，球与盒子可“可区分/不可区分”，以及盒子容量约束“任意/至多 1/至少 1”。\u003c/p\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth\u003e$ n $\u003c/th\u003e\n          \u003cth\u003e$ m $\u003c/th\u003e\n          \u003cth\u003e任意\u003c/th\u003e\n          \u003cth\u003e$ \\leq 1 $\u003c/th\u003e\n          \u003cth\u003e$ \\geq 1 $\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e不同\u003c/td\u003e\n          \u003ctd\u003e不同\u003c/td\u003e\n          \u003ctd\u003e$ m^{n} $\u003c/td\u003e\n          \u003ctd\u003e$ m^{\\underline{n}} $\u003c/td\u003e\n          \u003ctd\u003e$ m!\\left\\{ {n \\atop m} \\right\\} $\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e同\u003c/td\u003e\n          \u003ctd\u003e不同\u003c/td\u003e\n          \u003ctd\u003e$ \\binom{ n+m-1 }{ m-1 } $\u003c/td\u003e\n          \u003ctd\u003e$ \\binom{ m }{ n } $\u003c/td\u003e\n          \u003ctd\u003e$ \\binom{ n-1 }{ m-1 } $\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e不同\u003c/td\u003e\n          \u003ctd\u003e同\u003c/td\u003e\n          \u003ctd\u003e$ \\sum_{k=0}^{\\min(n,m)} \\left\\{ {n \\atop k} \\right\\} $\u003c/td\u003e\n          \u003ctd\u003e$ [n \\leq m] $\u003c/td\u003e\n          \u003ctd\u003e$ \\left\\{ {n \\atop m} \\right\\} $\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e同\u003c/td\u003e\n          \u003ctd\u003e同\u003c/td\u003e\n          \u003ctd\u003e$ p_{\\leq m}(n) $\u003c/td\u003e\n          \u003ctd\u003e$ [n \\leq m] $\u003c/td\u003e\n          \u003ctd\u003e$ p(n,m) $\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003e“把 $ n $ 个不同球分成 $ k $ 个非空无序盒”对应第二类斯特林数 $ \\left\\{ {n \\atop k} \\right\\} $。\u003c/p\u003e","title":"Lect1-Counting"},{"content":"课程讲义\n在这门课里，我们会专注于所谓的 科尔莫哥洛夫（Kolmogorov）的公理体系，它使得我们能够使用数学分析的工具来研究概率。\nSt. Petersburg Paradox 圣彼得堡悖论。假设一个基于抛硬币赌博的游戏，庄家会一直扔硬币直到结果是正面，如果扔了 $ k $ 次，那么就会给玩家 $ 2^{k} $ 元的奖金。现在的问题是你愿意花多少钱来购买一次玩这个游戏的机会。\n一个很自然的想法是计算游戏的期望，那么我们很容易发现期望收益是 $$ \\sum_{k \\geq 1} 2^{k}\\cdot 2^{-k} = 1 + 1 + \\dots = +\\infty $$ 这说明平均每一轮我们的收益是无穷大，然而在现实生活中你真的愿意花大价钱去玩这个游戏吗？或者可以写一个简单的程序模拟一下就会发现，在比如门票定为 $ 100 $ 元，玩几百局，还是会轻易地输掉几万块钱。我们生活中一个常见的直觉是如果重复一个随机过程足够多次，平均收益就会逐渐趋近于期望收益，这在概率论中叫做大数定律（Law of large numbers），但是在现实生活中我们并没有能力重复足够多游戏轮数去达到这个期望值。那么现在的问题就是如果定价用 $ a\\cdot n $ 元来购买 $ n $ 次游戏机会，$ a $ 定为多少是合理的？\n用这门课中后续会学习到的数学工具，我们可以得到答案为 $ \\log n $ （这个结果也符合我们实际的直觉）。\n随机游走 对二维随机游走问题的一个简化的建模是在 $ \\mathbb{Z}^{2} $ 的网格上随机游走，从原点 $ (0,0) $ 出发，每次以 $ \\dfrac{1}{4} $ 的概率往上下左右四个方向移动。我们现在询问，这个随机游走的路径是否会无数次回到原点？用 $ T $ 来表示第一次回到原点的时间，那么可以证明无数次回到原点等价于 $ \\mathbb{P}[T \u003c \\infty] = 1 $ ，也就是 $ T $ 以 $ 1 $ 的概率是有限的，当然目前只能从直觉上去理解，这个写法需要在后续的课程中去严格定义。\n关于这个问题的答案，波利亚证明了当考虑 $ n $ 维格点 $ \\mathbb{Z}^{n} $ 的随机游走时，对于 $ n\u003c 2 $ ，$ \\mathbb{P}[T \u003c \\infty] = 1 $ ，对于 $ n\\geq 2 $ ，$ \\mathbb{P}[T \u003c \\infty] \u003c 1 $。\n投资策略问题 考虑一个简化的投资模型，假设有两支股票，进行 $ T $ 天的交易，每一天选择一支股票进行投资。假设当前是 $ t $ 天，在这一天开始的时候，需要选定投资哪一只，在这一天结束的时候，可以看到收益。我们假设两只股票在第 $ t $ 天的收益是 $ r_{1}^{(t)},r_{2}^{(t)}\\in[0, 1] $。假设第 $ t $ 天玩家选择了投资股票 $ a_{t} $，则玩家在 $ t $ 天的总收益是 $$ R(T):=\\sum_{t=1}^{T} r_{a_{t}}^{(t)} $$ 那么我们如何选择一个好的投资策略？\n首先我们需要明确如何衡量一个投资策略的好坏。一个很自然的假设是把 $ R(T) $ 看成关于 $ T $ 的函数，希望 $ R(T) $ 能越大越好。但是我们的收益不仅仅和我们的策略有关，还和两只股票每天的收益挂钩，假设大环境不好，两只股票都亏钱，那不管投资策略怎么样都不能获得高收益。因此我们可以想到用我们的策略和表现最好的股票相比，这也就是懊悔值 (Regret) 的定义：对于给定投资策略，以及每天的收益情况 $ \\vec{r} = \\left(r_{1}^{(t)}, r_{2}^{(t)}\\right)_{1 \\leq t \\leq T} $ $$ \\text{Regret}(T) := \\left( \\max_{a\\in \\{ 1, 2 \\}} \\sum_{t = 1}^{T}r_{a}^{(t)} \\right) - R(T) $$ 朴素的理解就是，因为没有未卜先知而产生的懊悔程度。\n我们希望一个好的投资策略是，不管股票收益如何，我们的 $ \\text{Regret}(T) $ 都比较小。由于 $ \\text{Regret}(T) \\leq T $ ，因此我们希望策略满足 $ \\text{Regret}(T) = o(T) $ ，这表示当 $ T $ 足够大时，我们的策略事实上找到了最好的股票。\n我们可以证明，对于任何确定性的策略，都不可能达到 $ o(T) $ 的懊悔值。由于我们的策略是确定性的，第 $ t $ 天的选择完全取决于前 $ t-1 $ 天的选择和收益，因此如果假设有一个坏人针对我们的策略控制了市场，那他就可以预测我们的选择，如果我们会选择股票 $ 1 $ ，那他就让 $ r_{1}^{(t)}=0, r_{2}^{(t)}=1 $ ，反之亦然。计算这时候的懊悔值，很容易发现在这样针对性的设置下 $ R(T)=0 $。并且由于每一天的收益之和都是 $ 1 $ ，$ T $ 天的累计收益之和为 $ T $，因此一定有一个股票的 $ T $ 天累计收益之和 $ \\geq T / 2 $ ，这是就有 $ \\text{Regret}(T)\\geq T / 2 $。\nOnline Mirror Descent 可以看出，确定性的算法效果之所以不好，是因为对手可以进行针对性的设置，对应的我们可以使用随机化的策略来避免这一点。\n这就是所谓的在线镜像下降（Online Mirror Descent） 算法，它是一个在计算机科学非常著名的算法，在多个领域被重新发现过，因此，它也有很多其他的名字，比如 Multiplicative weight update method，Hedge 算法，EXP3 算法等。\n算法会每一轮维护一个分布 $ D_{t} $，玩家的决策来自于从这个分布中的采样，并且算法会根据每个回合的反馈来更新这个分布。\n初始情况 $ D_{0}=\\left( \\dfrac{1}{2}, \\dfrac{1}{2} \\right) $. 对于 $ t=1,2,\\dots,T $ 选择股票 $ a_{t}\\sim D_{t} $，并观察得到的 $ r_{1}^{(t)},r_{2}^{(t)} $. 更新 $ D_{t+1} $，使得 $ D_{t+1}(i) = \\dfrac{D_{t}(i)\\exp(-\\eta \\cdot(1 - r_{i}^{(t)}))}{\\sum_{k=1,2}D_{t}(k)\\exp(-\\eta \\cdot(1 - r_{k}^{(t)}))} $. 其中的参数 $ \\eta=\\sqrt{ \\dfrac{1}{T} } $ 。 算法本身思想很简单：这一轮哪个股票表现好，就在下一轮增加它被选取的概率。然后为什么要像算法这样操作，能不能用别的方式计算，背后的道理就要复杂得多。\n可以证明这个算法满足在期望上 $ \\text{Regret}(T)=o(\\sqrt{ T }) $（这个结果并非最优）。这个结论表示，有些时候使用随机化，可以让算法的效果产生质变。\n","permalink":"https://diefish1024.github.io/posts/class-notes/math2701-probability-theory/lect1-introduction/","summary":"\u003cp\u003e\u003ca href=\"https://chihaozhang.com/teaching/Prob2025/lectures/lec1/lec1.html\"\u003e课程讲义\u003c/a\u003e\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e在这门课里，我们会专注于所谓的 \u003ca href=\"https://en.wikipedia.org/wiki/Probability_axioms\"\u003e科尔莫哥洛夫（Kolmogorov）的公理体系\u003c/a\u003e，它使得我们能够使用数学分析的工具来研究概率。\u003c/p\u003e\u003c/blockquote\u003e\n\u003ch2 id=\"stpetersburg-paradox\"\u003e\u003ca href=\"https://en.wikipedia.org/wiki/St._Petersburg_paradox\"\u003eSt. Petersburg Paradox\u003c/a\u003e\u003c/h2\u003e\n\u003cp\u003e圣彼得堡悖论。假设一个基于抛硬币赌博的游戏，庄家会一直扔硬币直到结果是正面，如果扔了 $ k $ 次，那么就会给玩家 $ 2^{k} $ 元的奖金。现在的问题是你愿意花多少钱来购买一次玩这个游戏的机会。\u003c/p\u003e\n\u003cp\u003e一个很自然的想法是计算游戏的期望，那么我们很容易发现期望收益是\n$$ \n\n\\sum_{k \\geq  1} 2^{k}\\cdot 2^{-k} = 1 + 1 + \\dots = +\\infty\n\n $$\n这说明平均每一轮我们的收益是无穷大，然而在现实生活中你真的愿意花大价钱去玩这个游戏吗？或者可以写一个简单的程序模拟一下就会发现，在比如门票定为 $ 100 $ 元，玩几百局，还是会轻易地输掉几万块钱。我们生活中一个常见的直觉是如果重复一个随机过程足够多次，平均收益就会逐渐趋近于期望收益，这在概率论中叫做\u003cstrong\u003e大数定律（\u003ca href=\"https://en.wikipedia.org/wiki/Law_of_large_numbers\"\u003eLaw of large numbers\u003c/a\u003e）\u003c/strong\u003e，但是在现实生活中我们并没有能力重复足够多游戏轮数去达到这个期望值。那么现在的问题就是如果定价用 $ a\\cdot n $ 元来购买 $ n $ 次游戏机会，$ a $ 定为多少是合理的？\u003c/p\u003e\n\u003cp\u003e用这门课中后续会学习到的数学工具，我们可以得到答案为 $ \\log n $ （这个结果也符合我们实际的直觉）。\u003c/p\u003e\n\u003ch2 id=\"随机游走\"\u003e随机游走\u003c/h2\u003e\n\u003cp\u003e对二维随机游走问题的一个简化的建模是在 $ \\mathbb{Z}^{2} $ 的网格上随机游走，从原点 $ (0,0) $ 出发，每次以 $ \\dfrac{1}{4} $ 的概率往上下左右四个方向移动。我们现在询问，这个随机游走的路径是否会无数次回到原点？用 $ T $ 来表示第一次回到原点的时间，那么可以证明无数次回到原点等价于 $ \\mathbb{P}[T \u003c \\infty] = 1 $ ，也就是 $ T $ 以 $ 1 $ 的概率是有限的，当然目前只能从直觉上去理解，这个写法需要在后续的课程中去严格定义。\u003c/p\u003e","title":"Lect1-Introduction"},{"content":"本文简要介绍通用矩阵乘（GEMM，General Matrix Multiplication）优化的基本概念和方法。GEMM 是 HPC 领域中最基础且计算密集型的工作负载之一。在人工智能、科学模拟和图像处理等领域，它的性能直接影响着整个应用程序的效率。虽然其数学概念简单，但高效的 GEMM 实现却需要对计算机体系结构有深刻的理解，包括缓存、SIMD 指令集和并行化技术。\nNaive GEMM GEMM 通常定义为 $ C = A \\times B $，对于矩阵 $ A \\in \\mathbb{R}^{M \\times K} $，矩阵 $ B \\in \\mathbb{R}^{K \\times N} $，其乘积矩阵 $ C\\in \\mathbb{R}^{M \\times N} $ 可以表示为 $$ C_{i,j} = \\sum_{k=0}^{K-1} A_{i,k}\\times B_{k,j} $$ 对应的朴素代码通常如下（默认行主序存储）：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 void gemm_naive(int M, int N, int K, const float* A, const float* B, float* C) { for (int i = 0; i \u0026lt; M; ++i) { for (int j = 0; j \u0026lt; N; ++j) { C[i][j] = 0.0f; // 初始化 C[i][j] } } for (int i = 0; i \u0026lt; M; ++i) { for (int j = 0; j \u0026lt; N; ++j) { for (int k = 0; k \u0026lt; K; ++k) { C[i][j] += A[i][k] * B[k][j]; } } } } 分析：\n浮点运算总数（FLOPs）：\n对于每个 $ C_{i,j} $ 元素，需要执行 $ K $ 次乘法和 $ K $ 次加法。 总共有 $ M \\times N $ 个 $ C_{i,j} $ 元素。 总操作数约为 $ 2 \\times M \\times N \\times K $ 次浮点运算。 内存访问总数：忽略循环变量和指令的开销。\n矩阵 $ C $ 的初始化需要 $ M \\times N $ 次写入；循环中矩阵 $ A $ 和矩阵 $ B $ 分别被读取 $ M \\times N \\times K $ 次，矩阵 $ C $ 被读取和写入共 $ 2 \\times M \\times N \\times K $ 次。 总内存访问次数约为 $ 4 M N K + M N $。 Why Slow? 尽管代码简洁，但这种实现方式存在严重的性能瓶颈：\n缓存利用率低：对 B[k][j] 的访问大概率导致缓存未命中。由于 B 是行主序存储，每次迭代 k 都会跳到 B 矩阵的下一行，这导致巨大的内存跨越，破坏了空间局部性。\n缺乏 SIMD 向量化潜力：编译器很难将这种混合访问模式有效向量化，因为对 $ B $ 的访问模式不佳。\n算法本身时间复杂度为 $ O(N^{3}) $。\n对这样的矩阵乘的算法优化可分为两类：\n基于算法分析的方法：根据矩阵乘计算特性，从数学角度优化，典型的算法包括 Strassen 算法 和 Coppersmith–Winograd 算法。 基于软件优化的方法：根据计算机存储系统的层次结构特性，选择性地调整计算顺序，主要有循环拆分向量化、内存重排等。 数学角度的优化暂且不在本文的讨论范围内，有机会将单独介绍，下面给出计算机体系结构角度的一些优化角度。\n1 × 4 Register Blocking 参考 how to optimize gemm 一文，我们把输出的计算按照列拆分成若干个 $ 1 \\times 4 $ 的小块，通过一次性处理 $ C $ 的一小块内存来减少内存操作，最大化寄存器的利用率。\n与其一次计算 $ C_{i,j} $ 一个元素，不如一次性计算 $ C_{i, j\\sim j+3} $ 四个连续元素，这很好地利用了 $ C $ 矩阵行内的空间局部性。把这四个元素加载到寄存器，可以大大减少对主存的访问次数。\n下文我们将最内层的循环称为微内核（micro kernel），比如 AddDot1x4 就是一个微内核。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 // AddDot1x4: 计算 C 的一个 1x4 块（按行主序） // Ai 指向 A 的第 i 行起始；Bj 指向 B 的第 j 列所在的起始位置；Cij 指向 C[i][j] inline void AddDot1x4(int K, const float* Ai, const float* Bj, float* Cij, int N) { float c0 = 0.0f, c1 = 0.0f, c2 = 0.0f, c3 = 0.0f; for (int k = 0; k \u0026lt; K; ++k) { float a = Ai[k]; const float* bk = Bj + k * N; // B[k][j..j+3] c0 += a * bk[0]; c1 += a * bk[1]; c2 += a * bk[2]; c3 += a * bk[3]; } Cij[0] = c0; Cij[1] = c1; Cij[2] = c2; Cij[3] = c3; } void gemm_1x4_blocked(int M, int N, int K, const float* A, const float* B, float* C) { for (int i = 0; i \u0026lt; M; ++i) { const float* Ai = \u0026amp;A[i * K]; for (int j = 0; j \u0026lt; N; j += 4) { int w = std::min(4, N - j); if (w == 4) { AddDot1x4(K, Ai, \u0026amp;B[j], \u0026amp;C[i * N + j], N); } else { // 处理尾部 \u0026lt;4 列 for (int jj = 0; jj \u0026lt; w; ++jj) { float acc = 0.f; for (int k = 0; k \u0026lt; K; ++k) acc += Ai[k] * B[k * N + (j + jj)]; C[i * N + j + jj] = acc; } } } } } 分析：\nFLOPs：仍为 $ 2 M N K $。 内存访问：（以元素计，忽略缓存命中） 读取 $ A $：对每个 $ 1 \\times 4 $ 块，每次 $ K $ 次，共 $ \\frac{M N}{4} \\times K = \\frac{M N K}{4} $。 读取 $ B $：每次 $ 4K $，共 $ \\frac{M N}{4} \\times 4K = M N K $。 写入 $ C $：每块写 $ 4 $ 次，共 $ M N $。无需读取 $ C $（寄存器累加后赋值）。 合计：$ \\frac{1}{4} M N K + 1 \\cdot M N K + M N = 1.25\\, M N K + M N $。 与 naive 相比，$ A $ 的读取减少了 $ 4 \\times $（复用到 4 个连续列），$ B $ 的读取次数相同但连续访问更友好，$ C $ 的访存从每次迭代读写降为仅写一次。\n加速比：\n在内存带宽主导的 Roofline 模型 下，性能与内存访问次数近似成反比，因此加速比为 $$ S_{\\text{1x4}} \\approx \\frac{4 M N K + M N}{1.25 M N K + M N} \\approx \\frac{4}{1.25} = 3.2 \\quad (K \\gg 1) $$\nLoop Unrolling and Pointer Optimization 为了进一步优化，我们在 AddDot1x4 内部使用指针迭代与循环展开，减少地址计算和分支开销，提升指令级并行性与寄存器利用。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 inline void AddDot1x4_unroll4(int K, const float* Ai, const float* Bj, float* Cij, int N) { float c0 = 0.f, c1 = 0.f, c2 = 0.f, c3 = 0.f; const float* a = Ai; const float* b = Bj; int k = 0; for (; k + 3 \u0026lt; K; k += 4) { float a0 = a[0], a1 = a[1], a2 = a[2], a3 = a[3]; const float* b0 = b + 0 * N; const float* b1 = b + 1 * N; const float* b2 = b + 2 * N; const float* b3 = b + 3 * N; c0 += a0 * b0[0] + a1 * b1[0] + a2 * b2[0] + a3 * b3[0]; c1 += a0 * b0[1] + a1 * b1[1] + a2 * b2[1] + a3 * b3[1]; c2 += a0 * b0[2] + a1 * b1[2] + a2 * b2[2] + a3 * b3[2]; c3 += a0 * b0[3] + a1 * b1[3] + a2 * b2[3] + a3 * b3[3]; a += 4; b += 4 * N; } for (; k \u0026lt; K; ++k) { float av = *a++; const float* bk = b; b += N; c0 += av * bk[0]; c1 += av * bk[1]; c2 += av * bk[2]; c3 += av * bk[3]; } Cij[0] = c0; Cij[1] = c1; Cij[2] = c2; Cij[3] = c3; } 分析：\nFLOPs：仍为 $ 2 M N K $。 内存访问：与 $ 1 \\times 4 $ 相同（$ 1.25\\, M N K + M N $），仅减少了地址计算和分支开销。 加速比：\n内存主导：与 $ 1 \\times 4 $ 相同，约 $ 3.2 \\times $。 计算主导：循环展开可进一步减少指令开销，常见提升在 $ 5\\% \\sim 15\\% $ 范围（与编译器和微架构相关）。 4 × 4 Register Blocking 不难意识到，用一样的逻辑可以把上面的寄存器分块从 $ 1 \\times 4 $ 扩展到 $ 4 \\times 4 $。这样可以进一步减少内存操作，提高效率。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 // AddDot4x4: 计算 C 的一个 4x4 块（行主序，传入 C 的起始为 C[i][j]） inline void AddDot4x4(int K, const float* Aij, const float* Bkj, float* Cij, int N, int Kstride) { float c00=0.f,c01=0.f,c02=0.f,c03=0.f, c10=0.f,c11=0.f,c12=0.f,c13=0.f, c20=0.f,c21=0.f,c22=0.f,c23=0.f, c30=0.f,c31=0.f,c32=0.f,c33=0.f; const float* a0 = Aij + 0 * Kstride; const float* a1 = Aij + 1 * Kstride; const float* a2 = Aij + 2 * Kstride; const float* a3 = Aij + 3 * Kstride; for (int k = 0; k \u0026lt; K; ++k) { float a0k = a0[k], a1k = a1[k], a2k = a2[k], a3k = a3[k]; const float* bk = Bkj + k * N; float b0 = bk[0], b1 = bk[1], b2 = bk[2], b3 = bk[3]; c00 += a0k * b0; c01 += a0k * b1; c02 += a0k * b2; c03 += a0k * b3; c10 += a1k * b0; c11 += a1k * b1; c12 += a1k * b2; c13 += a1k * b3; c20 += a2k * b0; c21 += a2k * b1; c22 += a2k * b2; c23 += a2k * b3; c30 += a3k * b0; c31 += a3k * b1; c32 += a3k * b2; c33 += a3k * b3; } Cij[0*N+0]=c00; Cij[0*N+1]=c01; Cij[0*N+2]=c02; Cij[0*N+3]=c03; Cij[1*N+0]=c10; Cij[1*N+1]=c11; Cij[1*N+2]=c12; Cij[1*N+3]=c13; Cij[2*N+0]=c20; Cij[2*N+1]=c21; Cij[2*N+2]=c22; Cij[2*N+3]=c23; Cij[3*N+0]=c30; Cij[3*N+1]=c31; Cij[3*N+2]=c32; Cij[3*N+3]=c33; } 分析：\nFLOPs：仍为 $ 2 M N K $。 内存访问（元素计）： 读取 $ A $：每块 $ 4K $，块数 $ \\frac{M}{4}\\times\\frac{N}{4} $，合计 $ \\frac{M N K}{4} $。 读取 $ B $：每块 $ 4K $，同上合计 $ \\frac{M N K}{4} $。 写入 $ C $：每块 $ 16 $ 次，共 $ M $。 合计：$ 0.5\\, M N K + M N $。 与 $ 1 \\times 4 $ 相比，$ B $ 的读取也减少了 $ 4 \\times $（同一批 $ B[k, j..j+3] $ 复用到 4 行），因此总体内存访问显著下降。\n加速比： $$ S_{\\text{4x4}} \\approx \\frac{4 M N K + M N}{0.5 M N K + M N} \\approx \\frac{4}{0.5} = 8 \\quad (K \\gg 1) $$\nSIMD Vectorization 现在我们引入 SIMD，以 Intel SSE 指令集为例（128-bit，单精度宽度 $ W = 4 $）。下面给出与 AddDot4x4 对齐的简化向量化微内核。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 #include \u0026lt;immintrin.h\u0026gt; inline void AddDot4x4_SSE(int K, const float* Aij, const float* Bkj, float* Cij, int N, int Kstride) { __m128 c0 = _mm_setzero_ps(); __m128 c1 = _mm_setzero_ps(); __m128 c2 = _mm_setzero_ps(); __m128 c3 = _mm_setzero_ps(); const float* a0 = Aij + 0 * Kstride; const float* a1 = Aij + 1 * Kstride; const float* a2 = Aij + 2 * Kstride; const float* a3 = Aij + 3 * Kstride; for (int k = 0; k \u0026lt; K; ++k) { __m128 b = _mm_loadu_ps(\u0026amp;Bkj[k * N]); // B[k][j..j+3] __m128 a0v = _mm_set1_ps(a0[k]); __m128 a1v = _mm_set1_ps(a1[k]); __m128 a2v = _mm_set1_ps(a2[k]); __m128 a3v = _mm_set1_ps(a3[k]); c0 = _mm_add_ps(c0, _mm_mul_ps(a0v, b)); c1 = _mm_add_ps(c1, _mm_mul_ps(a1v, b)); c2 = _mm_add_ps(c2, _mm_mul_ps(a2v, b)); c3 = _mm_add_ps(c3, _mm_mul_ps(a3v, b)); } _mm_storeu_ps(\u0026amp;Cij[0 * N], c0); _mm_storeu_ps(\u0026amp;Cij[1 * N], c1); _mm_storeu_ps(\u0026amp;Cij[2 * N], c2); _mm_storeu_ps(\u0026amp;Cij[3 * N], c3); } 分析：\nFLOPs：仍为 $ 2 M N K $。 内存访问：与标量 4×4 相同（$ 0.5\\, M N K + M N $）。SIMD 仅改变算术吞吐，不改变 DRAM 访存量。 计算主导场景的理论加速：约等于向量宽度 $ W $（SSE 单精度为 $ 4 $；AVX2 为 $ 8 $；AVX-512 为 $ 16 $）。若支持 FMA（如 AVX2/FMA、AVX-512），每周期可进一步提升。 加速比：\n内存主导：约 $ 8 \\times $（同 4×4）。 计算主导： 4×4 与 SIMD 的收益不可直接相乘，约 $ 8 \\times W $ 的上界不成立；更实际的估计是：在 4×4 将算术强度显著提升后，若仍处于计算主导，则 SIMD 可再带来 $ W \\times $ 左右的额外提升。 Cache Blocking（Macro-kernel） 尽管 SIMD 和寄存器分块（微内核）带来了巨大的性能提升，但当矩阵尺寸超出 CPU 缓存容量时，性能仍会因高昂的内存访问延迟而下降。缓存分块 (Cache Blocking) 旨在将矩阵操作分解成一系列小块操作，使这些块的数据能够长时间驻留在不同级别的缓存中（例如 L1、L2、L3），从而实现数据重用最大化。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 // 缓存分块 + 4x4 微内核 void gemm_blocked_4x4(int M, int N, int K, const float* A, const float* B, float* C) { const int MR = 4, NR = 4; const int KC = 128; // 需按架构调优 for (int kk = 0; kk \u0026lt; K; kk += KC) { int Kc = std::min(KC, K - kk); for (int i = 0; i \u0026lt; M; i += MR) { int Mb = std::min(MR, M - i); for (int j = 0; j \u0026lt; N; j += NR) { int Nb = std::min(NR, N - j); if (Mb == MR \u0026amp;\u0026amp; Nb == NR) { AddDot4x4(Kc, \u0026amp;A[i * K + kk], \u0026amp;B[kk * N + j], \u0026amp;C[i * N + j], N, K); } else { // 退化处理 for (int ii = 0; ii \u0026lt; Mb; ++ii) for (int jj = 0; jj \u0026lt; Nb; ++jj) { float acc = 0.f; for (int k = 0; k \u0026lt; Kc; ++k) acc += A[(i + ii) * K + (kk + k)] * B[(kk + k) * N + (j + jj)]; C[(i + ii) * N + (j + jj)] = acc + C[(i + ii) * N + (j + jj)]; } } } } } } 分析：\nFLOPs：仍为 $ 2 M N K $。 DRAM 级内存访问：（理想分块并有良好复用时） $ A $：每个元素从 DRAM 读入约 $ 1 $ 次，$ M K $。 $ B $：每个元素从 DRAM 读入约 $ 1 $ 次，$ K N $。 $ C $：每个元素从 DRAM 读写各 $ 1 $ 次，$ 2 M N $。 合计：$ M K + K N + 2 M N $。 通过按 $ K $ 维度切块，$ A $ 与 $ B $ 的面板在较小的 $ K_c $ 上反复被微内核复用；只要 $ K_c $、$ M_r $、$ N_r $ 选取得当，就能使复用主要发生在 L1/L2/L3 中，从 DRAM 的视角看，$ A $/$ B $ 基本只需读取一次。\n加速比： $$ S_{\\text{blocked}} \\approx \\frac{4 M N K + M N}{M K + K N + 2 M N} $$\n当 $ M = N = K = n $ 时，有 $ S \\approx \\frac{4 n^3}{4 n^2} = n $，随问题规模线性增长，实际受缓存与带宽上限限制。\nData Packing 即使有了缓存分块，如果原始矩阵的内存布局导致块内部的数据不连续（例如，行主序矩阵中的列访问），缓存效率仍然会受损。数据打包 (Packing) 通过将需要计算的矩阵块复制到临时的、内存连续且对齐的缓冲区中来解决这个问题。\n将 $ A $ 的 $ M_r \\times K_c $ 面板按“列优先、行紧凑”的形式打包，便于微内核顺序读取。 将 $ B $ 的 $ K_c \\times N_r $ 面板按“行优先、列紧凑”的形式打包，使得每个 $ k $ 的 $ B[k, j..j+N_r-1] $ 连续、对齐。 示例打包代码（以 $ M_r=4, N_r=4 $ 为例）：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 // pack A: 从行主序 A 中取 4xKc，按列（k）主序、行（r）紧凑存放：Apack[k*4 + r] void pack_A_4xKc(const float* A, int lda, float* Apack, int Kc) { for (int k = 0; k \u0026lt; Kc; ++k) { Apack[k * 4 + 0] = A[0 * lda + k]; Apack[k * 4 + 1] = A[1 * lda + k]; Apack[k * 4 + 2] = A[2 * lda + k]; Apack[k * 4 + 3] = A[3 * lda + k]; } } // pack B: 从行主序 B 中取 Kc x 4，按行（k）主序、列（c）紧凑存放：Bpack[k*4 + c] void pack_B_Kc4(const float* B, int ldb, float* Bpack, int Kc) { for (int k = 0; k \u0026lt; Kc; ++k) { const float* bk = B + k * ldb; Bpack[k * 4 + 0] = bk[0]; Bpack[k * 4 + 1] = bk[1]; Bpack[k * 4 + 2] = bk[2]; Bpack[k * 4 + 3] = bk[3]; } } 配合打包的 4×4 微内核（内层线性访问）：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 inline void AddDot4x4_packed(int Kc, const float* Ap, const float* Bp, float* Cij, int N) { __m128 c0 = _mm_setzero_ps(); __m128 c1 = _mm_setzero_ps(); __m128 c2 = _mm_setzero_ps(); __m128 c3 = _mm_setzero_ps(); for (int k = 0; k \u0026lt; Kc; ++k) { __m128 b = _mm_loadu_ps(\u0026amp;Bp[k * 4]); float a0 = Ap[k * 4 + 0]; float a1 = Ap[k * 4 + 1]; float a2 = Ap[k * 4 + 2]; float a3 = Ap[k * 4 + 3]; c0 = _mm_add_ps(c0, _mm_mul_ps(_mm_set1_ps(a0), b)); c1 = _mm_add_ps(c1, _mm_mul_ps(_mm_set1_ps(a1), b)); c2 = _mm_add_ps(c2, _mm_mul_ps(_mm_set1_ps(a2), b)); c3 = _mm_add_ps(c3, _mm_mul_ps(_mm_set1_ps(a3), b)); } _mm_storeu_ps(\u0026amp;Cij[0 * N], _mm_add_ps(c0, _mm_loadu_ps(\u0026amp;Cij[0 * N]))); _mm_storeu_ps(\u0026amp;Cij[1 * N], _mm_add_ps(c1, _mm_loadu_ps(\u0026amp;Cij[1 * N]))); _mm_storeu_ps(\u0026amp;Cij[2 * N], _mm_add_ps(c2, _mm_loadu_ps(\u0026amp;Cij[2 * N]))); _mm_storeu_ps(\u0026amp;Cij[3 * N], _mm_add_ps(c3, _mm_loadu_ps(\u0026amp;Cij[3 * N]))); } FLOPs：不变。 DRAM 访存：与“理想分块”一致（$ M K + K N + 2 M N $），但常数项更小（线性、对齐、可预取），SIMD 装载更高效。 OpenMP Parallelization 在多核 CPU 上，使用 OpenMP 对外层块循环并行是提升性能的有效手段。推荐在线程之间划分 $ (i, j) $ 的宏块，避免对同一 $ C $ 子块的写冲突。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 // OpenMP 并行的分块 GEMM（以 4x4 微内核 + K 分块为例） void gemm_blocked_omp(int M, int N, int K, const float* A, const float* B, float* C, int num_threads) { const int MR = 4, NR = 4, KC = 256, MC = 256, NC = 256; #pragma omp parallel num_threads(num_threads) { // 线程私有的临时打包缓冲区 std::vector\u0026lt;float\u0026gt; Ap(MR * KC), Bp(KC * NR); #pragma omp for collapse(2) schedule(static) for (int jc = 0; jc \u0026lt; N; jc += NC) { for (int ic = 0; ic \u0026lt; M; ic += MC) { int Nc = std::min(NC, N - jc); int Mc = std::min(MC, M - ic); for (int pc = 0; pc \u0026lt; K; pc += KC) { int Kc = std::min(KC, K - pc); for (int i = ic; i \u0026lt; ic + Mc; i += MR) { int Mb = std::min(MR, ic + Mc - i); for (int j = jc; j \u0026lt; jc + Nc; j += NR) { int Nb = std::min(NR, jc + Nc - j); if (Mb == MR \u0026amp;\u0026amp; Nb == NR) { pack_A_4xKc(\u0026amp;A[i * K + pc], K, Ap.data(), Kc); pack_B_Kc4(\u0026amp;B[pc * N + j], N, Bp.data(), Kc); AddDot4x4_packed(Kc, Ap.data(), Bp.data(), \u0026amp;C[i * N + j], N); } else { for (int ii = 0; ii \u0026lt; Mb; ++ii) for (int jj = 0; jj \u0026lt; Nb; ++jj) { float acc = 0.f; for (int k = 0; k \u0026lt; Kc; ++k) acc += A[(i + ii) * K + (pc + k)] * B[(pc + k) * N + (j + jj)]; C[(i + ii) * N + (j + jj)] += acc; } } } } } } } } } 分析：\nFLOPs：不变。 DRAM 访存：与“分块 + 打包”的单线程相同（$ M K + K N + 2 M N $）。 加速上界： 计算主导：理想线性加速 $ \\leq T $（线程数）。 内存主导：受内存带宽限制，$ \\leq \\frac{\\text{BW}_{\\text{并行}}}{\\text{BW}_{\\text{单线程}}} $。当达到带宽饱和后继续加线程收益有限。 加速比：\n在“分块 + 打包”基础上，OpenMP 将计算并行化。理想上界（计算主导）：$$ S_{\\text{blocked+packed+OMP}} \\approx \\min\\left(T,\\ \\frac{\\text{PeakFLOPs}}{\\text{单线程 FLOPs}}\\right) \\times \\frac{4 M N K + M N}{M K + K N + 2 M N} $$ 在带宽主导时，上式中 $ T $ 替换为带宽扩展比。 Method Comparison 为便于对比，下面给出各优化策略在“忽略缓存命中、以元素访问计”的内存访问与内存主导模型下的理论加速比（相对 naive）：\n方法 微内核形状 FLOPs 内存访问（元素数） 相对 naive 加速比（内存主导，$ K \\gg 1 $） naive 无 $ 2MNK $ $ 4MNK + MN $ $ 1.0 $ 1×4 寄存器分块 1×4 $ 2MNK $ $ 1.25MNK + MN $ $ \\approx 3.2 $ 1×4 + 展开 1×4 $ 2MNK $ $ 1.25MNK + MN $ $ \\approx 3.2 $（计算主导再 +5%~15%） 4×4 寄存器分块 4×4 $ 2MNK $ $ 0.5MNK + MN $ $ \\approx 8.0 $ 4×4 + SIMD（SSE） 4×4 $ 2MNK $ $ 0.5MNK + MN $ 内存主导 $ \\approx 8.0 $；计算主导再 $ \\times 4 $ 分块（$ K_{c} $）+ 打包 任意 $ 2MNK $ $ MK + KN + 2MN $ $ \\frac{4MNK+MN}{MK+KN+2MN} $（方阵约为 $ n $） 分块 + 打包 +OpenMP 任意 $ 2MNK $ $ MK + KN + 2MN $ 上式 × 并行效率（受带宽与可伸缩性限制） 上表的内存访问为“理想化、从 DRAM 角度”的估算，实际性能取决于缓存命中、预取、对齐、访存指令融合和前端/后端瓶颈等。\n采用 += 写回将引入对 $ C $ 的读操作；若事先知道目标 $ C $ 块为零，可进一步减少读流量。\nComparing with BLAS Libraries 现代 BLAS（如 Intel MKL、OpenBLAS、BLIS）普遍采用“三级分块 + 数据打包 + 专用微内核（含 SIMD/FMA）”的体系： 最外层：$ N_c $、$ M_c $、$ K_c $ 级别的宏分块，匹配 L3/L2。 中层：面板打包（AB-panel），顺序、对齐、预取友好。 内层：手写/内联汇编微内核，固定 $ M_r \\times N_r $，深度展开，寄存器阻塞，利用 FMA 与流水线。 对 x86： SSE 场景常见微内核大小约 $ 4 \\times 4 $。 AVX2/AVX-512 场景常见 $ M_r, N_r $ 更大（如 $ 6 \\times 16 $、$ 8 \\times 30 $ 等），并利用 FMA。 这些库还会进行： 多级预取策略（硬件/软件结合）。 NUMA 感知的任务分配与内存归属（first-touch）。 针对边界块的专门路径和对齐优化。 Summary 从“寄存器分块（微内核）→ SIMD → 缓存分块（宏内核）→ 数据打包 → OpenMP 并行”的路径逐层优化了 GEMM 性能。\n核心思想：\n用寄存器保存部分和，显著减少对 $ C $ 的读写。 通过 $ 1 \\times 4 \\to 4 \\times 4 $ 提高 $ A $/$ B $ 的复用，降低 DRAM 访存。 用 SIMD/FMA 提高每条指令的 FLOPs。 宏分块与打包让复用在 L1/L2/L3 内生效，将 DRAM 流量降到 $ MK + KN + 2MN $ 的量级。 OpenMP 在多核扩展吞吐，但需注意带宽瓶颈与 NUMA。 在内存主导模型下的理论加速（相对 naive）：\n$ 1 \\times 4 $：约 $ 3.2 \\times $。 $ 4 \\times 4 $：约 $ 8 \\times $。 分块 + 打包：约 $ \\frac{4MNK+MN}{MK+KN+2MN} $（方阵近似 $ n $）。 SIMD 与 OpenMP 的收益叠加取决于是否进入计算主导。 References How to optimize GEMM（FLAME wiki） 通用矩阵乘（GEMM）优化算法 OpenBLAS ","permalink":"https://diefish1024.github.io/posts/hpc/gemm-%E7%AE%97%E6%B3%95%E4%BC%98%E5%8C%96/","summary":"\u003cp\u003e本文简要介绍通用矩阵乘（\u003ca href=\"https://en.wikipedia.org/wiki/Basic_Linear_Algebra_Subprograms#Level_3\"\u003eGEMM\u003c/a\u003e，General Matrix Multiplication）优化的基本概念和方法。GEMM 是 HPC 领域中最基础且计算密集型的工作负载之一。在人工智能、科学模拟和图像处理等领域，它的性能直接影响着整个应用程序的效率。虽然其数学概念简单，但高效的 GEMM 实现却需要对计算机体系结构有深刻的理解，包括缓存、SIMD 指令集和并行化技术。\u003c/p\u003e\n\u003ch2 id=\"naive-gemm\"\u003eNaive GEMM\u003c/h2\u003e\n\u003cp\u003eGEMM 通常定义为 $ C = A \\times B $，对于矩阵 $ A \\in \\mathbb{R}^{M \\times K} $，矩阵 $ B \\in \\mathbb{R}^{K \\times N} $，其乘积矩阵 $ C\\in \\mathbb{R}^{M \\times N} $ 可以表示为\n$$ \n\nC_{i,j} = \\sum_{k=0}^{K-1} A_{i,k}\\times B_{k,j} \n\n $$\n对应的朴素代码通常如下（默认行主序存储）：\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cdiv class=\"chroma\"\u003e\n\u003ctable class=\"lntable\"\u003e\u003ctr\u003e\u003ctd class=\"lntd\"\u003e\n\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode\u003e\u003cspan class=\"lnt\"\u003e 1\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 2\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 3\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 4\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 5\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 6\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 7\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 8\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 9\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e10\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e11\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e12\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e13\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e14\n\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\n\u003ctd class=\"lntd\"\u003e\n\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-cpp\" data-lang=\"cpp\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"kt\"\u003evoid\u003c/span\u003e \u003cspan class=\"nf\"\u003egemm_naive\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"kt\"\u003eint\u003c/span\u003e \u003cspan class=\"n\"\u003eM\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"kt\"\u003eint\u003c/span\u003e \u003cspan class=\"n\"\u003eN\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"kt\"\u003eint\u003c/span\u003e \u003cspan class=\"n\"\u003eK\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"k\"\u003econst\u003c/span\u003e \u003cspan class=\"kt\"\u003efloat\u003c/span\u003e\u003cspan class=\"o\"\u003e*\u003c/span\u003e \u003cspan class=\"n\"\u003eA\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"k\"\u003econst\u003c/span\u003e \u003cspan class=\"kt\"\u003efloat\u003c/span\u003e\u003cspan class=\"o\"\u003e*\u003c/span\u003e \u003cspan class=\"n\"\u003eB\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"kt\"\u003efloat\u003c/span\u003e\u003cspan class=\"o\"\u003e*\u003c/span\u003e \u003cspan class=\"n\"\u003eC\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"k\"\u003efor\u003c/span\u003e \u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"kt\"\u003eint\u003c/span\u003e \u003cspan class=\"n\"\u003ei\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"mi\"\u003e0\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e \u003cspan class=\"n\"\u003ei\u003c/span\u003e \u003cspan class=\"o\"\u003e\u0026lt;\u003c/span\u003e \u003cspan class=\"n\"\u003eM\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e \u003cspan class=\"o\"\u003e++\u003c/span\u003e\u003cspan class=\"n\"\u003ei\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"k\"\u003efor\u003c/span\u003e \u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"kt\"\u003eint\u003c/span\u003e \u003cspan class=\"n\"\u003ej\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"mi\"\u003e0\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e \u003cspan class=\"n\"\u003ej\u003c/span\u003e \u003cspan class=\"o\"\u003e\u0026lt;\u003c/span\u003e \u003cspan class=\"n\"\u003eN\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e \u003cspan class=\"o\"\u003e++\u003c/span\u003e\u003cspan class=\"n\"\u003ej\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e            \u003cspan class=\"n\"\u003eC\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"n\"\u003ei\u003c/span\u003e\u003cspan class=\"p\"\u003e][\u003c/span\u003e\u003cspan class=\"n\"\u003ej\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"mf\"\u003e0.0f\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e \u003cspan class=\"c1\"\u003e// 初始化 C[i][j]\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e\u003c/span\u003e        \u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"k\"\u003efor\u003c/span\u003e \u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"kt\"\u003eint\u003c/span\u003e \u003cspan class=\"n\"\u003ei\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"mi\"\u003e0\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e \u003cspan class=\"n\"\u003ei\u003c/span\u003e \u003cspan class=\"o\"\u003e\u0026lt;\u003c/span\u003e \u003cspan class=\"n\"\u003eM\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e \u003cspan class=\"o\"\u003e++\u003c/span\u003e\u003cspan class=\"n\"\u003ei\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"k\"\u003efor\u003c/span\u003e \u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"kt\"\u003eint\u003c/span\u003e \u003cspan class=\"n\"\u003ej\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"mi\"\u003e0\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e \u003cspan class=\"n\"\u003ej\u003c/span\u003e \u003cspan class=\"o\"\u003e\u0026lt;\u003c/span\u003e \u003cspan class=\"n\"\u003eN\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e \u003cspan class=\"o\"\u003e++\u003c/span\u003e\u003cspan class=\"n\"\u003ej\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e            \u003cspan class=\"k\"\u003efor\u003c/span\u003e \u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"kt\"\u003eint\u003c/span\u003e \u003cspan class=\"n\"\u003ek\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"mi\"\u003e0\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e \u003cspan class=\"n\"\u003ek\u003c/span\u003e \u003cspan class=\"o\"\u003e\u0026lt;\u003c/span\u003e \u003cspan class=\"n\"\u003eK\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e \u003cspan class=\"o\"\u003e++\u003c/span\u003e\u003cspan class=\"n\"\u003ek\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e                \u003cspan class=\"n\"\u003eC\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"n\"\u003ei\u003c/span\u003e\u003cspan class=\"p\"\u003e][\u003c/span\u003e\u003cspan class=\"n\"\u003ej\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e \u003cspan class=\"o\"\u003e+=\u003c/span\u003e \u003cspan class=\"n\"\u003eA\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"n\"\u003ei\u003c/span\u003e\u003cspan class=\"p\"\u003e][\u003c/span\u003e\u003cspan class=\"n\"\u003ek\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e \u003cspan class=\"o\"\u003e*\u003c/span\u003e \u003cspan class=\"n\"\u003eB\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"n\"\u003ek\u003c/span\u003e\u003cspan class=\"p\"\u003e][\u003c/span\u003e\u003cspan class=\"n\"\u003ej\u003c/span\u003e\u003cspan class=\"p\"\u003e];\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e            \u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\u003c/tr\u003e\u003c/table\u003e\n\u003c/div\u003e\n\u003c/div\u003e\u003cp\u003e\u003cstrong\u003e分析\u003c/strong\u003e：\u003c/p\u003e","title":"GEMM 算法优化"},{"content":"如何更好更快地访问内存是 HPC 中最大的瓶颈之一，仅仅了解 SIMD 或并行编程接口是不足够的，本文将梳理计算机的内存层次结构、缓存友好编程、内存墙现象、NUMA 架构以及预取技术。\nUnderstanding Memory Hierarchy 为了充分利用现代 CPU 的性能，我们必须理解数据是如何在不同层级的内存组件之间流动的。\nRegisters, Caches, and Main Memory 寄存器 (Registers)： CPU 内置的、容量最小但速度最快的数据存储单元，用于存储正在被 CPU 活跃操作的数据。CPU 直接在寄存器上执行大部分计算。\n缓存 (Cache)： 位于 CPU 和主内存之间的小容量、高速存储区域。它们的目的是通过存储最可能被 CPU 再次访问的数据来减少对主内存的访问延迟。\nL1 缓存 (Level 1 Cache)：最小、最快，通常分为数据缓存 (L1d) 和指令缓存 (L1i)，每个 CPU 核心独有。其访问速度与 CPU 核心时钟周期相近。 L2 缓存 (Level 2 Cache)：比 L1 大且慢，每个 CPU 核心独有或由几个核心共享。 L3 缓存 (Level 3 Cache)：最大、最慢的缓存，通常由同一 CPU 插槽上的所有核心共享。 主内存 (Main Memory/RAM)： 容量远大于缓存，但访问速度慢得多。当数据不在任何缓存中时，CPU 必须从主内存中获取。\nTLB (Translation Lookaside Buffer)： TLB 是一个专用的高性能缓存，用于存储虚拟地址到物理地址的转换映射。当 CPU 访问一个虚拟地址时，它首先检查 TLB。如果找到对应的物理地址（TLB 命中），则可以快速进行内存访问；如果未找到（TLB 未命中），则需要查询页表，这将导致显著的延迟。理解 TLB 对于优化内存页访问模式，尤其是在处理大型数据集时至关重要。\n通过这种多级内存层次结构访问内存，我们需要尽可能满足局部性原理来提高效率：\n时间局部性 (Temporal Locality)：如果一个数据项最近被访问过，那么它很可能在不久的将来再次被访问。 空间局部性 (Spatial Locality)：如果一个数据项被访问了，那么它附近的内存地址中的数据项也很可能在不久的将来被访问。 Cache-Friendly Programming 编写“缓存友好”的代码意味着组织数据和访问模式，最大化缓存命中率。\nCache Line and Performance Impact 缓存行 (Cache Line)： 缓存和主内存之间数据传输的最小单元，通常为 64 字节。当 CPU 从主内存中请求一个字节时，整个缓存行都会被加载到缓存中。 这强调了空间局部性：如果你的程序按顺序访问内存，那么一次缓存加载可以为未来的访问提供多个数据项，从而提高效率。 伪共享 (False Sharing)：如果两个或多个独立的变量不幸地位于同一个缓存行中，并且被不同的 CPU 核心修改，那么即使它们逻辑上不相关，也会因为缓存一致性协议导致大量的缓存行失效和重新加载，从而严重影响性能。 Cache Hit/Miss and Coherence 缓存命中 (Cache Hit)：当 CPU 需要的数据已经在某个缓存级别中时，访问速度非常快。 缓存未命中 (Cache Miss)：当 CPU 需要的数据不在任何缓存中时，必须从更慢的内存级别（最终是主内存）获取数据，这会引入延迟。未命中可分为： 强制性未命中 (Compulsory Miss/Cold Miss)：首次访问数据。 容量性未命中 (Capacity Miss)：缓存太小，无法容纳所有活跃数据。 冲突性未命中 (Conflict Miss)：多个数据项映射到缓存中的同一个位置。 缓存一致性 (Cache Coherence)： 在多核处理器系统中，不同的核心可能有同一份数据在各自的缓存副本中。为了确保所有核心看到的数据是一致的最新版本，需要缓存一致性协议，如 MESI (Modified, Exclusive, Shared, Invalid) 协议。理解这些协议有助于避免伪共享等问题。 SoA vs. AoS 选择正确的数据布局对缓存性能至关重要。这部分在 HPC 中的 C 和 C++ 中也有提及。\n结构体数组 (AoS: Array of Structs)： struct Point { float x, y, z; } points[N];\n这种布局下，一个 Point 结构体的所有成员在内存中是连续的。如果你的代码经常需要访问一个点的所有坐标，这种布局是高效的。 数组结构体 (SoA: Struct of Arrays)： struct { float x[N], y[N], z[N]; } points_soa;\n如果你需要对所有点的 $ x $ 坐标执行操作，那么可以高效地利用缓存行，因为内存访问是高度连续的。对于 SIMD 向量化操作来说，SoA 通常更优化。 选择 SoA 还是 AoS 取决于数据访问模式：如果经常需要访问一个对象的所有属性，AoS 可能更好（但要注意缓存行对齐和填充）。如果经常需要对多个对象的某个特定属性进行批处理操作，SoA 通常是更好的选择。\nThe Memory Wall 内存墙是指 CPU 的计算速度与主内存的访问速度之间日益扩大的差距。CPU 处理能力的增长远远快于内存延迟的改进速度，这意味着即使 CPU 理论上可以执行大量的指令，但如果它必须经常等待数据从主内存中加载，那么大部分时间都会处于空闲状态，从而限制了实际的应用程序性能。\n解决方案：\n优化算法，减少对内存的访问次数。 最大化缓存命中率，利用数据局部性。 采用预取技术来隐藏内存访问延迟。 NUMA Architectures Non-Uniform Memory Access Challenges NUMA (Non-Uniform Memory Access) ，即非一致性内存访问架构，在多处理器系统中变得越来越普遍。在 NUMA 系统中，每个 CPU (或 CPU 插槽) 都有一组直接连接的本地内存，访问本地内存比访问连接到另一个 CPU 的远端内存要快得多。不同的内存器件和 CPU 核心从属不同的 Node，每个 Node 都有自己的集成内存控制器（IMC，Integrated Memory Controller）。\n如果一个线程在 CPU0 上运行，却频繁访问挂载在 CPU1 上的内存，性能会显著下降，因为数据必须通过处理器间互连（如 Intel 的 UPI 或 AMD 的 Infinity Fabric）传输，这会引入额外的延迟。\n不当的内存放置策略可能导致严重的性能瓶颈，甚至超过内存墙的限制。\nNUMA Optimization with numactl 为了在 NUMA 架构下获得最佳性能，我们必须确保计算尽可能地在靠近其所访问数据的 CPU 核心上进行。numactl 是一个强大的 Linux 命令行工具，它允许我们精确控制进程的 CPU 亲和性和内存分配策略。\n查看 NUMA 节点布局：numactl --hardware 命令可以显示系统中所有的 NUMA 节点、每个节点的 CPU 核心及其本地内存大小。 1 numactl --hardware 输出示例：\n1 2 3 4 5 6 7 8 9 10 11 available: 2 nodes (0-1) node 0 cpus: 0 1 2 3 node 0 size: 16000 MB node 0 free: 15000 MB node 1 cpus: 4 5 6 7 node 1 size: 16000 MB node 1 free: 15000 MB node distances: node 0 1 0: 10 21 1: 21 10 这表示系统有 2 个 NUMA 节点（0 和 1）。节点 0 拥有 CPU 核心 0-3，节点 1 拥有 CPU 核心 4-7。node distances 表示访问本地内存的成本为 10，访问远端内存的成本为 21，远端访问的开销约为本地的两倍。\n重要 numactl 选项： --cpunodebind \u0026lt;nodes\u0026gt;：将进程或线程绑定到指定 NUMA 节点上的 CPU 核心。例如，--cpunodebind=0 将进程限制在节点 0 上的 CPU。 --membind \u0026lt;nodes\u0026gt;：强制所有内存分配都来自指定 NUMA 节点。例如，--membind=1 将所有内存都从节点 1 分配。 --localalloc：在当前线程运行的 NUMA 节点上分配内存。这是最佳实践，因为它确保了数据存储在距离计算最近的位置。 --physcpubind \u0026lt;cpus\u0026gt;：将进程或线程绑定到特定的物理 CPU 核心。 NUMA Memory Access Test 可以通过一个简单的多线程数组求和程序来演示 numactl 对 NUMA 性能的影响。程序会分配一个非常大（足够超出 cache）的数组，然后使用 OpenMP 让多个线程并行计算数组元素的总和。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 #include \u0026lt;iostream\u0026gt; #include \u0026lt;vector\u0026gt; #include \u0026lt;numeric\u0026gt; #include \u0026lt;chrono\u0026gt; #include \u0026lt;omp.h\u0026gt; #include \u0026lt;algorithm\u0026gt; // 确保足够大以超出缓存并触及 NUMA 效应 const size_t ARRAY_SIZE = 1000000000ULL; int main() { std::cout \u0026lt;\u0026lt; \u0026#34;Allocating array of \u0026#34; \u0026lt;\u0026lt; ARRAY_SIZE * sizeof(long long) / (1024 * 1024 * 1024.0) \u0026lt;\u0026lt; \u0026#34; GB...\u0026#34; \u0026lt;\u0026lt; std::endl; std::vector\u0026lt;long long\u0026gt; data(ARRAY_SIZE); #pragma omp parallel for for (size_t i = 0; i \u0026lt; ARRAY_SIZE; ++i) { data[i] = i % 100; } std::cout \u0026lt;\u0026lt; \u0026#34;Array initialized.\u0026#34; \u0026lt;\u0026lt; std::endl; int num_threads = 2; omp_set_num_threads(num_threads); std::cout \u0026lt;\u0026lt; \u0026#34;Using \u0026#34; \u0026lt;\u0026lt; num_threads \u0026lt;\u0026lt; \u0026#34; OpenMP threads.\u0026#34; \u0026lt;\u0026lt; std::endl; long long total_sum = 0; auto start = std::chrono::high_resolution_clock::now(); #pragma omp parallel reduction(+:total_sum) { int thread_id = omp_get_thread_num(); size_t chunk_size = ARRAY_SIZE / num_threads; size_t start_idx = thread_id * chunk_size; size_t end_idx = std::min(start_idx + chunk_size, ARRAY_SIZE); std::cout \u0026lt;\u0026lt; \u0026#34;Thread \u0026#34; \u0026lt;\u0026lt; thread_id \u0026lt;\u0026lt; \u0026#34; processing from \u0026#34; \u0026lt;\u0026lt; start_idx \u0026lt;\u0026lt; \u0026#34; to \u0026#34; \u0026lt;\u0026lt; end_idx \u0026lt;\u0026lt; std::endl; for (size_t i = start_idx; i \u0026lt; end_idx; ++i) { total_sum += data[i]; } } auto end = std::chrono::high_resolution_clock::now(); std::chrono::duration\u0026lt;double\u0026gt; diff = end - start; std::cout \u0026lt;\u0026lt; \u0026#34;Calculated total sum: \u0026#34; \u0026lt;\u0026lt; total_sum \u0026lt;\u0026lt; std::endl; std::cout \u0026lt;\u0026lt; \u0026#34;Time taken: \u0026#34; \u0026lt;\u0026lt; diff.count() \u0026lt;\u0026lt; \u0026#34; seconds\u0026#34; \u0026lt;\u0026lt; std::endl; return 0; } 可以使用 GCC 编译这个程序：\n1 g++ -std=c++11 -O3 -fopenmp numa_test.cpp -o numa_test （由于我的电脑只有一个 NUMA 核心，所以下面测试无法进行。。。）\nBaseline： 1 ./numa_test 远端内存访问：CPU 在节点 1，内存绑定到节点 0。这时所有数据都是远端访问，理论上性能应该最差。 1 numactl --cpunodebind=1 --membind=0 ./numa_test 本地内存访问：CPU 在节点 0，内存绑定到节点 0。这是理性的 NUMA 配置，所有数据访问都是本地的。 1 numactl --cpunodebind=0 --membind=0 ./numa_test 真实多线程场景：CPU 绑定到节点 0 和 1，但内存仅分配到节点 0。跑在节点 1 上的线程将进行远端内存访问。 1 2 export OMP_NUM_THREADS=2 numactl --cpunodebind=0,1 --membind=0 ./numa_test Prefetching 预取 (Prefetching) 是一种技术，它尝试在 CPU 实际需要数据之前，就将其从较慢的内存层级加载到较快的缓存中。这有助于隐藏内存访问延迟，使 CPU 能够专注于计算。\n硬件预取器 (Hardware Prefetcher)： 现代 CPU 内置的智能逻辑单元，它们会监控内存访问模式，并根据检测到的模式（如顺序访问）自动预测接下来可能需要哪些数据，将其提前加载到缓存中。\n优点：全自动，无需程序员干预。 缺点：有时预测不准确，可能将无用数据加载到缓存中，挤出有用数据，甚至增加内存总线流量。 编译器预取 (Compiler Prefetching)： 一些编译器能够根据代码中的循环和访问模式，在编译时插入预取指令。通过 -O3 等优化选项或特定的编译器提示，可以启用此功能。\n软件预取 (Software Prefetching)： 程序员可以通过使用特殊的 CPU 指令（通常通过内联函数 Intrinsics 暴露）显式地告诉 CPU 预取哪些数据。 例如，在 x86 架构上：\n1 2 3 4 5 6 7 8 9 10 11 12 #include \u0026lt;xmmintrin.h\u0026gt; // For _mm_prefetch void process_data(int* arr, int n) { for (int i = 0; i \u0026lt; n; ++i) { // 在实际访问 arr[i + PREFETCH_DISTANCE] 之前提前预取 if (i + PREFETCH_DISTANCE \u0026lt; n) { _mm_prefetch((char*)\u0026amp;arr[i + PREFETCH_DISTANCE], _MM_HINT_T0); } // 处理 arr[i] // ... } } 当硬件预取器无法有效应对复杂的访问模式时，软件预取可以提供更精确的控制。 需要程序员手动插入，可能会增加代码复杂性，不当使用可能导致性能下降。 Summary 在 HPC 领域，仅依靠 CPU 的原始计算能力和并行编程模型是不够的。深入理解计算机内存，是编写高性能代码的基础。通过采用缓存友好的编程，如优化数据布局和分块算法，我们可以显著提高应用程序的性能，真正发挥现代 CPU 的潜力。\nReference 每个程序员都应该知道的 CPU 知识：NUMA（知乎） 浅解 NUMA 机制（知乎） ","permalink":"https://diefish1024.github.io/posts/hpc/%E5%85%B3%E4%BA%8E%E5%86%85%E5%AD%98/","summary":"\u003cp\u003e如何更好更快地访问内存是 HPC 中最大的瓶颈之一，仅仅了解 SIMD 或并行编程接口是不足够的，本文将梳理计算机的内存层次结构、缓存友好编程、内存墙现象、NUMA 架构以及预取技术。\u003c/p\u003e\n\u003ch2 id=\"understanding-memory-hierarchy\"\u003eUnderstanding Memory Hierarchy\u003c/h2\u003e\n\u003cp\u003e为了充分利用现代 CPU 的性能，我们必须理解数据是如何在不同层级的内存组件之间流动的。\u003c/p\u003e\n\u003ch3 id=\"registers-caches-and-main-memory\"\u003eRegisters, Caches, and Main Memory\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e寄存器 (Registers)\u003c/strong\u003e： CPU 内置的、容量最小但速度最快的数据存储单元，用于存储正在被 CPU 活跃操作的数据。CPU 直接在寄存器上执行大部分计算。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e缓存 (Cache)\u003c/strong\u003e： 位于 CPU 和主内存之间的小容量、高速存储区域。它们的目的是通过存储最可能被 CPU 再次访问的数据来减少对主内存的访问延迟。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eL1 缓存 (Level 1 Cache)\u003c/strong\u003e：最小、最快，通常分为数据缓存 (L1d) 和指令缓存 (L1i)，每个 CPU 核心独有。其访问速度与 CPU 核心时钟周期相近。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eL2 缓存 (Level 2 Cache)\u003c/strong\u003e：比 L1 大且慢，每个 CPU 核心独有或由几个核心共享。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eL3 缓存 (Level 3 Cache)\u003c/strong\u003e：最大、最慢的缓存，通常由同一 CPU 插槽上的所有核心共享。\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e主内存 (Main Memory/RAM)\u003c/strong\u003e： 容量远大于缓存，但访问速度慢得多。当数据不在任何缓存中时，CPU 必须从主内存中获取。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eTLB (Translation Lookaside Buffer)\u003c/strong\u003e： TLB 是一个专用的高性能缓存，用于存储虚拟地址到物理地址的转换映射。当 CPU 访问一个虚拟地址时，它首先检查 TLB。如果找到对应的物理地址（TLB 命中），则可以快速进行内存访问；如果未找到（TLB 未命中），则需要查询页表，这将导致显著的延迟。理解 TLB 对于优化内存页访问模式，尤其是在处理大型数据集时至关重要。\u003c/p\u003e","title":"关于内存"},{"content":"去年超算队招新唯一没有解决的一道题，今在 Gemini 老师的帮助下成功解决，决定重写一份题解报告。\nDescription 题目传送门\n题目要求参赛者优化一个 C 语言函数 rotate_the_bit_vector，函数功能是对一个 bit vector 中的一个指定子区间进行循环旋转操作。\n具体而言，题目给的 bit_vector 是一种内存紧凑的数据结构，将 8 个 bit 打包存储到一个字节中。参赛者需要在只修改 submit_func.c 一个文件的前提下重写其中的 rotate_the_bit_vector 函数，使其在大规模数据时尽可能快。\n最后评分程序会通过三个不同的 benchmark (-s, -m, -l) 来衡量，每个测试中的数据规模会随着层数的增加而几何级增长，最终的得分取决于规定时间内能到达的“层数”，层数越高。说明性能越好，最终分数也越高。\nAnalysis Three-Reversal Algorithm 假设要移动的区间长度为 $ n $ ，需要移动 $ k $ 位；由于向右旋转 $ k $ 位可以等效于向左旋转 $ n-k $ 位，因此只讨论向左的移动。\n题目提供了一个初始的性能极差的实现，通过逐位移动 $ k $ 次来实现 $ k $ 位循环旋转，复杂度为 $ O(n^{2}) $。根据这个原始实现很容易想到一个初步的优化方案：\n问题的核心是把数组 [A|B] 变成 [B|A] ，一个经典的算法是三步翻转法：如果我们把翻转操作记为 ' ，A' 表示数组 A 前后反转，那么可以发现原问题的操作实际上等价于三次翻转操作：[A'|B']' = [B|A] ，复杂度为 $ O(n) $ ，代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 #include \u0026#34;./bit_vector.h\u0026#34; #include \u0026lt;assert.h\u0026gt; #include \u0026lt;stdbool.h\u0026gt; #include \u0026lt;sys/types.h\u0026gt; static void reverse_bits(bit_vector_t* const bit_vector, size_t start, size_t end) { while (start \u0026lt; end) { bool temp = bit_vector_get(bit_vector, start); bit_vector_set(bit_vector, start, bit_vector_get(bit_vector, end)); bit_vector_set(bit_vector, end, temp); start++; end--; } } static size_t modulo(const ssize_t n, const size_t m) { const ssize_t signed_m = (ssize_t)m; assert(signed_m \u0026gt; 0); const ssize_t result = ((n % signed_m) + signed_m) % signed_m; assert(result \u0026gt;= 0); return (size_t)result; } void rotate_the_bit_vector(bit_vector_t* const bit_vector, const size_t bit_offset, const size_t bit_length, const ssize_t bit_right_amount) { assert(bit_offset + bit_length \u0026lt;= bit_vector_get_bit_sz(bit_vector)); if (bit_length \u0026lt;= 1) { return; } size_t left_shift = modulo(-bit_right_amount, bit_length); if (left_shift == 0) { return; } // 1. reverse [0, left_shift - 1] reverse_bits(bit_vector, bit_offset, bit_offset + left_shift - 1); // 2. reverse [left_shift, bit_length - 1] reverse_bits(bit_vector, bit_offset + left_shift, bit_offset + bit_length - 1); // 3. reverse [0, bit_length - 1] reverse_bits(bit_vector, bit_offset, bit_offset + bit_length - 1); } 运行测试程序发现只能得到 72 pts\n1 2 3 4 5 6 7 8 9 check result: PASSED performance of -s: 26 performance of -m: 32 performance of -l: 37 ------score-------- -s : 60.00 /100 -m : 72.73 /100 -l : 76.00 /100 total score: 71.82 /100 Performance Analysis with perf 根据题目的提示，我们应该使用 perf 工具来分析性能的瓶颈：\n1 perf record ./everybit -s 运行结束之后生成了一个名为 perf.data 的文件，之后再运行指令分析报告\n1 perf report 输出的交互式界面显示\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 Overhead Command Shared Object Symbol 47.99% everybit everybit [.] bit_vector_set 20.29% everybit everybit [.] bit_vector_get 16.12% everybit everybit [.] bitmask 11.66% everybit everybit [.] reverse_bits 3.26% everybit libc.so.6 [.] __random 0.15% everybit libc.so.6 [.] rand 0.08% everybit [vdso] [.] __vdso_clock_gettime 0.08% everybit everybit [.] bit_vector_randfill 0.08% everybit ld-linux-x86-64.so.2 [.] _dl_init_paths 0.08% everybit ld-linux-x86-64.so.2 [.] handle_intel.constprop.0 0.08% everybit libc.so.6 [.] __random_r 0.08% everybit libc.so.6 [.] _int_free 0.08% everybit libc.so.6 [.] memmove 发现主要的性能瓶颈在 bit_vector_set 和 bit_vector_get 两个操作，这表明虽然我们的算法本身高效，但是其性能严重依赖这两个效率低下的 API ，这指出了我们的下一步优化方向就是这两个操作本身，任何不绕开这两个函数的优化都是治标不治本。\nSpace-for-Time 既然瓶颈在于逐位操作，那么优化的核心思想必然是用块级操作替代位级操作。因此我们需要放弃之前翻转的做法，因为这必然会涉及到位级操作。\n作为替代，我们很自然有用空间换时间的想法：\n在堆上用 malloc 开辟一块足够大的临时缓冲区 temp_buffer。 将原数组需要旋转的 B 和 A 两部分，依次拷贝到 temp_buffer 中，使其内容直接变成旋转后的 [B|A] 顺序。 将 temp_buffer 的内容一次性拷贝回原数组。 由于操作区间是非字节对齐的，我们不能直接使用 memcpy。因此，问题的关键就变成了实现一个高性能、支持任意比特偏移的 bithack_memcpy 函数。\n按照这个思路优化后的代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 #include \u0026#34;./bit_vector.h\u0026#34; #include \u0026lt;assert.h\u0026gt; #include \u0026lt;stdbool.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; #include \u0026lt;string.h\u0026gt; #include \u0026lt;sys/types.h\u0026gt; // alloca.h is no longer needed for the final version // #include \u0026lt;alloca.h\u0026gt; #include \u0026lt;stdint.h\u0026gt; /** * @brief A highly optimized bit-level memcpy. * * Copies \u0026#39;bit_len\u0026#39; bits from a source buffer at a given bit offset to a * destination buffer at another bit offset. This function is the core of the * performance optimization, using 64-bit word operations for the bulk of the copy. * * @param dst_buf The destination memory buffer. * @param dst_offset The starting bit offset in the destination buffer. * @param src_buf The source memory buffer. * @param src_offset The starting bit offset in the source buffer. * @param bit_len The number of bits to copy. */ static void bithack_memcpy(char* dst_buf, size_t dst_offset, const char* src_buf, size_t src_offset, size_t bit_len) { if (bit_len == 0) { return; } size_t bits_copied = 0; // Handle the head: copy bit by bit until the destination is byte-aligned. int head_bits = (8 - (dst_offset % 8)) % 8; if (head_bits \u0026gt; bit_len) { head_bits = bit_len; } for (int i = 0; i \u0026lt; head_bits; i++) { if ((src_buf[(src_offset + i) / 8] \u0026gt;\u0026gt; ((src_offset + i) % 8)) \u0026amp; 1) dst_buf[(dst_offset + i) / 8] |= (1 \u0026lt;\u0026lt; ((dst_offset + i) % 8)); else dst_buf[(dst_offset + i) / 8] \u0026amp;= ~(1 \u0026lt;\u0026lt; ((dst_offset + i) % 8)); } bits_copied += head_bits; // Handle the middle: use 64-bit word operations for maximum speed. while (bit_len - bits_copied \u0026gt;= 64) { size_t current_src_offset = src_offset + bits_copied; size_t current_dst_offset = dst_offset + bits_copied; uint64_t src_word; memcpy(\u0026amp;src_word, src_buf + current_src_offset / 8, sizeof(src_word)); int bit_shift = current_src_offset % 8; if (bit_shift != 0) { uint8_t next_byte = src_buf[current_src_offset / 8 + 8]; src_word = (src_word \u0026gt;\u0026gt; bit_shift) | (((uint64_t)next_byte) \u0026lt;\u0026lt; (64 - bit_shift)); } memcpy(dst_buf + current_dst_offset / 8, \u0026amp;src_word, sizeof(src_word)); bits_copied += 64; } // Handle the tail: copy the remaining bits one by one. for (size_t i = bits_copied; i \u0026lt; bit_len; i++) { if ((src_buf[(src_offset + i) / 8] \u0026gt;\u0026gt; ((src_offset + i) % 8)) \u0026amp; 1) dst_buf[(dst_offset + i) / 8] |= (1 \u0026lt;\u0026lt; ((dst_offset + i) % 8)); else dst_buf[(dst_offset + i) / 8] \u0026amp;= ~(1 \u0026lt;\u0026lt; ((dst_offset + i) % 8)); } } static size_t modulo(const ssize_t n, const size_t m) { const ssize_t signed_m = (ssize_t)m; assert(signed_m \u0026gt; 0); const ssize_t result = ((n % signed_m) + signed_m) % signed_m; assert(result \u0026gt;= 0); return (size_t)result; } void rotate_the_bit_vector(bit_vector_t* const bit_vector, const size_t bit_offset, const size_t bit_length, const ssize_t bit_right_amount) { assert(bit_offset + bit_length \u0026lt;= bit_vector_get_bit_sz(bit_vector)); if (bit_length \u0026lt;= 1) { return; } size_t left_shift = modulo(-bit_right_amount, bit_length); if (left_shift == 0) { return; } size_t buf_byte_size = (bit_length + 7) / 8; char* temp_buffer = (char*)malloc(buf_byte_size); if (temp_buffer == NULL) { exit(1); } size_t first_part_len = bit_length - left_shift; size_t second_part_len = left_shift; bithack_memcpy(temp_buffer, 0, bit_vector-\u0026gt;buf, bit_offset + left_shift, first_part_len); bithack_memcpy(temp_buffer, first_part_len, bit_vector-\u0026gt;buf, bit_offset, second_part_len); bithack_memcpy(bit_vector-\u0026gt;buf, bit_offset, temp_buffer, 0, bit_length); free(temp_buffer); } 现在可以完美获得满分：\n1 2 3 4 5 6 7 8 9 check result: PASSED performance of -s: 37 performance of -m: 40 performance of -l: 44 ------score-------- -s : 100.00 /100 -m : 100.00 /100 -l : 100.00 /100 total score: 100.00 /100 250918 upd: 稍微优化一下 middle 循环中的除法和取模操作，可以再提高一些性能。\nDetails 最终的满分代码完全围绕 bithack_memcpy 函数构建。其工作原理的关键在于分块处理和对底层硬件原理的理解。\n函数将任意拷贝任务拆分为三段：Head , Middle 和 Tail。Head 部分通过逐位拷贝，其唯一目的是让接下来的目标地址实现字节对齐。Tail 部分则处理最后剩下的、不足一个块的零散比特。\n性能优化的核心在 Middle 部分，它以 64 位（8 字节）为单位进行块拷贝。其中处理非对齐源数据的逻辑是精髓所在：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 uint64_t src_word; // 1. 预读取：从源地址的字节边界开始，安全地读取8个字节。 // 这导致我们拿到的数据相对于真正的起始点有一个偏移。 memcpy(\u0026amp;src_word, src_buf + current_src_offset / 8, sizeof(src_word)); int bit_shift = current_src_offset % 8; if (bit_shift != 0) { // 2. 抓取：读取紧邻的下一个字节，它包含了我们缺失的数据。 uint8_t next_byte = src_buf[current_src_offset / 8 + 8]; // 3. 移位与拼接： // a. (src_word \u0026gt;\u0026gt; bit_shift): 将预读取的数据右移，丢弃头部多余的比特。 // b. (((uint64_t)next_byte) \u0026lt;\u0026lt; (64 - bit_shift)): // 将下一个字节左移，使其恰好能填充右移后在高位留下的空缺。 // c. | : 通过或运算，将两部分拼接，重组出我们真正需要的64个比特。 src_word = (src_word \u0026gt;\u0026gt; bit_shift) | (((uint64_t)next_byte) \u0026lt;\u0026lt; (64 - bit_shift)); } // 4. 写入：因为目标地址已对齐，所以可以高效地将重组好的 64 位数据写入。 memcpy(dst_buf + current_dst_offset / 8, \u0026amp;src_word, sizeof(src_word)); 其高性能的根源在于两个核心的底层原理：内存对齐 (Data Alignment) 与 数据局部性 (Data Locality)。\nData Alignment：CPU 访问内存以“字”（Word，64 位 CPU 即 8 字节）为单位。如果数据地址是其大小的倍数，CPU 就能一次内存事务完成读写，这叫对齐访问。非对齐访问则可能需要两次内存事务和内部拼接，性能大幅下降。bithack_memcpy 的“头部处理”阶段，其唯一目的就是实现目标地址的字节对齐，确保占主导地位的中部循环可以执行最高效的对齐写入操作。\nMemory Locality \u0026amp; Caching：CPU 内部有多级 Cache，速度远快于 RAM。当 CPU 访问某块内存时，会把其邻近的一整个 Cache Line 都预加载到缓存中。这就是空间局部性原理 (Principle of Spatial Locality)。我们的 bithack_memcpy 函数利用了这一点，无论是从原数组读，还是在临时缓冲区里读写，操作的都是连续的大块内存。当循环处理第一个 64 位字时，CPU 很可能已经将后面几百个字节的数据预加载到了的 L1 Cache 中，后续迭代无需访问慢速的内存，缓存命中率 (Cache Hit Rate) 极高。相比之下，最初的三步翻转法在内存中“来回跳跃”地访问单个比特，破坏了空间局部性，导致缓存命中率极低，性能自然不佳。\n在开辟缓冲区的选择上面，笔者一开始选择了 alloc ，相比于堆内存，栈内存更快且不需要手动释放，但是发现在测试到一定的层数之后就会由于数据量过大而出现 Segment Falut ，因此最后还是选择了使用 malloc 来分配缓冲区。\n","permalink":"https://diefish1024.github.io/posts/solutions/xflops2024-bithack/","summary":"\u003cp\u003e去年超算队招新唯一没有解决的一道题，今在 Gemini 老师的帮助下成功解决，决定重写一份题解报告。\u003c/p\u003e\n\u003ch2 id=\"description\"\u003eDescription\u003c/h2\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/HPC-SJTU/Xflops2024_1st_exam/tree/main/Bithack\"\u003e题目传送门\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e题目要求参赛者优化一个 C 语言函数 \u003ccode\u003erotate_the_bit_vector\u003c/code\u003e，函数功能是对一个 bit vector 中的一个指定子区间进行\u003cstrong\u003e循环旋转\u003c/strong\u003e操作。\u003c/p\u003e\n\u003cp\u003e具体而言，题目给的 \u003ccode\u003ebit_vector\u003c/code\u003e 是一种内存紧凑的数据结构，将 8 个 bit 打包存储到一个字节中。参赛者需要在只修改 \u003ccode\u003esubmit_func.c\u003c/code\u003e 一个文件的前提下重写其中的 \u003ccode\u003erotate_the_bit_vector\u003c/code\u003e 函数，使其在大规模数据时尽可能快。\u003c/p\u003e\n\u003cp\u003e最后评分程序会通过三个不同的 benchmark (\u003ccode\u003e-s\u003c/code\u003e, \u003ccode\u003e-m\u003c/code\u003e, \u003ccode\u003e-l\u003c/code\u003e) 来衡量，每个测试中的数据规模会随着层数的增加而几何级增长，最终的得分取决于规定时间内能到达的“层数”，层数越高。说明性能越好，最终分数也越高。\u003c/p\u003e\n\u003ch2 id=\"analysis\"\u003eAnalysis\u003c/h2\u003e\n\u003ch3 id=\"three-reversal-algorithm\"\u003eThree-Reversal Algorithm\u003c/h3\u003e\n\u003cp\u003e假设要移动的区间长度为 $ n $ ，需要移动 $ k $ 位；由于向右旋转 $ k $ 位可以等效于向左旋转 $ n-k $ 位，因此只讨论向左的移动。\u003c/p\u003e\n\u003cp\u003e题目提供了一个初始的性能极差的实现，通过逐位移动 $ k $ 次来实现 $ k $ 位循环旋转，复杂度为 $ O(n^{2}) $。根据这个原始实现很容易想到一个初步的优化方案：\u003c/p\u003e\n\u003cp\u003e问题的核心是把数组 \u003ccode\u003e[A|B]\u003c/code\u003e 变成 \u003ccode\u003e[B|A]\u003c/code\u003e ，一个经典的算法是\u003cstrong\u003e三步翻转法\u003c/strong\u003e：如果我们把翻转操作记为 \u003ccode\u003e'\u003c/code\u003e ，\u003ccode\u003eA'\u003c/code\u003e 表示数组 \u003ccode\u003eA\u003c/code\u003e 前后反转，那么可以发现原问题的操作实际上等价于三次翻转操作：\u003ccode\u003e[A'|B']' = [B|A]\u003c/code\u003e ，复杂度为 $ O(n) $ ，代码如下：\u003c/p\u003e","title":"Xflops2024-Bithack"},{"content":"1. What is SIMD? SIMD，即 Single Instruction Multiple Data ，是一种并行计算的模式。传统的单指令单数据模型，也就是一条指令 CPU 只能处理一份数据，这在科学计算和图像渲染等大量数据密集的任务中是非常低效的。\nSIMD 的核心思想是用一条指令同时对多个数据进行操作，现代的 CPU 为此设计了特殊的硬件单元，包括宽位（比如 128、256 或 512 位）的向量寄存器 (Vector Registers) 和能够操作这些寄存器的向量指令 (Vector Instructions)。一个向量操作可以同时完成多个标量操作，从而实现数据并行 (Data Parallelism)，提高效率。假设一个 256 位的向量寄存器可以容纳 8 个 32 位浮点数，一条向量加法指令就可以一次性完成 8 个浮点数的加法，理论上将这部分计算的吞吐量提升至原来的 8 倍；并且相比于执行 8 条独立的标量加法指令，CPU 只需要获取并解码一条向量加法指令，这降低了指令流水线的压力。\n2. How SIMD Works 要理解 SIMD 的工作原理，需要了解两个核心概念：向量寄存器和向量指令。\n2.1. Vector Registers 向量寄存器是 CPU 内部的特殊存储单元，其宽度远大于通用寄存器。不同的 Instruction Set Architecture (ISA, 指令集架构) 提供了不同宽度和名称的向量寄存器。\nSSE (Streaming SIMD Extensions)：提供了 128 位的 XMM 寄存器。\nAVX (Advanced Vector Extensions)：提供了 256 位的 YMM 寄存器。\nAVX-512：提供了 512 位的 ZMM 寄存器。\nARM NEON：主要用于移动设备，提供 128 位的向量寄存器。\n比如一个 YMM 寄存器可以同时存放 8 个单精度浮点数（8 * 32 位 = 256 位）或 4 个双精度浮点数（4 * 64 位 = 256 位）。\n2.2. Vector Instructions 向量指令是专门用来操作向量寄存器中数据的指令。这些指令通常与标量指令功能对应，但作用于整个向量。\n算术运算：向量加、减、乘、除。\n逻辑运算：向量与、或、异或。\n数据加载/存储：将内存中的连续数据块加载到向量寄存器，或将寄存器中的数据存回内存。\n数据重排 (Shuffle/Permute)：在向量寄存器内部重新排列数据元素，这是许多高级算法优化的关键。\n3. SIMD Programming Models 实际编程中，主要通过两种凡是来利用 SIMD：自动向量化和手动向量化。\n3.1 Automatic Vectorization Automatic Vectorization (自动向量化) 是指编译器自动分析代码（通常是循环），并将其转换为 SIMD 指令的过程。这是最简单、最直接的优化方式。\n要让编译器成功进行自动向量化，代码需要满足一些条件：\n循环结构简单: 循环体内部没有复杂的分支判断。\n无数据依赖: 循环的每次迭代之间没有依赖关系。例如，a[i] = a[i-1] + 1 这样的代码就存在数据依赖，无法被直接向量化。\n内存访问连续: 对数组的访问是连续的，例如 row-major order (行主序) 访问。\n一个能被自动向量化的简单例子：\n1 2 3 4 5 6 7 void vector_add(float* a, float* b, float* c, int n) { for (int i = 0; i \u0026lt; n; ++i) { // 每次迭代之间没有数据依赖 // 内存访问也是连续的 c[i] = a[i] + b[i]; } } 现代的编译器（比如 Clang, GCC）在开启优化选项时会默认尝试自动向量化。\n3.2 Manual Vectorization with Intrinsics 当自动向量化不能满足性能要求，或者循环逻辑太复杂导致编译器无法分析时，就需要进行手动向量化。最常用的方法是使用 Intrinsics (内建函数)。\nIntrinsics 是编译器提供的、与特定汇编指令一一对应的函数。我们可以和调用普通函数一样使用，而编译器会直接将其翻译成对应的 SIMD 指令。\n这种方式的优点是：\n可以精准控制使用哪条 SIMD 指令，实现最大程度的优化。 可以实现自动向量化无法完成的复杂逻辑。 缺点是：\n代码可移植性差，和特定的架构强相关，基于特定 ISA 编写的代码不能在不支持该指令集的 CPU 上运行（除非使用 qemu ）。 需要学习特定指令集对应的函数，非常繁琐。 3.3 An Example 可以通过一个实例来对比普通实现和使用 AVX Intrinsics 的手动向量化实现。\n普通实现：\n1 2 3 4 5 6 // 传统的标量实现 void scalar_add(float* a, float* b, float* c, int n) { for (int i = 0; i \u0026lt; n; ++i) { c[i] = a[i] + b[i]; } } 手动向量化：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 // 引入AVX头文件 #include \u0026lt;immintrin.h\u0026gt; void avx_add(float* a, float* b, float* c, int n) { // 假设 n 是8的倍数，便于演示 for (int i = 0; i \u0026lt; n; i += 8) { // 1. 从内存加载8个浮点数到 YMM 寄存器 __m256 vec_a = _mm256_load_ps(\u0026amp;a[i]); __m256 vec_b = _mm256_load_ps(\u0026amp;b[i]); // 2. 执行向量加法，一条指令完成8个浮点数相加 __m256 vec_c = _mm256_add_ps(vec_a, vec_b); // 3. 将计算结果从 YMM 寄存器存回内存 _mm256_store_ps(\u0026amp;c[i], vec_c); } } __m256 是 AVX 中的数据类型，代表一个 256 位的向量。 _mm256_load_ps 从内存加载数据到向量寄存器。 _mm256_add_ps 执行单精度浮点数的向量加法。 _mm256_store_ps 将结果存回内存。 通过这种方式，循环迭代次数减少为原来的 1/8，并且每次迭代处理的数据量是原来的 8 倍，理论上性能提升巨大，但是由于这个入水平有限，写的 benchmark 没打过编译器自动优化✋😭🤚可能需要复杂一点的任务才能明显体现性能的优越性。\nSummary SIMD 是一种利用 Data Parallelism (数据并行) 提升性能的关键技术。\n其核心是通过 Vector Registers (向量寄存器) 和 Vector Instructions (向量指令)，实现单指令处理多数据的目标。\nAutomatic Vectorization (自动向量化) 是最便捷的 SIMD 优化方法，依赖于编译器的能力。\n当需要极致性能和精确控制时，可以使用 Intrinsics (内建函数) 进行手动向量化。\nReferences 向量化 - HPC入门指南 lect19 - NJU OS 2025 ","permalink":"https://diefish1024.github.io/posts/hpc/simd-%E5%85%A5%E9%97%A8/","summary":"\u003ch2 id=\"1-what-is-simd\"\u003e1. What is SIMD?\u003c/h2\u003e\n\u003cp\u003eSIMD，即 \u003cstrong\u003eSingle Instruction Multiple Data\u003c/strong\u003e ，是一种并行计算的模式。传统的单指令单数据模型，也就是一条指令 CPU 只能处理一份数据，这在科学计算和图像渲染等大量数据密集的任务中是非常低效的。\u003c/p\u003e\n\u003cp\u003eSIMD 的核心思想是\u003cstrong\u003e用一条指令同时对多个数据进行操作\u003c/strong\u003e，现代的 CPU 为此设计了特殊的硬件单元，包括宽位（比如 128、256 或 512 位）的\u003cstrong\u003e向量寄存器 (Vector Registers)\u003c/strong\u003e 和能够操作这些寄存器的\u003cstrong\u003e向量指令 (Vector Instructions)\u003c/strong\u003e。一个向量操作可以同时完成多个标量操作，从而实现\u003cstrong\u003e数据并行 (Data Parallelism)\u003c/strong\u003e，提高效率。假设一个 256 位的向量寄存器可以容纳 8 个 32 位浮点数，一条向量加法指令就可以一次性完成 8 个浮点数的加法，理论上将这部分计算的吞吐量提升至原来的 8 倍；并且相比于执行 8 条独立的标量加法指令，CPU 只需要获取并解码一条向量加法指令，这降低了指令流水线的压力。\u003c/p\u003e\n\u003ch2 id=\"2-how-simd-works\"\u003e2. How SIMD Works\u003c/h2\u003e\n\u003cp\u003e要理解 SIMD 的工作原理，需要了解两个核心概念：向量寄存器和向量指令。\u003c/p\u003e\n\u003ch3 id=\"21-vector-registers\"\u003e2.1. Vector Registers\u003c/h3\u003e\n\u003cp\u003e向量寄存器是 CPU 内部的特殊存储单元，其宽度远大于通用寄存器。不同的 \u003cstrong\u003eInstruction Set Architecture (ISA, 指令集架构)\u003c/strong\u003e 提供了不同宽度和名称的向量寄存器。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eSSE (Streaming SIMD Extensions)\u003c/strong\u003e：提供了 128 位的 \u003ccode\u003eXMM\u003c/code\u003e 寄存器。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eAVX (Advanced Vector Extensions)\u003c/strong\u003e：提供了 256 位的 \u003ccode\u003eYMM\u003c/code\u003e 寄存器。\u003c/p\u003e","title":"SIMD 入门"},{"content":"针对 CUMCM-2025 开始学习 COPT 求解器的使用，学习如何应用 COPT 的 Python API (coptpy) 来建模并求解数学建模中常见的离散优化问题。\nBasic API 本节将介绍 COPT 求解器 Python API (coptpy) 的核心组件和常用方法。\nEnvr Class Envr 类用于创建一个 COPT 环境。它是所有模型操作的起点。\nCreating Environment and Model:\n1 2 3 4 5 import coptpy as cp from coptpy import COPT env = cp.Envr() # 创建一个 COPT 环境实例 model = env.createModel(name=\u0026#39;YourModelName\u0026#39;) # 在环境中创建一个模型 name：模型的名称，此为可选参数。 Model Class Properties and Methods Model 类是 COPT 的核心，代表了优化模型，包含了所有变量、约束和目标函数。\nBasic Properties 在模型求解后，可以通过以下属性获取其基本信息：\nmodel.status：模型解的状态。此属性指示模型是否找到了最优解、无可行解等。例如，COPT.OPTIMAL 表示已找到最优解。 model.objval：目标函数值。此属性存储模型的最优目标函数值。 Adding Variables 可以通过 addVar() 和 addVars() 方法向模型中添加决策变量。\nAdding a Single Variable:\n使用 model.addVar() 方法向模型中添加一个单独的决策变量。\n1 x = model.addVar(lb=0.0, ub=cp.COPT.INFINITY, vtype=cp.COPT.CONTINUOUS, name=\u0026#39;x_var\u0026#39;) lb：变量的下界（默认为 $ 0.0 $）。 ub：变量的上界（默认为 COPT.INFINITY，表示正无穷）。 vtype：变量的类型，可以是： cp.COPT.CONTINUOUS (连续变量) cp.COPT.INTEGER (整数变量) cp.COPT.BINARY (二进制变量，即 $ 0 $ 或 $ 1 $) name：变量的名称。 Adding Multiple Variables:\n使用 model.addVars() 方法一次性添加一组变量。该方法返回一个 tupledict 对象，其键为变量的下标，值为相应的 Var 对象。\n1 model.addVars(*indices, lb=0.0, ub=cp.COPT.INFINITY, obj=0.0, vtype=cp.COPT.CONTINUOUS, nameprefix=\u0026#34;\u0026#34;) *indices：用于定义变量下标的参数。 lb/ub/vtype：含义与 addVar 相同。 obj：变量在目标函数中的系数，默认为 $ 0.0 $。 nameprefix：变量名称的前缀。 Form 1: Using Integer Parameters to Define Dimensions:\n这将创建一个具有给定维度和连续整数下标的变量组。\n1 2 3 4 # 添加一个 2x3 的整数变量 x，共计 6 个变量，下标从 (0,0) 到 (1,2) x = model.addVars(2, 3, vtype=COPT.INTEGER, nameprefix=\u0026#39;x\u0026#39;) print(x.select()) 输出：\n1 [\u0026lt;coptpy.Var: x(0,0)\u0026gt;, \u0026lt;coptpy.Var: x(0,1)\u0026gt;, \u0026lt;coptpy.Var: x(0,2)\u0026gt;, \u0026lt;coptpy.Var: x(1,0)\u0026gt;, \u0026lt;coptpy.Var: x(1,1)\u0026gt;, \u0026lt;coptpy.Var: x(1,2)\u0026gt;] 可以通过下标访问这些变量：\n1 2 3 for i in range(2): for j in range(3): print(x[i,j].name, end=\u0026#39; \u0026#39;) 输出：\n1 x(0,0) x(0,1) x(0,2) x(1,0) x(1,1) x(1,2) 可以看到 $ x $ 实际上是一个 tupledict 对象，其键是变量下标（如 (0,0)），值是 Var 对象。\nForm 2: Using tuplelist for Non-contiguous Indices:\n当变量下标不是连续整数时，可以使用 coptpy.tuplelist 来明确指定需要创建的变量。\n1 2 3 4 t = cp.tuplelist([(0, 1), (1, 2)]) x = model.addVars(t, nameprefix=\u0026#34;t\u0026#34;) print(x.select()) 输出：\n1 [\u0026lt;coptpy.Var: t(0,1)\u0026gt;, \u0026lt;coptpy.Var: t(1,2)\u0026gt;] Form 3: Using Multiple Lists for Cartesian Product:\n*indices 可以是多个列表，addVars 会自动生成这些列表的笛卡尔积作为变量的下标。\n1 2 3 4 5 t = [\u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;] # 创建 x[\u0026#39;a\u0026#39;,0,0], x[\u0026#39;a\u0026#39;,0,1], ..., x[\u0026#39;b\u0026#39;,1,2] 等变量 x = model.addVars(t, range(2), range(3)) print(x.select()) 输出：\n1 [\u0026lt;coptpy.Var: C(a,0,0)\u0026gt;, \u0026lt;coptpy.Var: C(a,0,1)\u0026gt;, \u0026lt;coptpy.Var: C(a,0,2)\u0026gt;, \u0026lt;coptpy.Var: C(a,1,0)\u0026gt;, \u0026lt;coptpy.Var: C(a,1,1)\u0026gt;, \u0026lt;coptpy.Var: C(a,1,2)\u0026gt;, \u0026lt;coptpy.Var: C(b,0,0)\u0026gt;, \u0026lt;coptpy.Var: C(b,0,1)\u0026gt;, \u0026lt;coptpy.Var: C(b,0,2)\u0026gt;, \u0026lt;coptpy.Var: C(b,1,0)\u0026gt;, \u0026lt;coptpy.Var: C(b,1,1)\u0026gt;, \u0026lt;coptpy.Var: C(b,1,2)\u0026gt;] 从此示例可以看出，变量的下标也可以是字符串类型。\nAdding Constraints 可以通过 addConstr() 和 addConstrs() 方法向模型中添加约束。\nAdding a Single Constraint:\n使用 model.addConstr() 添加一个约束。\n1 model.addConstr(lhs, sense=None, rhs=None, name=\u0026#34;\u0026#34;) lhs：约束的左侧表达式。对于线性约束，可以是 Var 对象、LinExpr 对象或 ConstrBuilder 对象。 sense：约束的类型，可以是： cp.COPT.LESS_EQUAL (\u0026lt;=) cp.COPT.EQUAL (==) cp.COPT.GREATER_EQUAL (\u0026gt;=) rhs：约束的右侧值。 name：约束的名称。 例子：\n1 2 3 # 假设 x 和 y 都是模型中的变量 # 添加一个线性约束 x + y \u0026lt;= 10 model.addConstr(x + y \u0026lt;= 10, name=\u0026#34;total_limit\u0026#34;) Adding Multiple Constraints:\n使用 model.addConstrs() 方法添加一组类似的约束，通常通过生成器表达式来完成。\n1 2 3 # 假设 x 和 y 是通过 addVars 生成的变量组 # 添加 10 个线性约束，每个约束形如：x[i] + y[i] \u0026gt;= 2.0 model.addConstrs(x[i] + y[i] \u0026gt;= 2.0 for i in range(10), nameprefix=\u0026#34;pairwise_sum\u0026#34;) nameprefix：约束名称的前缀，COPT 会自动在其后添加下标。 Adding Indicator Constraints:\n指示约束是一种特殊类型的约束，它在一个二值变量取特定值时激活一个线性约束。\n1 model.addGenConstrIndicator(binvar, binval, lhs, sense=None, rhs=None) binvar：作为指示器功能的二进制变量。 binval：binvar 的目标值（True 或 False / $ 1 $ 或 $ 0 $），当 binvar 取此值时，线性约束被激活。 lhs/sense/rhs：定义被激活的线性约束（与 addConstr 类似）。 例子：\n1 2 3 # 假设 x 是一个二进制变量，y 和 z 是模型中的变量 # 添加一个 Indicator 约束：当 x 为 True (即 x=1) 时，线性约束 y + 2*z \u0026gt;= 3 成立 model.addGenConstrIndicator(x, True, y + 2*z \u0026gt;= 3, name=\u0026#34;indicator_constr\u0026#34;) Setting the Objective Function 使用 model.setObjective() 方法定义模型的优化目标。\n1 model.setObjective(expr, sense=None) expr：目标函数表达式，通常是一个 LinExpr 对象。 sense：目标的优化方向，可以是 cp.COPT.MAXIMIZE 或 cp.COPT.MINIMIZE。 例子：\n1 2 # 假设 profit 是一个线性表达式 model.setObjective(profit, COPT.MAXIMIZE) Retrieving Model Information 以下方法用于获取模型求解后的各种信息。\nGetting All Variables:\n1 vars = model.getVars() 返回一个 VarArray 对象，包含模型中的所有变量。 Getting LP Analysis Results:\n1 values, slacks, duals, redcosts = model.getLpSolution() 仅适用于线性规划 (LP) 模型。 返回一个四元组，其中每个元素都是一个列表： values：变量的取值。 slacks：松弛变量的取值。 duals：约束的对偶变量取值。 redcosts：变量的 Reduced Cost。 Getting Specific Model Information:\n1 model.getInfo(infoname, args) infoname：待获取信息的名称（如 COPT.Info.VarPrimal 获取变量值，COPT.Info.ConDual 获取对偶值等）。 args：指定要获取信息的变量或约束。 若 args 为单个 Var 或 Constraint 对象，则返回其信息值常量。 若 args 为列表、VarArray 或 ConstrArray 对象，则返回信息值组成的列表。 若 args 为字典或 tupledict 对象，则返回键为指定变量/约束的下标，值为其信息值的 tupledict 对象。 Cloning a Model 1 mcopy = model.clone() 创建模型的深拷贝，mcopy 是一个与原模型独立的新模型实例。 Var Class Var 类表示模型中的一个单独决策变量。\nAttributes 在模型求解后，可以通过以下属性获取变量的相应信息。\nvar.x 或 var.Value：变量的当前取值。 var.name：变量的名称。 var.Slack：松弛变量的取值（对于约束，此属性在变量层面通常不直接使用）。 var.Dual：对偶变量的取值（与约束的对偶值相关，在变量层面通常不直接使用）。 var.LB：变量的下界。 var.UB：变量的上界。 Methods varname = v.getName()：获取变量 v 的名称。 v.setName('new_name')：设置变量 v 的名称。 x.remove()：从模型中删除变量 x。 VarArray Class VarArray 类是一个特殊的容器，用于存储一组 Var 对象。例如，model.getVars() 的返回值就是 VarArray 类型。\nMethods var = vararr.getVar(idx)：根据变量在 VarArray 对象中的下标获取相应的变量，返回一个 Var 对象。 varall = vararr.getAll()：获取 VarArray 对象中的所有变量，返回一个列表。 arrsize = vararr.getSize()：获取 vararr 中变量的个数。 Important Data Structures coptpy 库提供了一些特殊的数据结构，以方便处理变量和约束的集合，特别是多维情况。\nmultidict multidict 函数可以将输入字典拆分为多个平行字典。当有一个字典，其值是列表或元组，并且希望将每个子元素作为单独的字典时，它非常有用。\n1 2 3 4 5 6 7 8 9 10 11 import coptpy as cp # 将输入的字典对象拆分为键与多个字典对象并返回 keys, dict1, dict2 = cp.multidict({ \u0026#34;hello\u0026#34;: [0, 1], \u0026#34;world\u0026#34;: [2, 3] }) print(f\u0026#34;keys: {keys}\u0026#34;) print(f\u0026#34;dict1: {dict1}\u0026#34;) print(f\u0026#34;dict2: {dict2}\u0026#34;) 输出：\n1 2 3 keys: [\u0026#39;hello\u0026#39;, \u0026#39;world\u0026#39;] dict1: {\u0026#39;hello\u0026#39;: 0, \u0026#39;world\u0026#39;: 2} dict2: {\u0026#39;hello\u0026#39;: 1, \u0026#39;world\u0026#39;: 3} multidict 返回一个元组，第一个元素是原始字典的所有键组成的列表，随后的元素是根据原始字典值中对应位置元素生成的字典。\ntupledict tupledict 是 Python 内置 dict 的子类，专为使用元组作为键的字典进行了优化。它继承了 dict 的所有方法，并额外提供了 select、sum 和 prod 等方便的集合操作。model.addVars() 的返回值就是一个 tupledict。\nCreating a tupledict:\n1 2 d = cp.tupledict([((1,1),\u0026#39;a\u0026#39;), ((1,2),\u0026#39;b\u0026#39;),((2,1),\u0026#39;c\u0026#39;),((2,2),\u0026#39;d\u0026#39;)]) print(d) 输出：\n1 {(1, 1): \u0026#39;a\u0026#39;, (1, 2): \u0026#39;b\u0026#39;, (2, 1): \u0026#39;c\u0026#39;, (2, 2): \u0026#39;d\u0026#39;} 可以使用下标访问 tupledict 中的元素，如同访问普通字典一样：\n1 2 3 for i in range(1, 3): for j in range(1, 3): print(d[i,j], end=\u0026#39; \u0026#39;) 输出：\n1 a b c d select Method:\ntupledict.select(pattern) 方法根据指定的模式筛选出符合条件的项，返回包含所有符合条件的值的列表。pattern 中的 * 代表通配符。注意，pattern 匹配的是 tupledict 的键。\n1 2 3 4 5 d = cp.tupledict([((1,1),\u0026#39;a\u0026#39;), ((1,2),\u0026#39;b\u0026#39;),((2,1),\u0026#39;c\u0026#39;),((2,2),\u0026#39;d\u0026#39;)]) print(d.select(2,\u0026#39;*\u0026#39;)) # 筛选第一个键为 2 的项 print(d.select(1,2)) # 筛选精确键为 (1,2) 的项 print(d.select()) # 筛选所有项 输出：\n1 2 3 [\u0026#39;c\u0026#39;, \u0026#39;d\u0026#39;] [\u0026#39;b\u0026#39;] [\u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;, \u0026#39;c\u0026#39;, \u0026#39;d\u0026#39;] sum Method:\nexpr = tupledict.sum(pattern) 方法根据指定的模式筛选并累加项，返回一个 LinExpr 对象（如果 tupledict 中的值是数字）。这里的 pattern 用法与 select 方法完全相同。\n1 2 d = cp.tupledict([((1,1),1), ((1,2),2),((2,1),3),((2,2),4)]) print(d.sum(\u0026#39;*\u0026#39;, 2)) # 匹配第二个键为 2 的项，即 d[(1,2)] 和 d[(2,2)]，并求和 输出：\n1 6.0 prod Method:\nexpr = d.prod(coeff, pattern) 方法根据指定的模式筛选，并与乘积系数累乘项，返回一个 LinExpr 对象。coeff 是一个字典或 tupledict 类型，其键需要与 d 的键对应。pattern 的含义与 select 相同。本质上，prod 方法执行的是点积操作。\n1 2 3 4 5 6 d = cp.tupledict([((1,1),1), ((1,2),2),((2,1),3),((2,2),4)]) coef = cp.tupledict([((1,1),2), ((1,2),2),((2,1),3),((2,2),3)]) # 匹配第二个键为 2 的项，即 d[(1,2)] 和 d[(2,2)] # 计算 (d[(1,2)] * coeff[(1,2)]) + (d[(2,2)] * coeff[(2,2)]) # 即 (2 * 2) + (4 * 3) = 4 + 12 = 16 print(d.prod(coef, \u0026#39;*\u0026#39;, 2)) 输出：\n1 16.0 tuplelist tuplelist 是 Python 内置 list 的子类，专门用于存储元组列表。它继承了 list 的所有方法，并增强了 select 和 add 等功能。\nCreating a tuplelist:\n1 2 3 4 5 tl1 = cp.tuplelist([(0, 1), (1, 2)]) tl2 = cp.tuplelist([(\u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;), (\u0026#39;b\u0026#39;, \u0026#39;c\u0026#39;)]) print(tl1) print(tl2) 输出：\n1 2 [(0, 1), (1, 2)] [(\u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;), (\u0026#39;b\u0026#39;, \u0026#39;c\u0026#39;)] 可以直接用索引访问列表的成员。\nadd Method:\ntl.add((2, 3)) 方法用于向 tuplelist 中添加成员，功能类似于 list.append()。\n1 2 3 tl = cp.tuplelist([(0, 1), (1, 2)]) tl.add((2, 3)) print(tl) 输出：\n1 [(0, 1), (1, 2), (2, 3)] select Method:\nselect 方法的思想与 tupledict 中的 select 相同，根据指定的模式筛选符合条件的元组。\n1 2 tl = cp.tuplelist([(0, 1), (1, 2)]) print(tl.select(0,\u0026#39;*\u0026#39;)) # 筛选第一个元素为 0 的元组 输出：\n1 [(0, 1)] Mixed-Integer Programming (MIP) 离散优化的核心工具是混合整数规划 (Mixed-Integer Programming, MIP)。一个标准的 MIP 模型包含三个核心要素：\n决策变量 (Decision Variables)：模型中需要求解的未知数。在离散优化中，这些变量通常被约束为整数（例如，工人数、产品件数）或 0-1 二进制变量（例如，某个决策是否执行）。\n目标函数 (Objective Function)：一个关于决策变量的线性表达式，我们需要将其最大化（如利润、效率）或最小化（如成本、距离）。\n约束条件 (Constraints)：一系列关于决策变量的线性等式或不等式，用于定义问题的可行域。\n我们的任务就是将一个具体问题用这三个要素清晰地表达出来，然后交给 COPT 进行求解。\n0-1 Knapsack Problem 对于 0-1 背包问题，定义 $ N $ 为物品总数，$ w_{i},v_{i} $ 分别为物品 $ i $ 的重量和价值，$ C $ 为背包的容量。那么就可以列出这个问题的三个要素：\n决策变量：定义二进制串 $ x_{i} $ 表示是否选取。 $$ x_i \\in \\{0, 1\\}, \\quad \\forall i \\in \\{1, ..., N\\} $$ 目标函数：最大化背包内物品的总价值。 $$ \\max \\sum_{i=1}^{N} v_i x_i $$ 约束条件：装入背包的物品总重量不能超过背包容量。 $$ \\text{s.t.} \\quad \\sum_{i=1}^{N} w_i x_i \\leq C $$ 那么就可以得到 COPT 的求解代码： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 import coptpy as cp from coptpy import COPT # 1. 创建环境和模型 env = cp.Envr() model = env.createModel(\u0026#34;Knapsack\u0026#34;) # 2. 定义数据 weights = [4, 5, 2, 6, 3] # 重量 values = [10, 12, 5, 15, 7] # 价值 capacity = 12 # 背包容量 n = len(weights) # 3. 创建决策变量 # x[i] = 1 if item i is selected, 0 otherwise x = model.addVars(n, vtype=COPT.BINARY, nameprefix=\u0026#34;x\u0026#34;) # 4. 设置目标函数 model.setObjective(cp.quicksum(values[i] * x[i] for i in range(n)), COPT.MAXIMIZE) # 5. 添加约束条件 model.addConstr(cp.quicksum(weights[i] * x[i] for i in range(n)) \u0026lt;= capacity) # 6. 求解模型 model.solve() # 7. 打印结果 if model.status == COPT.OPTIMAL: print(\u0026#34;Optimal solution found.\u0026#34;) print(f\u0026#34;Total value: {model.objval:.2f}\u0026#34;) selected_items = [i for i in range(n) if x[i].x \u0026gt; 0.5] print(f\u0026#34;Selected items (indices): {selected_items}\u0026#34;) else: print(\u0026#34;No optimal solution found.\u0026#34;) Traveling Salesperson Problem (TSP) 旅行商问题。给定一系列城市和每对城市之间的距离，求解访问每一座城市一次并最终回到起始城市的最短可能路径。此问题的一个经典 MIP 模型是 Miller-Tucker-Zemlin (MTZ) 公式。\n定义 $ N $ 为城市总数量，$ d_{i,j} $ 为城市 $ i $ 到城市 $ j $ 的距离，那么可以得到：\n决策变量： 二进制变量 $ x_{i,j} $ ，表示是否经过 $ i $ 到 $ j $ 之间路径。 $$ x_{ij} \\in \\{0, 1\\}, \\quad \\forall i, j \\in \\{0, ..., N-1\\}, i \\neq j $$ 辅助连续变量 $ u_{i} $ 用于消除子回路 $$ u_i \\ge 0, \\quad \\forall i \\in \\{0, ..., N-1\\} $$ 目标函数：最小化总路程。 $$ \\min \\sum_{i=0}^{N-1} \\sum_{j=0, j\\neq i}^{N-1} d_{i,j} x_{i,j} $$ 约束条件： 每个城市必须且只能进入一次。 $$ \\sum_{i=0, i\\neq j}^{N-1} x_{i,j} = 1, \\quad \\forall j \\in \\{0, ..., N-1\\} $$ 每个城市必须且只能离开一次。 $$ \\sum_{j=0, j\\neq i}^{N-1} x_{ij} = 1, \\quad \\forall i \\in \\{0, ..., N-1\\} $$ 消除子回路约束。 $$ u_i - u_j + N \\cdot x_{ij} \\le N-1, \\quad \\forall i, j \\in \\{1, ..., N-1\\}, i \\neq j $$ 那么就可以得到代码： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 import coptpy as cp from coptpy import COPT import random # 1. 创建环境和模型 env = cp.Envr() model = env.createModel(\u0026#34;TSP\u0026#34;) # 2. 定义数据 n_cities = 10 # 生成随机城市坐标 coords = {i: (random.randint(0, 100), random.randint(0, 100)) for i in range(n_cities)} # 计算距离矩阵 distances = {(i, j): ((coords[i][0] - coords[j][0])**2 + (coords[i][1] - coords[j][1])**2)**0.5 for i in range(n_cities) for j in range(n_cities) if i != j} # 3. 创建决策变量 # x[i, j] = 1 if path from city i to j is taken, 0 otherwise x = model.addVars(distances.keys(), vtype=COPT.BINARY, nameprefix=\u0026#34;x\u0026#34;) # 辅助变量用于消除子回路 u = model.addVars(n_cities, vtype=COPT.CONTINUOUS, nameprefix=\u0026#34;u\u0026#34;) # 4. 设置目标函数 model.setObjective(x.prod(distances), COPT.MINIMIZE) # 5. 添加约束条件 # 每个城市必须离开一次 model.addConstrs((cp.quicksum(x[i, j] for j in range(n_cities) if i != j) == 1 for i in range(n_cities)), nameprefix=\u0026#34;leave\u0026#34;) # 每个城市必须进入一次 model.addConstrs((cp.quicksum(x[i, j] for i in range(n_cities) if i != j) == 1 for j in range(n_cities)), nameprefix=\u0026#34;enter\u0026#34;) # 消除子回路 (MTZ) model.addConstrs((u[i] - u[j] + n_cities * x[i, j] \u0026lt;= n_cities - 1 for i in range(1, n_cities) for j in range(1, n_cities) if i != j), nameprefix=\u0026#34;subtour\u0026#34;) # 6. 求解模型 # 为复杂问题设置时间限制 model.setParam(COPT.Param.TimeLimit, 60) model.solve() # 7. 打印结果 if model.status == COPT.OPTIMAL: print(f\u0026#34;Optimal solution found with total distance: {model.objval:.2f}\u0026#34;) path = [] current_city = 0 while len(path) \u0026lt; n_cities: path.append(current_city) for j in range(n_cities): if current_city != j and x[current_city, j].x \u0026gt; 0.5: current_city = j break print(f\u0026#34;Path: {path}\u0026#34;) 其余问题方法均类似，在此不再赘述，总之解决问题的流程就是定义决策变量，构建目标函数，构建约束三步。\nAdvanced Tips 在比赛中需要高效的建模和调试。\nDebugging Infeasible Models 当模型没有可行解时 (model.status == COPT.INFEASIBLE)，意味着约束条件之间存在冲突。找出问题所在非常困难。COPT 提供了不可约不一致子系统 (Irreducible Inconsistent Subsystem, IIS) 工具来定位问题。IIS 是原始模型约束的一个最小子集，其本身是不可行的。\n使用流程：\n首先调用 model.solve() 并确认模型状态为不可行。 调用 model.computeIIS() 来计算 IIS。 遍历模型的约束，通过检查其 IISConstr 属性，找出属于 IIS 的约束。这些约束就是导致模型不可行的元凶。 1 2 3 4 5 6 7 8 9 # (在模型求解后) if model.status == COPT.INFEASIBLE: print(\u0026#34;Model is infeasible. Computing IIS...\u0026#34;) model.computeIIS() print(\u0026#34;The following constraints are in the IIS:\u0026#34;) for constr in model.getConstrs(): if constr.IISConstr: print(f\u0026#34;- {constr.name}\u0026#34;) Parameter Tuning for Performance 对于大规模或复杂的 MIP 问题，默认参数可能无法在有限时间内找到好的解。可以使用 COPT 的参数调优工具 (Tuner) 自动寻找最佳参数组合。\n在 Python 中，可以通过 model.tune() 方法来启动调优器。它会尝试不同的参数设置，并在调优过程结束后，将最优参数应用到模型上。\n1 2 3 4 5 6 7 # 在调用 solve() 之前，可以先调用 tune() print(\u0026#34;Starting parameter tuning...\u0026#34;) model.tune() # 调优后，可以直接求解模型 print(\u0026#34;Tuning finished. Solving with best parameters...\u0026#34;) model.solve() References Python接口 - 杉树求解器用户指南 copt求解器的使用\u0026mdash;-常见api（知乎） ","permalink":"https://diefish1024.github.io/posts/misc/copt-%E6%B1%82%E8%A7%A3%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/","summary":"\u003cp\u003e针对 CUMCM-2025 开始学习 COPT 求解器的使用，学习如何应用 COPT 的 Python API (\u003ccode\u003ecoptpy\u003c/code\u003e) 来建模并求解数学建模中常见的离散优化问题。\u003c/p\u003e\n\u003ch2 id=\"basic-api\"\u003eBasic API\u003c/h2\u003e\n\u003cp\u003e本节将介绍 \u003ccode\u003eCOPT\u003c/code\u003e 求解器 \u003ccode\u003ePython API (coptpy)\u003c/code\u003e 的核心组件和常用方法。\u003c/p\u003e\n\u003ch3 id=\"envr-class\"\u003eEnvr Class\u003c/h3\u003e\n\u003cp\u003e\u003ccode\u003eEnvr\u003c/code\u003e 类用于创建一个 \u003ccode\u003eCOPT\u003c/code\u003e 环境。它是所有模型操作的起点。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eCreating Environment and Model:\u003c/strong\u003e\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cdiv class=\"chroma\"\u003e\n\u003ctable class=\"lntable\"\u003e\u003ctr\u003e\u003ctd class=\"lntd\"\u003e\n\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode\u003e\u003cspan class=\"lnt\"\u003e1\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e2\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e3\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e4\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e5\n\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\n\u003ctd class=\"lntd\"\u003e\n\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-python\" data-lang=\"python\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"nn\"\u003ecoptpy\u003c/span\u003e \u003cspan class=\"k\"\u003eas\u003c/span\u003e \u003cspan class=\"nn\"\u003ecp\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"kn\"\u003efrom\u003c/span\u003e \u003cspan class=\"nn\"\u003ecoptpy\u003c/span\u003e \u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"n\"\u003eCOPT\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003eenv\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003ecp\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eEnvr\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e  \u003cspan class=\"c1\"\u003e# 创建一个 COPT 环境实例\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003emodel\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eenv\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ecreateModel\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ename\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s1\"\u003e\u0026#39;YourModelName\u0026#39;\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e  \u003cspan class=\"c1\"\u003e# 在环境中创建一个模型\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\u003c/tr\u003e\u003c/table\u003e\n\u003c/div\u003e\n\u003c/div\u003e\u003cul\u003e\n\u003cli\u003e\u003ccode\u003ename\u003c/code\u003e：模型的名称，此为可选参数。\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"model-class-properties-and-methods\"\u003eModel Class Properties and Methods\u003c/h3\u003e\n\u003cp\u003e\u003ccode\u003eModel\u003c/code\u003e 类是 \u003ccode\u003eCOPT\u003c/code\u003e 的核心，代表了优化模型，包含了所有变量、约束和目标函数。\u003c/p\u003e\n\u003ch4 id=\"basic-properties\"\u003eBasic Properties\u003c/h4\u003e\n\u003cp\u003e在模型求解后，可以通过以下属性获取其基本信息：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003emodel.status\u003c/code\u003e：\u003cstrong\u003e模型解的状态\u003c/strong\u003e。此属性指示模型是否找到了最优解、无可行解等。例如，\u003ccode\u003eCOPT.OPTIMAL\u003c/code\u003e 表示已找到最优解。\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003emodel.objval\u003c/code\u003e：\u003cstrong\u003e目标函数值\u003c/strong\u003e。此属性存储模型的最优目标函数值。\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4 id=\"adding-variables\"\u003eAdding Variables\u003c/h4\u003e\n\u003cp\u003e可以通过 \u003ccode\u003eaddVar()\u003c/code\u003e 和 \u003ccode\u003eaddVars()\u003c/code\u003e 方法向模型中添加决策变量。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eAdding a Single Variable:\u003c/strong\u003e\u003c/p\u003e","title":"COPT 求解器学习笔记"},{"content":"File Allocation Table 要设计并实现一个文件系统，我们首先需要关注并解决存储媒介带来的两大核心挑战：\n读写放大 (Read/Write Amplification)：现代存储设备（无论是机械硬盘还是固态硬盘）的物理特性决定了，它们最高效的读写方式是操作连续的大块数据区域，我们称之为一个块 (Block)。如果需要修改一个块中哪怕一个字节的数据，也必须将整个块读入内存、修改、再完整写回。这种“操作少量数据却导致整块数据被读写”的现象就是读写放大，它会严重影响性能。\n局部性 (Locality)：程序的内存访问行为通常具有局部性原理 (Principle of Locality)，即在一段时间内，访问的地址会集中在某个区域。文件系统可以通过合理的数据排布，让物理上相邻的数据块在逻辑上也相关联（例如，属于同一个文件），从而在读取一块数据时，可以利用预读机制将后续可能被访问的数据也加载到内存缓存中，提高效率。\n在软盘上实现文件系统 我们的需求是为一个存储容量很小的设备（如软盘）设计一个文件系统。在这种场景下，使用复杂的树形数据结构（如 B+ 树）会因为元数据本身占用过多空间而显得浪费。因此，一个简单的链式结构是更合适的选择。\n目录的实现\n在简单的文件系统中，目录本身可以被实现为一个普通的文件。这个文件的特殊之处在于，它的内容遵循一种固定格式，即一个目录项数组。\n1 2 3 4 5 6 // 一个简单的目录项 (dentry) 结构 struct dentry { char filename[256]; // 文件名 unsigned int start_block; // 文件数据起始块的编号 unsigned int size; // 文件大小 (以字节为单位) }; 当我们需要打开一个目录时，文件系统只需读取这个文件的内容，并将其解析为一个 struct dentry 数组即可。\n文件数据的存储\n用链表来组织一个文件的所有数据块，主要有两种实现思路。\n方法一：在每个数据块后放置指针\n这种方法非常直观。每个数据块的末尾都留出一小块空间，用于存放下一个数据块的地址或编号。\n优点：实现简单，逻辑清晰。\n缺点：\n极差的随机访问性能：要访问文件的第 N 个数据块，必须从第一个块开始，依次读入前 N-1 个块来找到第 N 块的指针。这需要 N-1 次磁盘 I/O，对于大文件而言是毁灭性的。\n空间浪费：每个数据块都不能被 100% 用来存储文件内容，必须牺牲一部分空间给指针。\n方法二：将指针集中存放在文件系统的某个区域\n为了解决上述问题，我们可以将所有数据块的“链表指针”抽离出来，集中存放在一个被称为文件分配表 (File Allocation Table, FAT) 的核心数据结构中。\nFAT 本质上是一个大数组。数组的下标与磁盘上的数据块编号一一对应。数组中存储的值则是该文件链表中的下一个数据块的编号。\n它是如何工作的？\n一个文件的起始块号记录在它的目录项 (dentry) 中。\n假设文件从第 100 号块开始，我们查询 FAT[100]，如果值为 105，那么 105 号块就是文件的第二个数据块。\n接着我们查询 FAT[105]，得到下一个块号，如此往复，直到遇到一个特殊的文件结尾标记。\n优点：\n大幅改善的随机访问：虽然仍然需要遍历链表，但这个遍历过程发生在 FAT 表内部。因为 FAT 表相比整个磁盘要小得多，可以被完整加载到内存中缓存。要访问第 N 个数据块，只需要在内存中进行 N-1 次数组查询，这比 N-1 次磁盘 I/O 快了几个数量级。\n数据块纯净：数据块可以 100% 用于存储文件内容，没有元数据混入。\n写回策略：对文件结构的修改（如新增/删除数据块）可以先在内存中的 FAT 缓存上进行，然后利用延迟写回 (Write-back Caching) 机制，在稍后的某个时刻一次性将更新后的 FAT 表写回磁盘，合并了多次 I/O 操作，提升了性能。\nUnix 文件系统 FAT 文件系统虽然巧妙，但仍有其局限性，无法满足现代操作系统的复杂需求：\n支持链接：我们希望多个文件名可以指向同一个文件实体。\n支持高效的任意大小文件随机访问：对于非常大的文件，在 FAT 表中线性扫描仍然耗时。我们需要一种能实现 O(1) 或 O(logN) 复杂度查找的数据结构。\n为了解决这些问题，Unix 文件系统引入了一个核心概念：inode (索引节点)。\ninode 是一个独立于文件名的元数据结构，它存储了除文件名之外的、关于一个文件的所有信息，例如：\n文件模式（权限位） 所有者和用户组 ID 文件大小 时间戳（创建、修改、访问时间） 用于索引文件数据块的数据结构 inode 的引入将文件名和文件元数据彻底分离。目录项 (dentry) 的作用被简化为只维护 文件名 -\u0026gt; inode 编号 的映射关系。这天然地支持了硬链接 (Hard Link)：多个不同的目录项可以包含相同的 inode 编号，指向同一个文件实体。\n为了解决高效随机访问问题，ext2 文件系统的 inode 采用了一种非常经典的多级索引结构：\n1 2 3 4 5 6 7 8 // ext2 inode 结构示意 struct ext2_inode { // ... 其他元数据 ... unsigned int direct_blocks[12]; // 12个直接指针 unsigned int singly_indirect_block; // 1个一级间接指针 unsigned int doubly_indirect_block; // 1个二级间接指针 unsigned int triply_indirect_block; // 1个三级间接指针 }; 直接指针 (Direct Pointers)： inode 中直接包含 12 个指针，每个指针指向一个数据块。对于小文件（小于 12 个块），只需读取 inode 就可以获得所有数据块的位置，访问速度极快。\n一级间接指针 (Singly Indirect Pointer)： 如果文件大于 12 个块，文件系统会启用这个指针。它指向一个“指针块”，这个块里不存数据，而是存满了指向数据块的指针。假设一个块能存 1024 个指针，这一级就能多索引 1024 个数据块。\n二级/三级间接指针 (Doubly/Triply Indirect Pointers)： 以此类推，二级间接指针指向一个存储着一级间接指针块地址的块。这种树状的索引结构，仅需极少的几次磁盘读取（最多 4 次，inode -\u0026gt; 三级 -\u0026gt; 二级 -\u0026gt; 一级 -\u0026gt; 数据块），就能定位超大文件中任意一个数据块的位置，实现了真正高效的随机访问 (Random Access)。\n存储器上的数据结构 传统上，文件系统的所有逻辑都实现在操作系统的内核 (Kernel) 中，因为它需要直接管理硬件并保证系统安全与性能。\n然而，现代操作系统提供了一些机制，允许在用户空间 (User Space) 实现文件系统，最著名的就是 FUSE (Filesystem in Userspace)。\nFUSE 的工作原理是，内核提供一个通用的文件系统驱动，当有文件操作请求时，该驱动会将请求转发给一个在用户空间运行的守护进程。这个进程负责实现所有的文件系统逻辑（如何解析路径、读取数据等），然后将结果返回给内核。\n优点：开发、调试和测试变得极为方便，无需修改和重新编译内核。一个用户态文件系统的崩溃也不会影响整个系统的稳定性。这催生了大量创新的文件系统，如 sshfs（将远程服务器目录挂载到本地）、s3fs（将云存储挂载到本地）等。\n缺点：每次文件操作都需要在内核态和用户态之间进行上下文切换 (Context Switch)，带来了额外的性能开销，通常不适用于对性能要求极致的场景。\n","permalink":"https://diefish1024.github.io/posts/class-notes/nju-os-2025/23-%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%9A%84%E5%AE%9E%E7%8E%B0/","summary":"\u003ch2 id=\"file-allocation-table\"\u003eFile Allocation Table\u003c/h2\u003e\n\u003cp\u003e要设计并实现一个文件系统，我们首先需要关注并解决存储媒介带来的两大核心挑战：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e读写放大 (Read/Write Amplification)\u003c/strong\u003e：现代存储设备（无论是机械硬盘还是固态硬盘）的物理特性决定了，它们最高效的读写方式是操作连续的大块数据区域，我们称之为一个\u003cstrong\u003e块 (Block)\u003c/strong\u003e。如果需要修改一个块中哪怕一个字节的数据，也必须将整个块读入内存、修改、再完整写回。这种“操作少量数据却导致整块数据被读写”的现象就是读写放大，它会严重影响性能。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e局部性 (Locality)\u003c/strong\u003e：程序的内存访问行为通常具有\u003cstrong\u003e局部性原理 (Principle of Locality)\u003c/strong\u003e，即在一段时间内，访问的地址会集中在某个区域。文件系统可以通过合理的数据排布，让物理上相邻的数据块在逻辑上也相关联（例如，属于同一个文件），从而在读取一块数据时，可以利用预读机制将后续可能被访问的数据也加载到内存缓存中，提高效率。\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"在软盘上实现文件系统\"\u003e在软盘上实现文件系统\u003c/h3\u003e\n\u003cp\u003e我们的需求是为一个存储容量很小的设备（如软盘）设计一个文件系统。在这种场景下，使用复杂的树形数据结构（如 B+ 树）会因为元数据本身占用过多空间而显得浪费。因此，一个简单的链式结构是更合适的选择。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e目录的实现\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e在简单的文件系统中，目录本身可以被实现为一个普通的文件。这个文件的特殊之处在于，它的内容遵循一种固定格式，即一个目录项数组。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cdiv class=\"chroma\"\u003e\n\u003ctable class=\"lntable\"\u003e\u003ctr\u003e\u003ctd class=\"lntd\"\u003e\n\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode\u003e\u003cspan class=\"lnt\"\u003e1\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e2\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e3\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e4\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e5\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e6\n\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\n\u003ctd class=\"lntd\"\u003e\n\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-c\" data-lang=\"c\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e// 一个简单的目录项 (dentry) 结构\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e\u003c/span\u003e\u003cspan class=\"k\"\u003estruct\u003c/span\u003e \u003cspan class=\"n\"\u003edentry\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"kt\"\u003echar\u003c/span\u003e \u003cspan class=\"n\"\u003efilename\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"mi\"\u003e256\u003c/span\u003e\u003cspan class=\"p\"\u003e];\u003c/span\u003e        \u003cspan class=\"c1\"\u003e// 文件名\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e\u003c/span\u003e    \u003cspan class=\"kt\"\u003eunsigned\u003c/span\u003e \u003cspan class=\"kt\"\u003eint\u003c/span\u003e \u003cspan class=\"n\"\u003estart_block\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e  \u003cspan class=\"c1\"\u003e// 文件数据起始块的编号\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e\u003c/span\u003e    \u003cspan class=\"kt\"\u003eunsigned\u003c/span\u003e \u003cspan class=\"kt\"\u003eint\u003c/span\u003e \u003cspan class=\"n\"\u003esize\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e         \u003cspan class=\"c1\"\u003e// 文件大小 (以字节为单位)\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e\u003c/span\u003e\u003cspan class=\"p\"\u003e};\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\u003c/tr\u003e\u003c/table\u003e\n\u003c/div\u003e\n\u003c/div\u003e\u003cp\u003e当我们需要打开一个目录时，文件系统只需读取这个文件的内容，并将其解析为一个 \u003ccode\u003estruct dentry\u003c/code\u003e 数组即可。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e文件数据的存储\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e用链表来组织一个文件的所有数据块，主要有两种实现思路。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e方法一：在每个数据块后放置指针\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e这种方法非常直观。每个数据块的末尾都留出一小块空间，用于存放下一个数据块的地址或编号。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e优点\u003c/strong\u003e：实现简单，逻辑清晰。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e缺点\u003c/strong\u003e：\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e极差的随机访问性能\u003c/strong\u003e：要访问文件的第 N 个数据块，必须从第一个块开始，依次读入前 N-1 个块来找到第 N 块的指针。这需要 N-1 次磁盘 I/O，对于大文件而言是毁灭性的。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e空间浪费\u003c/strong\u003e：每个数据块都不能被 100% 用来存储文件内容，必须牺牲一部分空间给指针。\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e方法二：将指针集中存放在文件系统的某个区域\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e为了解决上述问题，我们可以将所有数据块的“链表指针”抽离出来，集中存放在一个被称为\u003cstrong\u003e文件分配表 (File Allocation Table, FAT)\u003c/strong\u003e 的核心数据结构中。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eFAT\u003c/strong\u003e 本质上是一个大数组。数组的\u003cstrong\u003e下标\u003c/strong\u003e与磁盘上的数据块编号一一对应。数组中存储的\u003cstrong\u003e值\u003c/strong\u003e则是该文件链表中的\u003cstrong\u003e下一个数据块的编号\u003c/strong\u003e。\u003c/p\u003e","title":"23. 文件系统的实现"},{"content":"1. Why Memory Performance Matters in HPC? 在 HPC 领域，我们常常关注 CPU 的浮点运算能力 (FLOPS)，但真正的性能瓶颈往往不在于计算本身，而在于数据访问。现代 CPU 的计算速度远超于内存的访问速度，这种差距被称为内存墙 (Memory Wall)。程序的大部分时间可能都消耗在等待数据从内存加载到 CPU 寄存器的过程中。因此，优化内存访问模式，最大限度地利用 Cache，是提升 C/C++ 程序性能至关重要的一环。\n2. Memory Alignment 内存对齐是指一个数据对象的内存地址是其自身大小或特定字节数（通常是 2 的幂）的整数倍。例如一个 4 字节的 int 类型变量，如果其内存地址是 4 的倍数（如 0x...00, 0x...04, 0x...08），那么它就是内存对齐的。\n2.2 Why is Alignment Important? CPU 并不是逐字节地从内存中读取数据，而是以块（通常是缓存行 (Cache Line)，例如 64 字节）为单位进行读取。\n性能提升：如果一个数据跨越了两个缓存行，CPU 就需要执行两次内存读取操作才能获取这一个数据，这会浪费一倍的时间。如果数据是对齐的，就可以保证它完整地落在一个缓存行内，CPU 只需一次读取操作。\n硬件要求：许多现代 CPU 指令集，尤其是用于并行计算的 SIMD 指令强制要求操作的数据必须是内存对齐的，对未对齐的数据执行这些指令可能会导致程序崩溃或性能急剧下降。\n2.3 How to Achieve Alignment in C/C++? C++11 alignas：这是 Modern C++ 的标准方式，可以指定变量或类型的对齐要求。 1 2 3 4 5 6 7 8 // 声明一个按 64 字节对齐的数组 alignas(64) float aligned_array[1024]; // 定义一个结构体，使其每个实例都按 32 字节对齐 struct alignas(32) MyData { float a; int b; }; GCC/Clang __attribute__((aligned(N)))：特定于编译器的扩展。 1 2 // 声明一个按 64 字节对齐的数组 float aligned_array[1024] __attribute__((aligned(64))); 动态内存对齐：标准的 malloc 不保证特定的对齐方式（通常只保证基本类型的对齐）。需要使用专用函数。 1 2 3 4 5 6 #include \u0026lt;stdlib.h\u0026gt; // C11 标准 // 分配 1024 个 float，并按 64 字节对齐 float* dynamic_array = (float*)aligned_alloc(64, 1024 * sizeof(float)); free(dynamic_array); // 必须用 free 释放 3. Data Locality 数据局部性是缓存工作的基本原理，也是性能优化的核心。描述了 CPU 访问内存地址的集中程度。\n3.1 Temporal and Spatial Locality 时间局部性 (Temporal Locality)：如果一个数据项被访问，那么在不久的将来它很可能再次被访问。\n空间局部性 (Spatial Locality)：如果一个数据项被访问，那么与它地址相近的数据项很可能在不久的将来被访问。\n当 CPU 访问一个内存地址时，它会将包含该地址的整个缓存行加载到缓存中。充分利用这两个局部性原则，可以极大地提高缓存命中率 (Cache Hit Rate)，减少访问主内存的次数。\n3.2 Optimizing Storage Layout 数据在内存中的布局方式直接影响空间局部性，尤其是在处理大量对象时。\nAoS (Array of Structures)：结构体数组。这是最直观的存储方式。 1 2 3 4 struct Point { float x, y, z; }; Point points[N]; 内存布局：[x0, y0, z0, x1, y1, z1, ...]\n在这种布局下当我们想要访问一个点的坐标时空间局部性较好；然后相对所有点的 x 坐标进行操作时，y 和 z 也会被一同加载到缓存中，污染了缓存，造成性能浪费。\nSoA (Structure of Arrays)：数组结构体。 1 2 3 4 5 6 struct Points { float x[N]; float y[N]; float z[N]; }; Points points; 内存布局：[x0, x1, ..., xN-1, y0, y1, ..., yN-1, ...]\n在这种布局下当我们需要对所有点的 x 坐标进行操作时，因为所有 x 的数据在内存中是连续的，空间局部性好，有利于 SIMD 向量化；然而当需要访问一个点的所有坐标时，需要三次内存访问，导致局部性较差。\n在 HPC 中，大量的计算通常是针对某一特定属性的，因此 SoA 布局往往能带来更好的性能，尤其是在需要向量化优化时。\n3.3 Optimizing Access Patterns 一旦数据在内存中完成布局，程序访问它的顺序就成为影响性能的下一个关键因素。以符合其存储顺序并最大化缓存利用率的方式访问数据，是挖掘数据局部性潜力的基础。\n遍历顺序 (Row-Major Order) C/C++ 中的多维数组默认是行主序 (Row-Major) 存储的。这意味着二维数组 A[M][N] 在内存中是按行连续存放的。\n内存布局: A[0][0], A[0][1], ..., A[0][N-1], A[1][0], ...\n为了保证最佳的空间局部性，内层循环应该遍历最右边的索引。\n高效的访问方式 (cache-firendly)： 1 2 3 4 5 for (int i = 0; i \u0026lt; M; i++) { for (int j = 0; j \u0026lt; N; j++) { A[i][j] = ...; // 访问模式与存储模式一致，顺序访问 } } 低效的访问方式 (cache-disaster)： 1 2 3 4 5 for (int j = 0; j \u0026lt; N; j++) { for (int i = 0; i \u0026lt; M; i++) { A[i][j] = ...; // 跨行跳跃访问，每次访问都可能导致缓存未命中 } } 循环分块 (Loop Tiling / Blocking)\n对于大型矩阵运算（如矩阵乘法），即使访问顺序正确，数据量太大也无法全部装入缓存。循环分块是一种将计算分解为适合缓存大小的子问题的方法，可以同时提升时间和空间局部性。\n未优化的矩阵乘法： 1 2 3 4 5 6 7 8 for (int i = 0; i \u0026lt; N; i++) { for (int j = 0; j \u0026lt; N; j++) { for (int k = 0; k \u0026lt; N; k++) { C[i][j] += A[i][k] * B[k][j]; } } } // B[k][j] 的访问是列访问，效率低下。 使用循环分块优化： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 int block_size = 16; // 块大小需根据缓存大小调整 for (int i0 = 0; i0 \u0026lt; N; i0 += block_size) { for (int j0 = 0; j0 \u0026lt; N; j0 += block_size) { for (int k0 = 0; k0 \u0026lt; N; k0 += block_size) { // 在缓存中计算一个子矩阵块 for (int i = i0; i \u0026lt; i0 + block_size; i++) { for (int j = j0; j \u0026lt; j0 + block_size; j++) { for (int k = k0; k \u0026lt; k0 + block_size; k++) { C[i][j] += A[i][k] * B[k][j]; } } } } } } 通过分块，程序可以把一小块数据加载到缓存中并充分复用，然后再处理下一块，大大提高了缓存命中率。\n4. False Sharing in Parallel Computing 在多核并行编程（如 OpenMP, pthreads）中，一个非常隐蔽的性能杀手是伪共享。\n原理：缓存不仅仅在 CPU 和主存之间工作，还在多个核心之间保持数据一致性 (Coherence)。当一个核心修改了其缓存中的数据，该缓存行会被标记为“dirty”，一致性协议会使其他核心中相同的缓存行失效。\n伪共享：如果两个核心上的线程频繁修改不同的变量，但这些变量碰巧位于同一个缓存行中，那么每次修改都会导致对方的缓存行失效并需要重新从主存加载。这种由不相关的变量共享同一个缓存行而导致的性能下降，就是伪共享。\n1 2 3 4 5 6 7 8 int results[NUM_THREADS]; // 假设 NUM_THREADS=2 #pragma omp parallel { int tid = omp_get_thread_num(); results[tid] = some_calculation(); } // 如果 results[0] 和 results[1] 在同一个缓存行， // 线程 0 修改 results[0] 会使线程 1 的缓存行失效，反之亦然。 解决方案：手动进行内存填充 (Padding)，确保每个线程操作的数据位于不同的缓存行。 1 2 3 4 5 struct PaddedResult { int value; char padding[64 - sizeof(int)]; // 假设缓存行大小为 64 字节 }; PaddedResult results[NUM_THREADS]; Summary 内存对齐是利用硬件特性的基础，确保单次操作的效率和 SIMD 的可行性。\n数据局部性是核心优化思想，通过优化存储布局 (AoS vs SoA) 和访问模式 (遍历顺序、循环分块) 来最大化缓存利用率。\n在并行环境中，必须警惕伪共享等陷阱，通过合理的内存布局避免多核间的性能干扰。\nReferences HPC 中的 C/C++ - HPC 入门指南 ","permalink":"https://diefish1024.github.io/posts/hpc/hpc-%E4%B8%AD%E7%9A%84-c-%E5%92%8C-c/","summary":"\u003ch2 id=\"1-why-memory-performance-matters-in-hpc\"\u003e1. Why Memory Performance Matters in HPC?\u003c/h2\u003e\n\u003cp\u003e在 HPC 领域，我们常常关注 CPU 的浮点运算能力 (FLOPS)，但真正的性能瓶颈往往不在于计算本身，而在于\u003cstrong\u003e数据访问\u003c/strong\u003e。现代 CPU 的计算速度远超于内存的访问速度，这种差距被称为\u003cstrong\u003e内存墙 (Memory Wall)\u003c/strong\u003e。程序的大部分时间可能都消耗在等待数据从内存加载到 CPU 寄存器的过程中。因此，优化内存访问模式，最大限度地利用 Cache，是提升 C/C++ 程序性能至关重要的一环。\u003c/p\u003e\n\u003ch2 id=\"2-memory-alignment\"\u003e2. Memory Alignment\u003c/h2\u003e\n\u003cp\u003e内存对齐是指一个数据对象的内存地址是其自身大小或特定字节数（通常是 2 的幂）的整数倍。例如一个 4 字节的 \u003ccode\u003eint\u003c/code\u003e 类型变量，如果其内存地址是 4 的倍数（如 \u003ccode\u003e0x...00\u003c/code\u003e, \u003ccode\u003e0x...04\u003c/code\u003e, \u003ccode\u003e0x...08\u003c/code\u003e），那么它就是内存对齐的。\u003c/p\u003e\n\u003ch3 id=\"22-why-is-alignment-important\"\u003e2.2 Why is Alignment Important?\u003c/h3\u003e\n\u003cp\u003eCPU 并不是逐字节地从内存中读取数据，而是以块（通常是\u003cstrong\u003e缓存行 (Cache Line)\u003c/strong\u003e，例如 64 字节）为单位进行读取。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e性能提升\u003c/strong\u003e：如果一个数据跨越了两个缓存行，CPU 就需要执行两次内存读取操作才能获取这一个数据，这会浪费一倍的时间。如果数据是对齐的，就可以保证它完整地落在一个缓存行内，CPU 只需一次读取操作。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e硬件要求\u003c/strong\u003e：许多现代 CPU 指令集，尤其是用于并行计算的 \u003cstrong\u003eSIMD\u003c/strong\u003e 指令强制要求操作的数据必须是内存对齐的，对未对齐的数据执行这些指令可能会导致程序崩溃或性能急剧下降。\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"23-how-to-achieve-alignment-in-cc\"\u003e2.3 How to Achieve Alignment in C/C++?\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eC++11 \u003ccode\u003ealignas\u003c/code\u003e\u003c/strong\u003e：这是 Modern C++ 的标准方式，可以指定变量或类型的对齐要求。\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cdiv class=\"chroma\"\u003e\n\u003ctable class=\"lntable\"\u003e\u003ctr\u003e\u003ctd class=\"lntd\"\u003e\n\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode\u003e\u003cspan class=\"lnt\"\u003e1\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e2\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e3\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e4\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e5\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e6\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e7\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e8\n\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\n\u003ctd class=\"lntd\"\u003e\n\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-c++\" data-lang=\"c++\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e// 声明一个按 64 字节对齐的数组\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e\u003c/span\u003e\u003cspan class=\"k\"\u003ealignas\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"mi\"\u003e64\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"kt\"\u003efloat\u003c/span\u003e \u003cspan class=\"n\"\u003ealigned_array\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"mi\"\u003e1024\u003c/span\u003e\u003cspan class=\"p\"\u003e];\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e// 定义一个结构体，使其每个实例都按 32 字节对齐\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e\u003c/span\u003e\u003cspan class=\"k\"\u003estruct\u003c/span\u003e \u003cspan class=\"nf\"\u003ealignas\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"mi\"\u003e32\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"n\"\u003eMyData\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"kt\"\u003efloat\u003c/span\u003e \u003cspan class=\"n\"\u003ea\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"kt\"\u003eint\u003c/span\u003e \u003cspan class=\"n\"\u003eb\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"p\"\u003e};\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\u003c/tr\u003e\u003c/table\u003e\n\u003c/div\u003e\n\u003c/div\u003e\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eGCC/Clang \u003ccode\u003e__attribute__((aligned(N)))\u003c/code\u003e\u003c/strong\u003e：特定于编译器的扩展。\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cdiv class=\"chroma\"\u003e\n\u003ctable class=\"lntable\"\u003e\u003ctr\u003e\u003ctd class=\"lntd\"\u003e\n\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode\u003e\u003cspan class=\"lnt\"\u003e1\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e2\n\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\n\u003ctd class=\"lntd\"\u003e\n\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-c\" data-lang=\"c\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e// 声明一个按 64 字节对齐的数组\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e\u003c/span\u003e\u003cspan class=\"kt\"\u003efloat\u003c/span\u003e \u003cspan class=\"n\"\u003ealigned_array\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"mi\"\u003e1024\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e \u003cspan class=\"nf\"\u003e__attribute__\u003c/span\u003e\u003cspan class=\"p\"\u003e((\u003c/span\u003e\u003cspan class=\"nf\"\u003ealigned\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"mi\"\u003e64\u003c/span\u003e\u003cspan class=\"p\"\u003e)));\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\u003c/tr\u003e\u003c/table\u003e\n\u003c/div\u003e\n\u003c/div\u003e\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e动态内存对齐\u003c/strong\u003e：标准的 \u003ccode\u003emalloc\u003c/code\u003e 不保证特定的对齐方式（通常只保证基本类型的对齐）。需要使用专用函数。\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cdiv class=\"chroma\"\u003e\n\u003ctable class=\"lntable\"\u003e\u003ctr\u003e\u003ctd class=\"lntd\"\u003e\n\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode\u003e\u003cspan class=\"lnt\"\u003e1\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e2\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e3\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e4\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e5\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e6\n\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\n\u003ctd class=\"lntd\"\u003e\n\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-c\" data-lang=\"c\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"cp\"\u003e#include\u003c/span\u003e \u003cspan class=\"cpf\"\u003e\u0026lt;stdlib.h\u0026gt;\u003c/span\u003e\u003cspan class=\"cp\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"cp\"\u003e\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e// C11 标准\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e// 分配 1024 个 float，并按 64 字节对齐\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e\u003c/span\u003e\u003cspan class=\"kt\"\u003efloat\u003c/span\u003e\u003cspan class=\"o\"\u003e*\u003c/span\u003e \u003cspan class=\"n\"\u003edynamic_array\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"kt\"\u003efloat\u003c/span\u003e\u003cspan class=\"o\"\u003e*\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\u003cspan class=\"nf\"\u003ealigned_alloc\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"mi\"\u003e64\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"mi\"\u003e1024\u003c/span\u003e \u003cspan class=\"o\"\u003e*\u003c/span\u003e \u003cspan class=\"k\"\u003esizeof\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"kt\"\u003efloat\u003c/span\u003e\u003cspan class=\"p\"\u003e));\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"nf\"\u003efree\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003edynamic_array\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e \u003cspan class=\"c1\"\u003e// 必须用 free 释放\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\u003c/tr\u003e\u003c/table\u003e\n\u003c/div\u003e\n\u003c/div\u003e\u003ch2 id=\"3-data-locality\"\u003e3. Data Locality\u003c/h2\u003e\n\u003cp\u003e数据局部性是缓存工作的基本原理，也是性能优化的核心。描述了 CPU 访问内存地址的集中程度。\u003c/p\u003e","title":"HPC 中的 C 和 C++"},{"content":"Abstract 现有 TTA 方法在处理图数据时，对节点属性偏移有效，但是对图结构偏移（同质性、节点度的变化）效果很差。原因是结构偏移会严重破坏节点表示的质量，使不同类别的节点在特征空间中混在一起。为此论文提出了 Matcha 框架，通过在测试的时候自适应地调整 GNN 的“跳数聚合参数 (hop-aggregation parameters)”，并且引入了新的预测感知的聚类损失函数来表示恢复节点表示的质量，从而有效应对结构偏移，并能和现有 TTA 方法相结合，进一步提高性能。\nIntroduction GNN 的脆弱性：GNNs 在各类图任务上的表现依赖于训练数据和测试数据分布相同的假设，然而在现实世界中，图的分布常常会发生变化（分布偏移），分为：\n属性偏移 (Attribute Shift)：节点的特征发生变化。例如不同社交平台，即使用户一样，其账号的内容也会因为平台差异而不同。\n结构偏移 (Structure Shift)：节点的连接方式发生变化。比如工作平台用户倾向于连接同事，生活平台用户倾向于连接家人朋友。这种连接模式的变化就是结构偏移，具体表现为同质性 (Homophily) 和 节点度 (Degree) 的变化。\nTTA 的局限性：TTA 允许一个预训练好的模型在不访问原始训练数据的情况下，利用无标签的测试数据进行自适应调整 。目前 TTA 在计算机视觉领域处理图像损坏、风格变化等属性偏移问题上很成功 。然而为图像处理设计的 TTA 方法直接应用到图上时，其在处理图结构偏移时的性能提升非常有限，几乎失效。\nAnalysis 两种偏移方式对 GNN 的影响存在本质不同。\nPerliminaries 论文聚焦于 GTTA 任务。一个 GNN 模型可以被看成两个部分的组合，一个特征提取器 $ f_{S} $ ，一个分类器 $ g_{S} $ ，通常是一个线性层。\n两种偏移的正式定义：\n属性偏移：源图和目标图中，节点的条件概率分布不同 $ \\mathbb{P}^{S}_{x | y} \\neq \\mathbb{P}^{T}_{x | y} $ 。 结构偏移：图的邻接矩阵和标签的联合分布不同，即 $ \\mathbb{P}^{S}_{A \\times Y} \\neq \\mathbb{P}^{T}_{A \\times Y} $ 。论文主要关注两种具体的结构偏移： 度偏移：源图和目标图的平均节点度数不同。 同质性偏移：源图和目标图的同质性水平不同。其中图的所有节点同质性的平均值 $ h(\\mathcal{G}) = \\dfrac{1}{N}\\sum_{i}h_{i} $ ，单个节点 $ v_{i} $ 的同质性计算公式为： $$ h_{i} = \\dfrac{\\left| \\{ v_{j} \\in \\mathbb{N}(v_{i}): y_{j} = y_{i} \\} \\right|}{d_{i}} $$ 其中 $ y $ 表示节点标签，$ d $ 表示节点度数。 Impact of Distribution Shifts 通过数学建模来显示两种偏移的不同影响机制。\n分析工具\nCSBM (上下文随机块模型)：广泛用于 GNN 分析的随机图生成器。参数 $ \\mu_{+},\\mu_{-} $ 编码节点属性，而 $ d,h $ 参数编码图的结构。\n单层 GCN：为了简化分析，使用了一个单层的 GCN 模型，其节点表示 $ z_{i} $ 的计算公式为： $$ z_{i} = x_{i} + \\gamma \\cdot \\dfrac{1}{d_{i}} \\sum_{v_{j} \\in \\mathbb{N}(v_{i})}x_{j} $$ 其中 $ \\gamma $ 是一个关键的跳数聚合参数，控制节点自身特征和邻居平均特征的混合比例。\n推论 3.1\n在 CSBM 图上，一个节点的最终表示 $ z_{i} $ 服从一个正态分布，其均值取决于节点的真实类别、图的同质性 $ h_{i} $ 以及 $ \\gamma $ 参数，而方差取决于节点度数 $ d_{i} $ 和 $ \\gamma $ 参数 $$ z_{i} \\sim \\mathcal{N}\\left( (1 + \\gamma h_{i})\\mu_{+} + \\gamma(1-h_{i})\\mu_{-}, \\left( 1 + \\dfrac{\\gamma^{2}}{d_{i}} \\right)I \\right) $$\n推论 3.2\n基于 3.1 直接给出了模型预期准确率的公式 $$ \\text{Acc} = \\varPhi\\left( \\sqrt{ \\dfrac{d}{d+\\gamma^{2}} } \\cdot \\left| 1 + \\gamma(2h - 1) \\right| \\cdot \\| \\mu \\|_{2} \\right) $$ 根据这个公式，只需要输入图的度数，同质性和 $ \\gamma $ 参数就能直接计算出模型的理论最高准确率，从而让定量分析成为可能。\n准确率差距分解\n论文指出当模型性能下降时，可能的原因有两种：\n表示退化 $ \\Delta_{f} $：GNN 的特征提取器出现了问题，其生成的节点表示本身质量就很差，无法区分不同类型的节点。\n分类器偏移 $ \\Delta_{g} $：指特征提取器本身没有问题，但是分类器出现了问题。\n命题 3.3 (属性偏移的影响)\n理论证明，在属性偏移下，性能损失完全来自于分类器偏移 $ \\Delta_{g} $ ，而表示退化 $ \\Delta_{f} $ 为零 。 $$ \\Delta_{f} = 0, \\Delta_{g} = \\Theta (\\| \\Delta \\mu \\| _{2}^{2}) $$\n这解释了为什么现有的 TTA 方法（主要调整分类器）在处理属性偏移时有效 。\n命题 3.4 (结构偏移的影响)\n理论证明，在结构偏移下，情况恰恰相反 。性能损失完全来自于表示退化 $ \\Delta_{f} $，而分类器偏移 $ \\Delta_{g} $ 为零 。 $$ \\Delta_{f} = \\Theta(\\Delta h + \\Delta g),\\Delta_{g} = 0 $$\n这是论文的核心发现，揭示了现有 TTA 方法在结构偏移下失效的根本原因：它们没有修复问题的根源——已经退化了的节点表示 。\n命题 3.5 (调整跳聚数参数)\n既然结构偏移的病根在于表示退化，那么治疗方案就必须调整特征提取器 。\n论文证明调整跳数聚合参数 $ \\gamma $ 是一个有效的方法，可以缓解表示退化问题 。\n其关键在于，最优的 $ \\gamma $ 值本身就依赖于图的度和同质性 $ \\gamma_{T} = d_{T}(2h_{T} - 1) $。因此，通过在测试时将 $ \\gamma $ 调整到适应目标图的新值，就可以提升模型的准确率 。这为后续 Matcha 框架的提出提供了理论基础。\nAdapting Hop-Aggregation Parameters 根据前面的分析，解决结构偏移的影响关键在于调整特征提取器 $ f_{S} $ 来恢复节点表示的质量。\n命题 3.5 (调整 $ \\gamma $ 的有效性)\n论文进一步证明调整跳数聚合参数 $ \\gamma $ 是一个有效的方法。命题指出，最优的 $ \\gamma $ 依赖于图的度和同质性（即 $ \\gamma_{T}^{*} = d_{T}(2h_{T} - 1) $ ），当图从源图变为目标图时，最优的 $ \\gamma $ 也会改变。因此在测试时把 $ \\gamma $ 调整到目标图的最优值就可以显著缓解表示退化，提升模型准确率。\nProposed Framework 基于以上洞察，论文设计了 Matcha 框架，旨在解决两个挑战：1. 在没有标签的情况下，如何更新跳数聚合参数以应对结构偏移？ 2. 如何确保算法与现有的 TTA 算法兼容，以同时解决结构和属性偏移？\nPrediction-Informed Clustering Loss 传统的 TTA 方法主要采用熵（entropy）作为代理损失函数，但论文发现熵最小化在提升表示质量方面效果有限，因为它对 logits 的尺度敏感，容易导致平凡解。\n为了解决这个问题，论文提出了一种新颖的预测感知聚类损失 (Prediction-Informed Clustering, PIC) 损失，其核心思想是：一个好的节点表示应该使得同类节点在特征空间中紧密聚集，而不同类节点则相互远离。\n其计算过程如下：\n计算质心：利用模型当前的软预测结果 $ \\hat{Y} $ 作为“伪类别”信息，计算每个伪类别 $ c $ 的质心 $ \\mu_c $ 和所有节点的总质心 $ \\mu_* $。$$ \\mu_{c} = \\frac{\\sum_{i=1}^{N}\\hat{Y}_{i,c}z_{i}}{\\sum_{i=1}^{N}\\hat{Y}_{i,c}}, \\quad \\mu_{*} = \\frac{1}{N}\\sum_{i=1}^{N}z_{i} $$ 计算方差：计算类内方差 $ \\sigma_{intra}^2 $（希望它小）和类间方差 $ \\sigma_{inter}^2 $（希望它大）。$$ \\sigma_{intra}^{2} = \\sum_{i=1}^{N}\\sum_{c=1}^{C}\\hat{Y}_{i,c}||z_{i}-\\mu_{c}||_{2}^{2} $$ $$ \\sigma_{inter}^{2} = \\sum_{c=1}^{C}(\\sum_{i=1}^{N}\\hat{Y}_{i,c})||\\mu_{c}-\\mu_{*}||_{2}^{2} $$ PIC 损失函数：最终的 PIC 损失被定义为类内方差占总方差的比例。$$ \\mathcal{L}_{PIC} = \\frac{\\sigma_{intra}^{2}}{\\sigma_{intra}^{2} + \\sigma_{inter}^{2}} $$ 通过最小化这个损失，模型会调整 $ \\gamma $ 来优化节点表示 $ Z $，使得类内尽可能紧凑，类间尽可能分离。这种比率形式对表示的尺度不敏感，可以有效避免平凡解。 Integration of Generic TTA Methods Matcha 框架可以和任何现有的 TTA 方法（论文中称为 BaseTTA）无缝集成。\n应用通用 TTA：使用 BaseTTA（如 Tent, T3A）对当前模型进行调整，得到一个初步的软预测 $ \\hat{Y} $ 。这一步主要处理属性偏移。\n更新跳数聚合参数：将 $ \\hat{Y} $ 作为伪标签，计算 $ \\mathcal{L}_{PIC} $ 损失，并根据该损失的梯度只更新跳数聚合参数 $ \\gamma $ 。这一步专门应对结构偏移，以恢复表示质量。\n这个过程形成了一种协同效应：通过调整 $ \\gamma $ 得到的更好表示，为 BaseTTA 提供了更高质量的输入，使其能做出更准的预测；而更准的预测又为 $ \\mathcal{L}_{PIC} $ 提供了更可靠的伪标签，从而更好地指导 $ \\gamma $ 的更新。\nExperiments 论文在合成数据集（CSBM）和多个真实世界数据集（如 Syn-Cora, Syn-Products 等）上进行了广泛的实验，以验证 Matcha 的有效性。\nMatcha Handles Various Structure Shifts 主要结果：\n与不进行自适应的模型（ERM）相比，单独使用 Matcha（ERM+Matcha）可以显著提升模型性能，在真实世界数据集上最高提升 31.95%。 与其他基线方法相比，Matcha 在大多数情况下取得了最佳性能，最高超出 40.61%。 Matcha 与基线 TTA 方法结合时，能进一步提升它们的性能，最高可达 22.72%（合成数据）和 39.31%（真实数据）。这些结果有力地证明了 Matcha 的有效性。 Matcha Restores The Representation Quality 除了性能提升，论文还通过 t-SNE 可视化方法，验证了 Matcha 是否成功恢复了节点表示的质量。\n在结构偏移下（b），原始模型的节点表示变得混乱不堪。在使用其他损失函数（c, d, e）后，表示质量虽有改善但仍不理想。而使用 Matcha 的 PIC 损失后（f），节点表示重新形成了非常清晰的聚类结构，证明其成功恢复了表示质量。\nConclusion 本文的贡献可以总结为：\n理论分析：首次从理论上揭示了属性偏移和结构偏移对 GNN 有着截然不同的影响模式，解释了为何通用 TTA 方法在结构偏移下会失效。 提出框架：提出了一个即插即用的 TTA 框架 Matcha，通过一种新颖的预测感知聚类损失（PIC Loss） 来指导跳数聚合参数的自适应调整，从而恢复因结构偏移而退化的节点表示质量。 实验验证：在多种数据集和场景下的广泛实验，一致且显著地证明了 Matcha 框架的有效性、高效性和通用性。 ","permalink":"https://diefish1024.github.io/posts/literature-notes/matcha/","summary":"\u003ch2 id=\"abstract\"\u003eAbstract\u003c/h2\u003e\n\u003cp\u003e现有 TTA 方法在处理图数据时，对\u003cstrong\u003e节点属性偏移\u003c/strong\u003e有效，但是对\u003cstrong\u003e图结构偏移\u003c/strong\u003e（同质性、节点度的变化）效果很差。原因是\u003cstrong\u003e结构偏移会严重破坏节点表示的质量\u003c/strong\u003e，使不同类别的节点在特征空间中混在一起。为此论文提出了 Matcha 框架，通过在测试的时候\u003cstrong\u003e自适应地调整 GNN 的“跳数聚合参数 (hop-aggregation parameters)”\u003c/strong\u003e，并且引入了新的\u003cstrong\u003e预测感知的聚类损失函数\u003c/strong\u003e来表示恢复节点表示的质量，从而有效应对结构偏移，并能和现有 TTA 方法相结合，进一步提高性能。\u003c/p\u003e\n\u003ch2 id=\"introduction\"\u003eIntroduction\u003c/h2\u003e\n\u003cp\u003e\u003cstrong\u003eGNN 的脆弱性\u003c/strong\u003e：GNNs 在各类图任务上的表现依赖于训练数据和测试数据分布相同的假设，然而在现实世界中，图的分布常常会发生变化（分布偏移），分为：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e属性偏移 (Attribute Shift)\u003c/strong\u003e：节点的特征发生变化。例如不同社交平台，即使用户一样，其账号的内容也会因为平台差异而不同。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e结构偏移 (Structure Shift)\u003c/strong\u003e：节点的连接方式发生变化。比如工作平台用户倾向于连接同事，生活平台用户倾向于连接家人朋友。这种连接模式的变化就是结构偏移，具体表现为\u003cstrong\u003e同质性 (Homophily)\u003c/strong\u003e 和 \u003cstrong\u003e节点度 (Degree)\u003c/strong\u003e 的变化。\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003eTTA 的局限性\u003c/strong\u003e：TTA 允许一个预训练好的模型在不访问原始训练数据的情况下，利用无标签的测试数据进行自适应调整 。目前 TTA 在计算机视觉领域处理图像损坏、风格变化等属性偏移问题上很成功 。然而为图像处理设计的 TTA 方法直接应用到图上时，其在处理图结构偏移时的性能提升非常有限，几乎失效。\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"400\" loading=\"lazy\" src=\"/images/matcha/pasted-image-20250828111414.png\"\u003e\u003c/p\u003e\n\u003ch2 id=\"analysis\"\u003eAnalysis\u003c/h2\u003e\n\u003cp\u003e两种偏移方式对 GNN 的影响存在本质不同。\u003c/p\u003e\n\u003ch3 id=\"perliminaries\"\u003ePerliminaries\u003c/h3\u003e\n\u003cp\u003e论文聚焦于 GTTA 任务。一个 GNN 模型可以被看成两个部分的组合，一个\u003cstrong\u003e特征提取器 $ f_{S} $\u003c/strong\u003e ，一个\u003cstrong\u003e分类器 $ g_{S} $\u003c/strong\u003e ，通常是一个线性层。\u003c/p\u003e\n\u003cp\u003e两种偏移的正式定义：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e属性偏移\u003c/strong\u003e：源图和目标图中，节点的条件概率分布不同 $ \\mathbb{P}^{S}_{x | y} \\neq \\mathbb{P}^{T}_{x | y} $ 。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e结构偏移\u003c/strong\u003e：图的邻接矩阵和标签的联合分布不同，即 $ \\mathbb{P}^{S}_{A \\times Y} \\neq \\mathbb{P}^{T}_{A \\times Y} $ 。论文主要关注两种具体的结构偏移：\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e度偏移\u003c/strong\u003e：源图和目标图的平均节点度数不同。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e同质性偏移\u003c/strong\u003e：源图和目标图的同质性水平不同。其中图的所有节点同质性的平均值 $ h(\\mathcal{G}) = \\dfrac{1}{N}\\sum_{i}h_{i} $ ，单个节点 $ v_{i} $ 的同质性计算公式为： $$ \n h_{i} = \\dfrac{\\left| \\{ v_{j} \\in \\mathbb{N}(v_{i}): y_{j} = y_{i} \\} \\right|}{d_{i}}  \n $$ 其中 $ y $ 表示节点标签，$ d $ 表示节点度数。\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"impact-of-distribution-shifts\"\u003eImpact of Distribution Shifts\u003c/h3\u003e\n\u003cp\u003e通过数学建模来显示两种偏移的不同影响机制。\u003c/p\u003e","title":"Matcha"},{"content":"HPC 领域中，除了基于共享内存的 OpenMP, 还有一种更广泛应用于分布式内存系统的并行编程范式——消息传递接口 (MPI)。MPI 不依赖于共享内存，而是通过进程间的显式消息传递来实现数据交换和同步，从而能支持更大规模的集群计算，是构建大规模 HPC 集群不可或缺的工具。\n1. What is MPI? MPI (Message Passing Interface) 是一种用于分布式内存系统并行编程的标准化通信协议和库函数规范。它定义了一套可移植的函数接口，允许在并行计算环境中独立运行的进程之间进行消息传递，从而实现数据交换和协同工作。MPI 不指定如何启动进程，也不要求所有进程在同一台机器上，这使得它非常适合用于集群或多节点环境中的大规模并行计算。\n2. The MPI Programming Model 分布式内存模型\n在分布式内存模型中，各个处理节点可以独立运行自己的进程，使用自己的本地内存来存储和处理数据。每个进程的内存是私有的，其他进程无法直接访问它们。如果一个进程需要访问另一个进程的数据，就必须通过显式的消息传递机制将数据从一个进程发送到另一个进程。同一个节点（服务器）内部需要借助高速数据总线等硬件实现，而跨节点的通信通常由网络连接来实现，比如通过高速以太网、IB（InfiniBand）等。\n核心概念\n进程 (Process)：一个 MPI 程序由一个或多个独立的进程组成。这些进程通过调用 MPI 库函数来进行通信。\n通信子 (Communicator)：一个通信子（MPI_Comm）定义了一个可以互相通信的进程组。最常用的通信子是 MPI_COMM_WORLD，它包含了程序启动时的所有进程。\n秩 (Rank)：在同一个通信子内，每个进程都被赋予一个唯一的整数标识，称为秩。秩的范围是从 0 到 进程总数 - 1。\n消息传递 (Message Passing)：进程间通信的核心机制，分为两大类：\n点对点通信 (Point-to-Point)：在两个指定的进程之间进行。 集体通信 (Collective)：在一个通信子内的所有进程共同参与的通信。 通信协议：MPI 提供了多种通信协议，如阻塞通信（Blocking）、非阻塞通信（Non-blocking）、同步通信（Synchronous）等。\n3. Basic Functions and Concepts 一个基础的 MPI 程序总是包含初始化、执行并行代码和结束这几个部分。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 #include \u0026lt;mpi.h\u0026gt; #include \u0026lt;stdio.h\u0026gt; int main(int argc, char** argv) { // 1. 初始化 MPI 环境 MPI_Init(\u0026amp;argc, \u0026amp;argv); int world_size; int world_rank; char processor_name[MPI_MAX_PROCESSOR_NAME]; int name_len; // 2. 获取通信子信息 MPI_Comm_size(MPI_COMM_WORLD, \u0026amp;world_size); // 获取总进程数 MPI_Comm_rank(MPI_COMM_WORLD, \u0026amp;world_rank); // 获取当前进程的秩 // 获取处理器名称 (可选) MPI_Get_processor_name(processor_name, \u0026amp;name_len); // 3. 基于秩执行不同的代码 printf(\u0026#34;Hello world from processor %s, rank %d out of %d processors\\n\u0026#34;, processor_name, world_rank, world_size); // 4. 结束 MPI 环境 MPI_Finalize(); return 0; } MPI_Init()：初始化 MPI 执行环境，必须是第一个被调用的 MPI 函数。 MPI_Comm_size()：获取指定通信子（这里是 MPI_COMM_WORLD）中的总进程数。 MPI_Comm_rank()：获取当前进程在指定通信子中的秩。 MPI_Finalize()：清理并结束 MPI 环境，必须是最后一个被调用的 MPI 函数。 4. Point-to-Point Communication 点对点通信是 MPI 中最基本的通信模式，用于在一个进程向另一个进程发送数据。核心操作是 Send 和 Recv。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 #include \u0026lt;mpi.h\u0026gt; #include \u0026lt;stdio.h\u0026gt; int main(int argc, char** argv) { MPI_Init(\u0026amp;argc, \u0026amp;argv); int world_rank, world_size; MPI_Comm_rank(MPI_COMM_WORLD, \u0026amp;world_rank); MPI_Comm_size(MPI_COMM_WORLD, \u0026amp;world_size); if (world_size \u0026lt; 2) { if (world_rank == 0) printf(\u0026#34;This program requires at least 2 processes.\\n\u0026#34;); MPI_Finalize(); return 1; } int number; if (world_rank == 0) { // 进程 0 发送数据给进程 1 number = 42; MPI_Send(\u0026amp;number, 1, MPI_INT, 1, 0, MPI_COMM_WORLD); printf(\u0026#34;Process 0 sent number %d to process 1\\n\u0026#34;, number); } else if (world_rank == 1) { // 进程 1 接收来自进程 0 的数据 MPI_Recv(\u0026amp;number, 1, MPI_INT, 0, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE); printf(\u0026#34;Process 1 received number %d from process 0\\n\u0026#34;, number); } MPI_Finalize(); return 0; } MPI_Send(void* data, int count, MPI_Datatype datatype, int dest, int tag, MPI_Comm comm):\ndata：发送缓冲区指针。 count：发送的数据元素个数。 datatype：发送的数据类型 (如 MPI_INT, MPI_FLOAT)。 dest：目标进程的秩。 tag：消息标签，用于区分不同的消息。 comm：使用的通信子。 MPI_Recv(void* data, int count, MPI_Datatype datatype, int source, int tag, MPI_Comm comm, MPI_Status* status):\ndata：接收缓冲区指针。 source：源进程的秩。 status：返回消息的状态信息 (可填 MPI_STATUS_IGNORE 忽略)。 5. Collective Communication 集体通信是涉及一个通信子中所有进程的通信操作，常用于实现数据分发、结果收集和同步等复杂操作。\n广播 (MPI_Bcast)：将一个进程（根进程）的数据发送给通信子中的所有其他进程。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 #include \u0026lt;mpi.h\u0026gt; #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; int main(int argc, char** argv) { MPI_Init(\u0026amp;argc, \u0026amp;argv); int world_size; int world_rank; MPI_Comm_rank(MPI_COMM_WORLD, \u0026amp;world_rank); MPI_Comm_size(MPI_COMM_WORLD, \u0026amp;world_size); int* data = NULL; int data_size; if (world_rank == 0) { // 主进程初始化数据 data_size = 5; data = (int*)malloc(data_size * sizeof(int)); for (int i = 0; i \u0026lt; data_size; i++) data[i] = i + 1; printf(\u0026#34;进程 0 广播数据：\u0026#34;); for (int i = 0; i \u0026lt; data_size; i++) printf(\u0026#34;%d \u0026#34;, data[i]); printf(\u0026#34;\\n\u0026#34;); } MPI_Bcast(\u0026amp;data_size, 1, MPI_INT, 0, MPI_COMM_WORLD); // 分配缓冲区 if (world_rank != 0) { data = (int*)malloc(data_size * sizeof(int)); } MPI_Bcast(data, data_size, MPI_INT, 0, MPI_COMM_WORLD); printf(\u0026#34;进程 %d 接收到的数据：\u0026#34;, world_rank); for (int i = 0; i \u0026lt; data_size; i++) { printf(\u0026#34;%d \u0026#34;, data[i]); } printf(\u0026#34;\\n\u0026#34;); free(data); MPI_Finalize(); return 0; } 分发 (MPI_Scatter)：将根进程中的一个数组，切分成若干块，然后分发给通信子中的所有进程（包括根进程自己）。\n归约 (MPI_Reduce)：从所有进程中收集数据，并通过指定的操作（如求和、最大值）将它们合并到根进程的变量中。\n下面的例子通过 Scatter 和 Reduce 高效地并行计算了两个向量的点积：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 #include \u0026lt;mpi.h\u0026gt; #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; #include \u0026lt;math.h\u0026gt; #include \u0026lt;time.h\u0026gt; int main(int argc, char** argv) { MPI_Init(\u0026amp;argc, \u0026amp;argv); int rank, size; MPI_Comm_rank(MPI_COMM_WORLD, \u0026amp;rank); MPI_Comm_size(MPI_COMM_WORLD, \u0026amp;size); const int vector_size = 1000000; const int local_size = vector_size / size; float *full_A = NULL; float *full_B = NULL; if (rank == 0) { full_A = (float*)malloc(vector_size * sizeof(float)); full_B = (float*)malloc(vector_size * sizeof(float)); // 使用固定种子初始化完整向量（保证可重复性） srand(12345); for (int i = 0; i \u0026lt; vector_size; i++) { full_A[i] = (float)rand() / RAND_MAX; full_B[i] = (float)rand() / RAND_MAX; } } float *local_A = (float*)malloc(local_size * sizeof(float)); float *local_B = (float*)malloc(local_size * sizeof(float)); //============ 并行计算 ============ float global_dot = 0.0; MPI_Scatter(full_A, local_size, MPI_FLOAT, local_A, local_size, MPI_FLOAT, 0, MPI_COMM_WORLD); MPI_Scatter(full_B, local_size, MPI_FLOAT, local_B, local_size, MPI_FLOAT, 0, MPI_COMM_WORLD); float local_dot = 0.0; for (int i = 0; i \u0026lt; local_size; ++i) { local_dot += (double)local_A[i] * (double)local_B[i]; } MPI_Reduce(\u0026amp;local_dot, \u0026amp;global_dot, 1, MPI_FLOAT, MPI_SUM, 0, MPI_COMM_WORLD); //============串行计算============ if (rank == 0) { double serial_dot = 0.0; for (int i = 0; i \u0026lt; vector_size; i++) { serial_dot += (double)full_A[i] * (double)full_B[i]; } double abs_error = fabs(global_dot - serial_dot); printf(\u0026#34;并行点积：%.16f\\n\u0026#34;, global_dot); printf(\u0026#34;串行点积：%.16f\\n\u0026#34;, serial_dot); printf(\u0026#34;绝对误差：%.6e\\n\u0026#34;, abs_error); free(full_A); free(full_B); } free(local_A); free(local_B); MPI_Finalize(); return 0; } 6. Communication Modes MPI 提供了不同的通信模式，以应对不同的性能需求。\n阻塞通信 (Blocking)：MPI_Send 和 MPI_Recv 都是阻塞的。\nMPI_Send 会一直等待，直到发送缓冲区的数据可以被安全地重用（通常是数据已被拷贝到系统缓冲区或已发送到接收方）。 MPI_Recv 会一直等待，直到消息完全接收到接收缓冲区。 优点：编程简单，逻辑清晰。 缺点：可能导致进程长时间等待，造成性能瓶颈。 非阻塞通信 (Non-blocking)：MPI_Isend 和 MPI_Irecv 是非阻塞的。\n函数会立即返回，允许程序在通信进行的同时执行其他计算任务。 需要配合 MPI_Wait 或 MPI_Test 来检查通信是否完成。 优点：可以实现 计算和通信的重叠，是 MPI 性能优化的关键。 缺点：编程复杂度更高。 核心函数： MPI_Isend: 非阻塞发送。 MPI_Irecv: 非阻塞接收。 MPI_Wait: 等待一个非阻塞操作完成。 7. How to Compile and Run 通常 HPC 集群会预装 MPI 环境。在 Ubuntu/Debian 系统上，可以这样安装：\n1 sudo apt-get install openmpi-bin libopenmpi-dev 编译：使用 mpicc 编译器包装器，它会自动链接 MPI 库。 1 mpicc my_program.c -o my_program 运行：使用 mpirun 或 mpiexec 命令启动程序。-np 参数指定要启动的进程总数。 1 2 # 启动 4 个进程来运行程序 mpirun -np 4 ./my_program Summary MPI 是分布式内存并行编程的基石，它通过一套标准化的函数接口，实现了进程间的显式消息传递。其核心思想是将一个大任务分解给多个独立进程，通过 点对点通信 和 集体通信 协同工作。虽然编程模型比 OpenMP 更复杂，但它摆脱了单机内存的限制，能够扩展到数千个计算节点，是解决超大规模计算问题的首选工具。\nReferences MPI - HPC入门指南 Open MPI 入门笔记 | JinBridge ","permalink":"https://diefish1024.github.io/posts/hpc/mpi-%E5%85%A5%E9%97%A8/","summary":"\u003cp\u003eHPC 领域中，除了基于共享内存的 OpenMP, 还有一种更广泛应用于\u003cstrong\u003e分布式内存\u003c/strong\u003e系统的并行编程范式——\u003cstrong\u003e消息传递接口 (MPI)\u003c/strong\u003e。MPI 不依赖于共享内存，而是通过进程间的显式消息传递来实现数据交换和同步，从而能支持更大规模的集群计算，是构建大规模 HPC 集群不可或缺的工具。\u003c/p\u003e\n\u003ch2 id=\"1-what-is-mpi\"\u003e1. What is MPI?\u003c/h2\u003e\n\u003cp\u003eMPI (Message Passing Interface) 是一种用于\u003cstrong\u003e分布式内存\u003c/strong\u003e系统并行编程的标准化通信协议和库函数规范。它定义了一套可移植的函数接口，允许在并行计算环境中独立运行的进程之间进行\u003cstrong\u003e消息传递\u003c/strong\u003e，从而实现数据交换和协同工作。MPI 不指定如何启动进程，也不要求所有进程在同一台机器上，这使得它非常适合用于\u003cstrong\u003e集群或多节点环境\u003c/strong\u003e中的大规模并行计算。\u003c/p\u003e\n\u003ch2 id=\"2-the-mpi-programming-model\"\u003e2. The MPI Programming Model\u003c/h2\u003e\n\u003cp\u003e\u003cstrong\u003e分布式内存模型\u003c/strong\u003e\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e在分布式内存模型中，各个处理节点可以独立运行自己的进程，使用自己的本地内存来存储和处理数据。每个进程的内存是私有的，其他进程无法直接访问它们。如果一个进程需要访问另一个进程的数据，就必须通过显式的消息传递机制将数据从一个进程发送到另一个进程。同一个节点（服务器）内部需要借助高速数据总线等硬件实现，而跨节点的通信通常由网络连接来实现，比如通过高速以太网、IB（InfiniBand）等。\u003c/p\u003e\u003c/blockquote\u003e\n\u003cp\u003e\u003cstrong\u003e核心概念\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e进程 (Process)\u003c/strong\u003e：一个 MPI 程序由一个或多个独立的进程组成。这些进程通过调用 MPI 库函数来进行通信。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e通信子 (Communicator)\u003c/strong\u003e：一个通信子（\u003ccode\u003eMPI_Comm\u003c/code\u003e）定义了一个可以互相通信的进程组。最常用的通信子是 \u003ccode\u003eMPI_COMM_WORLD\u003c/code\u003e，它包含了程序启动时的所有进程。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e秩 (Rank)\u003c/strong\u003e：在同一个通信子内，每个进程都被赋予一个唯一的整数标识，称为秩。秩的范围是从 \u003ccode\u003e0\u003c/code\u003e 到 \u003ccode\u003e进程总数 - 1\u003c/code\u003e。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e消息传递 (Message Passing)\u003c/strong\u003e：进程间通信的核心机制，分为两大类：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e点对点通信 (Point-to-Point)\u003c/strong\u003e：在两个指定的进程之间进行。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e集体通信 (Collective)\u003c/strong\u003e：在一个通信子内的所有进程共同参与的通信。\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e通信协议\u003c/strong\u003e：MPI 提供了多种通信协议，如阻塞通信（Blocking）、非阻塞通信（Non-blocking）、同步通信（Synchronous）等。\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"3-basic-functions-and-concepts\"\u003e3. Basic Functions and Concepts\u003c/h2\u003e\n\u003cp\u003e一个基础的 MPI 程序总是包含初始化、执行并行代码和结束这几个部分。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cdiv class=\"chroma\"\u003e\n\u003ctable class=\"lntable\"\u003e\u003ctr\u003e\u003ctd class=\"lntd\"\u003e\n\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode\u003e\u003cspan class=\"lnt\"\u003e 1\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 2\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 3\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 4\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 5\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 6\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 7\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 8\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 9\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e10\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e11\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e12\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e13\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e14\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e15\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e16\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e17\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e18\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e19\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e20\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e21\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e22\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e23\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e24\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e25\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e26\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e27\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e28\n\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\n\u003ctd class=\"lntd\"\u003e\n\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-c\" data-lang=\"c\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"cp\"\u003e#include\u003c/span\u003e \u003cspan class=\"cpf\"\u003e\u0026lt;mpi.h\u0026gt;\u003c/span\u003e\u003cspan class=\"cp\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"cp\"\u003e#include\u003c/span\u003e \u003cspan class=\"cpf\"\u003e\u0026lt;stdio.h\u0026gt;\u003c/span\u003e\u003cspan class=\"cp\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"cp\"\u003e\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"kt\"\u003eint\u003c/span\u003e \u003cspan class=\"nf\"\u003emain\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"kt\"\u003eint\u003c/span\u003e \u003cspan class=\"n\"\u003eargc\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"kt\"\u003echar\u003c/span\u003e\u003cspan class=\"o\"\u003e**\u003c/span\u003e \u003cspan class=\"n\"\u003eargv\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"c1\"\u003e// 1. 初始化 MPI 环境\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e\u003c/span\u003e    \u003cspan class=\"nf\"\u003eMPI_Init\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"o\"\u003e\u0026amp;\u003c/span\u003e\u003cspan class=\"n\"\u003eargc\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"o\"\u003e\u0026amp;\u003c/span\u003e\u003cspan class=\"n\"\u003eargv\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"kt\"\u003eint\u003c/span\u003e \u003cspan class=\"n\"\u003eworld_size\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"kt\"\u003eint\u003c/span\u003e \u003cspan class=\"n\"\u003eworld_rank\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"kt\"\u003echar\u003c/span\u003e \u003cspan class=\"n\"\u003eprocessor_name\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"n\"\u003eMPI_MAX_PROCESSOR_NAME\u003c/span\u003e\u003cspan class=\"p\"\u003e];\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"kt\"\u003eint\u003c/span\u003e \u003cspan class=\"n\"\u003ename_len\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"c1\"\u003e// 2. 获取通信子信息\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e\u003c/span\u003e    \u003cspan class=\"nf\"\u003eMPI_Comm_size\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eMPI_COMM_WORLD\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"o\"\u003e\u0026amp;\u003c/span\u003e\u003cspan class=\"n\"\u003eworld_size\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e \u003cspan class=\"c1\"\u003e// 获取总进程数\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e\u003c/span\u003e    \u003cspan class=\"nf\"\u003eMPI_Comm_rank\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eMPI_COMM_WORLD\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"o\"\u003e\u0026amp;\u003c/span\u003e\u003cspan class=\"n\"\u003eworld_rank\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e \u003cspan class=\"c1\"\u003e// 获取当前进程的秩\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"c1\"\u003e// 获取处理器名称 (可选)\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e\u003c/span\u003e    \u003cspan class=\"nf\"\u003eMPI_Get_processor_name\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eprocessor_name\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"o\"\u003e\u0026amp;\u003c/span\u003e\u003cspan class=\"n\"\u003ename_len\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"c1\"\u003e// 3. 基于秩执行不同的代码\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e\u003c/span\u003e    \u003cspan class=\"nf\"\u003eprintf\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;Hello world from processor %s, rank %d out of %d processors\u003c/span\u003e\u003cspan class=\"se\"\u003e\\n\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e           \u003cspan class=\"n\"\u003eprocessor_name\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eworld_rank\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eworld_size\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"c1\"\u003e// 4. 结束 MPI 环境\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e\u003c/span\u003e    \u003cspan class=\"nf\"\u003eMPI_Finalize\u003c/span\u003e\u003cspan class=\"p\"\u003e();\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"mi\"\u003e0\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\u003c/tr\u003e\u003c/table\u003e\n\u003c/div\u003e\n\u003c/div\u003e\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e\u003ccode\u003eMPI_Init()\u003c/code\u003e\u003c/strong\u003e：初始化 MPI 执行环境，必须是第一个被调用的 MPI 函数。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e\u003ccode\u003eMPI_Comm_size()\u003c/code\u003e\u003c/strong\u003e：获取指定通信子（这里是 \u003ccode\u003eMPI_COMM_WORLD\u003c/code\u003e）中的总进程数。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e\u003ccode\u003eMPI_Comm_rank()\u003c/code\u003e\u003c/strong\u003e：获取当前进程在指定通信子中的秩。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e\u003ccode\u003eMPI_Finalize()\u003c/code\u003e\u003c/strong\u003e：清理并结束 MPI 环境，必须是最后一个被调用的 MPI 函数。\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"4-point-to-point-communication\"\u003e4. Point-to-Point Communication\u003c/h2\u003e\n\u003cp\u003e点对点通信是 MPI 中最基本的通信模式，用于在一个进程向另一个进程发送数据。核心操作是 \u003ccode\u003eSend\u003c/code\u003e 和 \u003ccode\u003eRecv\u003c/code\u003e。\u003c/p\u003e","title":"MPI 入门"},{"content":"由于高性能计算场景下的并行编程任务的特性，OpenMP 可以通过简单受限的语法极大地化简了并行编程的复杂性，在普通的串行代码中添加一些指令就能够实现高效并行化。\n1. What is OpenMP? OpenMP (Open Multi-Processing) 是一种用于共享内存多处理器系统并行编程的 API。它通过在 C, C++, 或 Fortran 代码中添加 #pragma 的方式，让开发者可以轻松地将串行代码并行化，而无需手动管理复杂的线程创建、同步和销毁过程。\n2. The OpenMP Programming Model 共享内存模型：所有线程在同一个地址空间中共享数据。这意味着不同线程可以访问相同的内存位置，并且可以共享变量的值。\n共享变量：在并行区域中，默认情况下，大多数变量是共享的，即所有线程都可以访问和修改这些变量的值。\n私有变量：某些情况下，我们可能希望每个线程拥有变量的私有副本，这样不同线程之间不会相互干扰。OpenMP 通过 private 指令指定这些变量。\n数据竞争（Race Condition）：由于多个线程同时访问和修改共享变量，可能会导致数据竞争问题。为了避免这种情况，OpenMP 提供了同步机制，如 critical 和 atomic 等。\n并行区域（Parallel Region）：是 OpenMP 编程的核心概念。它是由编译器指令 #pragma omp parallel 指定的一段代码，告诉 OpenMP 在这段代码中创建多个线程并行执行。\nFork-Join 执行模型：从单线程开始执行，进入并行区域开始并行执行，在并行区域结尾进行同步和结束线程。\n3. Core Directives and Constructs OpenMP 的功能主要是通过编译指令（Directives）和相关的子句（Clauses）来实现的。\nparallel：用于创建一个并行区域。 1 2 3 4 5 #pragma omp parallel { // 这部分代码将由多个线程同时执行 printf(\u0026#34;Hello from thread %d\\n\u0026#34;, omp_get_thread_num()); } for：用于并行化 for 循环，必须与 parallel 结合使用。它会自动将循环迭代分配给不同的线程，这是 OpenMP 最常用、最高效的指令之一。 1 2 3 4 #pragma omp parallel for for (int i = 0; i \u0026lt; n; i++) { // 循环的 n 次迭代会被分配给不同线程 } sections：用于将不同的、独立的任务代码块分配给不同线程。适用于任务并行而不是数据并行。 1 2 3 4 5 6 7 #pragma omp parallel sections { #pragma omp section { /* task A */ } #pragma omp section { /* task B */ } } 4. Data Scoping 数据作用域定义了并行区域中变量如何被线程共享或者私有，OpenMP 通过子句 clauses 来控制变量属性。\nshared(list)：变量在所有线程间共享同一份内存，这是大多数变量的默认设置。读写共享变量通常需要同步。 1 2 3 4 5 int a; #pragma omp parallel for shared(a) for (int i = 0; i \u0026lt; n; i++) { // a为公有变量 } private(list)：每个线程在并行区域中有自己独立的变量副本，线程之间相互独立，互不干扰。并行区域内申明的变量默认为私有的，并行区域外申明的变量需要显式申明 private。 firstprivate(list)：是 private 的一种特殊情况。私有副本会用主线程中原始变量的值进行 初始化。 lastprivate(list)：是 private 的另一种特殊情况。当并行结束后，循环中最后一次迭代（或 sections 中最后一个 section）的线程会将其私有副本的值拷贝回主线程的原始变量。 1 2 3 4 5 6 int a; #pragma omp parallel for private(a) for (int i = 0; i \u0026lt; n; i++) { int b; //a,b均为私有变量 } reduction(operator:list)：用于解决并行计算中的归约操作（如求和、求积）。每个线程会计算一个局部结果，并行区结束后，所有局部结果会通过指定的操作符 (+, *, - 等) 合并到主线程的全局变量中，从而避免了竞争。 （规约的运算符规则） 1 2 3 4 5 int sum = 0; #pragma omp parallel for reduction(+:sum) for (int i = 0; i \u0026lt; 10; i++) { sum += i; } 5. Loop Scheduling 当使用 omp for 时，OpenMP 需要决定如何将循环的迭代次数分配给线程。这通过 schedule 子句控制，其选择会影响负载均衡 (Load Balancing) 和开销 (Overhead)。\nschedule(static, [chunk_size])：静态调度。在编译时就将迭代平均分配好。开销最小，适用于每次迭代计算量都相等的循环。 1 2 3 4 #pragma omp parallel for schedule(static, 3) for (int i = 0; i \u0026lt; n; i++) { // 每个线程执行3个连续的迭代 } schedule(dynamic, [chunk_size])：动态调度。线程每次完成一个（或 chunk_size 个）迭代后，动态地去任务队列领取新的任务。开销较大，但适用于每次迭代计算量不均匀的场景。\nschedule(guided, [chunk_size])：引导式调度。动态调度的一种优化。开始时分配大块任务，随着任务剩余量减少，分配的任务块也越来越小。是 static 和 dynamic 的一种折中。\nauto：自动调度将调度策略的选择权交给编译器或运行时库，由它们决定最佳的调度方式。\nschedule(runtime)：由环境变量 OMP_SCHEDULE 决定使用哪种调度策略，增加了灵活性。\n6. Synchronization Control 同步是用来协调线程间的执行顺序和保证对共享数据访问的正确性。\ncritical：定义一个临界区，同一时间只允许一个线程进入该代码块，开销较大。\natomic：针对单条内存更新语句（如 x++, x = x + 1）提供原子操作。比 critical 更轻量，是保护简单更新的首选。\nbarrier：一个同步点。所有线程必须执行到 barrier 处才会继续向下执行，没有任何线程可以提前。在并行区域末尾会有一个隐式的 barrier。\nmaster：指定一块代码只由主线程执行。\nsingle：指定一块代码只由线程组中第一个到达的线程执行。\n7. Environment Variables OpenMP 允许通过环境变量在运行时控制并行行为，而无需重新编译代码。\nOMP_NUM_THREADS：设置并行区默认使用的线程数，这是最常用的环境变量。\nOMP_SCHEDULE：当代码中使用 schedule(runtime) 时，该变量用于设定循环调度策略和块大小，例如：\u0026quot;dynamic,4\u0026quot;。\nOMP_PROC_BIND：控制线程与处理器核心的亲和性（绑定关系），对性能优化非常重要。\n8. How to Compile and Run 编译 C/C++ 代码时，需要添加一个特定的编译器标志来启用 OpenMP 支持。\nGCC / G++： 1 g++ -fopenmp my_program.cpp -o my_program Reference HPC 入门指南 OpenMP 入门笔记 | JinBridge ","permalink":"https://diefish1024.github.io/posts/hpc/openmp-%E5%85%A5%E9%97%A8/","summary":"\u003cp\u003e由于高性能计算场景下的并行编程任务的特性，OpenMP 可以通过简单受限的语法极大地化简了并行编程的复杂性，在普通的串行代码中添加一些指令就能够实现高效并行化。\u003c/p\u003e\n\u003ch2 id=\"1-what-is-openmp\"\u003e1. What is OpenMP?\u003c/h2\u003e\n\u003cp\u003eOpenMP (Open Multi-Processing) 是一种用于\u003cstrong\u003e共享内存\u003c/strong\u003e多处理器系统并行编程的 API。它通过在 C, C++, 或 Fortran 代码中添加 \u003ccode\u003e#pragma\u003c/code\u003e 的方式，让开发者可以轻松地将串行代码并行化，而无需手动管理复杂的线程创建、同步和销毁过程。\u003c/p\u003e\n\u003ch2 id=\"2-the-openmp-programming-model\"\u003e2. The OpenMP Programming Model\u003c/h2\u003e\n\u003cp\u003e\u003cstrong\u003e共享内存模型\u003c/strong\u003e：所有线程在同一个地址空间中共享数据。这意味着不同线程可以访问相同的内存位置，并且可以共享变量的值。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e共享变量\u003c/strong\u003e：在并行区域中，默认情况下，大多数变量是共享的，即所有线程都可以访问和修改这些变量的值。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e私有变量\u003c/strong\u003e：某些情况下，我们可能希望每个线程拥有变量的私有副本，这样不同线程之间不会相互干扰。OpenMP 通过 \u003ccode\u003eprivate\u003c/code\u003e 指令指定这些变量。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e数据竞争（Race Condition）\u003c/strong\u003e：由于多个线程同时访问和修改共享变量，可能会导致数据竞争问题。为了避免这种情况，OpenMP 提供了同步机制，如 \u003ccode\u003ecritical\u003c/code\u003e 和 \u003ccode\u003eatomic\u003c/code\u003e 等。\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e并行区域（Parallel Region）\u003c/strong\u003e：是 OpenMP 编程的核心概念。它是由编译器指令 \u003ccode\u003e#pragma omp parallel\u003c/code\u003e 指定的一段代码，告诉 OpenMP 在这段代码中创建多个线程并行执行。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eFork-Join 执行模型\u003c/strong\u003e：从单线程开始执行，进入并行区域开始并行执行，在并行区域结尾进行同步和结束线程。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/images/openmp-%E5%85%A5%E9%97%A8/pasted-image-20250827105206.png\"\u003e\u003c/p\u003e\n\u003ch2 id=\"3-core-directives-and-constructs\"\u003e3. Core Directives and Constructs\u003c/h2\u003e\n\u003cp\u003eOpenMP 的功能主要是通过编译指令（Directives）和相关的子句（Clauses）来实现的。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e\u003ccode\u003eparallel\u003c/code\u003e\u003c/strong\u003e：用于创建一个并行区域。\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cdiv class=\"chroma\"\u003e\n\u003ctable class=\"lntable\"\u003e\u003ctr\u003e\u003ctd class=\"lntd\"\u003e\n\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode\u003e\u003cspan class=\"lnt\"\u003e1\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e2\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e3\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e4\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e5\n\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\n\u003ctd class=\"lntd\"\u003e\n\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-c\" data-lang=\"c\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"cp\"\u003e#pragma omp parallel\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"cp\"\u003e\u003c/span\u003e\u003cspan class=\"p\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"c1\"\u003e// 这部分代码将由多个线程同时执行\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e\u003c/span\u003e    \u003cspan class=\"nf\"\u003eprintf\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;Hello from thread %d\u003c/span\u003e\u003cspan class=\"se\"\u003e\\n\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"nf\"\u003eomp_get_thread_num\u003c/span\u003e\u003cspan class=\"p\"\u003e());\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\u003c/tr\u003e\u003c/table\u003e\n\u003c/div\u003e\n\u003c/div\u003e\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e\u003ccode\u003efor\u003c/code\u003e\u003c/strong\u003e：用于并行化 \u003ccode\u003efor\u003c/code\u003e 循环，必须与 \u003ccode\u003eparallel\u003c/code\u003e 结合使用。它会自动将循环迭代分配给不同的线程，这是 OpenMP 最常用、最高效的指令之一。\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cdiv class=\"chroma\"\u003e\n\u003ctable class=\"lntable\"\u003e\u003ctr\u003e\u003ctd class=\"lntd\"\u003e\n\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode\u003e\u003cspan class=\"lnt\"\u003e1\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e2\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e3\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e4\n\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\n\u003ctd class=\"lntd\"\u003e\n\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-c\" data-lang=\"c\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"cp\"\u003e#pragma omp parallel for\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"cp\"\u003e\u003c/span\u003e\u003cspan class=\"k\"\u003efor\u003c/span\u003e \u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"kt\"\u003eint\u003c/span\u003e \u003cspan class=\"n\"\u003ei\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"mi\"\u003e0\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e \u003cspan class=\"n\"\u003ei\u003c/span\u003e \u003cspan class=\"o\"\u003e\u0026lt;\u003c/span\u003e \u003cspan class=\"n\"\u003en\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e \u003cspan class=\"n\"\u003ei\u003c/span\u003e\u003cspan class=\"o\"\u003e++\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"c1\"\u003e// 循环的 n 次迭代会被分配给不同线程\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e\u003c/span\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\u003c/tr\u003e\u003c/table\u003e\n\u003c/div\u003e\n\u003c/div\u003e\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e\u003ccode\u003esections\u003c/code\u003e\u003c/strong\u003e：用于将不同的、独立的任务代码块分配给不同线程。适用于任务并行而不是数据并行。\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cdiv class=\"chroma\"\u003e\n\u003ctable class=\"lntable\"\u003e\u003ctr\u003e\u003ctd class=\"lntd\"\u003e\n\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode\u003e\u003cspan class=\"lnt\"\u003e1\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e2\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e3\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e4\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e5\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e6\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e7\n\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\n\u003ctd class=\"lntd\"\u003e\n\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-c\" data-lang=\"c\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"cp\"\u003e#pragma omp parallel sections\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"cp\"\u003e\u003c/span\u003e\u003cspan class=\"p\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"cp\"\u003e#pragma omp section\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"cp\"\u003e\u003c/span\u003e    \u003cspan class=\"p\"\u003e{\u003c/span\u003e \u003cspan class=\"cm\"\u003e/* task A */\u003c/span\u003e \u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"cp\"\u003e#pragma omp section\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"cp\"\u003e\u003c/span\u003e    \u003cspan class=\"p\"\u003e{\u003c/span\u003e \u003cspan class=\"cm\"\u003e/* task B */\u003c/span\u003e \u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\u003c/tr\u003e\u003c/table\u003e\n\u003c/div\u003e\n\u003c/div\u003e\u003ch2 id=\"4-data-scoping\"\u003e4. Data Scoping\u003c/h2\u003e\n\u003cp\u003e数据作用域定义了并行区域中变量如何被线程共享或者私有，OpenMP 通过子句 clauses 来控制变量属性。\u003c/p\u003e","title":"OpenMP 入门"},{"content":"目录树 文件的抽象 操作系统将物理存储设备（如磁盘）的复杂性隐藏起来，提供了一个简单、统一的抽象——文件\n文件可以看作是一个虚拟的磁盘，即一个命名的、一维的字节序列，支持 read, write, lseek 等操作\n这种抽象使得上层应用无需关心数据在物理磁盘上的具体位置和存储方式\n目录的引入 当文件数量增多时，需要一种方式来组织和管理它们\n操作系统引入了目录 (Directory) 的概念，它是一种特殊的文件，其内容是其他文件或目录的列表\n通过将文件和目录组织成一个层次化的树状结构，即目录树，可以方便地对文件进行分类、查找和管理\n多数类 Unix 系统遵循 FHS (Filesystem Hierarchy Standard) 的目录结构约定，为软件和用户预测文件位置提供了便利\n目录操作 API 操作系统提供了一系列系统调用来操作目录树，核心操作围绕“增删改查”\nmkdir: 创建一个新的目录 rmdir: 删除一个空的目录 getdents: 读取目录中的条目 (directory entries) link / unlink: 创建或删除文件的链接 链接 链接是文件系统的一个重要特性，它允许一个文件拥有多个名字或存在于目录树的多个位置\n链接主要分为两种类型：硬链接和软链接（符号链接）\n硬链接 Hard Link 定义：硬链接是让多个目录条目（文件名）直接指向磁盘上同一个文件索引节点 (inode)\n每个文件在文件系统中都有一个唯一的 inode，它包含了文件的元数据（如权限、大小、数据块位置等）和数据本身\n创建一个硬链接，相当于为同一个 inode 增加了一个新的入口点（文件名）\n特性：\n所有指向同一个 inode 的硬链接地位平等，没有主次之分 inode 内部维护一个链接计数 (reference count), 只有当这个计数减到 0 时，文件系统才会真正删除该 inode 和对应的数据块，这也是 unlink 系统调用的由来 限制：\n不能为目录创建硬链接，以防止在目录树中产生循环 不能跨越不同的文件系统（因为 inode 号只在当前文件系统内唯一） 软链接 Symbolic Link 定义：软链接，也称符号链接 (symlink)，是一个特殊的文件，它的内容是另一个文件或目录的路径\n软链接本身拥有自己独立的 inode 和数据块，其数据块中存储的是一个文本字符串，即目标对象的路径名，当访问软链接时，操作系统会解析其内容，并将访问请求重定向到它所指向的路径\n特性：\n极其灵活，因为它本质上只是一个路径的“快捷方式” 可以链接到目录 可以跨越不同的文件系统 可以创建一个“悬空”的链接 (dangling link)，即它指向的目标路径当前并不存在 删除软链接本身，对它指向的原始文件没有任何影响 应用:\n常用于管理软件版本，例如让一个通用的命令（如 python）指向一个具体的版本文件（如 /usr/bin/python3.9） 被 NixOS 等系统用来构建高度可复现和隔离的环境，通过大量使用软链接将不同版本的软件包组合成一个虚拟的文件系统结构 文件的元数据 基本元数据 文件作为操作系统中的对象，拥有一系列的属性 (attributes)，这些属性就是元数据 (metadata), 你可以通过 ls -l 命令查看文件的主要元数据，这包括文件的类型、所有者、大小、修改时间等关键信息\n其中，模式 (Mode) 字段定义了文件的访问权限，它分为三组，分别对应所有者 (owner)、所属组 (group) 和其他用户 (other)，每组都包含读 (r)、写 (w)、执行 (x) 三种权限\n一个常见的权限例子是 755，这是一个八进制数，常用于程序或目录\n第一个 7 代表所有者权限, 7=4+2+1, 意味着读、写、执行 (rwx) 权限全开 第二个 5 代表所属组权限, 5=4+0+1, 意味着读、执行 (r-x) 权限 第三个 5 代表其他用户权限, 5=4+0+1, 同样是读、执行 (r-x) 权限 Extended Attributes (xattr) 扩展属性 xattr 是现代文件系统提供的一项强大功能，它允许为文件附加一个灵活的 key-value 键值对字典，用于存储标准元数据无法覆盖的任意信息，操作系统提供了 fsetxattr 和 fgetxattr 等系统调用来操作这些属性\n应用：\nmacOS 的安全隔离机制就是一个典型例子，当从网络下载文件后，系统会自动添加 com.apple.quarantine 属性，记录下载来源（URL）和时间，首次打开时，系统会检查此属性并向用户发出安全警告\n文件内容元信息: 应用程序可以利用 xattr 存储与文件内容相关的元信息，例如，图片浏览器可以存储照片的 EXIF 数据副本，或者音乐播放器可以存储歌曲的演唱者和专辑信息，便于管理和搜索；相比于文件目录只能按照文件标题索引，这种以内容作为索引才是现代文件系统更合理的做法\n缺陷：虽然 xattr 功能强大，但它“好用不火”的原因在于其固有的缺陷\n缺乏标准化与兼容性: xattr 的键名没有统一标准，不同应用和系统间随意定义，导致数据难以互通，例如，com.apple.quarantine 属性在 Linux 或 Windows 上没有意义 工具支持不完善: 许多经典的命令行工具，如 cp, mv, tar, rsync 等，默认不会处理扩展属性，在执行文件复制或打包时，这些重要的元数据可能会被静默丢弃，用户必须显式使用特定参数（如 cp --preserve=xattr, rsync -X）才能保留它们，这对依赖 xattr 的系统（如使用了 SELinux）可能是灾难性的 可见性低: 扩展属性对于普通用户是不可见的，ls -l 命令并不会显示它们，需要使用 getfattr 或 xattr -l 等专用工具才能查看，这使得问题排查变得更加困难 Access Control List (ACL) 传统的 user/group/other 权限模型在处理复杂的共享需求时显得力不从心，例如需要让用户 bob 访问 alice 的一个文件，但 bob 不在 alice 的用户组里，而又不想把文件权限开放给所有“其他用户”，ACL 就是为了解决这类问题而生的\nACL 提供了比传统模型更精细、更灵活的访问控制机制，它允许你为任意指定的用户或用户组设置独立的权限\n文件系统级 API 与针对单个文件或目录的操作不同，文件系统还提供了一系列“系统级”的 API，用于管理整个文件系统的结构和行为\n挂载 Mount 在类 Unix 系统中，所有的文件和目录都组织在一棵以根目录 / 为起点的巨大目录树下，而在 Windows 中，文件系统则分散在不同的“盘符”下（C:、D: 等）\n挂载 (mount) 是构建这棵统一目录树的核心机制, 它的作用是将一个文件系统（通常来自一个独立的存储设备，如硬盘分区、U 盘或光盘）“附加”到现有目录树的一个挂载点 (mount point) 上, 挂载点是一个已存在的空目录\n例如，命令 mount /dev/sdb1 /mnt/data 就将 /dev/sdb1 这个分区上的文件系统挂载到了 /mnt/data 目录, 此后，对 /mnt/data 目录内容的访问，实际上就是对 /dev/sdb1 分区根目录的访问, 整个 Linux 系统的根目录 / 本身也是在系统启动时挂载的第一个文件系统\n回环设备 Loopback Device mount 命令通常操作的是块设备 (block device)，但有时我们需要挂载一个存在于文件中的文件系统镜像（例如一个 .iso 光盘镜像文件）, 文件不是块设备，所以无法直接挂载\n为了解决这个问题，Linux 提供了回环设备 (loopback device), 这是一个虚拟的块设备，它不对应任何物理硬件，而是将一个普通文件作为其后端存储\n它的工作流程可以想象成一个适配器：\n将文件镜像与一个回环设备（如 /dev/loop0）关联起来, 这时，操作系统看待 /dev/loop0 就像看待一个真实的物理磁盘一样 对这个回环设备执行 mount 操作，将其挂载到指定目录 这个过程的底层是通过 ioctl 系统调用实现的，它向 loop 驱动发送 LOOP_SET_FD 等命令，将文件描述符与一个空闲的 loop 设备进行绑定\n联合文件系统 OverlayFS OverlayFS 是一种强大的联合文件系统 (UnionFS)，它允许将多个不同的目录（称为层）“堆叠”起来，对外提供一个统一的、合并后的视图\n我们可以用一个非常形象的比喻来理解它的工作原理：\n底层 (lowerdir): 想象一张已经印刷好的、不可修改的原始画稿, 这就是只读的底层, 它可以有很多张，层层叠放 上层 (upperdir)：在原始画稿上覆盖一张透明的塑料薄膜, 这就是可写的上层 合并视图 (merged view)：你透过这张透明薄膜看到的最终景象，就是 OverlayFS 呈现给你的目录 基于这个模型，所有操作都变得非常直观：\n读取文件: 当你读取一个文件时，相当于透过透明薄膜看画稿, 如果文件只存在于底层，你会直接看到它, 如果文件在上层也存在，那么上层的版本会“遮盖”住底层的版本\n修改文件：你不能直接修改原始画稿（lowerdir），当你第一次尝试修改一个来自底层的文件时，系统会启动写时复制 (Copy-on-Write) 机制，先把这个文件从底层复制一份到上层的透明薄膜上，然后你所有的修改都发生在这份复制品上\n创建文件：这就像直接在透明薄膜上画新的内容，完全不影响下面的原始画稿\n删除文件：你无法擦除原始画稿的内容, 当你删除一个来自底层的文件时，系统会在上层创建一个特殊的“白点”文件 (whiteout)，像贴了一张不透明的小贴纸，刚好遮住底层的文件，让它看起来像是被删除了\n这种分层和写时复制的机制是 Docker 等容器技术的核心, 容器镜像就是只读的 lowerdir，而每个运行的容器都有自己专属的可写 upperdir，这使得成百上千个容器可以共享同一个基础镜像，同时保持各自的隔离性，极大地节省了存储空间和部署时间\n文件系统快照 Snapshot 一些高级的文件系统（如 Btrfs, ZFS）或逻辑卷管理器（LVM）支持快照 (snapshot) 功能，它可以在瞬间“冻结”并创建一个文件系统在某个时间点的完整副本\n快照的实现也常常依赖于写时复制技术，创建快照时，并不会立即复制所有数据，而只是创建了一个指向当前数据块的指针集合, 当之后有数据块被修改时，文件系统不会覆盖旧的数据块，而是将修改写入新的位置，并让旧的快照指针继续指向未修改的旧数据块\n这个功能对于系统备份、快速回滚和创建安全的测试环境非常有用\n","permalink":"https://diefish1024.github.io/posts/class-notes/nju-os-2025/22-%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F-api/","summary":"\u003ch2 id=\"目录树\"\u003e目录树\u003c/h2\u003e\n\u003ch3 id=\"文件的抽象\"\u003e文件的抽象\u003c/h3\u003e\n\u003cp\u003e操作系统将物理存储设备（如磁盘）的复杂性隐藏起来，提供了一个简单、统一的抽象——\u003cstrong\u003e文件\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e文件可以看作是一个\u003cstrong\u003e虚拟的磁盘\u003c/strong\u003e，即一个命名的、一维的\u003cstrong\u003e字节序列\u003c/strong\u003e，支持 \u003ccode\u003eread\u003c/code\u003e, \u003ccode\u003ewrite\u003c/code\u003e, \u003ccode\u003elseek\u003c/code\u003e 等操作\u003c/p\u003e\n\u003cp\u003e这种抽象使得上层应用无需关心数据在物理磁盘上的具体位置和存储方式\u003c/p\u003e\n\u003ch3 id=\"目录的引入\"\u003e目录的引入\u003c/h3\u003e\n\u003cp\u003e当文件数量增多时，需要一种方式来组织和管理它们\u003c/p\u003e\n\u003cp\u003e操作系统引入了\u003cstrong\u003e目录 (Directory)\u003c/strong\u003e 的概念，它是一种特殊的文件，其内容是其他文件或目录的列表\u003c/p\u003e\n\u003cp\u003e通过将文件和目录组织成一个层次化的\u003cstrong\u003e树状结构\u003c/strong\u003e，即\u003cstrong\u003e目录树\u003c/strong\u003e，可以方便地对文件进行分类、查找和管理\u003c/p\u003e\n\u003cp\u003e多数类 Unix 系统遵循 \u003cstrong\u003eFHS (Filesystem Hierarchy Standard)\u003c/strong\u003e 的目录结构约定，为软件和用户预测文件位置提供了便利\u003c/p\u003e\n\u003ch3 id=\"目录操作-api\"\u003e目录操作 API\u003c/h3\u003e\n\u003cp\u003e操作系统提供了一系列系统调用来操作目录树，核心操作围绕“增删改查”\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003emkdir\u003c/code\u003e: 创建一个新的目录\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003ermdir\u003c/code\u003e: 删除一个空的目录\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003egetdents\u003c/code\u003e: 读取目录中的条目 (\u003cstrong\u003ed\u003c/strong\u003eirectory \u003cstrong\u003eent\u003c/strong\u003erie\u003cstrong\u003es\u003c/strong\u003e)\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003elink\u003c/code\u003e / \u003ccode\u003eunlink\u003c/code\u003e: 创建或删除文件的链接\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"链接\"\u003e链接\u003c/h3\u003e\n\u003cp\u003e链接是文件系统的一个重要特性，它允许一个文件拥有多个名字或存在于目录树的多个位置\u003c/p\u003e\n\u003cp\u003e链接主要分为两种类型：\u003cstrong\u003e硬链接\u003c/strong\u003e和\u003cstrong\u003e软链接（符号链接）\u003c/strong\u003e\u003c/p\u003e\n\u003ch4 id=\"硬链接-hard-link\"\u003e硬链接 Hard Link\u003c/h4\u003e\n\u003cp\u003e\u003cstrong\u003e定义\u003c/strong\u003e：\u003cstrong\u003e硬链接\u003c/strong\u003e是让多个目录条目（文件名）直接指向磁盘上同一个\u003cstrong\u003e文件索引节点 (inode)\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e每个文件在文件系统中都有一个唯一的 \u003ccode\u003einode\u003c/code\u003e，它包含了文件的元数据（如权限、大小、数据块位置等）和数据本身\u003c/p\u003e\n\u003cp\u003e创建一个硬链接，相当于为同一个 \u003ccode\u003einode\u003c/code\u003e 增加了一个新的入口点（文件名）\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e特性\u003c/strong\u003e：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e所有指向同一个 \u003ccode\u003einode\u003c/code\u003e 的硬链接地位平等，没有主次之分\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003einode\u003c/code\u003e 内部维护一个\u003cstrong\u003e链接计数 (reference count)\u003c/strong\u003e, 只有当这个计数减到 0 时，文件系统才会真正删除该 \u003ccode\u003einode\u003c/code\u003e 和对应的数据块，这也是 \u003ccode\u003eunlink\u003c/code\u003e 系统调用的由来\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e限制\u003c/strong\u003e：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e不能为目录创建硬链接，以防止在目录树中产生循环\u003c/li\u003e\n\u003cli\u003e不能跨越不同的文件系统（因为 \u003ccode\u003einode\u003c/code\u003e 号只在当前文件系统内唯一）\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4 id=\"软链接-symbolic-link\"\u003e软链接 Symbolic Link\u003c/h4\u003e\n\u003cp\u003e\u003cstrong\u003e定义\u003c/strong\u003e：\u003cstrong\u003e软链接\u003c/strong\u003e，也称\u003cstrong\u003e符号链接 (symlink)\u003c/strong\u003e，是一个\u003cstrong\u003e特殊的文件\u003c/strong\u003e，它的内容是另一个文件或目录的\u003cstrong\u003e路径\u003c/strong\u003e\u003c/p\u003e","title":"22. 文件系统 API"},{"content":"科普性质，简单记录一下\n1-Bit 的存储：磁铁 要实现“持久化”存储，核心是要找到一个能反复改写的状态，很容易想到能够利用磁的特性，这就有了磁带的初步想法：\n一个长条的带子上面均匀有磁性物质 定位到特定位置之后通过放大感应电流读取 用电磁铁改变磁化方向来写入数据 为了提高存储密度，可以把这样的带子给卷起来，于是就得到了磁带\n这样的存储方式主要缺点是几乎不能随机读写（比如磁带收音机需要倒带），一般用于冷数据的存档和备份\n为了解决这个缺点，可以想到用旋转的二维平面来替代卷起来的带子，这样读写延迟就不会超过旋转的周期，这就得到了磁鼓：\n再在磁鼓的基础上进一步内卷，把用圆盘代替柱面，从而可以堆叠起来，进一步提高了存储密度，这就得到了磁盘：\n磁盘作为存储设备的随机读写性能虽然相比磁带有了很大的改善，但是还是需要等待定位到正确的位置，性能仍然不够优秀，为了读写定位到一个扇区通常需要花费几个毫秒的时间，这一点可以通过缓存和调度算法来缓解，让数据尽可能连续存储\n当我们在磁盘的基础上把读写头和盘片本体分开，我们就实现了数据的移动，这也就得到了软盘，这是上个数据数据发行的主要方式，虽然性能和可靠性都比较低，但是胜在了便捷、可移动\n1-Bit 的存储：挖坑 古人实现持久化存储的方式是在石头上刻字，也就是通过挖坑来存储信息，这种方式可以跨越非常长的时间\n而现代工业使我们可以挖出更加精细的坑，从而可以存储更高密度的信息\n为了读取这样的信息，我们可以从光学的角度考虑：在反射平面上挖粗糙坑，激光扫过表面，在平面会反射回来，在坑里会发生漫反射，于是我们只要检测是否收到反射光就可以识别是坑还是表面，这也就是光盘\n光盘最有趣的特性是容易复制，我们要制造光盘可以先仔细地制造一张反转的盘片，坑的位置对应其表面的突起，之后只需要直接用这个盘片压制加热的塑料再镀上反射膜就可以得到一张光盘，这种方式可以达到极高的写入速度\n当然这种挖坑方式的一个重要特性就是不能修改已经写入的内容的，很难填上一个已经挖了的坑（当然通过特殊的制造材料和工艺也是可以做到的），这也就是说里面存储的数据是 append only 的，想要修改之前的内容可以采用可持久化二叉树的结构\n光盘作为存储设备，价格低的同时容量和可靠性都比较高，同时顺序读性能一般，随机读性能低并且很难写入，一个重要的应用常见就是数字时代的内容分发\n现代这种挖坑的存储方式还有一种应用方式是回归古人石碑的形式，把信息刻在很稳定的材料上来做到永久存储\n1-Bit 的存储：电荷 前两种存储介质都存在比较大的缺陷：\n磁：依赖机械部件，从而无法避免 ms 级别的延迟 坑（光）：挖坑效率低，同时填坑很困难 而电荷则是一种非常理想的存储介质：电子的密度极高，并且电路的速度极快（还天然并行）\n在电路中实现 1-bit 的持久存储，一个想法是我们可以挖一个坑，两种状态分别是：\n在坑里填入电子 从坑里放跑电子 而这就得到了闪存 (Flash Memory) ： 其作为存储设备，价格低，容量和可靠性高，而且读写性能极高（由于电路天然并行，所以容量越大，速度越快）\n然而，闪存的物理原理也带来了其固有的缺陷，即会磨损 (wear out)\n每次放电 (erase) 操作都无法 100% 将电子放干净，这会对存储单元造成微小的、不可逆的损伤 在经历数千或数万次擦写循环后，一些存储单元会因为累积的损伤而失效，无法再可靠地存储数据，这被称为 “死单元 (Dead Cell)” 为了解决闪存的磨损问题，并将其更好地呈现给操作系统，现代固态存储设备（如 SSD、U 盘、SD 卡）内部实际上都集成了一个微型计算机系统\n这个系统运行着一层被称为 FTL (Flash Translation Layer) 的固件，它的核心功能之一是 磨损均衡 (Wear Leveling)\nFTL 会记录每个物理块的擦写次数，当操作系统请求写入某个逻辑地址时，FTL 会避免总是写入同一个物理块，而是将写入请求重定向到一个较少被使用的物理块上，这种机制类似于操作系统中的虚拟内存，通过引入一个间接层（逻辑地址到物理地址的映射）来隐藏底层硬件的复杂性并优化其使用寿命\n这也意味着，即便是便宜的 U 盘 或 SD 卡，其内部也可能包含一个 ARM 芯片来运行 FTL，而高性能的 SSD 则拥有更强大的处理器、缓存和更复杂的 FTL 算法，从而提供更长的寿命和更高的性能\n这也解释了为什么我们不应该购买过于廉价的 U 盘，因为它们可能会在 FTL 上偷工减料，甚至伪造容量和厂商信息，导致数据丢失\n存储设备与操作系统 块设备抽象 无论是旋转的磁盘还是闪存芯片，它们都不适合以单个字节为单位进行寻址，因为定位和元数据（如扇区头、ECC 校验码）的开销太大\n因此，存储设备将它们的存储空间划分为固定大小的块 (Block)，并以块为单位进行读写，这大大摊销了单次 I/O 操作的开销，这些设备在操作系统中被称为块设备 (Block Devices)\n操作系统看到的是一个线性的、从 0 开始编号的块数组 struct block disk[NUM_BLOCKS]，应用程序可以直接像读写文件一样读写块设备（例如 /dev/sda），但这样做的效率很低，如果随机读写一个字节，操作系统和设备硬件最终可能会读取或写入整个块，导致读/写放大 (read/write amplification) 的问题，因此，上层的文件系统被设计为能够感知“块”的存在，并以块为单位来组织和管理数据\n为了高效地管理对块设备的访问，操作系统提供了一个专门的 I/O 栈\n在 Linux 中，上层文件系统或应用程序通过块 I/O (Bio) 层提交请求，Bio 层提供了一个请求/响应接口，它将上层的读写请求封装成 struct bio 结构体，这些请求被放入队列中，等待 I/O 调度器 (I/O Scheduler) 进行处理，调度器会根据策略（例如合并相邻的请求、排序请求以减少磁头寻道时间）来优化队列\n现代 Linux 内核使用多队列块 I/O (Multi-queue block I/O, blk-mq) 机制，为每个 CPU 核心 分配独立的请求队列，充分利用了现代多核处理器和高速 SSD 的并行性\n最终，由设备驱动程序将处理好的请求发送给硬件执行\n","permalink":"https://diefish1024.github.io/posts/class-notes/nju-os-2025/21-%E5%AD%98%E5%82%A8%E8%AE%BE%E5%A4%87%E5%8E%9F%E7%90%86/","summary":"\u003cp\u003e科普性质，简单记录一下\u003c/p\u003e\n\u003ch2 id=\"1-bit-的存储磁铁\"\u003e1-Bit 的存储：磁铁\u003c/h2\u003e\n\u003cp\u003e要实现“持久化”存储，核心是要找到一个能反复改写的状态，很容易想到能够利用磁的特性，这就有了磁带的初步想法：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e一个长条的带子上面均匀有磁性物质\u003c/li\u003e\n\u003cli\u003e定位到特定位置之后通过放大感应电流读取\u003c/li\u003e\n\u003cli\u003e用电磁铁改变磁化方向来写入数据\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e为了提高存储密度，可以把这样的带子给卷起来，于是就得到了磁带\u003c/p\u003e\n\u003cp\u003e这样的存储方式主要缺点是\u003cstrong\u003e几乎不能随机读写\u003c/strong\u003e（比如磁带收音机需要倒带），一般用于冷数据的存档和备份\u003c/p\u003e\n\u003cp\u003e为了解决这个缺点，可以想到用旋转的二维平面来替代卷起来的带子，这样读写延迟就不会超过旋转的周期，这就得到了\u003cstrong\u003e磁鼓\u003c/strong\u003e：\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/images/21-%E5%AD%98%E5%82%A8%E8%AE%BE%E5%A4%87%E5%8E%9F%E7%90%86/pasted-image-20250805012735.png\"\u003e\u003c/p\u003e\n\u003cp\u003e再在磁鼓的基础上进一步内卷，把用圆盘代替柱面，从而可以堆叠起来，进一步提高了存储密度，这就得到了\u003cstrong\u003e磁盘\u003c/strong\u003e：\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/images/21-%E5%AD%98%E5%82%A8%E8%AE%BE%E5%A4%87%E5%8E%9F%E7%90%86/pasted-image-20250805012958.png\"\u003e\u003c/p\u003e\n\u003cp\u003e磁盘作为存储设备的随机读写性能虽然相比磁带有了很大的改善，但是还是需要等待定位到正确的位置，性能仍然不够优秀，为了读写定位到一个扇区通常需要花费几个毫秒的时间，这一点可以通过缓存和调度算法来缓解，让数据尽可能连续存储\u003c/p\u003e\n\u003cp\u003e当我们在磁盘的基础上把读写头和盘片本体分开，我们就实现了数据的移动，这也就得到了\u003cstrong\u003e软盘\u003c/strong\u003e，这是上个数据数据发行的主要方式，虽然性能和可靠性都比较低，但是胜在了便捷、可移动\u003c/p\u003e\n\u003ch2 id=\"1-bit-的存储挖坑\"\u003e1-Bit 的存储：挖坑\u003c/h2\u003e\n\u003cp\u003e古人实现持久化存储的方式是在石头上刻字，也就是通过挖坑来存储信息，这种方式可以跨越非常长的时间\u003c/p\u003e\n\u003cp\u003e而现代工业使我们可以挖出更加精细的坑，从而可以存储更高密度的信息\u003c/p\u003e\n\u003cp\u003e为了读取这样的信息，我们可以从光学的角度考虑：在反射平面上挖粗糙坑，激光扫过表面，在平面会反射回来，在坑里会发生漫反射，于是我们只要检测是否收到反射光就可以识别是坑还是表面，这也就是\u003cstrong\u003e光盘\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e光盘最有趣的特性是容易复制，我们要制造光盘可以先仔细地制造一张反转的盘片，坑的位置对应其表面的突起，之后只需要直接用这个盘片压制加热的塑料再镀上反射膜就可以得到一张光盘，这种方式可以达到极高的写入速度\u003c/p\u003e\n\u003cp\u003e当然这种挖坑方式的一个重要特性就是不能修改已经写入的内容的，很难填上一个已经挖了的坑（当然通过特殊的制造材料和工艺也是可以做到的），这也就是说里面存储的数据是 append only 的，想要修改之前的内容可以采用可持久化二叉树的结构\u003c/p\u003e\n\u003cp\u003e光盘作为存储设备，价格低的同时容量和可靠性都比较高，同时顺序读性能一般，随机读性能低并且很难写入，一个重要的应用常见就是数字时代的内容分发\u003c/p\u003e\n\u003cp\u003e现代这种挖坑的存储方式还有一种应用方式是回归古人石碑的形式，把信息刻在很稳定的材料上来做到永久存储\u003c/p\u003e\n\u003ch2 id=\"1-bit-的存储电荷\"\u003e1-Bit 的存储：电荷\u003c/h2\u003e\n\u003cp\u003e前两种存储介质都存在比较大的缺陷：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e磁：依赖机械部件，从而无法避免 ms 级别的延迟\u003c/li\u003e\n\u003cli\u003e坑（光）：挖坑效率低，同时填坑很困难\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e而电荷则是一种非常理想的存储介质：电子的密度极高，并且电路的速度极快（还天然并行）\u003c/p\u003e\n\u003cp\u003e在电路中实现 1-bit 的持久存储，一个想法是我们可以挖一个坑，两种状态分别是：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e在坑里填入电子\u003c/li\u003e\n\u003cli\u003e从坑里放跑电子\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e而这就得到了\u003cstrong\u003e闪存 (Flash Memory)\u003c/strong\u003e ：\n\u003cimg loading=\"lazy\" src=\"/images/21-%E5%AD%98%E5%82%A8%E8%AE%BE%E5%A4%87%E5%8E%9F%E7%90%86/pasted-image-20250805112704.png\"\u003e\n其作为存储设备，价格低，容量和可靠性高，而且读写性能极高（由于电路天然并行，所以容量越大，速度越快）\u003c/p\u003e\n\u003cp\u003e然而，闪存的物理原理也带来了其固有的缺陷，即\u003cstrong\u003e会磨损 (wear out)\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e每次放电 (erase) 操作都无法 100% 将电子放干净，这会对存储单元造成微小的、不可逆的损伤\u003c/li\u003e\n\u003cli\u003e在经历数千或数万次擦写循环后，一些存储单元会因为累积的损伤而失效，无法再可靠地存储数据，这被称为 “\u003cstrong\u003e死单元 (Dead Cell)\u003c/strong\u003e”\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e为了解决闪存的磨损问题，并将其更好地呈现给操作系统，现代固态存储设备（如 SSD、U 盘、SD 卡）内部实际上都集成了一个微型计算机系统\u003c/p\u003e\n\u003cp\u003e这个系统运行着一层被称为 \u003cstrong\u003eFTL (Flash Translation Layer)\u003c/strong\u003e 的固件，它的核心功能之一是 \u003cstrong\u003e磨损均衡 (Wear Leveling)\u003c/strong\u003e\u003c/p\u003e","title":"21. 存储设备原理"},{"content":"输入输出设备 Everything is a File 在 Unix-like 系统中，与外部设备交互的核心思想是 Everything is a File\n文件描述符 (File Descriptor)：操作系统为上层软件提供了一个统一的抽象，即文件描述符，它是一个指向内核中任何 I/O 对象的“指针”或句柄\n统一接口：无论是普通文件、硬件设备（如终端、磁盘）、还是网络连接，都可以通过 open 获得一个文件描述符，然后使用相同的 read/write 等系统调用来进行操作，这极大地简化了应用程序的编写\n设备控制器与 MMIO “文件”这个美好的抽象背后，是具体的硬件工作原理\n设备控制器 (Device Controller)：每个 I/O 设备都有一个控制器，它是一个包含 CPU、内存和寄存器的微型计算机，作为 CPU 和物理设备之间的桥梁\n设备寄存器：控制器通过一组寄存器与 CPU 通信，通常包括：\n状态寄存器：用于表示设备当前是否繁忙、是否准备好等 指令寄存器：CPU 写入指令，告诉设备要做什么 数据寄存器：用于在 CPU 和设备之间传输数据 内存映射 I/O (MMIO)：为了让 CPU 能访问这些寄存器，现代系统普遍采用 MMIO (Memory-Mapped I/O)，操作系统会将设备的寄存器映射到物理内存地址空间中的特定区域，这样一来，CPU 就可以像访问普通内存一样，使用标准的 load/store 指令来读写设备寄存器，从而实现对设备的控制\nGPIO GPIO (General-Purpose Input/Output) 是理解 I/O 设备原理最直观的例子，GPIO 就是一个物理引脚，可以通过编程设置为输入或输出模式\n通过 MMIO，一个 GPIO 引脚的电平状态被映射到一个特定的内存地址，当 CPU 向这个地址写入 1 时，引脚就变为高电平；写入 0 时，则变为低电平，这个过程将一条内存写指令直接转化为了一个物理世界的动作（比如点亮一个 LED）\n输入输出设备案例 串口与键盘 经典的 I/O 设备，展示了最基础的设备交互方式\n端口 I/O：它们通常使用端口 I/O (Port I/O) 与 CPU 通信，设备寄存器被映射到专用的 I/O 端口地址（而非内存地址），CPU 需要使用特殊的 in/out 指令来读写这些端口\n向指定端口写入不同的数值，相当于向设备发送不同的指令（如设置波特率、控制键盘 LED 灯），而从指定端口读取数据则是接收设备的状态或输入（如串口收到的字符、键盘按键的扫描码）\n磁盘控制器与 PIO 早期的磁盘控制器（如 ATA/IDE）展示了一种更复杂但效率较低的交互模式：PIO 协议：全称为Programmed I/O，在这种模式下，数据的传输完全由 CPU 控制\n工作流程：\nCPU 向磁盘控制器的指令寄存器写入命令（如“读取第 N 个扇区”） CPU 进入轮询 (Polling) 状态，反复读取状态寄存器，直到设备报告“数据准备就绪” CPU 在一个循环中，逐个字节或字地将数据从磁盘的数据寄存器读入 CPU 寄存器，再写入内存 缺点：在轮询和数据传输期间，CPU 被完全占用，无法执行其他任务，效率极其低下\n打印机与 DSL 打印机这类设备，将交互模型提升到了一个新的高度\n领域专用语言 (DSL)：打印机不是简单地接收像素数据，而是作为一个独立的计算机，接收并解释用页面描述语言（如 PostScript 或 PCL）编写的“程序”\nCPU（驱动程序）的角色更像是一个编译器，将应用程序的打印请求（如一个 Word 文档）编译成一串 PostScript 指令流，然后发送给打印机\n打印机内部的处理器负责执行这些指令，将抽象的描述（如“在这里画一条线”、“使用这个字体显示文本”）翻译成打印头的物理动作\n总线与可扩展性 单个计算机系统需要连接多种多样的设备，这就需要一个标准化的扩展机制——总线 (Bus)\n总线是一组共享的电子线路，它定义了一套协议，允许 CPU、内存和多个 I/O 设备之间进行通信，它提供了一种“设备虚拟化”，CPU 只需与总线控制器通信，由总线负责将请求转发到正确的设备\n可扩展性：通过标准的扩展插槽（如早期的 ISA、现代的 PCIe），用户可以向系统中添加无穷无尽的新设备，而无需修改主板或 CPU 的设计 PCIe 总线与 DMA PCIe (PCI Express) 是目前主流的高速总线标准，它引入了一项革命性的技术来解决 PIO 的效率问题：DMA，全称为直接内存访问 (Direct Memory Access)，它允许设备控制器在没有 CPU 干预的情况下，直接与主内存进行数据传输\n工作流程：\nCPU 设置 DMA 控制器，告诉它源地址、目标地址和传输大小 CPU 向设备发出“开始传输”的指令后，就可以去执行其他任务了 DMA 控制器全权负责数据的搬运 传输完成后，DMA 控制器通过中断通知 CPU 优势：DMA 极大地解放了 CPU，使其不需要负责搬运数据，从而显著提升了整个系统的 I/O 吞吐量和效率，是所有现代高性能设备（显卡、NVMe 硬盘、高速网卡）的基础\n设备驱动程序 file_operations 结构体 操作系统内核通过名为 file_operations 的结构体落实“Everything is a File”的思想\n核心机制：这个结构体本质上是一个函数指针列表，定义了一系列标准的文件操作，如 read, write, open, llseek, ioctl 等\n驱动的本质：一个设备驱动程序 (Device Driver) 的核心，就是为特定的硬件或虚拟设备，提供一套具体的 file_operations 实现，当一个设备被注册到系统中时，内核就会将这个设备的“文件”与这套操作函数关联起来\n驱动的翻译职责 设备驱动程序的核心职责，就是翻译应用程序和物理硬件之间的交互\n翻译过程：当一个用户程序对文件描述符执行系统调用时（例如 read(fd, buf, size)），内核会：\n通过 fd 找到对应的内核文件对象 从文件对象中找到关联的 file_operations 结构体 调用其中的 .read 函数指针，并将系统调用的参数传递过去 驱动的实现：驱动程序中的 .read 函数则负责执行设备相关的底层操作，比如通过 MMIO 或 PIO 向设备控制器发送指令，等待数据就绪，然后将数据从设备寄存器中读出，最后复制到用户空间的 buf 中\n虚拟设备：这个模型同样适用于虚拟设备，例如对 /dev/null 的 write 操作，其驱动实现仅仅是直接返回写入的字节数，而什么也不做，对 /proc/stat 的 read 操作，则是读取内核中的统计数据并格式化成字符串返回\nioctl 万能接口 对于读写数据流之外的设备控制和配置需求（如设置键盘重复率、获取磁盘健康信息、配置网络参数等），read/write 模型显然不能满足，为此，Unix 系统提供了一个通用的 ioctl (I/O Control) 系统调用\nioctl 是一个高度灵活的接口，它的具体行为完全由设备驱动程序定义，应用程序通过传递一个设备专属的命令码和参数，来执行特定的控制功能\n虽然强大，但 ioctl 也带来了巨大的复杂性，因为每个设备的命令集都不同，形成了一系列隐藏的、非标准的协议，应用程序需要知道这些细节才能与设备深度交互（是巨大的屎山💩）\n实际案例：\nlibc 缓冲：libc 库通过对文件描述符 1 (stdout) 执行一个 tty 设备专属的 ioctl 命令（如 TCGETS），来判断输出目标是否为一个交互式终端，从而决定是采用行缓冲还是全缓冲\nKVM 虚拟化：KVM 就是一个通过 ioctl 暴露全部功能的复杂设备，用户程序打开 /dev/kvm 后，通过一系列 ioctl 命令（如 KVM_CREATE_VM, KVM_SET_REGS, KVM_RUN）来创建虚拟机、设定 CPU 状态并运行虚拟机，直到发生 VM Exit 事件返回到用户态\n","permalink":"https://diefish1024.github.io/posts/class-notes/nju-os-2025/20-%E8%AE%BE%E5%A4%87%E5%92%8C%E9%A9%B1%E5%8A%A8%E7%A8%8B%E5%BA%8F/","summary":"\u003ch2 id=\"输入输出设备\"\u003e输入输出设备\u003c/h2\u003e\n\u003ch3 id=\"everything-is-a-file\"\u003eEverything is a File\u003c/h3\u003e\n\u003cp\u003e在 Unix-like 系统中，与外部设备交互的核心思想是 \u003cstrong\u003eEverything is a File\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e文件描述符 (File Descriptor)\u003c/strong\u003e：操作系统为上层软件提供了一个统一的抽象，即文件描述符，它是一个指向内核中任何 I/O 对象的“指针”或句柄\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e统一接口\u003c/strong\u003e：无论是普通文件、硬件设备（如终端、磁盘）、还是网络连接，都可以通过 \u003ccode\u003eopen\u003c/code\u003e 获得一个文件描述符，然后使用相同的 \u003ccode\u003eread\u003c/code\u003e/\u003ccode\u003ewrite\u003c/code\u003e 等系统调用来进行操作，这极大地简化了应用程序的编写\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"设备控制器与-mmio\"\u003e设备控制器与 MMIO\u003c/h3\u003e\n\u003cp\u003e“文件”这个美好的抽象背后，是具体的硬件工作原理\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e设备控制器 (Device Controller)\u003c/strong\u003e：每个 I/O 设备都有一个控制器，它是一个包含 CPU、内存和寄存器的微型计算机，作为 CPU 和物理设备之间的桥梁\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e设备寄存器\u003c/strong\u003e：控制器通过一组\u003cstrong\u003e寄存器\u003c/strong\u003e与 CPU 通信，通常包括：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e状态寄存器\u003c/strong\u003e：用于表示设备当前是否繁忙、是否准备好等\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e指令寄存器\u003c/strong\u003e：CPU 写入指令，告诉设备要做什么\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e数据寄存器\u003c/strong\u003e：用于在 CPU 和设备之间传输数据\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e内存映射 I/O (MMIO)\u003c/strong\u003e：为了让 CPU 能访问这些寄存器，现代系统普遍采用 \u003cstrong\u003eMMIO (Memory-Mapped I/O)\u003c/strong\u003e，操作系统会将设备的寄存器映射到物理内存地址空间中的特定区域，这样一来，CPU 就可以像访问普通内存一样，使用标准的 \u003ccode\u003eload\u003c/code\u003e/\u003ccode\u003estore\u003c/code\u003e 指令来读写设备寄存器，从而实现对设备的控制\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"gpio\"\u003eGPIO\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003eGPIO (General-Purpose Input/Output)\u003c/strong\u003e 是理解 I/O 设备原理最直观的例子，GPIO 就是一个物理引脚，可以通过编程设置为输入或输出模式\u003c/p\u003e\n\u003cp\u003e通过 MMIO，一个 GPIO 引脚的电平状态被映射到一个特定的内存地址，当 CPU 向这个地址写入 \u003ccode\u003e1\u003c/code\u003e 时，引脚就变为高电平；写入 \u003ccode\u003e0\u003c/code\u003e 时，则变为低电平，这个过程将一条内存写指令直接转化为了一个物理世界的动作（比如点亮一个 LED）\u003c/p\u003e","title":"20. 设备和驱动程序"},{"content":"CPU 内的并行编程 CPU 的功耗 $ P=C\\cdot V^{2}\\cdot f $ 导致纵使有更大的电路，热功耗限制了性能上限，从而有一堵“功耗墙”限制了 CPU 的性能，为此需要考虑如何在降低 $ V $ 和 $ f $ 的同时用面积换性能\n有两个思路：\n让一条指令能处理更多的数据：SIMD (Single Instruction, Multiple Data)\n“一条指令” 浪费的能量大致是定数 处理的数据越多，浪费越少 用更多更简单的处理器：多处理器系统、异构多处理器\n同等面积，处理器越简单，数量越多 异构计算：最经典的例子是大小核架构（如 Apple M1） SIMD SIMD 的核心思想是在硬件层面实现数据级并行，它通过引入专门的硬件单元来达成这个目标：\n宽位寄存器 (Wide Registers)：CPU 内部增加了比通用寄存器宽很多的专用寄存器\nIntel 的 SSE 指令集引入了 128 位的 XMM 寄存器，而最新的 AVX-512 拥有 512 位的 ZMM 寄存器 这些宽位寄存器可以一次性装入多个数据元素，比如一个 128 位的寄存器可以同时容纳 4 个 32 位的浮点数，或者 16 个 8 位的整数 这些被打包在一起的数据被称为 Vector 向量处理单元 (Vector ALU)：CPU 内部也配备了能够对整个向量进行并行计算的 ALU\n当执行一条 SIMD 指令时，这个特殊的 ALU 会在同一个时钟周期内，同时对寄存器中的 4 对浮点数分别执行操作 例子：假设我们要计算两个数组 A 和 B 的和，存入数组 C，每个数组都有 4 个元素。\nTraditional：\nload A[0] load B[0] add -\u0026gt; store C[0] load A[1] load B[1] add -\u0026gt; store C[1] \u0026hellip; 重复 4 次，需要执行 4 轮独立的“load-compute-store”指令 SIMD：\nLOAD：将数组 A 的 4 个元素一次性加载到一个 128 位的 XMM 寄存器中 LOAD：将数组 B 的 4 个元素加载到另一个 XMM 寄存器中 VADDPS：CPU 的向量处理单元对这两个寄存器中的 4 对元素 同时 进行加法运算 STORE：将计算结果寄存器中的 4 个和值一次性存回内存中的数组 C 通过这种方式，原来需要循环多次的计算被压缩成了几条高效的向量指令，极大地提升了吞吐率，尤其是在图像处理、视频编解码、科学计算和人工智能等需要大量重复性计算的领域，效果非常显著\nGPU 和 GPGPU 第二种克服“功耗墙”的思路——使用更多、更简单的处理器——直接催生了 GPU (Graphics Processing Unit) 的发展，它最初为图形渲染这种高度并行的任务而设计，其架构被证明非常有效，最终演变成了一个通用计算的强大引擎\n从 PPU 到 GPU 对专用图形硬件的需求在早期游戏机中就很明显：CPU 在渲染方面效率极低，计算屏幕上每个像素的颜色，每秒重复 60 次，这种“大规模并行”任务会完全压垮为串行任务设计的 CPU\n早期方案 - PPU：早期系统将图形任务交给 PPU (Picture Processing Unit) 处理，这是一种领域专用硬件，它操作的是高级图形对象，如 tiles (8x8 像素块) 和 sprites (可移动的前景角色)，而非单个像素，CPU 的工作被简化为告诉 PPU 该画 哪个 图块以及画在 哪里\n固定功能 Pipeline：随着 3D 图形的出现，简单的 PPU 模型演变为更复杂但仍然固化的 “固定功能管线” (Fixed-Function Pipeline)，它有一系列硬件实现的固定阶段，虽然功能强大，但除了调整预设参数外，几乎没有创造性空间\n随后开发者为了自定义视觉效果，把图形管线中的关键部分被替换为可编程单元，发展出了可编程的特性\n这种可编程性赋予了开发者前所未有的控制力，也标志着现代 GPU 的诞生\nGPGPU 人们很快意识到，一个为像素并行执行数百万个简单程序的芯片，用途远不止于图形\n早期的 hack ：最初的 GPGPU (General-Purpose computing on GPU) 是开发者将一个科学问题（如矩阵乘法）伪装成一个图形任务，例如将矩阵作为“纹理”加载，然后编写一个“片元着色器”来进行乘法计算，最后将结果“颜色”写出 演变为计算平台：这种强大但繁琐的方法证明了其可行性，硬件厂商（比如 Nvidia）随即推出了专用的编程框架（CUDA）和开放标准（OpenCL），这些平台彻底剥离了图形接口，将 GPU 强大的并行计算能力直接暴露给开发者 AI 时代的并行编程 随着 GPGPU 平台的成熟，可编程的 Shader 模型也演变成了更通用的线程模型，最终在 AI 时代大放异彩\nSIMT：单指令，多线程 CUDA 编程模型的核心是 SIMT (Single Instruction, Multiple Threads)，这是对 SIMD 思想的扩展\nGPU 程序中每个像素执行一次的“着色器”，在 CUDA 被看作是一个 Kernel 函数，会被成千上万甚至数百万个 线程 并行执行\nSIMT 的魔法在于，GPU 会将线程分组（通常 32 个线程为一个 Warp），一个 Warp 内的所有线程共享同一个程序计数器 (PC)，在硬件层面，它们在同一时刻执行完全相同的指令\n这实际上创造了一种类似巨型 SIMD 的效果，每个线程虽然有自己独立的寄存器和数据（通过 threadIdx 等内置变量区分），但它们的执行流被捆绑在一起，这使得控制单元的设计可以极其简化，从而在芯片上集成海量的计算核心\nChallenges SIMT 架构在带来巨大并行优势的同时，也给带来了挑战：\n内存合并 (Memory Coalescing)：当一个 Warp 中的多个线程连续访问内存时，GPU 硬件能将这 32 个独立的访问请求合并成一笔或几笔大的内存事务，这是 CUDA 性能优化的关键\n分支发散 (Branch Divergence)：SIMT 最大的难点在于处理分支，如果一个 Warp 内的线程在 if-else 语句上做出不同选择，由于它们共享同一个 PC，硬件必须串行地执行 if 路径和 else 路径，并在执行每个路径时，将另一部分线程暂时屏蔽，这会使 Warp 的执行速度取决于内部执行最慢的线程\n共享内存 (Shared Memory)：虽然 CUDA 线程可以访问共享内存，但如何避免访问冲突 (Bank Conflict)，如何组织数据以最大化并行加载，都会增加 CUDA 程序的编写难度\n尽管编写高效的 CUDA 程序充满挑战，但其回报是巨大的，尤其对于那些计算密集、模式固定的任务，例如深度学习中的矩阵乘法和卷积运算，GPU 能提供比 CPU 高出数个数量级的性能和能效比\n","permalink":"https://diefish1024.github.io/posts/class-notes/nju-os-2025/19-%E7%9C%9F%E5%AE%9E%E4%B8%96%E7%95%8C%E7%9A%84%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B-2/","summary":"\u003ch2 id=\"cpu-内的并行编程\"\u003eCPU 内的并行编程\u003c/h2\u003e\n\u003cp\u003eCPU 的功耗 $ P=C\\cdot V^{2}\\cdot f $ 导致纵使有更大的电路，热功耗限制了性能上限，从而有一堵“功耗墙”限制了 CPU 的性能，为此需要考虑如何在降低 $ V $ 和 $ f $ 的同时用面积换性能\u003c/p\u003e\n\u003cp\u003e有两个思路：\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e让一条指令能处理更多的数据\u003c/strong\u003e：SIMD (Single Instruction, Multiple Data)\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e“一条指令” 浪费的能量大致是定数\u003c/li\u003e\n\u003cli\u003e处理的数据越多，浪费越少\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e用更多更简单的处理器\u003c/strong\u003e：多处理器系统、异构多处理器\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e同等面积，处理器越简单，数量越多\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e异构计算\u003c/strong\u003e：最经典的例子是\u003cstrong\u003e大小核架构\u003c/strong\u003e（如 Apple M1）\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch3 id=\"simd\"\u003eSIMD\u003c/h3\u003e\n\u003cp\u003eSIMD 的核心思想是在硬件层面实现数据级并行，它通过引入专门的硬件单元来达成这个目标：\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e宽位寄存器 (Wide Registers)\u003c/strong\u003e：CPU 内部增加了比通用寄存器宽很多的专用寄存器\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eIntel 的 SSE 指令集引入了 128 位的 XMM 寄存器，而最新的 AVX-512 拥有 512 位的 ZMM 寄存器\u003c/li\u003e\n\u003cli\u003e这些宽位寄存器可以一次性装入多个数据元素，比如一个 128 位的寄存器可以同时容纳 4 个 32 位的浮点数，或者 16 个 8 位的整数\u003c/li\u003e\n\u003cli\u003e这些被打包在一起的数据被称为 Vector\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e向量处理单元 (Vector ALU)\u003c/strong\u003e：CPU 内部也配备了能够对整个向量进行并行计算的 ALU\u003c/p\u003e","title":"19. 真实世界的并发编程 (2)"},{"content":"并发编程的核心抽象是实现一个计算图，计算发生在节点上，边表示节点之间的依赖关系，同时计算图在运行时可能是动态变化的\n使用条件变量、锁、信号量等 api 去实现计算图并不是一个优雅的实现方式，因为这样会在代码中引入众多干扰代码，也可能导致一些问题\n为此可以增加一些功能受限的语法，可以在同样描述计算图的功能下减少了许多潜在的问题\n高性能计算中的并行编程 在高性能计算中，计算图通常易于静态切分，尤其适用于物理模拟的网格划分，为此 HPC 发展出多种高效的并行编程模型，具体学习可以参考 SJTU HPC 学习手册\nMPI: 分布式内存并行 每个 MPI 进程有独立的内存空间，进程间通过显式消息传递（发送/接收）交换数据\nOpenMP: 共享内存并行 多个线程在同一地址空间中并行执行，所有线程可以直接访问相同的数据，使用 #pragma omp 指令实现并行化\n对非计算机专业来说非常友好，只需要在正常的代码上面加上编译指令即可，能轻松实现高效的并行优化\nCUDA: GPU 异构并行 CPU 调度，GPU 执行大规模并行计算\n概念：\n核函数 (Kernel) ：在 GPU 上并行执行的函数 线程层次：线程 (threadIdx) 组成线程块 (blockIdx)，线程块组成网格 (gridDim) 内存层次：寄存器、共享内存（块内高速）、全局内存（所有线程可访问） 我们身边的并发编程 从 Web 1.0 到 Web 2.0 在 Web 时代用的最广泛的是 Javascript\nAsynchronous JavaScript and XML (Ajax; ~1999) 允许网页实现“后台刷新” jQuery $ (2006): A DOM Query Language (编程抽象) Web 2.0 时代的并发编程 线程开销大，并且大多数 Web 开发者难以进行并发编程\n从而有了event-based concurrency (动态计算图) 的机制：禁止任何计算节点并行（和高性能计算的选择不同）\n允许网络请求、sleep 在后台进行（这才是主要开销），执行完之后产生新的计算节点 事件可以在浏览器里看到 直接用这样的方式描述计算图会产生大量屎山代码 (Callback hell) ，现代的选择是动态描述计算图\n数据中心的并发编程 数据中心以海量分布式数据为中心，需要处理的需求有：\n实时的“小数据”处理：内容分发、弹幕…… 离线的“大数据”处理：内容索引、数据挖掘…… 为 AI 提供支持 数据中心里的并发编程需要满足高吞吐量和低延迟的特点，难点在于：\n处理事件可能需要读写持久存储或请求网络上的服务，从而导致延迟不确定 线程维护和上下文切换都会带来开销 在数据中心进行并发编程时，传统的通过手动管理线程、锁等低级并发原语的方式变得越来越复杂且难以扩展，因此今天的解决方案是无服务器计算 (Serverless Computing) ，特别是函数即服务 (Function as a Service, FaaS) ，其优势在于\n开发人员不再需要直接处理底层的并发问题 FaaS 函数通常是短暂的、无状态的，并且每个请求通常触发一个独立的函数实例，不同的函数实例之间通常不共享内存，这从根本上规避了传统多线程编程中由于共享内存问题 这样的范式使得现代存储系统实现高可靠、低延迟的多副本分布式存储和计算变得非常 Challenge ，数据一致性、服务时刻可用和容忍机器离线三个特性不可以兼得 协程 协程是一种程序组件，与线程在概念上有一些相似之处，比如都在进程内部拥有独立的栈帧，并能在运行时维护自己的状态，可以看作是一个共享内存的状态机\n然而，协程与线程最大的不同在于它们的调度方式和上下文切换开销：\n协作式调度：协程的执行是协作式的，会“一直执行” ，直到遇到 yield() 等指令时，才会主动放弃处理器控制权，将执行权交还给调用者或调度器，这与线程的抢占式调度（由操作系统决定何时中断和切换）不同\n操作系统“不感知”的上下文切换：当协程通过 yield() 进行切换时，这仅仅是一个函数调用级别的操作，不需要像线程切换那样，保存和恢复完整的上下文信息，因此这种切换开销非常小，并且是操作系统完全不感知\n阻塞 I/O 的局限性：由于协程是协作式执行的，如果在一个协程内部执行了阻塞性操作（如耗时的 I/O 操作或 sleep()），那么当前所在的整个操作系统线程都会被卡住，这意味着所有在该线程上运行的协程都将停止执行，从而失去了并行\n示例\n1 2 3 4 5 6 7 8 9 10 11 import random def T_worker(name): i = 0 while (i := i + 1): print(f\u0026#39;[{name}] i = {i}\u0026#39;) yield() threads = [T_worker(i) for i in range(1000000)] while True: random.choice(threads).send(None) 这个例子很好地阐释了协程的特点：\n在同一个操作系统线程中执行：虽然创建了非常多个 T_worker 对象，但它们都运行在程序的同一个操作系统线程中，开销远小于创建相同数量个操作系统线程 由程序控制调度：while True: random.choice(threads).send(None) 这段代码是自定义的简单调度器，它随机选择一个协程并激活它，使其执行直到遇到 yield() 暂停，然后再选择下一个协程 资源占用极低：由于不涉及操作系统层面的上下文切换，除了协程本身所需要的一小块内存用于保存其栈帧和状态外，协程不占用额外的操作系统资源，因此可以创建海量的协程实例，非常适合高并发的 I/O 密集型任务。 ","permalink":"https://diefish1024.github.io/posts/class-notes/nju-os-2025/18-%E7%9C%9F%E5%AE%9E%E4%B8%96%E7%95%8C%E7%9A%84%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B-1/","summary":"\u003cp\u003e并发编程的核心抽象是实现一个计算图，计算发生在节点上，边表示节点之间的依赖关系，同时计算图在运行时可能是动态变化的\u003c/p\u003e\n\u003cp\u003e使用条件变量、锁、信号量等 api 去实现计算图并不是一个优雅的实现方式，因为这样会在代码中引入众多\u003cstrong\u003e干扰代码\u003c/strong\u003e，也可能导致一些问题\u003c/p\u003e\n\u003cp\u003e为此可以增加一些功能受限的\u003cstrong\u003e语法\u003c/strong\u003e，可以在同样描述计算图的功能下减少了许多潜在的问题\u003c/p\u003e\n\u003ch2 id=\"高性能计算中的并行编程\"\u003e高性能计算中的并行编程\u003c/h2\u003e\n\u003cp\u003e在高性能计算中，计算图通常易于\u003cstrong\u003e静态切分\u003c/strong\u003e，尤其适用于物理模拟的网格划分，为此 HPC 发展出多种高效的并行编程模型，具体学习可以参考 \u003ca href=\"https://xflops.sjtu.edu.cn/hpc-start-guide/parallel-computing/basic/\"\u003eSJTU HPC 学习手册\u003c/a\u003e\u003c/p\u003e\n\u003ch4 id=\"mpi-分布式内存并行\"\u003eMPI: 分布式内存并行\u003c/h4\u003e\n\u003cp\u003e每个 MPI 进程有独立的内存空间，进程间通过\u003cstrong\u003e显式消息传递\u003c/strong\u003e（发送/接收）交换数据\u003c/p\u003e\n\u003ch4 id=\"openmp-共享内存并行\"\u003eOpenMP: 共享内存并行\u003c/h4\u003e\n\u003cp\u003e多个线程在同一地址空间中并行执行，所有线程可以直接访问相同的数据，使用 \u003ccode\u003e#pragma omp\u003c/code\u003e 指令实现并行化\u003c/p\u003e\n\u003cp\u003e对非计算机专业来说非常友好，只需要在正常的代码上面加上编译指令即可，能轻松实现高效的并行优化\u003c/p\u003e\n\u003ch4 id=\"cuda-gpu-异构并行\"\u003eCUDA: GPU 异构并行\u003c/h4\u003e\n\u003cp\u003eCPU 调度，GPU 执行大规模并行计算\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e概念\u003c/strong\u003e：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e核函数 (Kernel)\u003c/strong\u003e ：在 GPU 上并行执行的函数\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e线程层次\u003c/strong\u003e：线程 (\u003ccode\u003ethreadIdx\u003c/code\u003e) 组成线程块 (\u003ccode\u003eblockIdx\u003c/code\u003e)，线程块组成网格 (\u003ccode\u003egridDim\u003c/code\u003e)\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e内存层次\u003c/strong\u003e：寄存器、共享内存（块内高速）、全局内存（所有线程可访问）\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"我们身边的并发编程\"\u003e我们身边的并发编程\u003c/h2\u003e\n\u003ch4 id=\"从-web-10-到-web-20\"\u003e从 Web 1.0 到 Web 2.0\u003c/h4\u003e\n\u003cp\u003e在 Web 时代用的最广泛的是 Javascript\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eAsynchronous JavaScript and XML\u003c/strong\u003e (Ajax; ~1999)\n\u003cul\u003e\n\u003cli\u003e允许网页实现“后台刷新”\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003ejQuery $ (2006): A DOM Query Language\u003c/strong\u003e (编程抽象)\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4 id=\"web-20-时代的并发编程\"\u003eWeb 2.0 时代的并发编程\u003c/h4\u003e\n\u003cp\u003e线程开销大，并且大多数 Web 开发者难以进行并发编程\u003c/p\u003e","title":"18. 真实世界的并发编程 (1)"},{"content":"数据竞争 大多并发 bug 最后都会体现为数据竞争 (Data Race)\n对于顺序程序而言，函数 f() 返回之后就已经完成了所有的状态修改，对于其他部分而言这个修改是立即生效的；如果对于并发程序而言模式的切换也在瞬间完成，那就不会导致并发的问题\n然而实际上模式的切换需要时间，执行的操作在未来一段时间之后才会就绪，但是我们在实际编程时总是容易有“立即生效”的肌肉记忆，这就导致了并发问题的可能性\n不过对于函数式编程而言，操作不存在对外状态的修改，没有副作用（只会操作局部变量），这就不会导致并发问题\nData Race 发生的实质是不同的线程同时访问同一内存，并且至少有一个是写，形象的理解就是不同的内存访问在“赛跑”，跑赢的操作先执行\nNot that easy: 虽然我们将数据竞争形象地比喻为“赛跑”，但实际上，哪一个操作能“跑赢”并没有想象中那么简单和确定，其复杂性主要体现在以下几个方面\n弱内存模型 (Weak memory model)：在现代处理器架构中，为了提升性能，处理器可能会对内存操作进行重排序。这意味着，不同的线程或“观察者”在不同时间点看到共享内存的状态可能是不一致的。一个线程对内存的写入操作，可能不会立即对所有其他线程可见，导致不同线程观察到不同的结果。这种内存模型的一致性问题使得确定哪个操作“先发生”变得非常困难且不确定。\n未定义行为 (Undefined Behavior)：从 C++11 标准开始，数据竞争被明确规定为未定义行为。这意味着，如果你的程序发生了数据竞争，编译器可以自由地产生任何行为，无论是崩溃、产生错误结果，还是看似正常运行但结果不可预测。这使得数据竞争成为非常危险且难以调试的并发错误，因为它的表现可能是不确定、不稳定的。\n多线程与多内存的复杂交互：在实际的并发程序中，通常会有多个线程同时访问多个共享内存位置。这些线程和内存之间存在复杂的读（R）写（W）交互。一个线程对一个内存位置的写入可能影响到其他多个线程对该位置的读取，同时，多个内存位置之间也可能存在复杂的依赖关系和缓存一致性问题。这种错综复杂的交互网络进一步加剧了数据竞争的不可预测性。\n为了消灭数据竞争，我们需要保证程序的 serializability ，可能竞争的内存访问要么互斥，要么同步\n实际编程中遇到的数据竞争 bug 大多属于上错了锁和忘记上锁两种情况的变种\nCase 1: 上错了锁\n1 2 void T_1() { spin_lock(\u0026amp;A); sum++; spin_unlock(\u0026amp;A); } void T_2() { spin_lock(\u0026amp;B); sum++; spin_unlock(\u0026amp;B); } Case 2: 忘记上锁\n1 2 void T_1() { spin_lock(\u0026amp;A); sum++; spin_unlock(\u0026amp;A); } void T_2() { sum++; } 但是实际系统面临的情况比这复杂的多，因为\n内存可以是地址空间的任何内存，比如全局变量、堆内存分配的变量、程序的栈…… 访问可以发生在任何代码，比如自己的代码、框架代码、一行没读到的汇编指令、某条 ret 指令 “一行没读到的汇编指令”造成的访问的情况有编译器优化造成的指令重排、硬件层面弱内存模型的内存访问重排、还有一些高层语言操作的隐式内存访问 实际系统中虽然难以避免，但是会尽可能保证底层的结构对上层尽可能封闭来防止这种错误 死锁 死锁 (Deadlock) 是指一个群体中的每个成员都在等待其他成员（包括自身）采取行动的状态\n死锁有两种：\nAA-Deadlock: 自己等待自己\n1 2 3 4 5 6 7 lock(\u0026amp;lk); // lk-\u0026gt;locked == ✅; proceed ... // Possibly in interrupt handler lock(\u0026amp;lk); // while (lk-\u0026gt;locked == ❌) ; 这样的错误虽然看起来很傻，但是在真实程序复杂的控制流中是可能出现的\nABBA-Deadlock: 两个（多个）锁互相等待\n比如 16. 并发控制：同步信号量 中的哲学家吃饭问题\nHow? 想要消除死锁，可以从死锁产生的必要条件入手，通常称为霍尔德（Holt）条件， 可以形象地把锁看成袋子里的球：\n互斥 (Mutual-exclusion)： 一个口袋一个球，即资源是互斥的，一次只能被一个线程占用 如果资源可以共享（例如，只读文件），则不会发生死锁 请求并保持 (Wait-for)： 得到球的人想要更多的球，即一个线程在持有至少一个资源的同时，又在等待获取其他被占用的资源 如果线程在请求新资源时，必须释放所有已持有的资源，则可以避免死锁 不可抢占 (No-preemption)： 不能抢别人的持有的球，即资源不能被强制从持有者手中抢走，只能由持有者自愿释放 如果系统可以抢占资源（例如，通过中断强制释放），则可以打破此条件 循环等待 (Circular-chain)： 形成循环等待的关系，即存在一个线程链 $ T_1, T_2, \\ldots, T_n $，其中 $ T_1 $ 正在等待 $ T_2 $ 占用的资源，$ T_2 $ 正在等待 $ T_3 $ 占用的资源，依此类推，$ T_n $ 正在等待 $ T_1 $ 占用的资源 这四个条件是死锁发生的必要条件，这意味着只要打破任何一个条件，就不会发生死锁了，理论上，我们可以通过破坏这些条件来预防或避免死锁。\n然而，将这套理论应用于实际复杂系统时，会发现它是一个正确的废话，不能称为一个合理的 argument\n对于玩具系统/模型：可以直接证明系统是 deadlock-free 的，因为其状态空间有限，可以通过穷举或形式化方法进行验证 对于真正的复杂系统：很难判断哪个条件最容易被打破，或者说，在保证系统功能性和性能的前提下，打破某个条件可能带来巨大的复杂性或性能开销 实际编程中通常会采用其他策略来预防死锁：\n一个常见的方法是锁排序，其核心思想是：\n任意时刻系统中的锁都是有限的。 给所有锁编号（或者定义一个全局的获取顺序） 线程在获取多个锁时，严格按照从小数到大的顺序获取锁 这种策略也相对容易检查和验证。 这样在任意时刻总有一个线程获得“编号最大”的锁，于是这个线程总是可以继续运行\n然而这种方法在实践中会遇到问题，代码的文档并不总是可靠，并且对于复杂系统这是难以扩展的；而最好的锁是封装的，并不会暴露出来，这样使用代码的人甚至不需要知道正在使用锁\nSome Methods 为了应对死锁，尤其是 ABBA-Deadlock，一些工具被开发出来，例如 Linux 内核中的 LockDep\n一个简单的想法：\n每次 acquire/release 锁时，都打印一个日志 如果任何线程存在 $ A\\to B $ 和 $ B\\to A $ 的依赖关系，就报告死锁 这可能导致 false positives ，比如存在同步机制 ($ A\\to B\\to \\mathrm{spawn}\\to B\\to A $) 通过优化这个方法可以得到一个相对高效的实现：动态维护“锁依赖图“并检测环路\n原子性和顺序违反 并发编程是本质困难的，我们只能用 sequential 的方式来理解并发：把程序分成若干的块，每一块的操作都是原子的，无法被打断\n并发的机制可以分成两类：\n互斥锁实现原子性 忘记上锁会导致原子性违反 (Atomicity Violation, AV) 条件变量/信号量实现先后顺序同步 忘记同步会导致顺序违反 (Order Violation, OV) 并发的机制完全是“后果自负”的，这也导致了 Threads cannot be implemented as a library ，因为？\n有研究统计了很多真是系统存在的并发 bug，发现 97% 的非死锁并发 bug 都是原子性或顺序错误\nAtomic Violation 代码被别的线程“强行插入”，即使分别上锁消除了数据竞争，还是会导致 AV\n比如图中的例子：\n如果在 Thread 1 结束判断进入 if 之后 Thread 2 再执行，就导致了错误\n并且注意到操作系统的状态也是共享状态，利用一样的原理还可能产生更难发现的 bug\n攻击者在 check 之后马上替换文件为符号链接，就可以造成权限问题等严重安全漏洞\nOrder Violation 事件没有按照预定的顺序发生，就会导致 OV ，比如 如果 Thread 2 中的 S4 发生在了条件变量的初始化之前，那么相当于全局的广播被吞掉了，就可能会导致 Thread 1 可能无法被唤醒\nHowever 我们可以使用加强版的 LockDep 来解决这些问题，比如直接分析程序的日志，检查有没有不相交的锁，事件的 happens-before 关系是否正确……甚至也可以直接用启发式（或者 LLM ）来分析日志是否正确\n然而即使这样也不能解决真实世界的所有并发问题，比如这个 GhostRace 的例子\n实现了正确的互斥、正确的同步 $ \\text{use}\\to\\text{free} $ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 void T_A() { lock(\u0026amp;obj-\u0026gt;lock); free(obj-\u0026gt;something); obj-\u0026gt;something = NULL; unlock(\u0026amp;obj-\u0026gt;lock); } void T_B() { lock(\u0026amp;obj-\u0026gt;lock); if (obj-\u0026gt;something) { // changes cache on speculative execution } unlock(\u0026amp;obj-\u0026gt;lock); } 实际上导致问题的是现代 CPU 的推测执行的特性，为了提高效率会提前通过分治预测器预判执行的方向，提前执行指令\n这段代码中线程 $ T_{B} $ 的 CPU 会在正式获得锁并判断 NULL 之前就提前推测性执行 if 块内部的代码，如果此时 $ T_{A} $ 恰好释放了 obj-something 指向的内存，那么 $ T_{B} $ 中就会访问到一块已经被释放的内存，从而通过缓存等方式泄露信息（虽然错误执行的语句已经回滚了，但是被加载到缓存中的数据等不会回滚），通过这种方式就有可能访问到程序本来没有权限访问的内存，从而产生安全漏洞\n这种并发 bug 的根源在于软件层面的同步无法约束硬件层面的行为\n","permalink":"https://diefish1024.github.io/posts/class-notes/nju-os-2025/17-%E5%B9%B6%E5%8F%91-bugs/","summary":"\u003ch2 id=\"数据竞争\"\u003e数据竞争\u003c/h2\u003e\n\u003cp\u003e大多并发 bug 最后都会体现为\u003cstrong\u003e数据竞争 (Data Race)\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e对于顺序程序而言，函数 \u003ccode\u003ef()\u003c/code\u003e 返回之后就已经完成了所有的状态修改，对于其他部分而言这个修改是立即生效的；如果对于并发程序而言模式的切换也在瞬间完成，那就不会导致并发的问题\u003c/p\u003e\n\u003cp\u003e然而实际上模式的切换需要时间，执行的操作在未来一段时间之后才会就绪，但是我们在实际编程时总是容易有“立即生效”的肌肉记忆，这就导致了并发问题的可能性\u003c/p\u003e\n\u003cp\u003e不过对于\u003cstrong\u003e函数式编程\u003c/strong\u003e而言，操作不存在对外状态的修改，没有副作用（只会操作局部变量），这就不会导致并发问题\u003c/p\u003e\n\u003cp\u003eData Race 发生的实质是\u003cstrong\u003e不同的线程\u003c/strong\u003e同时访问\u003cstrong\u003e同一内存\u003c/strong\u003e，并且\u003cstrong\u003e至少有一个是写\u003c/strong\u003e，形象的理解就是不同的内存访问在“赛跑”，跑赢的操作先执行\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eNot that easy\u003c/strong\u003e: 虽然我们将数据竞争形象地比喻为“赛跑”，但实际上，哪一个操作能“跑赢”并没有想象中那么简单和确定，其复杂性主要体现在以下几个方面\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e弱内存模型 (Weak memory model)\u003c/strong\u003e：在现代处理器架构中，为了提升性能，处理器可能会对内存操作进行重排序。这意味着，不同的线程或“观察者”在不同时间点看到共享内存的状态可能是不一致的。一个线程对内存的写入操作，可能不会立即对所有其他线程可见，导致不同线程观察到不同的结果。这种\u003cstrong\u003e内存模型的一致性问题\u003c/strong\u003e使得确定哪个操作“先发生”变得非常困难且不确定。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e未定义行为 (Undefined Behavior)\u003c/strong\u003e：从 C++11 标准开始，数据竞争被明确规定为\u003cstrong\u003e未定义行为\u003c/strong\u003e。这意味着，如果你的程序发生了数据竞争，编译器可以自由地产生任何行为，无论是崩溃、产生错误结果，还是看似正常运行但结果不可预测。这使得数据竞争成为非常危险且难以调试的并发错误，因为它的表现可能是不确定、不稳定的。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e多线程与多内存的复杂交互\u003c/strong\u003e：在实际的并发程序中，通常会有多个线程同时访问多个共享内存位置。这些线程和内存之间存在复杂的读（R）写（W）交互。一个线程对一个内存位置的写入可能影响到其他多个线程对该位置的读取，同时，多个内存位置之间也可能存在复杂的依赖关系和缓存一致性问题。这种错综复杂的交互网络进一步加剧了数据竞争的不可预测性。\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e为了消灭数据竞争，我们需要保证程序的 serializability ，\u003cstrong\u003e可能竞争的内存访问要么互斥，要么同步\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e实际编程中遇到的数据竞争 bug 大多属于\u003cstrong\u003e上错了锁\u003c/strong\u003e和\u003cstrong\u003e忘记上锁\u003c/strong\u003e两种情况的变种\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eCase 1: 上错了锁\u003c/strong\u003e\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cdiv class=\"chroma\"\u003e\n\u003ctable class=\"lntable\"\u003e\u003ctr\u003e\u003ctd class=\"lntd\"\u003e\n\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode\u003e\u003cspan class=\"lnt\"\u003e1\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e2\n\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\n\u003ctd class=\"lntd\"\u003e\n\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-c\" data-lang=\"c\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"kt\"\u003evoid\u003c/span\u003e \u003cspan class=\"nf\"\u003eT_1\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e \u003cspan class=\"nf\"\u003espin_lock\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"o\"\u003e\u0026amp;\u003c/span\u003e\u003cspan class=\"n\"\u003eA\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e \u003cspan class=\"n\"\u003esum\u003c/span\u003e\u003cspan class=\"o\"\u003e++\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e \u003cspan class=\"nf\"\u003espin_unlock\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"o\"\u003e\u0026amp;\u003c/span\u003e\u003cspan class=\"n\"\u003eA\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e \u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"kt\"\u003evoid\u003c/span\u003e \u003cspan class=\"nf\"\u003eT_2\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e \u003cspan class=\"nf\"\u003espin_lock\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"o\"\u003e\u0026amp;\u003c/span\u003e\u003cspan class=\"n\"\u003eB\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e \u003cspan class=\"n\"\u003esum\u003c/span\u003e\u003cspan class=\"o\"\u003e++\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e \u003cspan class=\"nf\"\u003espin_unlock\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"o\"\u003e\u0026amp;\u003c/span\u003e\u003cspan class=\"n\"\u003eB\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e \u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\u003c/tr\u003e\u003c/table\u003e\n\u003c/div\u003e\n\u003c/div\u003e\u003cp\u003e\u003cstrong\u003eCase 2: 忘记上锁\u003c/strong\u003e\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cdiv class=\"chroma\"\u003e\n\u003ctable class=\"lntable\"\u003e\u003ctr\u003e\u003ctd class=\"lntd\"\u003e\n\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode\u003e\u003cspan class=\"lnt\"\u003e1\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e2\n\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\n\u003ctd class=\"lntd\"\u003e\n\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-c\" data-lang=\"c\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"kt\"\u003evoid\u003c/span\u003e \u003cspan class=\"nf\"\u003eT_1\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e \u003cspan class=\"nf\"\u003espin_lock\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"o\"\u003e\u0026amp;\u003c/span\u003e\u003cspan class=\"n\"\u003eA\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e \u003cspan class=\"n\"\u003esum\u003c/span\u003e\u003cspan class=\"o\"\u003e++\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e \u003cspan class=\"nf\"\u003espin_unlock\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"o\"\u003e\u0026amp;\u003c/span\u003e\u003cspan class=\"n\"\u003eA\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e \u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"kt\"\u003evoid\u003c/span\u003e \u003cspan class=\"nf\"\u003eT_2\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e \u003cspan class=\"n\"\u003esum\u003c/span\u003e\u003cspan class=\"o\"\u003e++\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e \u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\u003c/tr\u003e\u003c/table\u003e\n\u003c/div\u003e\n\u003c/div\u003e\u003cp\u003e但是实际系统面临的情况比这复杂的多，因为\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e内存可以是地址空间的任何内存，比如全局变量、堆内存分配的变量、程序的栈……\u003c/li\u003e\n\u003cli\u003e访问可以发生在任何代码，比如自己的代码、框架代码、一行没读到的汇编指令、某条 ret 指令\n\u003cul\u003e\n\u003cli\u003e“一行没读到的汇编指令”造成的访问的情况有编译器优化造成的指令重排、硬件层面弱内存模型的内存访问重排、还有一些高层语言操作的隐式内存访问\u003c/li\u003e\n\u003cli\u003e实际系统中虽然难以避免，但是会尽可能保证底层的结构对上层尽可能封闭来防止这种错误\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"死锁\"\u003e死锁\u003c/h2\u003e\n\u003cp\u003e\u003cstrong\u003e死锁 (Deadlock)\u003c/strong\u003e 是指一个群体中的每个成员都在等待其他成员（包括自身）采取行动的状态\u003c/p\u003e\n\u003cp\u003e死锁有两种：\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eAA-Deadlock\u003c/strong\u003e: 自己等待自己\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cdiv class=\"chroma\"\u003e\n\u003ctable class=\"lntable\"\u003e\u003ctr\u003e\u003ctd class=\"lntd\"\u003e\n\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode\u003e\u003cspan class=\"lnt\"\u003e1\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e2\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e3\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e4\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e5\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e6\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e7\n\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\n\u003ctd class=\"lntd\"\u003e\n\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-c\" data-lang=\"c\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"nf\"\u003elock\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"o\"\u003e\u0026amp;\u003c/span\u003e\u003cspan class=\"n\"\u003elk\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e// lk-\u0026gt;locked == ✅; proceed\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e\u003c/span\u003e\u003cspan class=\"p\"\u003e...\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"c1\"\u003e// Possibly in interrupt handler\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e\u003c/span\u003e    \u003cspan class=\"nf\"\u003elock\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"o\"\u003e\u0026amp;\u003c/span\u003e\u003cspan class=\"n\"\u003elk\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"c1\"\u003e// while (lk-\u0026gt;locked == ❌) ;\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\u003c/tr\u003e\u003c/table\u003e\n\u003c/div\u003e\n\u003c/div\u003e\u003cp\u003e这样的错误虽然看起来很傻，但是在真实程序复杂的控制流中是可能出现的\u003c/p\u003e","title":"17. 并发 Bugs"},{"content":"推理效率对于 llm 是一个至关重要的问题。当模型生成文本时，尤其是以自回归方式逐词生成时，效率瓶颈会变得非常明显。KV Cache 就是为了解决这一问题而诞生的技术。\n1. What is KV Cache? KV Cache，全称 Key-Value Cache，是一种优化技术，用于加速 Transformer 架构在自回归生成过程中的推理速度。它的核心思想是缓存并重用在注意力机制中计算得到的 Key (K) 和 Value (V) 向量。\n2. Transformer Attention Mechanism Review 要理解 KV Cache，首先需要对 Transformer 架构中的自注意力机制有一个基本认识。自注意力机制允许模型在处理序列中的某个词时，考虑序列中所有其他词的重要性。\n每个输入 token（词或子词）在进入注意力层时，都会被转换成三个不同的向量：\nQ 向量：代表当前 token 的“查询”信息 K 向量：代表所有 token 的“键”信息，用于与 Query 进行匹配 V 向量：代表所有 token 的“值”信息，用于加权求和，得到最终的输出 自注意力机制的计算过程为以下步骤：\n计算 Query 与所有 Key 的点积，得到注意力分数 将注意力分数进行缩放，除以 $ \\sqrt{d_k} $（$ d_k $ 是 Key 向量的维度) 对缩放后的分数进行 Softmax，将其转换为注意力权重，表示每个 token 对当前 token 的重要性 将注意力权重与 Value 向量进行加权求和，得到当前 token 的注意力输出 公式为： $$ \\text{Attention}(Q, K, V) = \\text{softmax}\\left(\\frac{QK^T}{\\sqrt{d_k}}\\right)V $$ 其中矩阵 $ Q,K,V \\in \\mathbb{R}^{L \\times d} $ ，$ L $ 为当前上下文长度\n（处于简洁性的考虑，忽略了 Causal Mask ，实际上 $ QK^{T} $ 应该 Mask 成下三角矩阵来强制不能看到序列未来的信息）\n3. The Problem KV Cache Solves 在大型语言模型中，当模型以自回归方式生成文本时（每次生成一个新 token，并将其添加到输入序列中，然后根据整个序列生成下一个 token），会遇到一个效率问题：\n假设我们要生成“中华人民”\n输入：“中” 模型计算“中”的 $ Q, K, V $ 计算 attention ，生成“华” 输入：“中华” 模型再次计算“中”和“华”的 $ Q, K, V $ 计算 attention ，生成“人” 输入：“中华人” 模型再次计算“中”、“华”和“人”的 $ Q, K, V $ 计算 attention ，生成“民” 可以看到，在每一步生成新 token 时，都需要重新计算之前已经处理过的所有 token 的 $ K $ 和 $ V $ 向量。这种重复计算在序列较长时会消耗大量的计算资源和时间，效率低下。\n4. How KV Cache Works 根据上面分析得到的问题，很容易想到 KV Cache 的核心思想：将已经计算过的 Key 和 Value 向量缓存起来，在后续的生成步骤中直接重用，而不是重新计算。\n以生成“中华人民”为例，使用 KV Cache 的流程如下：\n输入：“中” 计算“中”的 $ K_1, V_1 $ 将 $ K_1, V_1 $ 存入 KV Cache 使用 $ Q_1, K_1, V_1 $ 计算 attention ，生成“华” 输入：“华”（当前 token 只有“华”，但注意力要关注整个序列“中华”） 计算“华”的 $ K_2, V_2 $ 将 $ K_2, V_2 $ 添加到 KV Cache。此时 KV Cache 包含 $ [K_1, K_2] $ 和 $ [V_1, V_2] $ 使用当前 $ Q_2 $ 和缓存中的 $ [K_1, K_2], [V_1, V_2] $ 计算 attention ，生成“人” 输入：“人” 计算“人”的 $ K_3, V_3 $ 将 $ K_3, V_3 $ 添加到 KV Cache。此时 KV Cache 包含 $ [K_1, K_2, K_3] $ 和 $ [V_1, V_2, V_3] $ 使用当前 $ Q_3 $ 和缓存中的 $ [K_1, K_2, K_3], [V_1, V_2, V_3] $ 计算 attention ，生成“民” 通过这种方式，每一步只需要计算当前新生成 token 的 $ K, V $ 向量，而无需重新计算之前所有 token 的 $ K, V $。\n5. Why Not QKV Cache? 可能会好奇，既然 K 和 V 都需要缓存，为什么不也缓存 Q 呢？也就是说，为什么是 KV Cache 而不是 QKV Cache？\n原因在于 Q 向量的性质：\nQ 向量是用来“查询”当前 token 与序列中其他 token 的相关性的。在自回归生成过程中，每一步生成一个新的 token，这个新 token 对应的 Query 向量是新的，它基于当前步的隐藏状态计算得出。换句话说，每次生成新 token 时，其对应的 $ Q $ 向量都是独一无二的，并且需要重新计算以反映最新的生成上下文。 K 和 V 向量则代表了序列中每个 token 的“内容”信息。对于已经处理过的 token，它们的 $ K $ 和 $ V $ 向量一旦计算出来，其内容信息就是固定不变的。因此，这些 $ K $ 和 $ V $ 向量可以直接被缓存并反复使用，而无需重新计算。 因此，不缓存 Q 是因为它在每一步都是一个新的计算结果；而缓存 K 和 V 则可以显著减少重复计算，从而提高效率。\n6. KV Cache in Attention Mechanism 在数学上，当使用 KV Cache 进行自回归解码时，注意力公式中的 $ K $ 和 $ V $ 矩阵会随着生成过程的进行而不断增长。\n假设我们正在生成第 $ t $ 个 token。\n当前 token 的 Q 向量是 $ Q_t $ ，这是一个行向量，代表当前第 $ t $ 个 token 的 Query ，维度为 $ 1 \\times d_k $ K 矩阵 $ K_{\\text{cached}} $ 将包含从第一个 token 到第 $ t $ 个 token 的所有 K 向量： $ K_{\\text{cached}} = [K_1^T, K_2^T, \\dots, K_t^T]^T $ ，维度为 $ t \\times d_k $ V 矩阵 $ V_{\\text{cached}} $ 将包含从第一个 token 到第 $ t $ 个 token 的所有 V 向量： $ V_{\\text{cached}} = [V_1^T, V_2^T, \\dots, V_t^T]^T $ 。其维度为 $ t \\times d_v $ 那么，第 $ t $ 个 token 的注意力计算变为： $$ \\text{Attention}_{t}(Q_t, K_{\\text{cached}}, V_{\\text{cached}}) = \\text{softmax}\\left(\\frac{Q_t K_{\\text{cached}}^T}{\\sqrt{d_k}}\\right)V_{\\text{cached}} $$ 其中\n$ Q_t K_{\\text{cached}}^T $ 是一个 $ 1 \\times t $ 的行向量，代表当前 Query 与所有历史 Key 的相关性分数 $ \\text{softmax} $ 操作将这个 $ 1 \\times t $ 的向量转化为注意力权重 这个 $ 1 \\times t $ 的注意力权重向量再与 $ V_{\\text{cached}} $ 矩阵（维度 $ t \\times d_v $）相乘，得到最终的注意力输出，维度是 $ 1 \\times d_v $ 每次生成新的 token $ t+1 $ 时，我们只需要计算新的 $ Q_{t+1} $，将新计算的 $ K_{t+1} $ 和 $ V_{t+1} $ 拼接到 $ K_{\\text{cached}} $ 和 $ V_{\\text{cached}} $ 末尾，形成 $ K'_{\\text{cached}} = \\text{concat}(K_{\\text{cached}}, K_{t+1}) $ 和 $ V'_{\\text{cached}} = \\text{concat}(V_{\\text{cached}}, V_{t+1}) $\n7. Limitations and Considerations 尽管 KV Cache 带来了巨大的性能提升，但也存在一些问题：\n内存占用：KV Cache 需要存储所有已处理 token 的 Key 和 Value 向量。对于大型模型和长上下文序列，这些缓存可能非常大，导致显存（GPU Memory）成为瓶颈。 上下文长度限制：由于内存限制，KV Cache 会限制模型能够处理的最大上下文长度。一旦达到内存上限，就需要采取策略来管理缓存，例如丢弃最早的 Key/Value 对（类似于循环缓冲区），但这可能会影响模型对长距离依赖的理解。 Summary KV Cache 是 Transformer 模型在自回归推理过程中非常重要的一种优化技术。通过缓存并重用已经计算过的 Key 和 Value 向量，它极大地减少了重复计算，从而显著提升了大型语言模型的生成速度。\nReferences KV Cache 原理讲解 （Bilibili） 注意：此视频内容存在部分错误 看图学KV Cache（知乎） 为什么没有Q Cache（知乎） ","permalink":"https://diefish1024.github.io/posts/ai-infra/kv-cache-%E5%85%A5%E9%97%A8/","summary":"\u003cp\u003e推理效率对于 llm 是一个至关重要的问题。当模型生成文本时，尤其是以自回归方式逐词生成时，效率瓶颈会变得非常明显。KV Cache 就是为了解决这一问题而诞生的技术。\u003c/p\u003e\n\u003ch2 id=\"1-what-is-kv-cache\"\u003e1. What is KV Cache?\u003c/h2\u003e\n\u003cp\u003eKV Cache，全称 \u003cstrong\u003eKey-Value Cache\u003c/strong\u003e，是一种优化技术，用于加速 Transformer 架构在自回归生成过程中的推理速度。它的核心思想是\u003cstrong\u003e缓存\u003c/strong\u003e并\u003cstrong\u003e重用\u003c/strong\u003e在注意力机制中计算得到的 \u003cstrong\u003eKey (K)\u003c/strong\u003e 和 \u003cstrong\u003eValue (V)\u003c/strong\u003e 向量。\u003c/p\u003e\n\u003ch2 id=\"2-transformer-attention-mechanism-review\"\u003e2. Transformer Attention Mechanism Review\u003c/h2\u003e\n\u003cp\u003e要理解 KV Cache，首先需要对 Transformer 架构中的自注意力机制有一个基本认识。自注意力机制允许模型在处理序列中的某个词时，考虑序列中所有其他词的重要性。\u003c/p\u003e\n\u003cp\u003e每个输入 token（词或子词）在进入注意力层时，都会被转换成三个不同的向量：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eQ 向量：代表当前 token 的“查询”信息\u003c/li\u003e\n\u003cli\u003eK 向量：代表所有 token 的“键”信息，用于与 Query 进行匹配\u003c/li\u003e\n\u003cli\u003eV 向量：代表所有 token 的“值”信息，用于加权求和，得到最终的输出\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e自注意力机制的计算过程为以下步骤：\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e计算 Query 与所有 Key 的点积，得到\u003cstrong\u003e注意力分数\u003c/strong\u003e\u003c/li\u003e\n\u003cli\u003e将注意力分数进行缩放，除以 $ \\sqrt{d_k} $（$ d_k $ 是 Key 向量的维度)\u003c/li\u003e\n\u003cli\u003e对缩放后的分数进行 Softmax，将其转换为\u003cstrong\u003e注意力权重\u003c/strong\u003e，表示每个 token 对当前 token 的重要性\u003c/li\u003e\n\u003cli\u003e将注意力权重与 Value 向量进行加权求和，得到当前 token 的注意力输出\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e公式为：\n$$ \n\n\\text{Attention}(Q, K, V) = \\text{softmax}\\left(\\frac{QK^T}{\\sqrt{d_k}}\\right)V\n\n $$\n其中矩阵 $ Q,K,V \\in \\mathbb{R}^{L \\times d} $ ，$ L $ 为当前上下文长度\u003c/p\u003e","title":"KV Cache 入门"},{"content":"Abstract 问题：现有 EEG 情绪识别方法对长期上下文信息关注不足，导致跨被试泛化能力减弱 方案：提出 Emotion Transformer (EmT) ，为 Graph-Transformer 混和架构 核心模块： TGC：将 EEG 信号转换为时序图序列 RMPG：使用残差多视图金字塔 GCN，学习动态、多尺度的空间连接模式，生成 token（核心） TCT：使用任务自适应的 Transformer，学习 token 序列上下文（核心） TSO：输出分类/回归结果 成果：在多个公开数据集的广义跨被试任务上面超过了 baseline Introduction \u0026amp; Related Work 为什么 EEG 难以使用跨被试 (cross-subject) 的场景？\n个体差异：不同被试生理结构和认知策略差异，导致 EEG 模式不同 低信噪比：EEG 信号容易受到外源噪声干扰（肌电、眼电……） 目标是学习一种跨被试共享、具有泛化能力的情绪表征\nGpaph Neural Networks 核心思想：EEG 数据具有非欧图结构，适合使用 GNN 来处理 代表工作： ChebyNet：使用切比雪夫多项式近似光谱滤波，EmT 模型中采用其作为 GCN 层 GCN：通过局部一阶聚合近似光谱滤波 DGCNN / RGNN：使用 GNNs 提取 EEG 空间信息；依赖单一的邻接矩阵，忽略时序上下文，具有局限性；而 EmT 通过多视图可学习邻接矩阵和时序图来弥补 Temporal Context Learning 核心理念：情绪是连续认知过程，EEG 信号中嵌入时序上下文信息 代表工作： LSTM / TCN / TESANet / Conformer / AMDET 局限性：这些方法通常从扁平化的 EEG 特征向量学习，可能未能有效学习空间关系；EmT 则通过并行 GCN 和 STA 层更有效地捕捉时空信息 EEG Emotion Recognition 核心理念：EEG 情绪识别面临个体差异大、信噪比低等挑战，需提取光谱、空间、时序特征 代表工作： GCB-Net / TSception 局限性：没有关注长时序上下文信息 Method EmT 是一个端到端的框架，包含四大模块：\nraw EEG -\u0026gt; TGC -\u0026gt; 时序图 -\u0026gt; RMPG -\u0026gt; Tokens -\u0026gt; TCT -\u0026gt; 深层特征 -\u0026gt; TSO -\u0026gt; Result\nEEG-Temporal-Graph Representations (TGC) 目标：将连续的 EEG 信号转化为结构化的时序图序列\n图：每个“图”是指在一个短的窗口内大脑状态的数学表示，图中的每个节点对应一个 EEG 电极通道，节点的特征是该通道在 7 个不同的频段上的 rPSD 时序序列：序列是通过滑动窗口技术截取的一段较长的 EEG 数据里面切分成许多重叠的短的子片段，每个子片段生成的图所形成的序列 双层滑动窗口分段：为了捕捉不同时间尺度上的信息，TGC 采用了一种双层分段策略\n首先将一次完整实验的 (trail) 的 EEG 数据，表示为 $ X \\in \\mathbb{R}^{c \\times L} $ （其中 $ c $ 为通道数，$ L $ 为总采样点数），通过一个较长的滑动窗口（长度为 $ l $ ，步长为 $ s $ ）分割成多个重叠的长片段 $ \\overline{X} \\in \\mathbb{R}^{c \\times l} $ 接着对于每一个长片段 $ \\overline{X} $ 使用一个更短的滑动窗口（长度为 $ l' $ ，步长为 $ s' $ ）将其分割为一系列子片段 $ \\tilde{X} \\in \\mathbb{R}^{c \\times l'} $ 这使得模型能够在一个长片段的标签下，观察到内部更精细的信号动态变化，为后续的 Transformer 模块捕捉时间上下文提供了基础 节点特征提取：对于每一个子片段 $ \\tilde{X} $，需要为其对应的图节点（即 EEG 通道）提取有意义的特征，论文选择了相对功率谱密度 (Relative PSD, rPSD) 作为节点属性\n具体地，使用 welch\u0026rsquo;s method 计算每个 EEG 通道在七个经典频带上的 rPSD 这样，每个子片段 $ \\tilde{X} $ 都对应一个特征矩阵 $ F \\in \\mathbb{R}^{c \\times f} $，其中 $ f=7 $ 最终，一个长片段 $ \\overline{X} $ 被转换成一个按时间顺序排列的图序列 $ G_{T} = \\{\\mathcal{G}^{i}\\} \\in \\mathbb{R}^{seq \\times c \\times f} $，其中 $ seq $ 是子片段的数量。这个时间图序列就是 RMPG 模块的输入\nResidual Multiview Pyramid GCN (RMPG) 核心：解决传统 GNN“单一视角”问题，为时间图序列 $ G_{T} $​ 中的每一个图 $ \\mathcal{G}^i $ 学习一个丰富的、多层次的空间表征，并将其压缩成一个单一的 token ，以供后续的 TCT 模块处理\nRMPG 模块由一个基础的图编码器 $ \\Phi_{g}(\\cdot) $ 构成，文中采用了 ChebyNet 作为基础图编码器，对于给定特征输入 $ F^{m-1} $ 和邻接矩阵 $ A $ （通过拉普拉斯算子 $ \\hat{L} $ 转换） $$ \\Phi_{g}(F^{m}, A) = \\sigma\\left( \\sum_{k=0}^{K-1}\\theta_{k}^{m}T_{k}(\\hat{L})F^{m-1} - b^{m}\\right) $$ 其中 $ m $ 为 GCN 层的索引，$ \\sigma $ 为 ReLU 激活函数，$ \\theta $ 为参数，$ T_{k} $ 为 $ k $ 阶 Chebyshev 多项式\n多视图学习 (Multiview Learning) ：为了模拟情绪背后多种认知子过程驱动的不同大脑连接模式，RMPG 并非使用单一的图卷积网络，而是并行地使用了多个 GCN 分支，$ \\{ \\Phi_{g}^{0}(\\cdot), \\Phi_{g}^{1}(\\cdot), \\dots, \\Phi_{g}^{i}(\\cdot) \\} $\n每个分支都拥有一个独立的可学习邻接矩阵 $ A^{i} \\in \\mathbb{R}^{c \\times c} $ ，能在模型训练过程中通过梯度反向传播进行端到端的优化 这意味着每个 GCN 分支都能从数据中学习到一种独特的大脑功能连接“视图” 金字塔学习 (Pyramid Learning) ：为了捕捉不同尺度的空间信息，并行的 GCN 分支被设计成具有不同的深度（即 GCN 层数）\n较浅的 GCN 能够有效地聚合全局的、跨脑区的功能连接信息，聚合远距离节点的信息而不过度平滑 较深的 GCN 能够更好地聚合局部邻域内的信息，在脑区内部形成一致的表征 GCN 的深度越深，其输出所代表的特征金字塔层级越高。 残差连接 (Residual) ：除了并行的 GCN 分支外，RMPG 还包含一个并行的线性残差分支。该分支直接对原始的时序图 $ G $ （或者对应的特征矩阵 $ F $ ）进行线性投影，不经过任何图卷积，从而保留最原始的节点信息，作为特征金字塔的“基座”\n线性投影层 $ LP(\\cdot) $ 将扁平化的图表示投影到隐藏嵌入 $ H_{g}^{i} \\in \\mathbb{R}^{d_{g}} $ 堆叠来自不同层的 GCN 的并行输出，得到多金字塔视图嵌入 $$ \\{ H_{g}^{i} \\} = \\{ LP^{i}(\\Gamma(\\Phi_{g}^{i}(F, A^{i}))) \\} $$ 其中 $ \\Gamma(\\cdot) $ 是扁平操作，$ \\{ \\cdot \\} $ 是堆叠操作 特征融合与 Token 生成：最终，对于图序列中的每一个图 $ G_{i} $，其所有 GCN 视图的输出 $ \\{ H_{i}^{g} \\} $ 和残差基座 $ H_{g-\\text{base}} $​ 通过一个 mean fusion 操作合并成当前时间步 $ i $ 的最终 token $ s_{i} $ $$ s_{i} = \\text{mean}(\\{ H_{g-\\text{base}}, H_{g}^{0}, H_{g}^{1}, \\dots, H_{g}^{i} \\}) $$\n通过 RMPG 模块，输入的图序列 $ G_{T} $ 被高效地转化为一个 token 序列 $ S_{T}=\\{ s^{i} \\} \\in \\mathbb{R}^{seq \\times d_{g}} $ ，这个序列既蕴含了每个时刻丰富的多视图、多层次空间信息，又具备了适合 Transformer 处理的格式\nTemporal Contextual Transformer (TCT) 核心：接受由 RMPG 生成的 token 序列 $ S_{T} $ ，并利用 Transformer 的结构来高效捕捉这些 token 之间的时间依赖关系；与标准的 Transformer 不同，TCT 引入了两种为 EEG 情绪识别任务定制的 Token Mixer，分别用于分类和回归任务\nTCT 模块由多个堆叠的 Transformer Block 组成，对于输入 token 序列 $ Z^{m} $ （ $ Z^{0} = S_{T} $ ），每个 Block 的计算过程为 $$ Z^{m'} = \\text{TokenMixer}(\\text{Norm}(Z^{m})) + Z^{m} $$ $$ Z^{m+1} = \\text{MLP}(\\text{Norm}(Z^{m'})) + Z^{m'} $$ 其中 $ m $ 是层的索引，MLP 是带 ReLU 激活函数的两层感知机\n$ \\text{TokenMixer}_{\\text{clas}} $ for Classification Tasks 旨在捕捉随时间变化的长短时序上下文信息\n多头自注意力 (Multi-head Self-Attention, MSA) ：用于全局地关注序列中与整体情绪状态高度相关的部分 $$ \\text{Attn}(Q,K,V) = \\text{softmax}\\left( \\frac{QK^{T}}{\\sqrt{ d }} \\right)V $$\n并行应用多个注意力头（每个头有独立的 $ LP_h(\\cdot) $ 来生成 $ Q, K, V $），然后将所有头的输出拼接：$$ \\text{MSA}(S_{T}) = \\text{Concat}(\\text{Attn}(LP_0(S_{T})), ..., \\text{Attn}(LP_{n_{\\text{head}}-1}(S_{T}))) $$ 其中 $ S_{T} $ 是 token 序列，$ n_{\\text{head}} $ 是注意力头的数量 短期聚合层 (Short-Time Aggregation, STA) ：\n基于“情绪短期连续而长期变化”的先验知识，STA 在 MSA 之后应用来学习短期的上下文信息 首先对 MSA 的输出 $ H_{\\text{attn}} \\in \\mathbb{R}^{n_{\\text{head}} \\times \\text{seq} \\times d_{\\text{head}}} $ 应用一个带有比例因子 $ \\alpha $ 的 Dropout 层 $ \\text{dp}(\\alpha) $ 接着，通过 Conv2D 聚合 $ n_{\\text{anchor}} $ 个时序近邻 Conv2D 的卷积核 $ K_{\\text{cnn}} $ 的尺寸为 $ (n_{\\text{anchor}}, 1) $，步长为 $ (1,1) $ 最后，卷积的输出会被 Reshape 并进行线性投影（$ W_{\\text{sta}} $） 可以描述为 $$ \\text{STA}(H_{\\text{attn}}) = \\text{Reshape}(\\text{Conv2D}(\\text{dp}(H_{\\text{attn}}), K_{\\text{cnn}})) W_{\\text{sta}} $$ $ \\text{Reshape}(\\cdot) $ 将维度从 $ (n_{\\text{head}},\\text{seq},d_{\\text{head}}) $ 转换为 $ (\\text{seq}, n_{\\text{head}} \\cdot d_{\\text{head}}) $ ， $ W_{\\text{sta}} \\in \\mathbb{R}^{n_{\\text{head}} \\cdot d_{\\text{head}} \\times d_g} $ 是投影权重矩阵 $ \\text{TokenMixer}_{\\text{Clas}} $ 最终由上述两个模块串联构成 $$ \\text{TokenMixer}_{\\text{clas}}(S_{T}) = \\text{STA}(\\text{MSA}(S_{T})) $$\n$ \\text{TokenMixer}_{\\text{regr}} $ for Regression Tasks 旨在预测序列中情绪状态的连续变化\n不同于分类任务：分类任务的目标通常是从整个序列中提取几个核心特征来判断整体情绪状态，这通过 MSA 聚焦于重要部分是有效的；然而回归任务需要模型对序列中每个时步的连续情绪变化进行预测，因此不使用全局的 MSA，而是采用了一种基于 RNN 的混合器（ RNN family ）\nRNN Mixer ：\nRNN 结构天然适合处理连续序列的演变过程，能够更好地建模情绪值的平滑变化 经验性选择的两层双向 GRU (bi-directional GRU) 作为 $ \\text{TokenMixer}_{\\text{regr}} $ ，输出长度为 $ 2 \\times d_{\\text{head}} $ 计算过程为 $$ \\text{TokenMixer}_{\\text{regr}}(S_T) = \\text{RNNs}(\\text{LP}(S_T)) $$ 其中 $ LP(S_{T}) = S_{T}W_{v} $ ，把 token 序列投影为 $ V $ 值\nTSO Module 头部接收来自不同 Token Mixer 的输出：用于分类的 $ S_{\\text{clas}} $ 和用于回归的 $ S_{\\text{regr}} $\n分类任务：对所有 token 进行 mean fusion ，再通过线性层得到最终 logits $$ \\hat{Y}_{\\text{clas}} = \\text{mean}(S_{\\text{clas}})W_{\\text{clas}} + b_{\\text{clas}} $$ 其中 $ S_{\\text{clas}} \\in \\mathbb{R}^{\\text{seq} \\times d_{\\text{head}}} $ ，$ W_{\\text{clas}} \\in \\mathbb{R}^{d_{\\text{head}} \\times d_{\\text{class}}} $ ，$ b_{\\text{clas}} \\in \\mathbb{R}^{n_{\\text{class}}} $\n回归任务：直接将每个时间步的 token 特征通过线性层，得到对应每个时刻的回归值 $$ \\hat{Y}_{\\text{regr}} = S_{\\text{regr}}W_{\\text{regr}} + b_{\\text{regr}} $$ 其中 $ S_{\\text{regr}} \\in \\mathbb{R}^{\\text{seq} \\times 2\\cdot d_{\\text{head}}} $ （双向），$ W_{\\text{regr}} \\in \\mathbb{R}^{2\\cdot d_{\\text{head}} \\times 1} $ ，$ b_{\\text{regr}} \\in \\mathbb{R} $\nExperiment Datasets 使用 SEED, THU-EP, FACED, MAHNOB-HCI 四个公开数据集\n其中 SEED 数据集使用了 0.3-50 Hz 的带通滤波\nEEG-Temporal-Graph 长片段：窗口长度 $ l=20\\,\\mathrm{s} $ （即 $ 20 \\times f_{s} $ ），步长 $ s=4\\,\\mathrm{s} $ 子片段： 对于 SEED 和 THU-EP： $ l'=2\\,\\mathrm{s},s'=0.5\\,\\mathrm{s} $ 对于 FACED： $ l'=4\\,\\mathrm{s},s'=1\\,\\mathrm{s} $ Settings 数据划分： SEED：采用留一被试交叉验证，每次迭代一个被试的数据作为测试集，剩余数据中 80% 作为训练集，20% 作为验证集 THU-EP 和 FACED：采用留 $ n $ 被试交叉验证，其中 $ n_{\\text{THU-EP}}=8,n_{\\text{FACED}}=12 $ ，训练数据中 10% 作为验证集 分类任务：对 SEED、THU-EP 和 FACED 进行积极/消极情绪的二分类，THU-EP 和 FACED 的效价分数通过阈值 3.0 划分为高/低效价 回归任务：MAHNOB-HCI 并进行 LOSO 验证 Evaluation Metrics Classfication Accuracy：$$ \\text{Accuracy} = \\frac{\\text{TP + TN}}{\\text{TP + FP + TN + FN}} $$ F1 Score：$$ \\text{F1} = 2 \\times \\frac{\\text{Precision} \\times \\text{Recall}}{\\text{Precision + Recall}} = \\frac{\\text{TP}}{\\text{TP} + \\frac{1}{2}(\\text{FP} + \\text{FN})} $$ 其中 $ \\text{TP} $ 表示真阳性，$ \\text{TN} $ 表示真阴性，$ \\text{FP} $ 表示假阳性，$ \\text{FN} $ 表示假阴性\nRegression 给定预测值 $ \\hat{y} $ 和连续标签 $ y $ ：\n均方根误差 (RMSE) ：$$ \\text{RMSE} = \\sqrt{\\frac{1}{N} \\sum_{i=0}^{N-1} (\\hat{y}_i - y_i)^2} $$ 皮尔逊相关系数 (PCC) ：$$ \\text{PCC} = \\frac{\\sigma_{\\hat{y}y}}{\\sigma_{\\hat{y}} \\sigma_y} = \\frac{\\sum_{i=0}^{N-1} (\\hat{y}_i - \\mu_{\\hat{y}})(\\hat{y}_i - \\mu_y)}{\\sqrt{\\sum_{i=0}^{N-1} (\\hat{y}_i - \\mu_{\\hat{y}})^2} \\sqrt{\\sum_{i=0}^{N-1} (y_i - \\mu_y)^2}} $$ 一致性相关系数 (CCC) ：$$ \\text{CCC} = \\frac{2\\sigma_{\\hat{y}y}}{\\sigma^2_{\\hat{y}} + \\sigma^2_y + (\\mu_{\\hat{y}} - \\mu_y)^2} $$ 其中 $ N $ 是向量中的元素数量，$ \\sigma_{\\hat{y}y} $ 是协方差，$ \\sigma_{\\hat{y}} $ 和 $ \\sigma_y $ 是标准差，$ \\mu_{\\hat{y}} $ 和 $ \\mu_y $ 是均值\nImplementation Details 模型的三种变体： Analyses Classification SEED： EmT-D 表现最佳，EmT-B 和 EmT-S 表现也良好，RGNN 表现第二佳 使用特征作为输入的模型通常优于直接使用 EEG 信号作为输入的模型，从时序特征而非直接特征学习通常能取得更好的性能（RGNN 除外），这表明了学习时序上下文信息的有效性，EmT 借助基于 GCN 的模块，能更好地学习空间信息 THU-EP / FACED： THU-EP：EmT-B 取得了最佳 F1 分数，Conformer 取得了最佳 ACC FACED：EmT-B 取得了第二佳 ACC 和最佳 F1 分数 由于类不平衡，F1 分数比 ACC 更重要，EmT-B 在这两个数据集上均取得了最高 F1 分数 与 SEED 不同，直接使用 EEG 作为输入的 baseline 模型表现更好，这可能因为这两个数据集的被试人数更多 Features： SEED (62 channels，15 subjects) ：EmT-D (8 层) 表现最佳，说明 Transformer 层数越多，学到的空间信息越丰富 THU-EP 和 FACED (32 channels，more subjects) ：EmT-B (4 层) 表现更好，通道数少且被试间变异性大时，更深的模型（EmT-D）容易过拟合 Regression 在 MAHNOB-HCI 数据集上，EmT-Regr (LP+LSTM) 取得了最低的 RMSE，而 EmT-Regr (LP+GRU) 取得了最佳的 PCC 和 CCC 使用 MSA 作为 Token Mixer 时，模型性能急剧下降，甚至低于所有基线模型 这表明对于回归任务，融合所有片段的信息至关重要，而 RNN 的顺序信息融合能力比 MSA 更适合建模连续的情绪变化 Ablation Study Effect of EEG Features Effect of The Depth and Width of GCNs in RMPG Depth：增加 GCN 层的数量会导致性能显著下降，这与更深 GCN 中存在的过平滑问题一致 Width：宽度从 8 增加到 32 时，性能呈正相关；当宽度进一步增加时，性能下降，这可能是由更大的模型尺寸导致的过拟合 Effect of The Number of TCT Blocks Classfication (SEED) ：TCT 块的数量从 2 增加到 8 时，ACC 和 F1 分数均显著提高，这表明增加 TCT 块数能增强模型捕捉时序上下文信息的能力，从而提升分类性能 Regression (MAHNOB-HCI) ：TCT 块的数量对性能指标几乎没有影响 Visualization Learned Connections 在 SEED 数据集上学习到的两种不同连接模式的可视化证据 在 SEED 数据集上，两个可学习的邻接矩阵揭示了情绪认知过程中不同的连接模式：\n(a) 中主要关注额叶、顶叶和颞叶区域之间的连接，这些区域与心理注意力密切相关 (b) 中则包括额叶、颞叶和顶叶区域之间的互动（与情绪相关），以及枕叶和顶叶区域的互动（与视觉过程相关，因为刺激为视频） Learned Temporal Contextual Information Classfication (FACED) Regression 分类任务在 TCT 块之前，特征随时间变化，TCT 块之后，激活变得更加一致；这可能是因为自注意力机制关注与整体情绪状态高度相关的部分，而 STA 层通过聚合邻近的时序信息来平滑波动 回归任务：特征空间也显示出时序变化；与分类不同，回归特征并非简单平滑，形成了更复杂的表示 总结：TCT 块处理分类和回归任务的方式不同：分类中，特征被平滑以增强可分离性；回归中，RNN Token Mixer 保留了时序变化，从而实现连续情绪预测 ","permalink":"https://diefish1024.github.io/posts/literature-notes/emt/","summary":"\u003ch2 id=\"abstract\"\u003eAbstract\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e问题\u003c/strong\u003e：现有 EEG 情绪识别方法对长期上下文信息关注不足，导致跨被试泛化能力减弱\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e方案\u003c/strong\u003e：提出 \u003cstrong\u003eEmotion Transformer (EmT)\u003c/strong\u003e ，为 Graph-Transformer 混和架构\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e核心模块\u003c/strong\u003e：\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003eTGC\u003c/strong\u003e：将 EEG 信号转换为时序图序列\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eRMPG\u003c/strong\u003e：使用残差多视图金字塔 GCN，学习动态、多尺度的空间连接模式，生成 token（核心）\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eTCT\u003c/strong\u003e：使用任务自适应的 Transformer，学习 token 序列上下文（核心）\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eTSO\u003c/strong\u003e：输出分类/回归结果\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e成果\u003c/strong\u003e：在多个公开数据集的广义跨被试任务上面超过了 baseline\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"introduction--related-work\"\u003eIntroduction \u0026amp; Related Work\u003c/h2\u003e\n\u003cp\u003e为什么 EEG 难以使用跨被试 (cross-subject) 的场景？\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e个体差异\u003c/strong\u003e：不同被试生理结构和认知策略差异，导致 EEG 模式不同\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e低信噪比\u003c/strong\u003e：EEG 信号容易受到外源噪声干扰（肌电、眼电……）\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e目标是学习一种\u003cstrong\u003e跨被试共享\u003c/strong\u003e、具有\u003cstrong\u003e泛化能力\u003c/strong\u003e的情绪表征\u003c/p\u003e\n\u003ch3 id=\"gpaph-neural-networks\"\u003eGpaph Neural Networks\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e核心思想\u003c/strong\u003e：EEG 数据具有非欧图结构，适合使用 GNN 来处理\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e代表工作\u003c/strong\u003e：\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eChebyNet\u003c/strong\u003e：使用切比雪夫多项式近似光谱滤波，EmT 模型中采用其作为 GCN 层\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eGCN\u003c/strong\u003e：通过局部一阶聚合近似光谱滤波\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eDGCNN / RGNN\u003c/strong\u003e：使用 GNNs 提取 EEG 空间信息；依赖单一的邻接矩阵，忽略时序上下文，具有\u003cstrong\u003e局限性\u003c/strong\u003e；而 EmT 通过\u003cstrong\u003e多视图可学习邻接矩阵\u003c/strong\u003e和\u003cstrong\u003e时序图\u003c/strong\u003e来弥补\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"temporal-context-learning\"\u003eTemporal Context Learning\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e核心理念\u003c/strong\u003e：情绪是连续认知过程，EEG 信号中嵌入时序上下文信息\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e代表工作\u003c/strong\u003e：\n\u003cul\u003e\n\u003cli\u003eLSTM / TCN / TESANet / Conformer / AMDET\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e局限性\u003c/strong\u003e：这些方法通常从扁平化的 EEG 特征向量学习，可能\u003cstrong\u003e未能有效学习空间关系\u003c/strong\u003e；EmT 则通过并行 GCN 和 STA 层更有效地捕捉时空信息\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"eeg-emotion-recognition\"\u003eEEG Emotion Recognition\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e核心理念\u003c/strong\u003e：EEG 情绪识别面临个体差异大、信噪比低等挑战，需提取光谱、空间、时序特征\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e代表工作\u003c/strong\u003e：\n\u003cul\u003e\n\u003cli\u003eGCB-Net / TSception\u003c/li\u003e\n\u003cli\u003e局限性：没有关注长时序上下文信息\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"method\"\u003eMethod\u003c/h2\u003e\n\u003cp\u003eEmT 是一个端到端的框架，包含四大模块：\u003c/p\u003e","title":"EmT"},{"content":"Introduction TTA 在回归任务上的局限：为分类任务设计，一般基于熵最小化和特征对齐；熵最小化不适用，回归模型产生单一值，不产生概率分布；简单特征对齐对回归模型效果不佳，可能反而会稀释需要学习的特征\nProblem Setting 考虑一个回归模型 $ f_\\theta: \\mathcal{X} \\to \\mathbb{R} $，可以进一步分解为特征提取器 $ g_\\phi: \\mathcal{X} \\to \\mathbb{R}^D $（从输入 $ \\mathcal{X} $ 提取 $ D $ 维特征 $ z $）和线性回归器 $ h_\\psi(z) = w^T z + b $（或者 $ h_{\\psi}(z)=Wz+b $）\n$ f_\\theta $ 首先在一个有标签的源数据集 $ S = \\{(x_i, y_i)\\}_{i=1}^{N_s} $ 上进行预训练，数据从源域分布 $ p_s $ 中采样\n目标是使用一个无标签的目标数据集 $ T = \\{x_j\\}_{j=1}^{N_t} $ 来适应预训练好的模型 $ f_\\theta $ 到目标域\n我们假设存在 covariate shift ，这意味着：\n输入数据的分布在源域和目标域之间是不同的：$ p_s(x) \\neq p_t(x) $ 但给定输入后，输出的条件分布是相同的：$ p_s(y|x) = p_t(y|x) $ Test-time Adaptation for Regression Basic Idea: Feature Alignment 朴素实现：\n计算源域特征统计量：在源域训练后，计算源域特征的均值 $ \\mu^s $ 和元素级方差 $ \\sigma^{s2} $ $$ \\mu^s = \\frac{1}{N_s} \\sum_{i=1}^{N_s} z_i^s, \\quad \\sigma^{s2} = \\frac{1}{N_s} \\sum_{i=1}^{N_s} (z_i^s - \\mu^s) \\odot (z_i^s - \\mu^s) \\quad \\text{(1)} $$ 其中 $ z_i^s = g_\\phi(x_i) $ 是源特征，$ N_s $ 是源数据样本数，$ \\odot $ 表示元素级乘积\n目标域特征统计量：在目标域，对每个迷你批次（mini-batch）$ B = \\{x_j\\}_{j=1}^{N_B} $，计算其特征均值 $ \\hat{\\mu}^t $ 和方差 $ \\hat{\\sigma}^{t2} $，计算方式与公式 (1) 类似\n对齐损失函数：使用 KL 散度来衡量两个对角高斯分布 $ N(\\mu^s, \\sigma^{s2}) $ 和 $ N(\\hat{\\mu}^t, \\hat{\\sigma}^{t2}) $ 之间的差异，并最小化该差异。 $$ L_{TTA} (\\phi) = \\frac{1}{2} \\sum_{d=1}^D \\left\\{ D_{KL} (N(\\mu^s_d, \\sigma^s_{d}{}^2)||N(\\hat{\\mu}^t_d, \\hat{\\sigma}^t_{d}{}^2)) + D_{KL} (N(\\hat{\\mu}^t_d, \\hat{\\sigma}^t_{d}{}^2)||N(\\mu^s_d, \\sigma^s_{d}{}^2)) \\right\\} \\quad \\text{(2)} $$ 这里的 $ d $ 表示向量的第 $ d $ 个元素。之所以使用双向的 KL 散度，是为了经验上获得更好的结果\n一维高斯 KL 散度公式： $$ D_{KL} (N(\\mu_1, \\sigma_1^2)||N(\\mu_2, \\sigma_2^2)) = \\dfrac{\\left[ \\log(\\sigma_2^2/\\sigma_1^2) + \\dfrac{(\\mu_1 - \\mu_2)^2 + \\sigma_1^2}{\\sigma_2^2} - 1 \\right]}{2} \\quad \\text{(3)} $$\n朴素对齐的问题：\n回归模型特征倾向于分布在一个小型的子空间中，许多特征维度方差为零或接近零 公式 (3) 中涉及到方差在分母上，使得这种朴素对齐在面对零方差维度时变得不稳定 对所有维度“一视同仁”地对齐不适用于回归任务的特性，因为许多维度对最终输出影响很小 Significant-subspace Alignment SSA 的三个步骤：\n子空间检测 (Subspace detection)：\n在源数据集 $ S $ 上进行训练后，检测源特征分布所在的子空间。不计算每个维度的方差，而是计算协方差矩阵： $$ \\Sigma^s = \\frac{1}{N_s} \\sum_{i=1}^{N_s} (z_i^s - \\mu^s) (z_i^s - \\mu^s)^T \\quad \\text{(4)} $$ 其中 $ \\mu^s $ 是源特征的均值向量（同理 (1)） 基于 PCA 的思想，通过对 $ \\Sigma^s $ 进行特征分解，得到特征向量 $ v_d^s $ 和对应的特征值 $ \\lambda_d^s $ 选取前 K 个最大的特征值 $ \\lambda_1^s, \\dots, \\lambda_K^s $ 及其对应的源基向量 $ v_1^s, \\dots, v_K^s $ 来定义源子空间，这些基向量张成的子空间代表了源特征数据最有代表性和最重要的变化方向 维度加权 (Dimension weighting)：\n考虑到回归模型 $ h_\\psi(z)=w^T z + b $，子空间维度 $ v_d^s $ 对最终输出的影响由 $ w^T v_d^s $ 决定（即特征向量与回归器权重向量的点积） 为了优先对齐那些对输出影响更大的子空间维度，为每个子空间维度 $ d $ 定义权重 $ a_d $： $$ a_d = 1 + |w^T v_d^s| \\quad \\text{(5)} $$ 这个权重 $ a_d $ 会在对应的子空间基方向对输出有较大影响时值更大（最小为 1）。 特征对齐 (Feature alignment)：\n这一步在目标域进行。对于目标域的迷你批次 $ B $，首先将目标特征 $ z^t = g_\\phi(x^t) $ 投影到源子空间。 $$ \\tilde{z}^t = V_s^T (z^t - \\mu^s) \\quad \\text{(6)} $$ 其中 $ V_s = [v_1^s, \\dots, v_K^s] \\in \\mathbb{R}^{D \\times K} $ 是由前 K 个源基向量构成的矩阵，$ \\tilde{z}^t \\in \\mathbb{R}^K $ 是投影后的目标特征。 然后，计算投影后目标特征的迷你批次均值 $ \\tilde{\\mu}^t $ 和方差 $ \\tilde{\\sigma}^{t2} $ （同理公式 (1) ） 最后，使用结合子空间检测和维度加权的新损失函数来最小化目标特征分布与源特征分布在子空间中的差异。源域投影后的均值是 0，方差是其特征值 $ \\Lambda^s = [\\lambda_1^s, \\dots, \\lambda_K^s] $。 $$ \\begin{align}L_{TTA}(\\phi) = \u0026 \\frac{1}{2} \\sum_{d=1}^K a_d \\left\\{ D_{KL} (N(0, \\lambda^s_d)||N(\\tilde{\\mu}^t_d, \\tilde{\\sigma}^t_{d}{}^2)) + D_{KL} (N(\\tilde{\\mu}^t_d, \\tilde{\\sigma}^t_{d}{}^2)||N(0, \\lambda^s_d)) \\right\\} \\\\ = \u0026 \\sum_{d=1}^K a_d \\left\\{ \\frac{(\\tilde{\\mu}^t_d)^2 + \\lambda^s_d}{2\\tilde{\\sigma}^t_{d}{}^2} + \\frac{(\\tilde{\\mu}^t_d)^2 + \\tilde{\\sigma}^t_{d}{}^2}{2\\lambda^s_d} - 1 \\right\\} \\quad \\text{(7)} \\end{align} $$ 其中 $ a_d $ 是维度权重，$ \\lambda_d^s $ 是源域子空间的第 $ d $ 个特征值，$ \\tilde{\\mu}_d^t $ 和 $ \\tilde{\\sigma}_{d}{}^2 $ 是投影后的目标特征在第 $ d $ 个维度上的均值和方差 伪代码：\n输入：预训练好的源模型 $ f_\\theta $、源基向量 $ V_s $、源均值 $ \\mu^s $、源方差 $ \\Lambda^s $、目标数据集 $ T $ 输出：适应后的模型 $ f_\\phi^t $ 步骤： 计算源子空间中每个维度的权重 $ a_d $ 对于目标数据集 $ T $ 中的每个 mini batch $ \\{x\\}_i^B $： 提取目标特征 $ z = g_\\phi(x) $。 将目标特征投影到源子空间 $ \\tilde{z} $ 计算投影后目标特征的均值 $ \\tilde{\\mu}^t $ 和方差 $ \\tilde{\\sigma}^{t2} $ 更新特征提取器 $ g_\\phi $ 以最小化损失函数 $ L_{TTA}(\\phi) $ 重复直到收敛。 对角高斯分布的合理性 为什么假设特征分布为对角高斯分布是合理的：\n中心极限定理：当特征被投影到子空间后，如果原始特征维度 $ D $ 足够大，根据中心极限定理，投影后的特征分布会倾向于高斯分布。 PCA 的去相关性：由于子空间检测使用了 PCA，投影到主成分上的特征是去相关的，这意味着不同维度之间是独立的，这使得对角高斯分布的假设（即各维度独立）变得合理。 Appendix A. LIMITATION：SSA 假设是协变量偏移，即 $ p(y|x) $ 不变，未来工作将考虑 $ p(y|x) $ 变化的情况\nB. EVALUATION METRIC：R²接近 1 表示模型拟合效果好 $$ R^2 = 1 - \\frac{\\sum_{i=1}^N (y_i - \\hat{y}_i)^2}{\\sum_{i=1}^N (y_i - \\bar{y})^2} \\quad \\text{(10)} $$ 其中 $ \\hat{y}_i $ 是预测值，$ y_i $ 是真实值，$ \\bar{y} $ 是真实值的平均值。\nD. ADDITIONAL EXPERIMENTAL RESULTS：\nD.1 特征对齐的度量：比较了 KL 散度、2WD 和 L1 范数作为特征对齐损失的效果，结果显示 KL 散度结合子空间检测（SSA）表现最佳。 公式 (11)：2-Wasserstein Distance for Gaussians $$ W_2^2 (N(\\mu_1, \\sigma_1^2), N(\\mu_2, \\sigma_2^2)) = (\\mu_1 - \\mu_2)^2 + (\\sigma_1 - \\sigma_2)^2 $$ 公式 (12)：L1 Norm of Statistics $$ L_1 (N(\\mu_1, \\sigma_1^2), N(\\mu_2, \\sigma_2^2)) = |\\mu_1 - \\mu_2| + |\\sigma_1 - \\sigma_2| $$ 公式 (13)：SSA Loss with 2WD $$ L_{TTA-2WD} = \\sum_{d=1}^K a_d \\left\\{ (\\tilde{\\mu}^t_d)^2 + (\\tilde{\\sigma}^t_d - \\sqrt{\\lambda^s_d})^2 \\right\\} $$ 公式 (14)：SSA Loss with L1 Norm $$ L_{TTA-L1} = \\sum_{d=1}^K a_d \\left\\{ |\\tilde{\\mu}^t_d| + |\\tilde{\\sigma}^t_d - \\sqrt{\\lambda^s_d}| \\right\\} $$ D.2 特征可视化：通过 PCA 和 UMAP 等降维技术可视化了源域和目标域特征分布（图 4-5），直观地展示了 SSA 如何成功地将目标特征分布拉近源域。 D.3 原始特征维度对子空间的影响：分析了原始特征维度对子空间的重要性。 公式 (15)：Gradient Norm $ s_d $ $$ s_d = ||\\frac{\\partial \\tilde{z}}{\\partial z_d}||_2 = ||(V_s^T)_d||_2 = ||[v_{1,d}^s, \\dots, v_{K,d}^s]||_2, $$ 其中 $ (V_s^T)_d $ 是 $ V_s^T $ 的第 $ d $ 行。 发现：回归模型的特征子空间确实受许多原始特征维度影响很小（图 6），这进一步确认了子空间检测的必要性。 D.4 附加消融实验：进一步证实了子空间检测对于 SSA 性能的重要性（表 13-14）。 D.5 Vision Transformer 实验：在 Vision Transformer 上验证了 SSA 的有效性（表 15-16），表明该方法对不同模型架构也适用。 D.6 多任务回归模型：将 SSA 应用于多任务回归，模型同时输出多个预测值（如头部姿态的俯仰、偏航、滚转角度），结果表明 SSA 同样有效（表 17）。 D.7 与分类 TTA 结合：探索了 SSA 与分类 TTA 结合的可能性（表 18-20）。 D.8 超参数敏感性：分析了学习率和批次大小等超参数对 SSA 性能的影响（表 21-26），发现 SSA 在典型参数范围内表现稳定。 D.9 额外结果：提供了 MAE 等其他指标的性能数据（表 27-28）。 D.10 在线设置：SSA 在分批在线（batched online）设置下也表现出色（表 29-31）。 ","permalink":"https://diefish1024.github.io/posts/literature-notes/ssa/","summary":"\u003ch2 id=\"introduction\"\u003eIntroduction\u003c/h2\u003e\n\u003cp\u003eTTA 在回归任务上的局限：为分类任务设计，一般基于熵最小化和特征对齐；熵最小化不适用，回归模型产生单一值，不产生概率分布；简单特征对齐对回归模型效果不佳，可能反而会稀释需要学习的特征\u003c/p\u003e\n\u003ch2 id=\"problem-setting\"\u003eProblem Setting\u003c/h2\u003e\n\u003cp\u003e考虑一个回归模型 $ f_\\theta: \\mathcal{X} \\to \\mathbb{R} $，可以进一步分解为\u003cstrong\u003e特征提取器\u003c/strong\u003e $ g_\\phi: \\mathcal{X} \\to \\mathbb{R}^D $（从输入 $ \\mathcal{X} $ 提取 $ D $ 维特征 $ z $）和\u003cstrong\u003e线性回归器\u003c/strong\u003e $ h_\\psi(z) = w^T z + b $（或者 $ h_{\\psi}(z)=Wz+b $）\u003c/p\u003e\n\u003cp\u003e$ f_\\theta $ 首先在一个有标签的\u003cstrong\u003e源数据集\u003c/strong\u003e $ S = \\{(x_i, y_i)\\}_{i=1}^{N_s} $ 上进行预训练，数据从源域分布 $ p_s $ 中采样\u003c/p\u003e\n\u003cp\u003e目标是使用一个\u003cstrong\u003e无标签的\u003c/strong\u003e目标数据集 $ T = \\{x_j\\}_{j=1}^{N_t} $ 来适应预训练好的模型 $ f_\\theta $ 到目标域\u003c/p\u003e\n\u003cp\u003e我们假设存在 \u003cstrong\u003ecovariate shift\u003c/strong\u003e ，这意味着：\u003c/p\u003e","title":"SSA"},{"content":"Method Problem Set EEG 数据 $ \\{ X_{s,l}^{i},y_{s,l}^{i} \\}_{i=1}^{n_{s,l}} $ ，进行无监督在线 K 分类\nSource Model Training 对源数据做 Euclidean alignment (EA) 数据对齐，减少不同个体 EEG 信号差异\nEA 计算每个个体所有 EEG 试次协方差矩阵的算术平均值 $$ R_{s,l} = \\dfrac{1}{n}\\sum_{i=1}^{n} X_{i}(X_{i})^{T} \\implies \\bar{X}_{i} = R_{s,l}^{-1/2}X_{i} $$ 之后再整合经过对齐的受试者数据，形成“源域”\n在整合后的数据上独立训练 $ M $ 个模型\nIncremental EA on Target Data 对新数据增量式更新协方差矩阵，再用新的矩阵更新所有测试数据\nTarget Label Prediction 用训练好的 $ M $ 模型初始化用于适应目标域的 $ M $ 个 TTA 模型 $ f_{m} $\n新的 $ X_{a} $ 经过 IEA 被变换为 $ X_{a}' $ 后被输入到每个模型 $ f_{m} $ 中进行分类，输出概率向量 $ f_{m}(X_{a}') $\n之后结合这 $ M $ 个概率向量来获得最终的预测标签 $ \\hat{y}_{a} $\n$ a\\leq M $ 数据量较少：直接对所有模型的预测向量平均 $ a\u003eM $ 数据量较多：使用谱元学习器对各个模型进行加权平均，根据历史表现（预测的协方差矩阵）分配不同的权重 Target Model Update 在数据量足够以后（$ a\u003eB $）使用一个滑动批次的数据更新模型，在此之前模型不变\n组合损失函数： $$ L_{M} = L_{CEM}(f_{m};\\{ X'_{i} \\}_{i=a-B+1}^{a}) + L_{MDR}(f_{m};\\{ X'_{i} \\}_{i=a-B+1}^{a}) $$ 有两个部分\n1) Conditional Entropy Minimization 条件熵最小化\n使分类边界更加清晰 通过最小化每个预测的条件熵（使用温度缩放因子 $ T $ 进行校准），使模型倾向于输出接近 0 或 1 的概率 2) Adaptive Marginal Distribution Regularization 自适应边缘分布正则化\n防止出现所有数据都在单类别和对错误结果过于自信的不良结果 计算当前批次每个类别的平均预测概率 $ p_{k} $ 通过设置阈值得到伪标签，估计目标域的类别评论 $ z_{k} $ 校准平均预测概率 $ q'_{k} $ $$ q_{k} = \\dfrac{p_{k}}{c+z_{k}},\\quad q'_{k} = \\dfrac{q_{k}}{\\sum q} $$ $ L_{MDR} = \\sum_{k=1}^{K}q'_{k}\\log q'_{k} $ （采用负熵的形式） Complete T-TIME Algorithm 先预测，后台并行地更新模型\nExperiment 使用三个运动想象数据集\n每次把一个受试者的数据作为目标域，其余作为源域\nClassification Accuracies on Balanced Classes 过于复杂的算法由于数据不足，性能反而下降 基于熵的方法普遍表现良好，MCC 在离线迁移学习中表现最好 T-TIME 在所有在线迁移学习算法中表现最佳，并且其性能与表现最佳的离线迁移学习方法相当 Classification Performance Under Class-Imbalance 使用随机移除数据来创建不平衡数据集\n传统方法表现较弱 T-TIME 表现突出 ","permalink":"https://diefish1024.github.io/posts/literature-notes/t-time/","summary":"\u003ch1 id=\"method\"\u003eMethod\u003c/h1\u003e\n\u003ch3 id=\"problem-set\"\u003eProblem Set\u003c/h3\u003e\n\u003cp\u003eEEG 数据 $ \\{ X_{s,l}^{i},y_{s,l}^{i} \\}_{i=1}^{n_{s,l}} $ ，进行无监督在线 K 分类\u003c/p\u003e\n\u003ch3 id=\"source-model-training\"\u003eSource Model Training\u003c/h3\u003e\n\u003cp\u003e对源数据做 Euclidean alignment (EA) 数据对齐，减少不同个体 EEG 信号差异\u003c/p\u003e\n\u003cp\u003eEA 计算每个个体所有 EEG 试次协方差矩阵的算术平均值\n$$ \n\nR_{s,l} = \\dfrac{1}{n}\\sum_{i=1}^{n} X_{i}(X_{i})^{T} \\implies \\bar{X}_{i} = R_{s,l}^{-1/2}X_{i}\n\n $$\n之后再整合经过对齐的受试者数据，形成“源域”\u003c/p\u003e\n\u003cp\u003e在整合后的数据上独立训练 $ M $ 个模型\u003c/p\u003e\n\u003ch3 id=\"incremental-ea-on-target-data\"\u003eIncremental EA on Target Data\u003c/h3\u003e\n\u003cp\u003e对新数据增量式更新协方差矩阵，再用新的矩阵更新所有测试数据\u003c/p\u003e\n\u003ch3 id=\"target-label-prediction\"\u003eTarget Label Prediction\u003c/h3\u003e\n\u003cp\u003e用训练好的 $ M $ 模型初始化用于适应目标域的 $ M $ 个 TTA 模型 $ f_{m} $\u003c/p\u003e\n\u003cp\u003e新的 $ X_{a} $ 经过 IEA 被变换为 $ X_{a}' $ 后被输入到每个模型 $ f_{m} $ 中进行分类，输出概率向量 $ f_{m}(X_{a}') $\u003c/p\u003e","title":"T-TIME"},{"content":"Setting Fully Test-Time Adaptation 是一种独特的模型适应设定。在此设定下，模型 $ f_\\theta(x) $ 在训练阶段已通过源数据 $ x^s $ 和标签 $ y^s $ 完成训练，获得参数 $ \\theta $。但在测试阶段，模型将遇到与源数据分布不同的无标签目标数据 $ x^t $。\nFTT-Adaptation 与以下方法不同：\nFine-tuning：需要目标标签进行重新训练。 Domain Adaptation：需要源数据和目标数据进行联合训练。 Test-Time Training (TTT)：需要修改训练过程并共同优化有监督及自监督损失。 相比之下，FTT-Adaptation 仅能利用预训练模型 $ f_\\theta $ 和无标签目标数据 $ x^t $ 进行适应，不依赖源数据或额外的监督信息。\nMethod 论文的核心贡献是提出了 Tent 方法，其核心思想是通过最小化测试熵（Test Entropy Minimization）来适应模型预测，旨在使模型对测试数据的预测结果更“有信心”。\nEntropy Objective Tent 的测试时目标函数是最小化模型预测 $ \\hat{y} = f_\\theta(x^t) $ 的熵 $ H(\\hat{y}) $。论文中使用的香农熵计算公式如下：\n$$ H(\\hat{y}) = - \\sum_c p(\\hat{y}_c) \\log p(\\hat{y}_c) $$ 其中， $ p(\\hat{y}_c) $ 表示模型预测目标数据 $ x^t $ 属于类别 $ c $ 的概率。\n最小化熵促使模型输出更“尖锐”或更“确定”的预测分布。 优势：熵是一种无监督目标，仅依赖于模型预测，不需要真实标签。最小化熵与减少预测误差和数据漂移之间存在内在联系，因为更确定的预测通常意味着更正确的预测。 Modulation Parameters Tent 不直接修改原始模型的全部参数 $ \\theta $。相反，它仅更新模型内部归一化层（如Batch Normalization layers）中的线性且低维度的仿射变换参数：尺度参数 $ \\gamma $ 和偏移参数 $ \\beta $。\n这一选择的理由是：这些参数只占模型总参数的极小部分（\u0026lt;1%），优化效率高且稳定。 特征调制过程包含两个步骤： 1.Normalization (标准化)：根据当前批次测试数据的均值 $ \\mu $ 和标准差 $ \\sigma $ 来标准化特征 $ x $，即 $ \\hat{x} = (x - \\mu)/\\sigma $。这里的 $ \\mu, \\sigma $ 是在测试时从当前批次数据中估计的。 2.Transformation (仿射变换)：对标准化后的特征 $ \\hat{x} $ 应用仿射变换，即 $ x' = \\gamma \\hat{x} + \\beta $。参数 $ \\gamma $ 和 $ \\beta $ 通过最小化熵目标函数进行优化。 Algorithm Tent 算法的流程如下：\nInitialization： 加载预训练好的源模型参数 $ \\theta $。 固定所有非仿射变换的参数。 丢弃源数据中估计的归一化统计量。 优化器收集所有归一化层的通道级仿射变换参数 $ \\{\\gamma_{l,k}, \\beta_{l,k}\\} $。 Iteration：在线处理数据批次。 Forward Pass：对每个数据批次，逐层估计该批次数据的归一化统计量 ($ \\mu, \\sigma $)。 Backward Pass：计算预测熵 $ H(\\hat{y}) $ 相对于仿射变换参数 $ \\gamma, \\beta $ 的梯度 $ \\nabla H(\\hat{y}) $。 Update：使用梯度更新 $ \\gamma, \\beta $ 参数。Tent 采用高效的在线更新策略，每次更新只影响下一个批次的数据处理。 Termination：对于在线适应，适应过程只要有测试数据就持续进行。对于离线适应，模型会先进行更新，然后重复推断，适应可以持续多个Epochs。 Experiments 论文在多种计算机视觉任务和数据集上对 Tent 进行了全面评估。\nRobustness To Corruptions 在图像分类的鲁棒性基准测试中，使用受损版本的 CIFAR-10/100-C 和 ImageNet-C 数据集（15 种损坏类型，不同严重程度）。\n主要发现： Tent 在 ImageNet-C 上达到了 44.0% 的最低错误率，优于 SOTA 鲁棒性训练方法（如Adversarial Noise Training (ANT) 的 50.2%）和Test-Time Normalization (BN) 基线（49.9%）。 在 CIFAR-10/100-C 上，Tent 也显著优于其他 TTA baseline（BN, Pseudo-Labeling (PL)）以及需要联合训练源域和目标域的Domain Adaptation（RG, UDA-SS）和Test-Time Training (TTT) 方法。 这些改进仅通过一次Epoch的测试时优化实现，且未改变原始模型训练。 Source-Free Domain Adaptation 评估 Tent 在无源域适应场景下的性能，包括数字识别（从 SVHN 到 MNIST/MNIST-M/USPS）和语义分割（从 GTA 到 Cityscapes）。\n主要发现： 在数字识别任务中，Tent 大多数情况下错误率低于源模型和BN，部分情况甚至优于需要源数据的Domain Adaptation方法（RG, UDA-SS）。 语义分割任务中，Tent 将Intersection-Over-Union (IOU) 分数从源模型的 28.8% 提高到 35.8%，显著优于 BN 的 31.4%。 Analysis 论文通过多项分析实验探究了 Tent 的工作原理和特性：\nTent 降低熵和误差：实验证实，Tent 成功降低了预测的熵值和任务损失（如Softmax Cross-Entropy），印证了熵最小化与误差减少之间的正相关性。 Tent 需要特征调制：不更新归一化统计量或不优化仿射变换参数会显著降低 Tent 性能，说明这些特征调制步骤对于适应不可或缺。 Tent 泛化到不同的目标数据：适应过程对未用于更新的其他测试数据点同样有效，表明其学习到的调制是通用的。 Tent 调制与归一化不同：对比分析显示，Tent 的特征调制使特征更接近在目标标签上优化的Oracle模型（理想模型），而非仅像Batch Normalization那样接近原始参考分布。 Tent 适应其他网络架构：Tent 在基于Self-Attention 和Equilibrium Solving (MDEQ) 的模型上也能有效降低误差，展现了其普适性。 Related Work 论文回顾了与 Tent 相关的现有工作：\nTrain-Time Adaptation 方法：传统的Domain Adaptation、Test-Time Training (TTT) 等，通常需要源数据或训练阶段修改模型。 Source-Free Adaptation 方法：近期一些不依赖源数据的方法，但通常需要更复杂的设计、离线优化或修改训练过程。Tent 的优势在于其在线、高效且不改变训练过程。 Entropy Minimization：熵最小化已被广泛用于Semi-Supervised Learning和Domain Adaptation的正则化项，但 Tent 首次将其作为Fully Test-Time Adaptation中唯一的无监督损失来驱动模型适应。 Feature Modulation：归一化层和仿射变换已被用于各种任务的特征调制，但 Tent 将其作为在测试时通过无监督目标进行优化的核心机制。 Discussion Tent 通过Test Entropy Minimization实现了在数据漂移情况下的泛化误差降低。其核心在于模型的自监督自我改进，即依据自身的预测反馈进行调整。\n优势总结： 高效：仅通过在线优化少数参数（$ \\gamma, \\beta $）实现。 实用：无需源数据访问，不改变模型训练过程。 通用：适用于多种数据漂移类型和不同网络架构。 尽管 Tent 在广泛的场景中表现出色，但仍存在挑战，例如在特定困难的数据漂移（如 SVHN 到 MNIST-M/USPS）上仍有提升空间。未来研究方向可探索更全面的参数调整、更通用的Test-Time Adaptation Loss以及进一步提升效率的方法。总而言之，Tent 为Fully Test-Time Adaptation 提供了一个创新且实用的范式，使得模型能够在部署后，在面对未知且无标签的测试数据时，具备强大的自我适应能力。\n","permalink":"https://diefish1024.github.io/posts/literature-notes/tent/","summary":"\u003ch1 id=\"setting\"\u003eSetting\u003c/h1\u003e\n\u003cp\u003e\u003cstrong\u003eFully Test-Time Adaptation\u003c/strong\u003e 是一种独特的模型适应设定。在此设定下，模型 $ f_\\theta(x) $ 在训练阶段已通过源数据 $ x^s $ 和标签 $ y^s $ 完成训练，获得参数 $ \\theta $。但在测试阶段，模型将遇到与源数据分布不同的无标签目标数据 $ x^t $。\u003c/p\u003e\n\u003cp\u003eFTT-Adaptation 与以下方法不同：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eFine-tuning\u003c/strong\u003e：需要目标标签进行重新训练。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eDomain Adaptation\u003c/strong\u003e：需要源数据和目标数据进行联合训练。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eTest-Time Training (TTT)\u003c/strong\u003e：需要修改训练过程并共同优化有监督及自监督损失。\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e相比之下，FTT-Adaptation 仅能利用预训练模型 $ f_\\theta $ 和无标签目标数据 $ x^t $ 进行适应，不依赖源数据或额外的监督信息。\u003c/p\u003e\n\u003ch2 id=\"method\"\u003eMethod\u003c/h2\u003e\n\u003cp\u003e论文的核心贡献是提出了 \u003cstrong\u003eTent\u003c/strong\u003e 方法，其核心思想是通过\u003cstrong\u003e最小化测试熵\u003c/strong\u003e（\u003cstrong\u003eTest Entropy Minimization\u003c/strong\u003e）来适应模型预测，旨在使模型对测试数据的预测结果更“有信心”。\u003c/p\u003e\n\u003ch3 id=\"entropy-objective\"\u003eEntropy Objective\u003c/h3\u003e\n\u003cp\u003eTent 的测试时目标函数是最小化模型预测 $ \\hat{y} = f_\\theta(x^t) $ 的\u003cstrong\u003e熵 $ H(\\hat{y}) $\u003c/strong\u003e。论文中使用的\u003cstrong\u003e香农熵\u003c/strong\u003e计算公式如下：\u003c/p\u003e\n$$ \n\nH(\\hat{y}) = - \\sum_c p(\\hat{y}_c) \\log p(\\hat{y}_c)\n\n $$\n\u003cp\u003e其中， $ p(\\hat{y}_c) $ 表示模型预测目标数据 $ x^t $ 属于类别 $ c $ 的概率。\u003c/p\u003e","title":"Tent"},{"content":"Setting Continual Test-Time Domain Adaptation 是一种更具挑战性的模型适应设定。在此设定下，一个在源数据上预训练好的模型，在测试时会遇到一个非平稳且持续变化的目标环境 。\nCoTTA 与以下方法不同：\nStandard Domain Adaptation：需要同时访问源数据和（静态的）目标数据进行训练。 Standard Test-Time Adaptation / Fully Test-Time Adaptation：通常假设目标域是固定的或静态的，而 CoTTA 关注的是持续变化的目标域。 Test-Time Training (TTT)：需要修改源模型的训练过程以加入辅助任务，因此无法使用任意的“开箱即用”预训练模型。 相比之下，CoTTA 专门解决在无源数据的条件下，模型如何在线适应一个持续变化的数据流，同时克服现有方法中常见的错误累积和灾难性遗忘问题。\nMethod 论文的核心贡献是提出了CoTTA (Continual Test-Time Adaptation) 方法，旨在通过减少错误累积和避免灾难性遗忘，实现模型在非平稳环境下的长期稳定适应，主要有两个关键部分。\n1. 减少错误累积 (Reducing Error Accumulation) 为了生成更可靠的自训练信号，CoTTA 采用了平均化的伪标签策略，该策略结合了权重平均和数据增强平均。\n权重平均伪标签 (Weight-Averaged Pseudo-Labels) 该方法采用一个教师 - 学生 (teacher-student) 框架。学生模型 (student model) 在线进行学习和更新。 教师模型 (teacher model) 的权重是学生模型权重的指数移动平均 (Exponential Moving Average, EMA)。 由于教师模型的更新更平滑，其预测结果通常比学生模型更准确，因此用它来生成伪标签，可以有效减少错误累积。学生模型通过最小化与教师伪标签的一致性损失 (consistency loss) 来进行更新。 数据增强平均伪标签 (Augmentation-Averaged Pseudo-Labels) 为了进一步提升伪标签在遇到较大域偏移时的质量，CoTTA 会有条件地使用数据增强。 它首先使用原始预训练模型评估当前测试数据的预测置信度，以此来近似域差异的大小。 条件性应用： 如果置信度高（域差异小），则直接使用教师模型的预测作为伪标签。 如果置信度低（域差异大），则对输入数据进行 N 次随机增强，并将教师模型对这些增强样本的平均预测结果作为伪标签。这可以进一步提高伪标签的鲁棒性。 2. 避免灾难性遗忘 (Avoiding Catastrophic Forgetting) 为了在长期适应过程中保留从源域学到的知识，CoTTA 引入了随机恢复 (Stochastic Restoration) 机制。\n核心思想：在每次模型更新后，以一个很小的概率 p，将模型中的一小部分权重参数随机地恢复到其原始的、预训练时的状态。 优势： 这种机制可以看作一种特殊的 Dropout。它能有效防止模型在适应新数据时“漂移”得离源模型太远，从而显式地保留了源知识，避免了灾难性遗忘。 通过保留源知识，CoTTA 能够安全地更新网络中的所有参数，而不仅仅是归一化层，这为模型适应提供了更大的容量。 Algorithm CoTTA 算法的在线流程如下：\nInitialization (初始化)： 加载一个“开箱即用”的预训练源模型 $ f_{\\theta_{0}} $ 用源模型权重初始化教师模型 $ f_{\\theta'_{0}} $ Iteration (迭代)：对于在线输入的每个测试数据 $ x_{t} $​： 生成伪标签：使用教师模型 $ f_{\\theta'_{t}} $​​，并结合条件性数据增强，生成权重和增强平均的伪标签。 更新学生模型：通过一致性损失更新学生模型 $ f_{\\theta_{t}} $ 更新教师模型：使用 EMA 更新教师模型的权重 $ f_{\\theta'_{t+1}} $ 随机恢复：对学生模型的权重进行随机恢复 Output (输出)：使用教师模型 $ f_{\\theta'_{t}} $​​ 进行在线预测，并传递更新后的学生和教师模型到下一个时间步。 Experiments 论文在多个图像分类和语义分割任务上对 CoTTA 进行了评估，特别是在一个持续变化的测试环境中。\nContinual Adaptation on Corrupted Images 在 CIFAR10-C、CIFAR100-C 和 ImageNet-C 数据集上，模型被顺序输入 15 种不同类型的损坏图像。\n主要发现： 在 CIFAR10-C 上，CoTTA 的平均错误率仅为 16.2%，显著优于 Source-only 基线 (43.5%) 和 TENT-continual (20.7%)。 在更难的 CIFAR100-C 上，TENT 等方法因错误累积导致性能随时间推移而急剧下降（错误率从 37.2% 恶化到 90.4%），而 CoTTA 表现稳定，平均错误率仅为 32.5% 。 实验表明，TENT 在持续适应的后期会因错误累积而性能崩溃，而 CoTTA 的随机恢复机制成功避免了这一点。 Continual Adaptation on Semantic Segmentation 在一个从 Cityscapes (晴天) 到 ACDC (雾、夜、雨、雪等恶劣天气) 的持续语义分割任务中，模型会循环经历这四种天气条件 10 次，以测试其长期适应和遗忘情况。\n主要发现： CoTTA 将平均 mIoU 提升至 58.6%，优于源模型 (56.7%) 和其他适应方法。 TENT 在此任务上表现不佳，因为其依赖的批量归一化 (Batch Normalization) 层在 Transformer 架构 (Segformer) 中很少。 CoTTA 不依赖于特定层，因此在基于 Transformer 的架构上同样有效，展现了其通用性。 Analysis 通过消融实验验证了 CoTTA 各个组件的有效性。\n权重平均的作用：仅使用权重平均的伪标签，就将错误率从 20.7% (TENT-continual) 降至 18.3%，证明了教师模型伪标签的优越性。 数据增强平均的作用：在权重平均的基础上再加入条件性数据增强，错误率进一步降至 17.4%。 随机恢复的作用：最后加入随机恢复机制，错误率最终降至 16.2%，并且解决了长期适应中的性能衰退问题，证明了其在避免灾难性遗忘中的关键作用。 Related Work 论文回顾了与 CoTTA 相关的领域：\nTest-Time Adaptation (TTA)：现有工作大多关注静态目标域，在持续变化的环境中，基于熵最小化或伪标签的方法容易因伪标签噪声而累积错误。 Continuous Domain Adaptation：与 CoTTA 目标相似，但现有方法通常需要访问源数据来对齐分布。 Continual Learning：CoTTA 借鉴了该领域的思想来解决灾难性遗忘问题，但将其应用在了一个无监督、测试时适应的独特场景中。 Source-Free Domain Adaptation：CoTTA 属于此范畴，其新颖之处在于它专为在线和持续变化的环境设计，而这是先前工作很少考虑的。 Discussion CoTTA 成功地解决了在无源数据、非平稳环境下进行持续测试时适应的挑战。它通过创新的机制同时解决了错误累积和灾难性遗忘这两个核心难题。\n优势总结： 稳定与长效：通过随机恢复机制，CoTTA 实现了在长期持续适应过程中的性能稳定，避免了性能崩溃。 实用与通用：无需访问源数据，也无需修改模型训练过程，可直接用于各类“开箱即用”的预训练模型（包括 CNN 和 Transformer） 。 高效：整个适应过程在线进行，模型根据当前数据流即时更新和预测。 总而言之，CoTTA 为模型在真实世界中部署后的持续自我进化提供了一个强大且实用的框架，使模型能够鲁棒地适应不断变化的操作环境。\n","permalink":"https://diefish1024.github.io/posts/literature-notes/cotta/","summary":"\u003ch1 id=\"setting\"\u003eSetting\u003c/h1\u003e\n\u003cp\u003e\u003cstrong\u003eContinual Test-Time Domain Adaptation\u003c/strong\u003e 是一种更具挑战性的模型适应设定。在此设定下，一个在源数据上预训练好的模型，在测试时会遇到一个\u003cstrong\u003e非平稳\u003c/strong\u003e且\u003cstrong\u003e持续变化\u003c/strong\u003e的目标环境 。\u003c/p\u003e\n\u003cp\u003eCoTTA 与以下方法不同：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eStandard Domain Adaptation\u003c/strong\u003e：需要同时访问源数据和（静态的）目标数据进行训练。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eStandard Test-Time Adaptation / Fully Test-Time Adaptation\u003c/strong\u003e：通常假设目标域是固定的或静态的，而 CoTTA 关注的是持续变化的目标域。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eTest-Time Training (TTT)\u003c/strong\u003e：需要修改源模型的训练过程以加入辅助任务，因此无法使用任意的“开箱即用”预训练模型。\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e相比之下，CoTTA 专门解决在\u003cstrong\u003e无源数据\u003c/strong\u003e的条件下，模型如何在线适应一个\u003cstrong\u003e持续变化的\u003c/strong\u003e数据流，同时克服现有方法中常见的\u003cstrong\u003e错误累积\u003c/strong\u003e和\u003cstrong\u003e灾难性遗忘\u003c/strong\u003e问题。\u003c/p\u003e\n\u003ch2 id=\"method\"\u003eMethod\u003c/h2\u003e\n\u003cp\u003e论文的核心贡献是提出了\u003cstrong\u003eCoTTA (Continual Test-Time Adaptation)\u003c/strong\u003e 方法，旨在通过\u003cstrong\u003e减少错误累积\u003c/strong\u003e和\u003cstrong\u003e避免灾难性遗忘\u003c/strong\u003e，实现模型在非平稳环境下的长期稳定适应，主要有两个关键部分。\u003c/p\u003e\n\u003ch3 id=\"1-减少错误累积-reducing-error-accumulation\"\u003e1. 减少错误累积 (Reducing Error Accumulation)\u003c/h3\u003e\n\u003cp\u003e为了生成更可靠的自训练信号，CoTTA 采用了平均化的伪标签策略，该策略结合了权重平均和数据增强平均。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e权重平均伪标签 (Weight-Averaged Pseudo-Labels)\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003e该方法采用一个\u003cstrong\u003e教师 - 学生 (teacher-student)\u003c/strong\u003e 框架。学生模型 (student model) 在线进行学习和更新。\u003c/li\u003e\n\u003cli\u003e教师模型 (teacher model) 的权重是学生模型权重的\u003cstrong\u003e指数移动平均 (Exponential Moving Average, EMA)\u003c/strong\u003e。\u003c/li\u003e\n\u003cli\u003e由于教师模型的更新更平滑，其预测结果通常比学生模型更准确，因此用它来生成伪标签，可以有效减少错误累积。学生模型通过最小化与教师伪标签的\u003cstrong\u003e一致性损失\u003c/strong\u003e (consistency loss) 来进行更新。\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e数据增强平均伪标签 (Augmentation-Averaged Pseudo-Labels)\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003e为了进一步提升伪标签在遇到较大域偏移时的质量，CoTTA 会有条件地使用数据增强。\u003c/li\u003e\n\u003cli\u003e它首先使用\u003cstrong\u003e原始预训练模型\u003c/strong\u003e评估当前测试数据的\u003cstrong\u003e预测置信度\u003c/strong\u003e，以此来近似域差异的大小。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e条件性应用\u003c/strong\u003e：\n\u003cul\u003e\n\u003cli\u003e如果置信度\u003cstrong\u003e高\u003c/strong\u003e（域差异小），则直接使用教师模型的预测作为伪标签。\u003c/li\u003e\n\u003cli\u003e如果置信度\u003cstrong\u003e低\u003c/strong\u003e（域差异大），则对输入数据进行 N 次随机增强，并将教师模型对这些增强样本的平均预测结果作为伪标签。这可以进一步提高伪标签的鲁棒性。\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"2-避免灾难性遗忘-avoiding-catastrophic-forgetting\"\u003e2. 避免灾难性遗忘 (Avoiding Catastrophic Forgetting)\u003c/h3\u003e\n\u003cp\u003e为了在长期适应过程中保留从源域学到的知识，CoTTA 引入了\u003cstrong\u003e随机恢复 (Stochastic Restoration)\u003c/strong\u003e 机制。\u003c/p\u003e","title":"CoTTA"},{"content":"Introduction 类似 GAN 的对抗训练思想\nDomain Adaptation 给定源域 $ D_{S} $ （有标签）和目标域 $ D_{T} $ （无标签），目标是训练一个分类器 $ \\eta: X\\to Y $ 使其在目标域上的目标风险 $$ R_{D_{T}}(\\eta) = \\underset{(\\mathbf{x},y)\\sim D_{T}}{\\mathrm{Pr}}(\\eta(\\mathbf{x}) \\neq y) $$ 最小\nDomain Divergence 需要量化两个领域的“相似度”，从而引出了 H- 散度 的概念： $$ d_{\\mathcal{H}}(D_S, D_T) = 2 \\sup_{\\eta \\in \\mathcal{H}} \\left| \\Pr_{x \\sim D_S}[\\eta(x) = 1] - \\Pr_{x \\sim D_T}[\\eta(x) = 1] \\right| $$ 含义是最优的分类器将目标域和源域判定为 1 的可能性之差，当 H- 散度非常小时，说明两个领域很难被区分，也就说明学习的特征实现了领域不变性的效果\n由于理论 H 散度是理想数据分布上的定义，实际中只有有限的样本集 $ S $ 和 $ T $ ，因此需要一定的近似，于是需要经验 H- 散度 $$ \\hat{d}_{\\mathcal{H}}(S, T) = 2 \\left(1 - \\min_{\\eta \\in \\mathcal{H}} \\left[ \\dfrac{1}{n}\\sum_{i=1}^n \\mathcal{I}[\\eta(x_i) = 0] + \\dfrac{1}{n'}\\sum_{i=n+1}^N \\mathcal{I}[\\eta(x_i) = 1] \\right] \\right) $$ 其中 $ \\mathcal{I}[\\cdot] $ 表示条件为真时为 1，否则为 0\nProxy Distance 经验 H- 散度也需要直接遍历所有的 $ \\eta $ ，在计算上不现实，需要一个进一步的近似方法，因此考虑 Proxy A-distance (PAD)\n构造用于领域分类的数据集 $$ U = \\{ (\\mathbf{x}_{i},0) \\}_{i=1}^{n} \\cup \\{ (\\mathbf{x}_{i},1) \\}_{i=n+1}^{N} $$ 用这个数据集训练分类器，设 $ \\epsilon $ 为在数据集 $ U $ 上训练出的最优领域分类器所达到的最小错误率，那么可以用 $$ \\hat{d}_{\\mathcal{A}} = 2(1-2\\epsilon) $$ 来近似 H- 散度\nGeneralization Bound on the Target Risk 有效性证明\n理论研究说明模型的目标风险可以通过源风险和两个领域的散度来限制，主要思想是 $$ R_{D_T}(\\eta) \\le R_S(\\eta) + \\text{Domain Divergence Terms} + \\text{Complexity Terms} + \\beta $$ 其中 $ \\text{Domain Divergence Terms}\\approx d_{\\mathcal{H}}(S, T) $ ，可以用上面的 $ \\hat{d}_{\\mathcal{A}} $ 近似；$ \\text{Complexity Terms} $ 是一个比较小的常数项，和模型本身训练有关（原公式没看懂。。）；$ \\beta $ 是一个理想化的项，表示最好情况下在目标域和源域上同时取得的最低错误率\nDANN 优化目标： $$ E(\\theta_f, \\theta_y, \\theta_d) = \\frac{1}{n} \\sum_{i=1}^n \\mathcal{L}_y(\\theta_f, \\theta_y) - \\lambda \\left( \\frac{1}{n} \\sum_{i=1}^n \\mathcal{L}_d(\\theta_f, \\theta_d) + \\frac{1}{n'} \\sum_{i=n+1}^N \\mathcal{L}_d(\\theta_f, \\theta_d) \\right) $$ 核心是 Saddle Point Problem ，找到需要找到鞍点而非最小值\n如何实现对抗：\n标签预测参数： $$ \\theta_{y} \\leftarrow \\theta_{y} - \\mu \\dfrac{ \\partial \\mathcal{L}_{y} }{ \\partial \\theta_{y} } $$ 领域分类参数： $$ \\theta_{d} \\leftarrow \\theta_{d} - \\mu \\lambda \\dfrac{ \\partial \\mathcal{L}_{d} }{ \\partial \\theta_{d} } $$ 特征提取参数： $$ \\theta_{f} \\leftarrow \\theta_{f} - \\mu\\left( \\dfrac{ \\partial \\mathcal{L}_{y} }{ \\partial \\theta_{f} } - \\lambda \\dfrac{ \\partial \\mathcal{L}_{d} }{ \\partial \\theta_{f} } \\right) $$ 核心需要最大化 $ \\mathcal{L}_{d} $ ，因此需要沿着梯度的正向优化 Gradient Reversal Layer (GRL) 是实现对抗的核心组件，具体原理是在前向传播时表现为 $ R(x)=x $ ，但是反向传播时 $ \\dfrac{\\mathrm{d} R}{\\mathrm{d}x}=-I $ ，这样可以直接利用内置的自动微分优雅实现对抗\n","permalink":"https://diefish1024.github.io/posts/literature-notes/dann/","summary":"\u003ch2 id=\"introduction\"\u003eIntroduction\u003c/h2\u003e\n\u003cp\u003e类似 GAN 的对抗训练思想\u003c/p\u003e\n\u003ch2 id=\"domain-adaptation\"\u003eDomain Adaptation\u003c/h2\u003e\n\u003cp\u003e给定源域 $ D_{S} $ （有标签）和目标域 $ D_{T} $ （无标签），目标是训练一个分类器 $ \\eta: X\\to Y $ 使其在目标域上的目标风险\n$$ \n\nR_{D_{T}}(\\eta) = \\underset{(\\mathbf{x},y)\\sim D_{T}}{\\mathrm{Pr}}(\\eta(\\mathbf{x}) \\neq y)\n\n $$\n最小\u003c/p\u003e\n\u003ch4 id=\"domain-divergence\"\u003eDomain Divergence\u003c/h4\u003e\n\u003cp\u003e需要量化两个领域的“相似度”，从而引出了 \u003cstrong\u003eH- 散度\u003c/strong\u003e 的概念：\n$$ \n\nd_{\\mathcal{H}}(D_S, D_T) = 2 \\sup_{\\eta \\in \\mathcal{H}} \\left| \\Pr_{x \\sim D_S}[\\eta(x) = 1] - \\Pr_{x \\sim D_T}[\\eta(x) = 1] \\right|\n\n $$\n含义是最优的分类器将目标域和源域判定为 1 的可能性之差，当 H- 散度非常小时，说明两个领域很难被区分，也就说明学习的特征实现了领域不变性的效果\u003c/p\u003e\n\u003cp\u003e由于理论 H 散度是理想数据分布上的定义，实际中只有有限的样本集 $ S $ 和 $ T $ ，因此需要一定的近似，于是需要经验 H- 散度\n$$ \n\n\\hat{d}_{\\mathcal{H}}(S, T) = 2 \\left(1 - \\min_{\\eta \\in \\mathcal{H}} \\left[ \\dfrac{1}{n}\\sum_{i=1}^n \\mathcal{I}[\\eta(x_i) = 0] + \\dfrac{1}{n'}\\sum_{i=n+1}^N \\mathcal{I}[\\eta(x_i) = 1] \\right] \\right)\n\n $$\n其中 $ \\mathcal{I}[\\cdot] $ 表示条件为真时为 1，否则为 0\u003c/p\u003e","title":"DANN"},{"content":"A General Paradigm of Test-Time Adaptation 根据测试数据接收方式和适应过程，TTA 分为三种主要范式：\nTest-Time Batch Adaptation (TTBA) 测试时间批次适应： 数据以小批次形式到达。模型会针对每个到来的小批次进行适应，并立即提供预测。 Online Test-Time Adaptation (OTTA) 在线测试时间适应： 数据以序列化的方式（小批次）到达。模型进行增量更新，并且过去的适应经验会影响未来的预测。 Test-Time Domain Adaptation (TTDA) 测试时间域适应： 整个目标域的数据（所有测试数据）可在预测前一次性用于适应。 Datasets for Evaluation 论文使用了两种不同类型的分布偏移数据集进行评估：\nCorruption Datasets 损坏数据集： 原始数据集（CIFAR-10，ImageNet）经过人为损坏处理后得到的，通过添加不同类型的噪声、模糊等，模拟不同严重程度的分布偏移。 Natural-shift Datasets 自然偏移数据集： 这些数据集代表数据分布中自然发生的变化，收集自不同的真实世界来源或条件（Office-Home，DomainNet，其中图像可能是不同风格的艺术作品、剪贴画、真实世界照片或草图）。 Results on Natural Shift Datasets TTA 方法在自然偏移数据集上的表现与在损坏数据集上的表现有所不同。 PredBN 在损坏数据集上有效，但在自然偏移数据集上表现不佳，有时甚至比源模型更差。这可能是因为自然偏移对数据分布的影响与人工损坏不同。 T3A 在 OTTA 范式下的自然偏移数据集上表现优于其他 OTTA 算法。这归因于其特征生成方式及其分类器优化能力。 对于自然偏移数据集，TTDA 算法 持续取得了最高的性能。一些 OTTA 方法的多轮次也能达到可比的成果。 ","permalink":"https://diefish1024.github.io/posts/literature-notes/benchmarking-tta/","summary":"\u003ch3 id=\"a-general-paradigm-of-test-time-adaptation\"\u003eA General Paradigm of Test-Time Adaptation\u003c/h3\u003e\n\u003cp\u003e根据测试数据接收方式和适应过程，TTA 分为三种主要范式：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eTest-Time Batch Adaptation (TTBA) 测试时间批次适应：\u003c/strong\u003e 数据以小批次形式到达。模型会针对每个到来的小批次进行适应，并立即提供预测。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eOnline Test-Time Adaptation (OTTA) 在线测试时间适应：\u003c/strong\u003e 数据以序列化的方式（小批次）到达。模型进行增量更新，并且过去的适应经验会影响未来的预测。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eTest-Time Domain Adaptation (TTDA) 测试时间域适应：\u003c/strong\u003e 整个目标域的数据（所有测试数据）可在预测前一次性用于适应。\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"datasets-for-evaluation\"\u003eDatasets for Evaluation\u003c/h3\u003e\n\u003cp\u003e论文使用了两种不同类型的分布偏移数据集进行评估：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eCorruption Datasets 损坏数据集：\u003c/strong\u003e 原始数据集（CIFAR-10，ImageNet）经过\u003cstrong\u003e人为损坏处理\u003c/strong\u003e后得到的，通过添加不同类型的噪声、模糊等，模拟不同严重程度的分布偏移。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eNatural-shift Datasets 自然偏移数据集：\u003c/strong\u003e 这些数据集代表数据分布中\u003cstrong\u003e自然发生的变化\u003c/strong\u003e，收集自不同的真实世界来源或条件（Office-Home，DomainNet，其中图像可能是不同风格的艺术作品、剪贴画、真实世界照片或草图）。\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"results-on-natural-shift-datasets\"\u003eResults on Natural Shift Datasets\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eTTA 方法在自然偏移数据集上的表现与在损坏数据集上的表现有所不同。\u003c/li\u003e\n\u003cli\u003ePredBN 在损坏数据集上有效，但在自然偏移数据集上表现不佳，有时甚至比源模型更差。这可能是因为自然偏移对数据分布的影响与人工损坏不同。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eT3A\u003c/strong\u003e 在 OTTA 范式下的自然偏移数据集上表现优于其他 OTTA 算法。这归因于其特征生成方式及其分类器优化能力。\u003c/li\u003e\n\u003cli\u003e对于自然偏移数据集，\u003cstrong\u003eTTDA 算法\u003c/strong\u003e 持续取得了最高的性能。一些 OTTA 方法的多轮次也能达到可比的成果。\u003c/li\u003e\n\u003c/ul\u003e","title":"Benchmarking TTA"},{"content":"信号量 互斥锁在某种意义上也可以认为实现了 \u0026ldquo;happens-before\u0026rdquo; 的依赖关系—— release 必然发生在 acquire 之前。我们可以试着利用这种依赖关系来实现计算图的调度：为每条边分配一个互斥锁，代表数据或前置任务的完成；一个节点必须获得所有入边对应的互斥锁才能开始计算，计算完成后，就释放所有出边对应的互斥锁，通知下游节点输出就绪（但是这种直接使用互斥锁作为边状态信号的方式是 undefined behavior，因为互斥锁主要用于保护临界区，其释放通常要求由持有它的线程完成，若释放未曾获取的锁，则行为未定义）\n我们可以从这种想法中抽象出其本质，也就是用一个“信号”去获取资源的许可，类似餐厅的取号吃饭\n这种信号的思想很适合用来管理计数类型的同类资源，比如停车场的空位，为了实现这种 producer-customer 的问题，用 条件变量 可以轻易解决，进入的条件就是存在空位 count \u0026lt; capacity ，那我们从减少变量的角度出发，这实际上也就是剩余空位的数量大于零，我们停车相当于消耗了一个车位，离开相当于创造了一个车位，这也就得到了所谓“信号量”的机制\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 void P(sem_t *sem) { // Prolaag - try + decrease/down/wait/acquire mutex_lock(\u0026amp;sem-\u0026gt;lk); while (!(sem-\u0026gt;count \u0026gt; 0)) { cond_wait(\u0026amp;sem-\u0026gt;cv, \u0026amp;sem-\u0026gt;lk); } sem-\u0026gt;count--; // 消耗一个信号 (车位) mutex_unlock(\u0026amp;sem-\u0026gt;lk); } void V(sem_t *sem) { // Verhoog - increase/up/post/signal/release mutex_lock(\u0026amp;sem-\u0026gt;lk); sem-\u0026gt;count++; // 创建一个信号 (车位) cond_broadcast(\u0026amp;sem-\u0026gt;cv); mutex_unlock(\u0026amp;sem-\u0026gt;lk); } 根据这个一路推出信号量的思路，或许可以认为这是互斥锁的扩展\n信号量：应用 信号量有两种典型的应用：\n实现一个临时的 happens-before：$ A\\to V(s)\\to P(s)\\to B $ 管理计数资源：停车场、餐厅…… 可以利用信号量优雅地实现 producer-customer 的模型：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 sem_t empty = SEM_INIT(depth); sem_t fill = SEM_INIT(0); void T_produce() { P(\u0026amp;empty); printf(\u0026#34;(\u0026#34;); V(\u0026amp;fill); } void T_consume() { P(\u0026amp;fill); printf(\u0026#34;)\u0026#34;); V(\u0026amp;empty); } 信号量、条件变量与同步 信号量对比条件变量：\n信号量：更加干净优雅，但是不一定能很好地表示同步条件（用更 hack 的方式解决问题） 条件变量：更加万能，但是代码比较丑陋（用更标准化的方式解决问题） 尝试用信号量解决更复杂的同步问题：哲学家吃饭，一张圆桌围坐 $ n $ 个哲学家，每两个人之间有一把叉子（筷子更加合适？？），每个哲学家（线程）有时思考有时吃饭，思考时什么也不用做，吃饭时同时需要左手右手的叉子\n用条件变量解决这个问题只需要无脑设置同步条件即可，用信号量解决这个问题有一个初步的想法是 P(\u0026amp;sem[lhs]) \u0026amp;\u0026amp; P(\u0026amp;sem[rhs]) ，乍一看没什么问题，但是实际上这个条件在所有人都同时举起了同一边的叉子时会陷入死锁（所以并发编程一定要仔细再仔细！），所以为了排除这种方案，有两种解决方案：\n从桌子赶走一个人：为上桌吃饭人数设置一个信号量，限制不让所有人同时上桌即可（显然不可能所有人同时吃上饭） 为叉子编号，总是先拿起编号小的一把（最后一个人的顺序会和其他人反过来） 但是这样的解决方案是不够优雅不够通用的，因此更多时候条件变量是一个更好的选择，可以总结为信号量在适合的适合很好用，但不总是很好用\n","permalink":"https://diefish1024.github.io/posts/class-notes/nju-os-2025/16-%E5%B9%B6%E5%8F%91%E6%8E%A7%E5%88%B6%E5%90%8C%E6%AD%A5%E4%BF%A1%E5%8F%B7%E9%87%8F/","summary":"\u003ch2 id=\"信号量\"\u003e信号量\u003c/h2\u003e\n\u003cp\u003e互斥锁在某种意义上也可以认为实现了 \u0026ldquo;happens-before\u0026rdquo; 的依赖关系—— release 必然发生在 acquire 之前。我们可以试着利用这种依赖关系来实现计算图的调度：为每条边分配一个互斥锁，代表数据或前置任务的完成；一个节点必须获得所有入边对应的互斥锁才能开始计算，计算完成后，就释放所有出边对应的互斥锁，通知下游节点输出就绪（但是这种直接使用互斥锁作为边状态信号的方式是 undefined behavior，因为互斥锁主要用于保护临界区，其释放通常要求由持有它的线程完成，若释放未曾获取的锁，则行为未定义）\u003c/p\u003e\n\u003cp\u003e我们可以从这种想法中抽象出其本质，也就是用一个“\u003cstrong\u003e信号\u003c/strong\u003e”去获取资源的许可，类似餐厅的取号吃饭\u003c/p\u003e\n\u003cp\u003e这种\u003cstrong\u003e信号\u003c/strong\u003e的思想很适合用来管理\u003cstrong\u003e计数类型的同类资源\u003c/strong\u003e，比如停车场的空位，为了实现这种 producer-customer 的问题，用 \u003ca href=\"15.%20%E5%B9%B6%E5%8F%91%E6%8E%A7%E5%88%B6%EF%BC%9A%E5%90%8C%E6%AD%A5%E6%9D%A1%E4%BB%B6%E5%8F%98%E9%87%8F.md\"\u003e条件变量\u003c/a\u003e 可以轻易解决，进入的条件就是存在空位 \u003ccode\u003ecount \u0026lt; capacity\u003c/code\u003e ，那我们从减少变量的角度出发，这实际上也就是剩余空位的数量大于零，我们停车相当于\u003cstrong\u003e消耗\u003c/strong\u003e了一个车位，离开相当于\u003cstrong\u003e创造\u003c/strong\u003e了一个车位，这也就得到了所谓“\u003cstrong\u003e信号量\u003c/strong\u003e”的机制\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cdiv class=\"chroma\"\u003e\n\u003ctable class=\"lntable\"\u003e\u003ctr\u003e\u003ctd class=\"lntd\"\u003e\n\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode\u003e\u003cspan class=\"lnt\"\u003e 1\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 2\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 3\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 4\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 5\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 6\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 7\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 8\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 9\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e10\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e11\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e12\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e13\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e14\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e15\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e16\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e17\n\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\n\u003ctd class=\"lntd\"\u003e\n\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-c\" data-lang=\"c\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"kt\"\u003evoid\u003c/span\u003e \u003cspan class=\"nf\"\u003eP\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"kt\"\u003esem_t\u003c/span\u003e \u003cspan class=\"o\"\u003e*\u003c/span\u003e\u003cspan class=\"n\"\u003esem\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"c1\"\u003e// Prolaag - try + decrease/down/wait/acquire\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e\u003c/span\u003e    \u003cspan class=\"nf\"\u003emutex_lock\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"o\"\u003e\u0026amp;\u003c/span\u003e\u003cspan class=\"n\"\u003esem\u003c/span\u003e\u003cspan class=\"o\"\u003e-\u0026gt;\u003c/span\u003e\u003cspan class=\"n\"\u003elk\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"k\"\u003ewhile\u003c/span\u003e \u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"o\"\u003e!\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003esem\u003c/span\u003e\u003cspan class=\"o\"\u003e-\u0026gt;\u003c/span\u003e\u003cspan class=\"n\"\u003ecount\u003c/span\u003e \u003cspan class=\"o\"\u003e\u0026gt;\u003c/span\u003e \u003cspan class=\"mi\"\u003e0\u003c/span\u003e\u003cspan class=\"p\"\u003e))\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"nf\"\u003econd_wait\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"o\"\u003e\u0026amp;\u003c/span\u003e\u003cspan class=\"n\"\u003esem\u003c/span\u003e\u003cspan class=\"o\"\u003e-\u0026gt;\u003c/span\u003e\u003cspan class=\"n\"\u003ecv\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"o\"\u003e\u0026amp;\u003c/span\u003e\u003cspan class=\"n\"\u003esem\u003c/span\u003e\u003cspan class=\"o\"\u003e-\u0026gt;\u003c/span\u003e\u003cspan class=\"n\"\u003elk\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"n\"\u003esem\u003c/span\u003e\u003cspan class=\"o\"\u003e-\u0026gt;\u003c/span\u003e\u003cspan class=\"n\"\u003ecount\u003c/span\u003e\u003cspan class=\"o\"\u003e--\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e  \u003cspan class=\"c1\"\u003e// 消耗一个信号 (车位)\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e\u003c/span\u003e    \u003cspan class=\"nf\"\u003emutex_unlock\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"o\"\u003e\u0026amp;\u003c/span\u003e\u003cspan class=\"n\"\u003esem\u003c/span\u003e\u003cspan class=\"o\"\u003e-\u0026gt;\u003c/span\u003e\u003cspan class=\"n\"\u003elk\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"kt\"\u003evoid\u003c/span\u003e \u003cspan class=\"nf\"\u003eV\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"kt\"\u003esem_t\u003c/span\u003e \u003cspan class=\"o\"\u003e*\u003c/span\u003e\u003cspan class=\"n\"\u003esem\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"c1\"\u003e// Verhoog - increase/up/post/signal/release\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e\u003c/span\u003e    \u003cspan class=\"nf\"\u003emutex_lock\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"o\"\u003e\u0026amp;\u003c/span\u003e\u003cspan class=\"n\"\u003esem\u003c/span\u003e\u003cspan class=\"o\"\u003e-\u0026gt;\u003c/span\u003e\u003cspan class=\"n\"\u003elk\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"n\"\u003esem\u003c/span\u003e\u003cspan class=\"o\"\u003e-\u0026gt;\u003c/span\u003e\u003cspan class=\"n\"\u003ecount\u003c/span\u003e\u003cspan class=\"o\"\u003e++\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e  \u003cspan class=\"c1\"\u003e// 创建一个信号 (车位)\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e\u003c/span\u003e    \u003cspan class=\"nf\"\u003econd_broadcast\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"o\"\u003e\u0026amp;\u003c/span\u003e\u003cspan class=\"n\"\u003esem\u003c/span\u003e\u003cspan class=\"o\"\u003e-\u0026gt;\u003c/span\u003e\u003cspan class=\"n\"\u003ecv\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"nf\"\u003emutex_unlock\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"o\"\u003e\u0026amp;\u003c/span\u003e\u003cspan class=\"n\"\u003esem\u003c/span\u003e\u003cspan class=\"o\"\u003e-\u0026gt;\u003c/span\u003e\u003cspan class=\"n\"\u003elk\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\u003c/tr\u003e\u003c/table\u003e\n\u003c/div\u003e\n\u003c/div\u003e\u003cp\u003e根据这个一路推出信号量的思路，或许可以认为这是互斥锁的扩展\u003c/p\u003e","title":"16. 并发控制：同步信号量"},{"content":"同步和条件变量 互斥实现了原子性，但是无法实现确定性，也就是无法正确实现 \u0026ldquo;happens-before\u0026rdquo; 的关系\n因此需要引入条件变量来实现线程的同步，形成受控制的并发事件的发生顺序（可以用乐团指挥来类比），把一系列不确定的状态在某一个时间点同步到了一个确定的状态，将发散的并发程序状态 “收束”\n实现同步\n实现 $ A\\to B $：\n1 2 3 4 5 6 7 A; can_proceed = true; (signal) while(!can_proceed); B // B: wait until the condition is satisfied 这样的思路大致正确，但是自选的循环有很大的性能问题，因此需要一个更加底层的机制来帮助实现这一点\n最理想的 API 是 wait_until(cond) ，但是过去为了简化设计，变成了\n条件不满足时等待：wait - 直接睡眠等待 条件满足时继续：signal/broadcast - 唤醒所有线程 （小时候的 scratch 编程其实已经有了这样的思想😂）\n在 c++ 代码中我们可以把条件放到 $ \\lambda $ 表达式中：\n1 2 3 4 5 6 7 8 9 10 11 12 std::mutex mtx; std::condition_variable cv; void T_player() { std::unique_lock lk(mtx); cv.wait(lk, []{ return can_proceed; } ); cv.notify_all(); lk.unlock(); } 注意条件变量在等待时需要带着一把锁（需要确保检查和等待是原子操作）\n使用条件变量解决同步问题 大部分的同步问题都可以用经典的生产者 - 消费者问题归纳：\nProducer 和 Consumer 共享一个缓冲区，其中\nProducer 看到缓冲区有空位就会放入，否则等待 Consumer 看到缓冲区有数据就回去走，否则等待 显然一个对象的生产和消费必须满足 \u0026ldquo;happens-before\u0026rdquo; 的关系\n可以等价成打印匹配的括号，并且嵌套深度有上限（缓冲区的深度）\n处理这样的问题首先要想清楚程序继续执行的条件，比如生产的条件是 $ d\u003c n $ ，而消费的条件是 $ d\u003e0 $ ，然后套入固定的模板代码即可：\n1 2 3 4 5 6 mutex_lock(lk); while (!cond) { // cond can be any calculate cond_wait(\u0026amp;cv, lk); } assert(cond); mutex_lock(lk); 1 2 3 4 mutex_lock(lk); cond = true cond_broadcast(\u0026amp;cv); //⚠️ mutex_unlock(lk); 注意：全局广播 cond_broadcast 不能被替换成单独唤醒一个线程 cond_signal ，在这里显然可能会导致所有进程都被锁住无法触发新的同步变量；并发编程很多看起来正确的地方都需要仔细思考\n遇到任何同步问题的核心都是同步条件是什么，比如括号打印可以拓展成打印 \u0026lt;\u0026gt;\u0026lt; 或者 \u0026gt;\u0026lt;\u0026gt; 两种形状，核心也是画出状态机，找到同步条件，再套入模板就解决了问题\n计算图与并发控制 并行计算的模型可以用一个 DAG 计算图去理解，任务之间存在依赖关系，通过拓扑排序的顺序去解决问题，相互不存在 \u0026ldquo;happens-before\u0026rdquo; 依赖关系的任务都可以并发解决\n为了优化效率，我们对计算任务的分配需要保证每个节点计算的消耗是远大于同步和锁的开销的，因此实际上可能是把很多个小的任务聚合成一个大的并发计算节点，交给一个线程去执行\n实现计算图有两种思路，第一种是朴素的为每个节点设置一个线程和条件变量\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 // The dependency edge is u-\u0026gt;v void T_u() { // calculate u mutex_lock(v-\u0026gt;lock); v-\u0026gt;num_done++; cond_signal(v-\u0026gt;cv); // it\u0026#39;s okay mutex_unlock(v-\u0026gt;lock); } void T_v() { mutex_lock(v-\u0026gt;lock); while (!(v-\u0026gt;num_done == v-\u0026gt;num_predecessors)){ cond_wait(v-\u0026gt;cv, v-\u0026gt;lock); } mutex_unlock(v-\u0026gt;lock); // calculate v } 但是这样实际会产生过多的线程，造成不必要的性能开销（比如产生了多余 CPU 的 core 数量的线程），实际上更优的办法是创建一个任务调度器线程 $ T_{\\text{scheduler}} $ 来专门控制产生 $ T_{\\text{worker}} $ ：\n1 2 3 4 5 6 7 8 9 10 11 12 13 mutex_lock(lk); while (!(all_done || has_job(tid))) { cond_wait(\u0026amp;worker_cv[tid], lk); } mutex_unlock(lk); if (all_done) { break; } else { process_job(tid); } signal(\u0026amp;sched_cv); ","permalink":"https://diefish1024.github.io/posts/class-notes/nju-os-2025/15-%E5%B9%B6%E5%8F%91%E6%8E%A7%E5%88%B6%E5%90%8C%E6%AD%A5%E6%9D%A1%E4%BB%B6%E5%8F%98%E9%87%8F/","summary":"\u003ch2 id=\"同步和条件变量\"\u003e同步和条件变量\u003c/h2\u003e\n\u003cp\u003e互斥实现了\u003cstrong\u003e原子性\u003c/strong\u003e，但是无法实现\u003cstrong\u003e确定性\u003c/strong\u003e，也就是无法正确实现 \u0026ldquo;happens-before\u0026rdquo; 的关系\u003c/p\u003e\n\u003cp\u003e因此需要引入条件变量来实现线程的同步，形成受控制的并发事件的\u003cstrong\u003e发生顺序\u003c/strong\u003e（可以用乐团指挥来类比），把一系列不确定的状态在某一个时间点同步到了一个确定的状态，将发散的并发程序状态 “收束”\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e实现同步\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e实现 $ A\\to B $：\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cdiv class=\"chroma\"\u003e\n\u003ctable class=\"lntable\"\u003e\u003ctr\u003e\u003ctd class=\"lntd\"\u003e\n\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode\u003e\u003cspan class=\"lnt\"\u003e1\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e2\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e3\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e4\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e5\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e6\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e7\n\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\n\u003ctd class=\"lntd\"\u003e\n\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-gdscript3\" data-lang=\"gdscript3\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003eA\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003ecan_proceed\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"bp\"\u003etrue\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"k\"\u003esignal\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"k\"\u003ewhile\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"o\"\u003e!\u003c/span\u003e\u003cspan class=\"n\"\u003ecan_proceed\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003eB\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"o\"\u003e//\u003c/span\u003e \u003cspan class=\"n\"\u003eB\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"n\"\u003ewait\u003c/span\u003e \u003cspan class=\"n\"\u003euntil\u003c/span\u003e \u003cspan class=\"n\"\u003ethe\u003c/span\u003e \u003cspan class=\"n\"\u003econdition\u003c/span\u003e \u003cspan class=\"n\"\u003eis\u003c/span\u003e \u003cspan class=\"n\"\u003esatisfied\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\u003c/tr\u003e\u003c/table\u003e\n\u003c/div\u003e\n\u003c/div\u003e\u003cp\u003e这样的思路大致正确，但是自选的循环有很大的性能问题，因此需要一个更加底层的机制来帮助实现这一点\u003c/p\u003e\n\u003cp\u003e最理想的 API 是 \u003ccode\u003ewait_until(cond)\u003c/code\u003e ，但是过去为了简化设计，变成了\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e条件不满足时等待：\u003ccode\u003ewait\u003c/code\u003e - 直接睡眠等待\u003c/li\u003e\n\u003cli\u003e条件满足时继续：\u003ccode\u003esignal/broadcast\u003c/code\u003e - 唤醒所有线程\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e（小时候的 scratch 编程其实已经有了这样的思想😂）\u003c/p\u003e\n\u003cp\u003e在 c++ 代码中我们可以把条件放到 $ \\lambda $ 表达式中：\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cdiv class=\"chroma\"\u003e\n\u003ctable class=\"lntable\"\u003e\u003ctr\u003e\u003ctd class=\"lntd\"\u003e\n\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode\u003e\u003cspan class=\"lnt\"\u003e 1\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 2\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 3\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 4\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 5\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 6\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 7\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 8\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 9\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e10\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e11\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e12\n\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\n\u003ctd class=\"lntd\"\u003e\n\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-c++\" data-lang=\"c++\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003estd\u003c/span\u003e\u003cspan class=\"o\"\u003e::\u003c/span\u003e\u003cspan class=\"n\"\u003emutex\u003c/span\u003e \u003cspan class=\"n\"\u003emtx\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003estd\u003c/span\u003e\u003cspan class=\"o\"\u003e::\u003c/span\u003e\u003cspan class=\"n\"\u003econdition_variable\u003c/span\u003e \u003cspan class=\"n\"\u003ecv\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"kt\"\u003evoid\u003c/span\u003e \u003cspan class=\"nf\"\u003eT_player\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\t\u003cspan class=\"n\"\u003estd\u003c/span\u003e\u003cspan class=\"o\"\u003e::\u003c/span\u003e\u003cspan class=\"n\"\u003eunique_lock\u003c/span\u003e \u003cspan class=\"n\"\u003elk\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003emtx\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\t\u003cspan class=\"n\"\u003ecv\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ewait\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003elk\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\t\t\u003cspan class=\"p\"\u003e[]{\u003c/span\u003e \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"n\"\u003ecan_proceed\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e \u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\t\u003cspan class=\"p\"\u003e);\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\t\u003cspan class=\"n\"\u003ecv\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003enotify_all\u003c/span\u003e\u003cspan class=\"p\"\u003e();\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\t\u003cspan class=\"n\"\u003elk\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eunlock\u003c/span\u003e\u003cspan class=\"p\"\u003e();\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\u003c/tr\u003e\u003c/table\u003e\n\u003c/div\u003e\n\u003c/div\u003e\u003cp\u003e注意条件变量在等待时需要带着一把锁（需要确保检查和等待是原子操作）\u003c/p\u003e","title":"15. 并发控制：同步条件变量"}]