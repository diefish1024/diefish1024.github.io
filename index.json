[{"content":"åŒæ­¥å’Œæ¡ä»¶å˜é‡ äº’æ–¥å®ç°äº†åŸå­æ€§ï¼Œä½†æ˜¯æ— æ³•å®ç°ç¡®å®šæ€§ï¼Œä¹Ÿå°±æ˜¯æ— æ³•æ­£ç¡®å®ç° \u0026ldquo;happens-before\u0026rdquo; çš„å…³ç³»\nå› æ­¤éœ€è¦å¼•å…¥æ¡ä»¶å˜é‡æ¥å®ç°çº¿ç¨‹çš„åŒæ­¥ï¼Œå½¢æˆå—æ§åˆ¶çš„å¹¶å‘äº‹ä»¶çš„å‘ç”Ÿé¡ºåºï¼ˆå¯ä»¥ç”¨ä¹å›¢æŒ‡æŒ¥æ¥ç±»æ¯”ï¼‰ï¼ŒæŠŠä¸€ç³»åˆ—ä¸ç¡®å®šçš„çŠ¶æ€åœ¨æŸä¸€ä¸ªæ—¶é—´ç‚¹åŒæ­¥åˆ°äº†ä¸€ä¸ªç¡®å®šçš„çŠ¶æ€ï¼Œå°†å‘æ•£çš„å¹¶å‘ç¨‹åºçŠ¶æ€ â€œæ”¶æŸâ€\nå®ç°åŒæ­¥\nå®ç° $A\\to B$ï¼š\n1 2 3 4 5 6 7 A; can_proceed = true; (signal) while(!can_proceed); B // B: wait until the condition is satisfied è¿™æ ·çš„æ€è·¯å¤§è‡´æ­£ç¡®ï¼Œä½†æ˜¯è‡ªé€‰çš„å¾ªç¯æœ‰å¾ˆå¤§çš„æ€§èƒ½é—®é¢˜ï¼Œå› æ­¤éœ€è¦ä¸€ä¸ªæ›´åŠ åº•å±‚çš„æœºåˆ¶æ¥å¸®åŠ©å®ç°è¿™ä¸€ç‚¹\næœ€ç†æƒ³çš„ API æ˜¯ wait_until(cond) ï¼Œä½†æ˜¯è¿‡å»ä¸ºäº†ç®€åŒ–è®¾è®¡ï¼Œå˜æˆäº†\næ¡ä»¶ä¸æ»¡è¶³æ—¶ç­‰å¾…ï¼šwait - ç›´æ¥ç¡çœ ç­‰å¾… æ¡ä»¶æ»¡è¶³æ—¶ç»§ç»­ï¼šsignal/broadcast - å”¤é†’æ‰€æœ‰çº¿ç¨‹ ï¼ˆå°æ—¶å€™çš„ scratch ç¼–ç¨‹å…¶å®å·²ç»æœ‰äº†è¿™æ ·çš„æ€æƒ³ğŸ˜‚ï¼‰\nåœ¨ c++ ä»£ç ä¸­æˆ‘ä»¬å¯ä»¥æŠŠæ¡ä»¶æ”¾åˆ° $\\lambda$ è¡¨è¾¾å¼ä¸­ï¼š\n1 2 3 4 5 6 7 8 9 10 11 12 std::mutex mtx; std::condition_variable cv; void T_player() { std::unique_lock lk(mtx); cv.wait(lk, []{ return can_proceed; } ); cv.notify_all(); lk.unlock(); } æ³¨æ„æ¡ä»¶å˜é‡åœ¨ç­‰å¾…æ—¶éœ€è¦å¸¦ç€ä¸€æŠŠé”ï¼ˆéœ€è¦ç¡®ä¿æ£€æŸ¥å’Œç­‰å¾…æ˜¯åŸå­æ“ä½œï¼‰\nä½¿ç”¨æ¡ä»¶å˜é‡è§£å†³åŒæ­¥é—®é¢˜ å¤§éƒ¨åˆ†çš„åŒæ­¥é—®é¢˜éƒ½å¯ä»¥ç”¨ç»å…¸çš„ç”Ÿäº§è€… - æ¶ˆè´¹è€…é—®é¢˜å½’çº³ï¼š\nProducer å’Œ Consumer å…±äº«ä¸€ä¸ªç¼“å†²åŒºï¼Œå…¶ä¸­\nProducer çœ‹åˆ°ç¼“å†²åŒºæœ‰ç©ºä½å°±ä¼šæ”¾å…¥ï¼Œå¦åˆ™ç­‰å¾… Consumer çœ‹åˆ°ç¼“å†²åŒºæœ‰æ•°æ®å°±å›å»èµ°ï¼Œå¦åˆ™ç­‰å¾… æ˜¾ç„¶ä¸€ä¸ªå¯¹è±¡çš„ç”Ÿäº§å’Œæ¶ˆè´¹å¿…é¡»æ»¡è¶³ \u0026ldquo;happens-before\u0026rdquo; çš„å…³ç³»\nå¯ä»¥ç­‰ä»·æˆæ‰“å°åŒ¹é…çš„æ‹¬å·ï¼Œå¹¶ä¸”åµŒå¥—æ·±åº¦æœ‰ä¸Šé™ï¼ˆç¼“å†²åŒºçš„æ·±åº¦ï¼‰\nå¤„ç†è¿™æ ·çš„é—®é¢˜é¦–å…ˆè¦æƒ³æ¸…æ¥šç¨‹åºç»§ç»­æ‰§è¡Œçš„æ¡ä»¶ï¼Œæ¯”å¦‚ç”Ÿäº§çš„æ¡ä»¶æ˜¯ $d\u0026lt;n$ ï¼Œè€Œæ¶ˆè´¹çš„æ¡ä»¶æ˜¯ $d\u0026gt;0$ ï¼Œç„¶åå¥—å…¥å›ºå®šçš„æ¨¡æ¿ä»£ç å³å¯ï¼š\n1 2 3 4 5 6 mutex_lock(lk); while (!cond) { // cond can be any calculate cond_wait(\u0026amp;cv, lk); } assert(cond); mutex_lock(lk); 1 2 3 4 mutex_lock(lk); cond = true cond_broadcast(\u0026amp;cv); //âš ï¸ mutex_unlock(lk); æ³¨æ„ï¼šå…¨å±€å¹¿æ’­ cond_broadcast ä¸èƒ½è¢«æ›¿æ¢æˆå•ç‹¬å”¤é†’ä¸€ä¸ªçº¿ç¨‹ cond_signal ï¼Œåœ¨è¿™é‡Œæ˜¾ç„¶å¯èƒ½ä¼šå¯¼è‡´æ‰€æœ‰è¿›ç¨‹éƒ½è¢«é”ä½æ— æ³•è§¦å‘æ–°çš„åŒæ­¥å˜é‡ï¼›å¹¶å‘ç¼–ç¨‹å¾ˆå¤šçœ‹èµ·æ¥æ­£ç¡®çš„åœ°æ–¹éƒ½éœ€è¦ä»”ç»†æ€è€ƒ\né‡åˆ°ä»»ä½•åŒæ­¥é—®é¢˜çš„æ ¸å¿ƒéƒ½æ˜¯åŒæ­¥æ¡ä»¶æ˜¯ä»€ä¹ˆï¼Œæ¯”å¦‚æ‹¬å·æ‰“å°å¯ä»¥æ‹“å±•æˆæ‰“å° \u0026lt;\u0026gt;\u0026lt; æˆ–è€… \u0026gt;\u0026lt;\u0026gt; ä¸¤ç§å½¢çŠ¶ï¼Œæ ¸å¿ƒä¹Ÿæ˜¯ç”»å‡ºçŠ¶æ€æœºï¼Œæ‰¾åˆ°åŒæ­¥æ¡ä»¶ï¼Œå†å¥—å…¥æ¨¡æ¿å°±è§£å†³äº†é—®é¢˜\nè®¡ç®—å›¾ä¸å¹¶å‘æ§åˆ¶ å¹¶è¡Œè®¡ç®—çš„æ¨¡å‹å¯ä»¥ç”¨ä¸€ä¸ª DAG è®¡ç®—å›¾å»ç†è§£ï¼Œä»»åŠ¡ä¹‹é—´å­˜åœ¨ä¾èµ–å…³ç³»ï¼Œé€šè¿‡æ‹“æ‰‘æ’åºçš„é¡ºåºå»è§£å†³é—®é¢˜ï¼Œç›¸äº’ä¸å­˜åœ¨ \u0026ldquo;happens-before\u0026rdquo; ä¾èµ–å…³ç³»çš„ä»»åŠ¡éƒ½å¯ä»¥å¹¶å‘è§£å†³\nä¸ºäº†ä¼˜åŒ–æ•ˆç‡ï¼Œæˆ‘ä»¬å¯¹è®¡ç®—ä»»åŠ¡çš„åˆ†é…éœ€è¦ä¿è¯æ¯ä¸ªèŠ‚ç‚¹è®¡ç®—çš„æ¶ˆè€—æ˜¯è¿œå¤§äºåŒæ­¥å’Œé”çš„å¼€é”€çš„ï¼Œå› æ­¤å®é™…ä¸Šå¯èƒ½æ˜¯æŠŠå¾ˆå¤šä¸ªå°çš„ä»»åŠ¡èšåˆæˆä¸€ä¸ªå¤§çš„å¹¶å‘è®¡ç®—èŠ‚ç‚¹ï¼Œäº¤ç»™ä¸€ä¸ªçº¿ç¨‹å»æ‰§è¡Œ\nå®ç°è®¡ç®—å›¾æœ‰ä¸¤ç§æ€è·¯ï¼Œç¬¬ä¸€ç§æ˜¯æœ´ç´ çš„ä¸ºæ¯ä¸ªèŠ‚ç‚¹è®¾ç½®ä¸€ä¸ªçº¿ç¨‹å’Œæ¡ä»¶å˜é‡\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 // The dependency edge is u-\u0026gt;v void T_u() { // calculate u mutex_lock(v-\u0026gt;lock); v-\u0026gt;num_done++; cond_signal(v-\u0026gt;cv); // it\u0026#39;s okay mutex_unlock(v-\u0026gt;lock); } void T_v() { mutex_lock(v-\u0026gt;lock); while (!(v-\u0026gt;num_done == v-\u0026gt;num_predecessors)){ cond_wait(v-\u0026gt;cv, v-\u0026gt;lock); } mutex_unlock(v-\u0026gt;lock); // calculate v } ä½†æ˜¯è¿™æ ·å®é™…ä¼šäº§ç”Ÿè¿‡å¤šçš„çº¿ç¨‹ï¼Œé€ æˆä¸å¿…è¦çš„æ€§èƒ½å¼€é”€ï¼ˆæ¯”å¦‚äº§ç”Ÿäº†å¤šä½™ CPU çš„ core æ•°é‡çš„çº¿ç¨‹ï¼‰ï¼Œå®é™…ä¸Šæ›´ä¼˜çš„åŠæ³•æ˜¯åˆ›å»ºä¸€ä¸ªä»»åŠ¡è°ƒåº¦å™¨çº¿ç¨‹ $T\\{\\text{scheduler}}$ æ¥ä¸“é—¨æ§åˆ¶äº§ç”Ÿ $T\\{\\text{worker}}$ ï¼š\n1 2 3 4 5 6 7 8 9 10 11 12 13 mutex_lock(lk); while (!(all_done || has_job(tid))) { cond_wait(\u0026amp;worker_cv[tid], lk); } mutex_unlock(lk); if (all_done) { break; } else { process_job(tid); } signal(\u0026amp;sched_cv); ","permalink":"https://diefish1024.github.io/posts/nju-os-2025/15-%E5%B9%B6%E5%8F%91%E6%8E%A7%E5%88%B6%E5%90%8C%E6%AD%A5%E6%9D%A1%E4%BB%B6%E5%8F%98%E9%87%8F/","summary":"\u003ch2 id=\"åŒæ­¥å’Œæ¡ä»¶å˜é‡\"\u003eåŒæ­¥å’Œæ¡ä»¶å˜é‡\u003c/h2\u003e\n\u003cp\u003eäº’æ–¥å®ç°äº†\u003cstrong\u003eåŸå­æ€§\u003c/strong\u003eï¼Œä½†æ˜¯æ— æ³•å®ç°\u003cstrong\u003eç¡®å®šæ€§\u003c/strong\u003eï¼Œä¹Ÿå°±æ˜¯æ— æ³•æ­£ç¡®å®ç° \u0026ldquo;happens-before\u0026rdquo; çš„å…³ç³»\u003c/p\u003e\n\u003cp\u003eå› æ­¤éœ€è¦å¼•å…¥æ¡ä»¶å˜é‡æ¥å®ç°çº¿ç¨‹çš„åŒæ­¥ï¼Œå½¢æˆå—æ§åˆ¶çš„å¹¶å‘äº‹ä»¶çš„\u003cstrong\u003eå‘ç”Ÿé¡ºåº\u003c/strong\u003eï¼ˆå¯ä»¥ç”¨ä¹å›¢æŒ‡æŒ¥æ¥ç±»æ¯”ï¼‰ï¼ŒæŠŠä¸€ç³»åˆ—ä¸ç¡®å®šçš„çŠ¶æ€åœ¨æŸä¸€ä¸ªæ—¶é—´ç‚¹åŒæ­¥åˆ°äº†ä¸€ä¸ªç¡®å®šçš„çŠ¶æ€ï¼Œå°†å‘æ•£çš„å¹¶å‘ç¨‹åºçŠ¶æ€ â€œæ”¶æŸâ€\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eå®ç°åŒæ­¥\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eå®ç° $A\\to B$ï¼š\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cdiv class=\"chroma\"\u003e\n\u003ctable class=\"lntable\"\u003e\u003ctr\u003e\u003ctd class=\"lntd\"\u003e\n\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode\u003e\u003cspan class=\"lnt\"\u003e1\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e2\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e3\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e4\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e5\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e6\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e7\n\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\n\u003ctd class=\"lntd\"\u003e\n\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-gdscript3\" data-lang=\"gdscript3\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003eA\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003ecan_proceed\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"bp\"\u003etrue\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"k\"\u003esignal\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"k\"\u003ewhile\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"o\"\u003e!\u003c/span\u003e\u003cspan class=\"n\"\u003ecan_proceed\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003eB\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"o\"\u003e//\u003c/span\u003e \u003cspan class=\"n\"\u003eB\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"n\"\u003ewait\u003c/span\u003e \u003cspan class=\"n\"\u003euntil\u003c/span\u003e \u003cspan class=\"n\"\u003ethe\u003c/span\u003e \u003cspan class=\"n\"\u003econdition\u003c/span\u003e \u003cspan class=\"n\"\u003eis\u003c/span\u003e \u003cspan class=\"n\"\u003esatisfied\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\u003c/tr\u003e\u003c/table\u003e\n\u003c/div\u003e\n\u003c/div\u003e\u003cp\u003eè¿™æ ·çš„æ€è·¯å¤§è‡´æ­£ç¡®ï¼Œä½†æ˜¯è‡ªé€‰çš„å¾ªç¯æœ‰å¾ˆå¤§çš„æ€§èƒ½é—®é¢˜ï¼Œå› æ­¤éœ€è¦ä¸€ä¸ªæ›´åŠ åº•å±‚çš„æœºåˆ¶æ¥å¸®åŠ©å®ç°è¿™ä¸€ç‚¹\u003c/p\u003e\n\u003cp\u003eæœ€ç†æƒ³çš„ API æ˜¯ \u003ccode\u003ewait_until(cond)\u003c/code\u003e ï¼Œä½†æ˜¯è¿‡å»ä¸ºäº†ç®€åŒ–è®¾è®¡ï¼Œå˜æˆäº†\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eæ¡ä»¶ä¸æ»¡è¶³æ—¶ç­‰å¾…ï¼š\u003ccode\u003ewait\u003c/code\u003e - ç›´æ¥ç¡çœ ç­‰å¾…\u003c/li\u003e\n\u003cli\u003eæ¡ä»¶æ»¡è¶³æ—¶ç»§ç»­ï¼š\u003ccode\u003esignal/broadcast\u003c/code\u003e - å”¤é†’æ‰€æœ‰çº¿ç¨‹\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eï¼ˆå°æ—¶å€™çš„ scratch ç¼–ç¨‹å…¶å®å·²ç»æœ‰äº†è¿™æ ·çš„æ€æƒ³ğŸ˜‚ï¼‰\u003c/p\u003e\n\u003cp\u003eåœ¨ c++ ä»£ç ä¸­æˆ‘ä»¬å¯ä»¥æŠŠæ¡ä»¶æ”¾åˆ° $\\lambda$ è¡¨è¾¾å¼ä¸­ï¼š\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cdiv class=\"chroma\"\u003e\n\u003ctable class=\"lntable\"\u003e\u003ctr\u003e\u003ctd class=\"lntd\"\u003e\n\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode\u003e\u003cspan class=\"lnt\"\u003e 1\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 2\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 3\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 4\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 5\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 6\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 7\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 8\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 9\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e10\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e11\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e12\n\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\n\u003ctd class=\"lntd\"\u003e\n\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-c++\" data-lang=\"c++\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003estd\u003c/span\u003e\u003cspan class=\"o\"\u003e::\u003c/span\u003e\u003cspan class=\"n\"\u003emutex\u003c/span\u003e \u003cspan class=\"n\"\u003emtx\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003estd\u003c/span\u003e\u003cspan class=\"o\"\u003e::\u003c/span\u003e\u003cspan class=\"n\"\u003econdition_variable\u003c/span\u003e \u003cspan class=\"n\"\u003ecv\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"kt\"\u003evoid\u003c/span\u003e \u003cspan class=\"nf\"\u003eT_player\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\t\u003cspan class=\"n\"\u003estd\u003c/span\u003e\u003cspan class=\"o\"\u003e::\u003c/span\u003e\u003cspan class=\"n\"\u003eunique_lock\u003c/span\u003e \u003cspan class=\"n\"\u003elk\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003emtx\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\t\u003cspan class=\"n\"\u003ecv\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ewait\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003elk\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\t\t\u003cspan class=\"p\"\u003e[]{\u003c/span\u003e \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"n\"\u003ecan_proceed\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e \u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\t\u003cspan class=\"p\"\u003e);\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\t\u003cspan class=\"n\"\u003ecv\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003enotify_all\u003c/span\u003e\u003cspan class=\"p\"\u003e();\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\t\u003cspan class=\"n\"\u003elk\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eunlock\u003c/span\u003e\u003cspan class=\"p\"\u003e();\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\u003c/tr\u003e\u003c/table\u003e\n\u003c/div\u003e\n\u003c/div\u003e\u003cp\u003eæ³¨æ„æ¡ä»¶å˜é‡åœ¨ç­‰å¾…æ—¶éœ€è¦å¸¦ç€ä¸€æŠŠé”ï¼ˆéœ€è¦ç¡®ä¿æ£€æŸ¥å’Œç­‰å¾…æ˜¯åŸå­æ“ä½œï¼‰\u003c/p\u003e","title":"15. å¹¶å‘æ§åˆ¶ï¼šåŒæ­¥æ¡ä»¶å˜é‡"},{"content":"Introduction ç±»ä¼¼ GAN çš„å¯¹æŠ—è®­ç»ƒæ€æƒ³\nDomain Adaptation ç»™å®šæºåŸŸ $D\\{S}$ ï¼ˆæœ‰æ ‡ç­¾ï¼‰å’Œç›®æ ‡åŸŸ $D\\{T}$ ï¼ˆæ— æ ‡ç­¾ï¼‰ï¼Œç›®æ ‡æ˜¯è®­ç»ƒä¸€ä¸ªåˆ†ç±»å™¨ $\\eta: X\\to Y$ ä½¿å…¶åœ¨ç›®æ ‡åŸŸä¸Šçš„ç›®æ ‡é£é™© $$ R\\{D\\{T}}(\\eta) = \\underset{(\\mathbf{x},y)\\sim D\\_{T}}{\\mathrm{Pr}}(\\eta(\\mathbf{x}) \\neq y) $$ æœ€å°\nDomain Divergence éœ€è¦é‡åŒ–ä¸¤ä¸ªé¢†åŸŸçš„â€œç›¸ä¼¼åº¦â€ï¼Œä»è€Œå¼•å‡ºäº† H- æ•£åº¦ çš„æ¦‚å¿µï¼š $$ d\\_{\\mathcal{H}}(D\\S, D\\T) = 2 \\sup\\{\\eta \\in \\mathcal{H}} \\left| \\Pr\\{x \\sim D\\S}[\\eta(x) = 1] - \\Pr\\{x \\sim D\\_T}[\\eta(x) = 1] \\right| $$ å«ä¹‰æ˜¯æœ€ä¼˜çš„åˆ†ç±»å™¨å°†ç›®æ ‡åŸŸå’ŒæºåŸŸåˆ¤å®šä¸º 1 çš„å¯èƒ½æ€§ä¹‹å·®ï¼Œå½“ H- æ•£åº¦éå¸¸å°æ—¶ï¼Œè¯´æ˜ä¸¤ä¸ªé¢†åŸŸå¾ˆéš¾è¢«åŒºåˆ†ï¼Œä¹Ÿå°±è¯´æ˜å­¦ä¹ çš„ç‰¹å¾å®ç°äº†é¢†åŸŸä¸å˜æ€§çš„æ•ˆæœ\nç”±äºç†è®º H æ•£åº¦æ˜¯ç†æƒ³æ•°æ®åˆ†å¸ƒä¸Šçš„å®šä¹‰ï¼Œå®é™…ä¸­åªæœ‰æœ‰é™çš„æ ·æœ¬é›† $S$ å’Œ $T$ ï¼Œå› æ­¤éœ€è¦ä¸€å®šçš„è¿‘ä¼¼ï¼Œäºæ˜¯éœ€è¦ç»éªŒ H- æ•£åº¦ $$ \\hat{d}\\{\\mathcal{H}}(S, T) = 2 \\left(1 - \\min\\{\\eta \\in \\mathcal{H}} \\left[ \\dfrac{1}{n}\\sum\\_{i=1}^n \\mathcal{I}[\\eta(x\\i) = 0] + \\dfrac{1}{n\u0026rsquo;}\\sum\\{i=n+1}^N \\mathcal{I}[\\eta(x\\_i) = 1] \\right] \\right) $$ å…¶ä¸­ $\\mathcal{I}[\\cdot]$ è¡¨ç¤ºæ¡ä»¶ä¸ºçœŸæ—¶ä¸º 1ï¼Œå¦åˆ™ä¸º 0\nProxy Distance ç»éªŒ H- æ•£åº¦ä¹Ÿéœ€è¦ç›´æ¥éå†æ‰€æœ‰çš„ $\\eta$ ï¼Œåœ¨è®¡ç®—ä¸Šä¸ç°å®ï¼Œéœ€è¦ä¸€ä¸ªè¿›ä¸€æ­¥çš„è¿‘ä¼¼æ–¹æ³•ï¼Œå› æ­¤è€ƒè™‘ Proxy A-distance (PAD)\næ„é€ ç”¨äºé¢†åŸŸåˆ†ç±»çš„æ•°æ®é›† $$ U = { (\\mathbf{x}\\{i},0) }\\{i=1}^{n} \\cup { (\\mathbf{x}\\{i},1) }\\{i=n+1}^{N} $$ ç”¨è¿™ä¸ªæ•°æ®é›†è®­ç»ƒåˆ†ç±»å™¨ï¼Œè®¾ $\\epsilon$ ä¸ºåœ¨æ•°æ®é›† $U$ ä¸Šè®­ç»ƒå‡ºçš„æœ€ä¼˜é¢†åŸŸåˆ†ç±»å™¨æ‰€è¾¾åˆ°çš„æœ€å°é”™è¯¯ç‡ï¼Œé‚£ä¹ˆå¯ä»¥ç”¨ $$ \\hat{d}\\_{\\mathcal{A}} = 2(1-2\\epsilon) $$ æ¥è¿‘ä¼¼ H- æ•£åº¦\nGeneralization Bound on the Target Risk æœ‰æ•ˆæ€§è¯æ˜\nç†è®ºç ”ç©¶è¯´æ˜æ¨¡å‹çš„ç›®æ ‡é£é™©å¯ä»¥é€šè¿‡æºé£é™©å’Œä¸¤ä¸ªé¢†åŸŸçš„æ•£åº¦æ¥é™åˆ¶ï¼Œä¸»è¦æ€æƒ³æ˜¯ $$ R\\_{D\\T}(\\eta) \\le R\\S(\\eta) + \\text{Domain Divergence Terms} + \\text{Complexity Terms} + \\beta $$ å…¶ä¸­ $\\text{Domain Divergence Terms}\\approx d\\{\\mathcal{H}}(S, T)$ ï¼Œå¯ä»¥ç”¨ä¸Šé¢çš„ $\\hat{d}\\{\\mathcal{A}}$ è¿‘ä¼¼ï¼›$\\text{Complexity Terms}$ æ˜¯ä¸€ä¸ªæ¯”è¾ƒå°çš„å¸¸æ•°é¡¹ï¼Œå’Œæ¨¡å‹æœ¬èº«è®­ç»ƒæœ‰å…³ï¼ˆåŸå…¬å¼æ²¡çœ‹æ‡‚ã€‚ã€‚ï¼‰ï¼›$\\beta$ æ˜¯ä¸€ä¸ªç†æƒ³åŒ–çš„é¡¹ï¼Œè¡¨ç¤ºæœ€å¥½æƒ…å†µä¸‹åœ¨ç›®æ ‡åŸŸå’ŒæºåŸŸä¸ŠåŒæ—¶å–å¾—çš„æœ€ä½é”™è¯¯ç‡\nDANN ä¼˜åŒ–ç›®æ ‡ï¼š $$ E(\\theta\\_f, \\theta\\_y, \\theta\\d) = \\frac{1}{n} \\sum\\{i=1}^n \\mathcal{L}\\_y(\\theta\\_f, \\theta\\y) - \\lambda \\left( \\frac{1}{n} \\sum\\{i=1}^n \\mathcal{L}\\_d(\\theta\\_f, \\theta\\d) + \\frac{1}{n\u0026rsquo;} \\sum\\{i=n+1}^N \\mathcal{L}\\_d(\\theta\\_f, \\theta\\_d) \\right) $$ æ ¸å¿ƒæ˜¯ Saddle Point Problem ï¼Œæ‰¾åˆ°éœ€è¦æ‰¾åˆ°éç‚¹è€Œéæœ€å°å€¼\nå¦‚ä½•å®ç°å¯¹æŠ—ï¼š\næ ‡ç­¾é¢„æµ‹å‚æ•°ï¼š $$ \\theta\\{y} \\leftarrow \\theta\\{y} - \\mu \\dfrac{ \\partial \\mathcal{L}\\{y} }{ \\partial \\theta\\{y} } $$ é¢†åŸŸåˆ†ç±»å‚æ•°ï¼š $$ \\theta\\{d} \\leftarrow \\theta\\{d} - \\mu \\lambda \\dfrac{ \\partial \\mathcal{L}\\{d} }{ \\partial \\theta\\{d} } $$ ç‰¹å¾æå–å‚æ•°ï¼š $$ \\theta\\{f} \\leftarrow \\theta\\{f} - \\mu\\left( \\dfrac{ \\partial \\mathcal{L}\\{y} }{ \\partial \\theta\\{f} } - \\lambda \\dfrac{ \\partial \\mathcal{L}\\{d} }{ \\partial \\theta\\{f} } \\right) $$ æ ¸å¿ƒéœ€è¦æœ€å¤§åŒ– $\\mathcal{L}\\_{d}$ ï¼Œå› æ­¤éœ€è¦æ²¿ç€æ¢¯åº¦çš„æ­£å‘ä¼˜åŒ– Gradient Reversal Layer (GRL) æ˜¯å®ç°å¯¹æŠ—çš„æ ¸å¿ƒç»„ä»¶ï¼Œå…·ä½“åŸç†æ˜¯åœ¨å‰å‘ä¼ æ’­æ—¶è¡¨ç°ä¸º $R(x)=x$ ï¼Œä½†æ˜¯åå‘ä¼ æ’­æ—¶ $\\dfrac{\\mathrm{d} R}{\\mathrm{d}x}=-I$ ï¼Œè¿™æ ·å¯ä»¥ç›´æ¥åˆ©ç”¨å†…ç½®çš„è‡ªåŠ¨å¾®åˆ†ä¼˜é›…å®ç°å¯¹æŠ—\n","permalink":"https://diefish1024.github.io/posts/literature-notes/dann/","summary":"\u003ch2 id=\"introduction\"\u003eIntroduction\u003c/h2\u003e\n\u003cp\u003eç±»ä¼¼ GAN çš„å¯¹æŠ—è®­ç»ƒæ€æƒ³\u003c/p\u003e\n\u003ch2 id=\"domain-adaptation\"\u003eDomain Adaptation\u003c/h2\u003e\n\u003cp\u003eç»™å®šæºåŸŸ $D\\\u003cem\u003e{S}$ ï¼ˆæœ‰æ ‡ç­¾ï¼‰å’Œç›®æ ‡åŸŸ $D\\\u003c/em\u003e{T}$ ï¼ˆæ— æ ‡ç­¾ï¼‰ï¼Œç›®æ ‡æ˜¯è®­ç»ƒä¸€ä¸ªåˆ†ç±»å™¨ $\\eta: X\\to Y$ ä½¿å…¶åœ¨ç›®æ ‡åŸŸä¸Šçš„ç›®æ ‡é£é™©\n$$\nR\\\u003cem\u003e{D\\\u003c/em\u003e{T}}(\\eta) = \\underset{(\\mathbf{x},y)\\sim D\\_{T}}{\\mathrm{Pr}}(\\eta(\\mathbf{x}) \\neq y)\n$$\næœ€å°\u003c/p\u003e\n\u003ch4 id=\"domain-divergence\"\u003eDomain Divergence\u003c/h4\u003e\n\u003cp\u003eéœ€è¦é‡åŒ–ä¸¤ä¸ªé¢†åŸŸçš„â€œç›¸ä¼¼åº¦â€ï¼Œä»è€Œå¼•å‡ºäº† \u003cstrong\u003eH- æ•£åº¦\u003c/strong\u003e çš„æ¦‚å¿µï¼š\n$$\nd\\_{\\mathcal{H}}(D\\\u003cem\u003eS, D\\\u003cem\u003eT) = 2 \\sup\\\u003c/em\u003e{\\eta \\in \\mathcal{H}} \\left| \\Pr\\\u003c/em\u003e{x \\sim D\\\u003cem\u003eS}[\\eta(x) = 1] - \\Pr\\\u003c/em\u003e{x \\sim D\\_T}[\\eta(x) = 1] \\right|\n$$\nå«ä¹‰æ˜¯æœ€ä¼˜çš„åˆ†ç±»å™¨å°†ç›®æ ‡åŸŸå’ŒæºåŸŸåˆ¤å®šä¸º 1 çš„å¯èƒ½æ€§ä¹‹å·®ï¼Œå½“ H- æ•£åº¦éå¸¸å°æ—¶ï¼Œè¯´æ˜ä¸¤ä¸ªé¢†åŸŸå¾ˆéš¾è¢«åŒºåˆ†ï¼Œä¹Ÿå°±è¯´æ˜å­¦ä¹ çš„ç‰¹å¾å®ç°äº†é¢†åŸŸä¸å˜æ€§çš„æ•ˆæœ\u003c/p\u003e\n\u003cp\u003eç”±äºç†è®º H æ•£åº¦æ˜¯ç†æƒ³æ•°æ®åˆ†å¸ƒä¸Šçš„å®šä¹‰ï¼Œå®é™…ä¸­åªæœ‰æœ‰é™çš„æ ·æœ¬é›† $S$ å’Œ $T$ ï¼Œå› æ­¤éœ€è¦ä¸€å®šçš„è¿‘ä¼¼ï¼Œäºæ˜¯éœ€è¦ç»éªŒ H- æ•£åº¦\n$$\n\\hat{d}\\\u003cem\u003e{\\mathcal{H}}(S, T) = 2 \\left(1 - \\min\\\u003c/em\u003e{\\eta \\in \\mathcal{H}} \\left[ \\dfrac{1}{n}\\sum\\_{i=1}^n \\mathcal{I}[\\eta(x\\\u003cem\u003ei) = 0] + \\dfrac{1}{n\u0026rsquo;}\\sum\\\u003c/em\u003e{i=n+1}^N \\mathcal{I}[\\eta(x\\_i) = 1] \\right] \\right)\n$$\nå…¶ä¸­ $\\mathcal{I}[\\cdot]$ è¡¨ç¤ºæ¡ä»¶ä¸ºçœŸæ—¶ä¸º 1ï¼Œå¦åˆ™ä¸º 0\u003c/p\u003e","title":"DANN"},{"content":"æ¨ç†æ•ˆç‡å¯¹äº llm æ˜¯ä¸€ä¸ªè‡³å…³é‡è¦çš„é—®é¢˜ã€‚å½“æ¨¡å‹ç”Ÿæˆæ–‡æœ¬æ—¶ï¼Œå°¤å…¶æ˜¯ä»¥è‡ªå›å½’æ–¹å¼é€è¯ç”Ÿæˆæ—¶ï¼Œæ•ˆç‡ç“¶é¢ˆä¼šå˜å¾—éå¸¸æ˜æ˜¾ã€‚KV Cache å°±æ˜¯ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜è€Œè¯ç”Ÿçš„æŠ€æœ¯ã€‚\n1. What is KV Cache? KV Cacheï¼Œå…¨ç§° Key-Value Cacheï¼Œæ˜¯ä¸€ç§ä¼˜åŒ–æŠ€æœ¯ï¼Œç”¨äºåŠ é€Ÿ Transformer æ¶æ„åœ¨è‡ªå›å½’ç”Ÿæˆè¿‡ç¨‹ä¸­çš„æ¨ç†é€Ÿåº¦ã€‚å®ƒçš„æ ¸å¿ƒæ€æƒ³æ˜¯ç¼“å­˜å¹¶é‡ç”¨åœ¨æ³¨æ„åŠ›æœºåˆ¶ä¸­è®¡ç®—å¾—åˆ°çš„ Key (K) å’Œ Value (V) å‘é‡ã€‚\n2. Transformer Attention Mechanism Review è¦ç†è§£ KV Cacheï¼Œé¦–å…ˆéœ€è¦å¯¹ Transformer æ¶æ„ä¸­çš„è‡ªæ³¨æ„åŠ›æœºåˆ¶æœ‰ä¸€ä¸ªåŸºæœ¬è®¤è¯†ã€‚è‡ªæ³¨æ„åŠ›æœºåˆ¶å…è®¸æ¨¡å‹åœ¨å¤„ç†åºåˆ—ä¸­çš„æŸä¸ªè¯æ—¶ï¼Œè€ƒè™‘åºåˆ—ä¸­æ‰€æœ‰å…¶ä»–è¯çš„é‡è¦æ€§ã€‚\næ¯ä¸ªè¾“å…¥ tokenï¼ˆè¯æˆ–å­è¯ï¼‰åœ¨è¿›å…¥æ³¨æ„åŠ›å±‚æ—¶ï¼Œéƒ½ä¼šè¢«è½¬æ¢æˆä¸‰ä¸ªä¸åŒçš„å‘é‡ï¼š\nQ å‘é‡ï¼šä»£è¡¨å½“å‰ token çš„â€œæŸ¥è¯¢â€ä¿¡æ¯ K å‘é‡ï¼šä»£è¡¨æ‰€æœ‰ token çš„â€œé”®â€ä¿¡æ¯ï¼Œç”¨äºä¸ Query è¿›è¡ŒåŒ¹é… V å‘é‡ï¼šä»£è¡¨æ‰€æœ‰ token çš„â€œå€¼â€ä¿¡æ¯ï¼Œç”¨äºåŠ æƒæ±‚å’Œï¼Œå¾—åˆ°æœ€ç»ˆçš„è¾“å‡º è‡ªæ³¨æ„åŠ›æœºåˆ¶çš„è®¡ç®—è¿‡ç¨‹ä¸ºä»¥ä¸‹æ­¥éª¤ï¼š\nè®¡ç®— Query ä¸æ‰€æœ‰ Key çš„ç‚¹ç§¯ï¼Œå¾—åˆ°æ³¨æ„åŠ›åˆ†æ•° å°†æ³¨æ„åŠ›åˆ†æ•°è¿›è¡Œç¼©æ”¾ï¼Œé™¤ä»¥ $\\sqrt{d\\_k}$ï¼ˆ$d\\_k$ æ˜¯ Key å‘é‡çš„ç»´åº¦) å¯¹ç¼©æ”¾åçš„åˆ†æ•°è¿›è¡Œ Softmaxï¼Œå°†å…¶è½¬æ¢ä¸ºæ³¨æ„åŠ›æƒé‡ï¼Œè¡¨ç¤ºæ¯ä¸ª token å¯¹å½“å‰ token çš„é‡è¦æ€§ å°†æ³¨æ„åŠ›æƒé‡ä¸ Value å‘é‡è¿›è¡ŒåŠ æƒæ±‚å’Œï¼Œå¾—åˆ°å½“å‰ token çš„æ³¨æ„åŠ›è¾“å‡º å…¬å¼ä¸ºï¼š $$ \\text{Attention}(Q, K, V) = \\text{softmax}\\left(\\frac{QK^T}{\\sqrt{d\\_k}}\\right)V $$ å…¶ä¸­çŸ©é˜µ $Q,K,V \\in \\mathbb{R}^{L \\times d}$ ï¼Œ$L$ ä¸ºå½“å‰ä¸Šä¸‹æ–‡é•¿åº¦\nï¼ˆå¤„äºç®€æ´æ€§çš„è€ƒè™‘ï¼Œå¿½ç•¥äº† Causal Mask ï¼Œå®é™…ä¸Š $QK^{T}$ åº”è¯¥ Mask æˆä¸‹ä¸‰è§’çŸ©é˜µæ¥å¼ºåˆ¶ä¸èƒ½çœ‹åˆ°åºåˆ—æœªæ¥çš„ä¿¡æ¯ï¼‰\n3. The Problem KV Cache Solves åœ¨å¤§å‹è¯­è¨€æ¨¡å‹ä¸­ï¼Œå½“æ¨¡å‹ä»¥è‡ªå›å½’æ–¹å¼ç”Ÿæˆæ–‡æœ¬æ—¶ï¼ˆæ¯æ¬¡ç”Ÿæˆä¸€ä¸ªæ–° tokenï¼Œå¹¶å°†å…¶æ·»åŠ åˆ°è¾“å…¥åºåˆ—ä¸­ï¼Œç„¶åæ ¹æ®æ•´ä¸ªåºåˆ—ç”Ÿæˆä¸‹ä¸€ä¸ª tokenï¼‰ï¼Œä¼šé‡åˆ°ä¸€ä¸ªæ•ˆç‡é—®é¢˜ï¼š\nå‡è®¾æˆ‘ä»¬è¦ç”Ÿæˆâ€œä¸­åäººæ°‘â€\nè¾“å…¥ï¼šâ€œä¸­â€ æ¨¡å‹è®¡ç®—â€œä¸­â€çš„ $Q, K, V$ è®¡ç®— attention ï¼Œç”Ÿæˆâ€œåâ€ è¾“å…¥ï¼šâ€œä¸­åâ€ æ¨¡å‹å†æ¬¡è®¡ç®—â€œä¸­â€å’Œâ€œåâ€çš„ $Q, K, V$ è®¡ç®— attention ï¼Œç”Ÿæˆâ€œäººâ€ è¾“å…¥ï¼šâ€œä¸­åäººâ€ æ¨¡å‹å†æ¬¡è®¡ç®—â€œä¸­â€ã€â€œåâ€å’Œâ€œäººâ€çš„ $Q, K, V$ è®¡ç®— attention ï¼Œç”Ÿæˆâ€œæ°‘â€ å¯ä»¥çœ‹åˆ°ï¼Œåœ¨æ¯ä¸€æ­¥ç”Ÿæˆæ–° token æ—¶ï¼Œéƒ½éœ€è¦é‡æ–°è®¡ç®—ä¹‹å‰å·²ç»å¤„ç†è¿‡çš„æ‰€æœ‰ token çš„ $K$ å’Œ $V$ å‘é‡ã€‚è¿™ç§é‡å¤è®¡ç®—åœ¨åºåˆ—è¾ƒé•¿æ—¶ä¼šæ¶ˆè€—å¤§é‡çš„è®¡ç®—èµ„æºå’Œæ—¶é—´ï¼Œæ•ˆç‡ä½ä¸‹ã€‚\n4. How KV Cache Works æ ¹æ®ä¸Šé¢åˆ†æå¾—åˆ°çš„é—®é¢˜ï¼Œå¾ˆå®¹æ˜“æƒ³åˆ° KV Cache çš„æ ¸å¿ƒæ€æƒ³ï¼šå°†å·²ç»è®¡ç®—è¿‡çš„ Key å’Œ Value å‘é‡ç¼“å­˜èµ·æ¥ï¼Œåœ¨åç»­çš„ç”Ÿæˆæ­¥éª¤ä¸­ç›´æ¥é‡ç”¨ï¼Œè€Œä¸æ˜¯é‡æ–°è®¡ç®—ã€‚\nä»¥ç”Ÿæˆâ€œä¸­åäººæ°‘â€ä¸ºä¾‹ï¼Œä½¿ç”¨ KV Cache çš„æµç¨‹å¦‚ä¸‹ï¼š\nè¾“å…¥ï¼šâ€œä¸­â€ è®¡ç®—â€œä¸­â€çš„ $K\\_1, V\\_1$ å°† $K\\_1, V\\_1$ å­˜å…¥ KV Cache ä½¿ç”¨ $Q\\_1, K\\_1, V\\_1$ è®¡ç®— attention ï¼Œç”Ÿæˆâ€œåâ€ è¾“å…¥ï¼šâ€œåâ€ï¼ˆå½“å‰ token åªæœ‰â€œåâ€ï¼Œä½†æ³¨æ„åŠ›è¦å…³æ³¨æ•´ä¸ªåºåˆ—â€œä¸­åâ€ï¼‰ è®¡ç®—â€œåâ€çš„ $K\\_2, V\\_2$ å°† $K\\_2, V\\_2$ æ·»åŠ åˆ° KV Cacheã€‚æ­¤æ—¶ KV Cache åŒ…å« $[K\\_1, K\\_2]$ å’Œ $[V\\_1, V\\_2]$ ä½¿ç”¨å½“å‰ $Q\\_2$ å’Œç¼“å­˜ä¸­çš„ $[K\\_1, K\\_2], [V\\_1, V\\_2]$ è®¡ç®— attention ï¼Œç”Ÿæˆâ€œäººâ€ è¾“å…¥ï¼šâ€œäººâ€ è®¡ç®—â€œäººâ€çš„ $K\\_3, V\\_3$ å°† $K\\_3, V\\_3$ æ·»åŠ åˆ° KV Cacheã€‚æ­¤æ—¶ KV Cache åŒ…å« $[K\\_1, K\\_2, K\\_3]$ å’Œ $[V\\_1, V\\_2, V\\_3]$ ä½¿ç”¨å½“å‰ $Q\\_3$ å’Œç¼“å­˜ä¸­çš„ $[K\\_1, K\\_2, K\\_3], [V\\_1, V\\_2, V\\_3]$ è®¡ç®— attention ï¼Œç”Ÿæˆâ€œæ°‘â€ é€šè¿‡è¿™ç§æ–¹å¼ï¼Œæ¯ä¸€æ­¥åªéœ€è¦è®¡ç®—å½“å‰æ–°ç”Ÿæˆ token çš„ $K, V$ å‘é‡ï¼Œè€Œæ— éœ€é‡æ–°è®¡ç®—ä¹‹å‰æ‰€æœ‰ token çš„ $K, V$ã€‚\n5. Why Not QKV Cache? å¯èƒ½ä¼šå¥½å¥‡ï¼Œæ—¢ç„¶ K å’Œ V éƒ½éœ€è¦ç¼“å­˜ï¼Œä¸ºä»€ä¹ˆä¸ä¹Ÿç¼“å­˜ Q å‘¢ï¼Ÿä¹Ÿå°±æ˜¯è¯´ï¼Œä¸ºä»€ä¹ˆæ˜¯ KV Cache è€Œä¸æ˜¯ QKV Cacheï¼Ÿ\nåŸå› åœ¨äº Q å‘é‡çš„æ€§è´¨ï¼š\nQ å‘é‡æ˜¯ç”¨æ¥â€œæŸ¥è¯¢â€å½“å‰ token ä¸åºåˆ—ä¸­å…¶ä»– token çš„ç›¸å…³æ€§çš„ã€‚åœ¨è‡ªå›å½’ç”Ÿæˆè¿‡ç¨‹ä¸­ï¼Œæ¯ä¸€æ­¥ç”Ÿæˆä¸€ä¸ªæ–°çš„ tokenï¼Œè¿™ä¸ªæ–° token å¯¹åº”çš„ Query å‘é‡æ˜¯æ–°çš„ï¼Œå®ƒåŸºäºå½“å‰æ­¥çš„éšè—çŠ¶æ€è®¡ç®—å¾—å‡ºã€‚æ¢å¥è¯è¯´ï¼Œæ¯æ¬¡ç”Ÿæˆæ–° token æ—¶ï¼Œå…¶å¯¹åº”çš„ $Q$ å‘é‡éƒ½æ˜¯ç‹¬ä¸€æ— äºŒçš„ï¼Œå¹¶ä¸”éœ€è¦é‡æ–°è®¡ç®—ä»¥åæ˜ æœ€æ–°çš„ç”Ÿæˆä¸Šä¸‹æ–‡ã€‚ K å’Œ V å‘é‡åˆ™ä»£è¡¨äº†åºåˆ—ä¸­æ¯ä¸ª token çš„â€œå†…å®¹â€ä¿¡æ¯ã€‚å¯¹äºå·²ç»å¤„ç†è¿‡çš„ tokenï¼Œå®ƒä»¬çš„ $K$ å’Œ $V$ å‘é‡ä¸€æ—¦è®¡ç®—å‡ºæ¥ï¼Œå…¶å†…å®¹ä¿¡æ¯å°±æ˜¯å›ºå®šä¸å˜çš„ã€‚å› æ­¤ï¼Œè¿™äº› $K$ å’Œ $V$ å‘é‡å¯ä»¥ç›´æ¥è¢«ç¼“å­˜å¹¶åå¤ä½¿ç”¨ï¼Œè€Œæ— éœ€é‡æ–°è®¡ç®—ã€‚ å› æ­¤ï¼Œä¸ç¼“å­˜ Q æ˜¯å› ä¸ºå®ƒåœ¨æ¯ä¸€æ­¥éƒ½æ˜¯ä¸€ä¸ªæ–°çš„è®¡ç®—ç»“æœï¼›è€Œç¼“å­˜ K å’Œ V åˆ™å¯ä»¥æ˜¾è‘—å‡å°‘é‡å¤è®¡ç®—ï¼Œä»è€Œæé«˜æ•ˆç‡ã€‚\n6. KV Cache in Attention Mechanism åœ¨æ•°å­¦ä¸Šï¼Œå½“ä½¿ç”¨ KV Cache è¿›è¡Œè‡ªå›å½’è§£ç æ—¶ï¼Œæ³¨æ„åŠ›å…¬å¼ä¸­çš„ $K$ å’Œ $V$ çŸ©é˜µä¼šéšç€ç”Ÿæˆè¿‡ç¨‹çš„è¿›è¡Œè€Œä¸æ–­å¢é•¿ã€‚\nå‡è®¾æˆ‘ä»¬æ­£åœ¨ç”Ÿæˆç¬¬ $t$ ä¸ª tokenã€‚\nå½“å‰ token çš„ Q å‘é‡æ˜¯ $Q\\_t$ ï¼Œè¿™æ˜¯ä¸€ä¸ªè¡Œå‘é‡ï¼Œä»£è¡¨å½“å‰ç¬¬ $t$ ä¸ª token çš„ Query ï¼Œç»´åº¦ä¸º $1 \\times d\\_k$ K çŸ©é˜µ $K\\{\\text{cached}}$ å°†åŒ…å«ä»ç¬¬ä¸€ä¸ª token åˆ°ç¬¬ $t$ ä¸ª token çš„æ‰€æœ‰ K å‘é‡ï¼š $K\\{\\text{cached}} = [K\\_1^T, K\\_2^T, \\dots, K\\_t^T]^T$ ï¼Œç»´åº¦ä¸º $t \\times d\\_k$ V çŸ©é˜µ $V\\{\\text{cached}}$ å°†åŒ…å«ä»ç¬¬ä¸€ä¸ª token åˆ°ç¬¬ $t$ ä¸ª token çš„æ‰€æœ‰ V å‘é‡ï¼š $V\\{\\text{cached}} = [V\\_1^T, V\\_2^T, \\dots, V\\_t^T]^T$ ã€‚å…¶ç»´åº¦ä¸º $t \\times d\\_v$ é‚£ä¹ˆï¼Œç¬¬ $t$ ä¸ª token çš„æ³¨æ„åŠ›è®¡ç®—å˜ä¸ºï¼š $$ \\text{Attention}\\{t}(Q\\t, K\\{\\text{cached}}, V\\{\\text{cached}}) = \\text{softmax}\\left(\\frac{Q\\t K\\{\\text{cached}}^T}{\\sqrt{d\\k}}\\right)V\\{\\text{cached}} $$ å…¶ä¸­\n$Q\\t K\\{\\text{cached}}^T$ æ˜¯ä¸€ä¸ª $1 \\times t$ çš„è¡Œå‘é‡ï¼Œä»£è¡¨å½“å‰ Query ä¸æ‰€æœ‰å†å² Key çš„ç›¸å…³æ€§åˆ†æ•° $\\text{softmax}$ æ“ä½œå°†è¿™ä¸ª $1 \\times t$ çš„å‘é‡è½¬åŒ–ä¸ºæ³¨æ„åŠ›æƒé‡ è¿™ä¸ª $1 \\times t$ çš„æ³¨æ„åŠ›æƒé‡å‘é‡å†ä¸ $V\\_{\\text{cached}}$ çŸ©é˜µï¼ˆç»´åº¦ $t \\times d\\_v$ï¼‰ç›¸ä¹˜ï¼Œå¾—åˆ°æœ€ç»ˆçš„æ³¨æ„åŠ›è¾“å‡ºï¼Œç»´åº¦æ˜¯ $1 \\times d\\_v$ æ¯æ¬¡ç”Ÿæˆæ–°çš„ token $t+1$ æ—¶ï¼Œæˆ‘ä»¬åªéœ€è¦è®¡ç®—æ–°çš„ $Q\\{t+1}$ï¼Œå°†æ–°è®¡ç®—çš„ $K\\{t+1}$ å’Œ $V\\{t+1}$ æ‹¼æ¥åˆ° $K\\{\\text{cached}}$ å’Œ $V\\{\\text{cached}}$ æœ«å°¾ï¼Œå½¢æˆ $K\u0026rsquo;\\{\\text{cached}} = \\text{concat}(K\\{\\text{cached}}, K\\{t+1})$ å’Œ $V\u0026rsquo;\\{\\text{cached}} = \\text{concat}(V\\{\\text{cached}}, V\\_{t+1})$\n7. Limitations and Considerations å°½ç®¡ KV Cache å¸¦æ¥äº†å·¨å¤§çš„æ€§èƒ½æå‡ï¼Œä½†ä¹Ÿå­˜åœ¨ä¸€äº›é—®é¢˜ï¼š\nå†…å­˜å ç”¨ï¼šKV Cache éœ€è¦å­˜å‚¨æ‰€æœ‰å·²å¤„ç† token çš„ Key å’Œ Value å‘é‡ã€‚å¯¹äºå¤§å‹æ¨¡å‹å’Œé•¿ä¸Šä¸‹æ–‡åºåˆ—ï¼Œè¿™äº›ç¼“å­˜å¯èƒ½éå¸¸å¤§ï¼Œå¯¼è‡´æ˜¾å­˜ï¼ˆGPU Memoryï¼‰æˆä¸ºç“¶é¢ˆã€‚ ä¸Šä¸‹æ–‡é•¿åº¦é™åˆ¶ï¼šç”±äºå†…å­˜é™åˆ¶ï¼ŒKV Cache ä¼šé™åˆ¶æ¨¡å‹èƒ½å¤Ÿå¤„ç†çš„æœ€å¤§ä¸Šä¸‹æ–‡é•¿åº¦ã€‚ä¸€æ—¦è¾¾åˆ°å†…å­˜ä¸Šé™ï¼Œå°±éœ€è¦é‡‡å–ç­–ç•¥æ¥ç®¡ç†ç¼“å­˜ï¼Œä¾‹å¦‚ä¸¢å¼ƒæœ€æ—©çš„ Key/Value å¯¹ï¼ˆç±»ä¼¼äºå¾ªç¯ç¼“å†²åŒºï¼‰ï¼Œä½†è¿™å¯èƒ½ä¼šå½±å“æ¨¡å‹å¯¹é•¿è·ç¦»ä¾èµ–çš„ç†è§£ã€‚ Summary KV Cache æ˜¯ Transformer æ¨¡å‹åœ¨è‡ªå›å½’æ¨ç†è¿‡ç¨‹ä¸­éå¸¸é‡è¦çš„ä¸€ç§ä¼˜åŒ–æŠ€æœ¯ã€‚é€šè¿‡ç¼“å­˜å¹¶é‡ç”¨å·²ç»è®¡ç®—è¿‡çš„ Key å’Œ Value å‘é‡ï¼Œå®ƒæå¤§åœ°å‡å°‘äº†é‡å¤è®¡ç®—ï¼Œä»è€Œæ˜¾è‘—æå‡äº†å¤§å‹è¯­è¨€æ¨¡å‹çš„ç”Ÿæˆé€Ÿåº¦ã€‚\nReferences KV Cache åŸç†è®²è§£ ï¼ˆBilibiliï¼‰ æ³¨æ„ï¼šæ­¤è§†é¢‘å†…å®¹å­˜åœ¨éƒ¨åˆ†é”™è¯¯ çœ‹å›¾å­¦KV Cacheï¼ˆçŸ¥ä¹ï¼‰ ä¸ºä»€ä¹ˆæ²¡æœ‰Q Cacheï¼ˆçŸ¥ä¹ï¼‰ ","permalink":"https://diefish1024.github.io/posts/ai-infra/kv-cache-%E5%85%A5%E9%97%A8/","summary":"\u003cp\u003eæ¨ç†æ•ˆç‡å¯¹äº llm æ˜¯ä¸€ä¸ªè‡³å…³é‡è¦çš„é—®é¢˜ã€‚å½“æ¨¡å‹ç”Ÿæˆæ–‡æœ¬æ—¶ï¼Œå°¤å…¶æ˜¯ä»¥è‡ªå›å½’æ–¹å¼é€è¯ç”Ÿæˆæ—¶ï¼Œæ•ˆç‡ç“¶é¢ˆä¼šå˜å¾—éå¸¸æ˜æ˜¾ã€‚KV Cache å°±æ˜¯ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜è€Œè¯ç”Ÿçš„æŠ€æœ¯ã€‚\u003c/p\u003e\n\u003ch3 id=\"1-what-is-kv-cache\"\u003e1. What is KV Cache?\u003c/h3\u003e\n\u003cp\u003eKV Cacheï¼Œå…¨ç§° \u003cstrong\u003eKey-Value Cache\u003c/strong\u003eï¼Œæ˜¯ä¸€ç§ä¼˜åŒ–æŠ€æœ¯ï¼Œç”¨äºåŠ é€Ÿ Transformer æ¶æ„åœ¨è‡ªå›å½’ç”Ÿæˆè¿‡ç¨‹ä¸­çš„æ¨ç†é€Ÿåº¦ã€‚å®ƒçš„æ ¸å¿ƒæ€æƒ³æ˜¯\u003cstrong\u003eç¼“å­˜\u003c/strong\u003eå¹¶\u003cstrong\u003eé‡ç”¨\u003c/strong\u003eåœ¨æ³¨æ„åŠ›æœºåˆ¶ä¸­è®¡ç®—å¾—åˆ°çš„ \u003cstrong\u003eKey (K)\u003c/strong\u003e å’Œ \u003cstrong\u003eValue (V)\u003c/strong\u003e å‘é‡ã€‚\u003c/p\u003e\n\u003ch3 id=\"2-transformer-attention-mechanism-review\"\u003e2. Transformer Attention Mechanism Review\u003c/h3\u003e\n\u003cp\u003eè¦ç†è§£ KV Cacheï¼Œé¦–å…ˆéœ€è¦å¯¹ Transformer æ¶æ„ä¸­çš„è‡ªæ³¨æ„åŠ›æœºåˆ¶æœ‰ä¸€ä¸ªåŸºæœ¬è®¤è¯†ã€‚è‡ªæ³¨æ„åŠ›æœºåˆ¶å…è®¸æ¨¡å‹åœ¨å¤„ç†åºåˆ—ä¸­çš„æŸä¸ªè¯æ—¶ï¼Œè€ƒè™‘åºåˆ—ä¸­æ‰€æœ‰å…¶ä»–è¯çš„é‡è¦æ€§ã€‚\u003c/p\u003e\n\u003cp\u003eæ¯ä¸ªè¾“å…¥ tokenï¼ˆè¯æˆ–å­è¯ï¼‰åœ¨è¿›å…¥æ³¨æ„åŠ›å±‚æ—¶ï¼Œéƒ½ä¼šè¢«è½¬æ¢æˆä¸‰ä¸ªä¸åŒçš„å‘é‡ï¼š\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eQ å‘é‡ï¼šä»£è¡¨å½“å‰ token çš„â€œæŸ¥è¯¢â€ä¿¡æ¯\u003c/li\u003e\n\u003cli\u003eK å‘é‡ï¼šä»£è¡¨æ‰€æœ‰ token çš„â€œé”®â€ä¿¡æ¯ï¼Œç”¨äºä¸ Query è¿›è¡ŒåŒ¹é…\u003c/li\u003e\n\u003cli\u003eV å‘é‡ï¼šä»£è¡¨æ‰€æœ‰ token çš„â€œå€¼â€ä¿¡æ¯ï¼Œç”¨äºåŠ æƒæ±‚å’Œï¼Œå¾—åˆ°æœ€ç»ˆçš„è¾“å‡º\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eè‡ªæ³¨æ„åŠ›æœºåˆ¶çš„è®¡ç®—è¿‡ç¨‹ä¸ºä»¥ä¸‹æ­¥éª¤ï¼š\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eè®¡ç®— Query ä¸æ‰€æœ‰ Key çš„ç‚¹ç§¯ï¼Œå¾—åˆ°\u003cstrong\u003eæ³¨æ„åŠ›åˆ†æ•°\u003c/strong\u003e\u003c/li\u003e\n\u003cli\u003eå°†æ³¨æ„åŠ›åˆ†æ•°è¿›è¡Œç¼©æ”¾ï¼Œé™¤ä»¥ $\\sqrt{d\\_k}$ï¼ˆ$d\\_k$ æ˜¯ Key å‘é‡çš„ç»´åº¦)\u003c/li\u003e\n\u003cli\u003eå¯¹ç¼©æ”¾åçš„åˆ†æ•°è¿›è¡Œ Softmaxï¼Œå°†å…¶è½¬æ¢ä¸º\u003cstrong\u003eæ³¨æ„åŠ›æƒé‡\u003c/strong\u003eï¼Œè¡¨ç¤ºæ¯ä¸ª token å¯¹å½“å‰ token çš„é‡è¦æ€§\u003c/li\u003e\n\u003cli\u003eå°†æ³¨æ„åŠ›æƒé‡ä¸ Value å‘é‡è¿›è¡ŒåŠ æƒæ±‚å’Œï¼Œå¾—åˆ°å½“å‰ token çš„æ³¨æ„åŠ›è¾“å‡º\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003eå…¬å¼ä¸ºï¼š\n$$\n\\text{Attention}(Q, K, V) = \\text{softmax}\\left(\\frac{QK^T}{\\sqrt{d\\_k}}\\right)V\n$$\nå…¶ä¸­çŸ©é˜µ $Q,K,V \\in \\mathbb{R}^{L \\times d}$ ï¼Œ$L$ ä¸ºå½“å‰ä¸Šä¸‹æ–‡é•¿åº¦\u003c/p\u003e","title":"KV Cache å…¥é—¨"},{"content":"Introduction TTA åœ¨å›å½’ä»»åŠ¡ä¸Šçš„å±€é™ï¼šä¸ºåˆ†ç±»ä»»åŠ¡è®¾è®¡ï¼Œä¸€èˆ¬åŸºäºç†µæœ€å°åŒ–å’Œç‰¹å¾å¯¹é½ï¼›ç†µæœ€å°åŒ–ä¸é€‚ç”¨ï¼Œå›å½’æ¨¡å‹äº§ç”Ÿå•ä¸€å€¼ï¼Œä¸äº§ç”Ÿæ¦‚ç‡åˆ†å¸ƒï¼›ç®€å•ç‰¹å¾å¯¹é½å¯¹å›å½’æ¨¡å‹æ•ˆæœä¸ä½³ï¼Œå¯èƒ½åè€Œä¼šç¨€é‡Šéœ€è¦å­¦ä¹ çš„ç‰¹å¾\nProblem Setting è€ƒè™‘ä¸€ä¸ªå›å½’æ¨¡å‹ $f\\\\theta: \\mathcal{X} \\to \\mathbb{R}$ï¼Œå¯ä»¥è¿›ä¸€æ­¥åˆ†è§£ä¸ºç‰¹å¾æå–å™¨ $g\\\\phi: \\mathcal{X} \\to \\mathbb{R}^D$ï¼ˆä»è¾“å…¥ $\\mathcal{X}$ æå– $D$ ç»´ç‰¹å¾ $z$ï¼‰å’Œçº¿æ€§å›å½’å™¨ $h\\\\psi(z) = w^T z + b$ï¼ˆæˆ–è€… $h\\{\\psi}(z)=Wz+b$ï¼‰\n$f\\_\\theta$ é¦–å…ˆåœ¨ä¸€ä¸ªæœ‰æ ‡ç­¾çš„æºæ•°æ®é›† $S = {(x\\_i, y\\i)}\\{i=1}^{N\\_s}$ ä¸Šè¿›è¡Œé¢„è®­ç»ƒï¼Œæ•°æ®ä»æºåŸŸåˆ†å¸ƒ $p\\_s$ ä¸­é‡‡æ ·\nç›®æ ‡æ˜¯ä½¿ç”¨ä¸€ä¸ªæ— æ ‡ç­¾çš„ç›®æ ‡æ•°æ®é›† $T = {x\\j}\\{j=1}^{N\\t}$ æ¥é€‚åº”é¢„è®­ç»ƒå¥½çš„æ¨¡å‹ $f\\\\theta$ åˆ°ç›®æ ‡åŸŸ\næˆ‘ä»¬å‡è®¾å­˜åœ¨ covariate shift ï¼Œè¿™æ„å‘³ç€ï¼š\nè¾“å…¥æ•°æ®çš„åˆ†å¸ƒåœ¨æºåŸŸå’Œç›®æ ‡åŸŸä¹‹é—´æ˜¯ä¸åŒçš„ï¼š$p\\_s(x) \\neq p\\_t(x)$ ä½†ç»™å®šè¾“å…¥åï¼Œè¾“å‡ºçš„æ¡ä»¶åˆ†å¸ƒæ˜¯ç›¸åŒçš„ï¼š$p\\_s(y|x) = p\\_t(y|x)$ Test-time Adaptation for Regression Basic Idea: Feature Alignment æœ´ç´ å®ç°ï¼š\nè®¡ç®—æºåŸŸç‰¹å¾ç»Ÿè®¡é‡ï¼šåœ¨æºåŸŸè®­ç»ƒåï¼Œè®¡ç®—æºåŸŸç‰¹å¾çš„å‡å€¼ $\\mu^s$ å’Œå…ƒç´ çº§æ–¹å·® $\\sigma^{s2}$ $$ \\mu^s = \\frac{1}{N\\s} \\sum\\{i=1}^{N\\_s} z\\_i^s, \\quad \\sigma^{s2} = \\frac{1}{N\\s} \\sum\\{i=1}^{N\\_s} (z\\_i^s - \\mu^s) \\odot (z\\_i^s - \\mu^s) \\quad \\text{(1)} $$ å…¶ä¸­ $z\\i^s = g\\\\phi(x\\_i)$ æ˜¯æºç‰¹å¾ï¼Œ$N\\_s$ æ˜¯æºæ•°æ®æ ·æœ¬æ•°ï¼Œ$\\odot$ è¡¨ç¤ºå…ƒç´ çº§ä¹˜ç§¯\nç›®æ ‡åŸŸç‰¹å¾ç»Ÿè®¡é‡ï¼šåœ¨ç›®æ ‡åŸŸï¼Œå¯¹æ¯ä¸ªè¿·ä½ æ‰¹æ¬¡ï¼ˆmini-batchï¼‰$B = {x\\j}\\{j=1}^{N\\_B}$ï¼Œè®¡ç®—å…¶ç‰¹å¾å‡å€¼ $\\hat{\\mu}^t$ å’Œæ–¹å·® $\\hat{\\sigma}^{t2}$ï¼Œè®¡ç®—æ–¹å¼ä¸å…¬å¼ (1) ç±»ä¼¼\nå¯¹é½æŸå¤±å‡½æ•°ï¼šä½¿ç”¨ KL æ•£åº¦æ¥è¡¡é‡ä¸¤ä¸ªå¯¹è§’é«˜æ–¯åˆ†å¸ƒ $N(\\mu^s, \\sigma^{s2})$ å’Œ $N(\\hat{\\mu}^t, \\hat{\\sigma}^{t2})$ ä¹‹é—´çš„å·®å¼‚ï¼Œå¹¶æœ€å°åŒ–è¯¥å·®å¼‚ã€‚ $$ L\\{TTA} (\\phi) = \\frac{1}{2} \\sum\\{d=1}^D \\left{ D\\{KL} (N(\\mu^s\\d, \\sigma^s\\{d}{}^2)||N(\\hat{\\mu}^t\\d, \\hat{\\sigma}^t\\{d}{}^2)) + D\\{KL} (N(\\hat{\\mu}^t\\d, \\hat{\\sigma}^t\\{d}{}^2)||N(\\mu^s\\d, \\sigma^s\\{d}{}^2)) \\right} \\quad \\text{(2)} $$ è¿™é‡Œçš„ $d$ è¡¨ç¤ºå‘é‡çš„ç¬¬ $d$ ä¸ªå…ƒç´ ã€‚ä¹‹æ‰€ä»¥ä½¿ç”¨åŒå‘çš„ KL æ•£åº¦ï¼Œæ˜¯ä¸ºäº†ç»éªŒä¸Šè·å¾—æ›´å¥½çš„ç»“æœ\nä¸€ç»´é«˜æ–¯ KL æ•£åº¦å…¬å¼ï¼š $$ D\\_{KL} (N(\\mu\\_1, \\sigma\\_1^2)||N(\\mu\\_2, \\sigma\\_2^2)) = \\dfrac{\\left[ \\log(\\sigma\\_2^2/\\sigma\\_1^2) + \\dfrac{(\\mu\\_1 - \\mu\\_2)^2 + \\sigma\\_1^2}{\\sigma\\_2^2} - 1 \\right]}{2} \\quad \\text{(3)} $$\næœ´ç´ å¯¹é½çš„é—®é¢˜ï¼š\nå›å½’æ¨¡å‹ç‰¹å¾å€¾å‘äºåˆ†å¸ƒåœ¨ä¸€ä¸ªå°å‹çš„å­ç©ºé—´ä¸­ï¼Œè®¸å¤šç‰¹å¾ç»´åº¦æ–¹å·®ä¸ºé›¶æˆ–æ¥è¿‘é›¶ å…¬å¼ (3) ä¸­æ¶‰åŠåˆ°æ–¹å·®åœ¨åˆ†æ¯ä¸Šï¼Œä½¿å¾—è¿™ç§æœ´ç´ å¯¹é½åœ¨é¢å¯¹é›¶æ–¹å·®ç»´åº¦æ—¶å˜å¾—ä¸ç¨³å®š å¯¹æ‰€æœ‰ç»´åº¦â€œä¸€è§†åŒä»â€åœ°å¯¹é½ä¸é€‚ç”¨äºå›å½’ä»»åŠ¡çš„ç‰¹æ€§ï¼Œå› ä¸ºè®¸å¤šç»´åº¦å¯¹æœ€ç»ˆè¾“å‡ºå½±å“å¾ˆå° Significant-subspace Alignment SSA çš„ä¸‰ä¸ªæ­¥éª¤ï¼š\nå­ç©ºé—´æ£€æµ‹ (Subspace detection)ï¼š\nåœ¨æºæ•°æ®é›† $S$ ä¸Šè¿›è¡Œè®­ç»ƒåï¼Œæ£€æµ‹æºç‰¹å¾åˆ†å¸ƒæ‰€åœ¨çš„å­ç©ºé—´ã€‚ä¸è®¡ç®—æ¯ä¸ªç»´åº¦çš„æ–¹å·®ï¼Œè€Œæ˜¯è®¡ç®—åæ–¹å·®çŸ©é˜µï¼š $$ \\Sigma^s = \\frac{1}{N\\s} \\sum\\{i=1}^{N\\_s} (z\\_i^s - \\mu^s) (z\\_i^s - \\mu^s)^T \\quad \\text{(4)} $$ å…¶ä¸­ $\\mu^s$ æ˜¯æºç‰¹å¾çš„å‡å€¼å‘é‡ï¼ˆåŒç† (1)ï¼‰ åŸºäº PCA çš„æ€æƒ³ï¼Œé€šè¿‡å¯¹ $\\Sigma^s$ è¿›è¡Œç‰¹å¾åˆ†è§£ï¼Œå¾—åˆ°ç‰¹å¾å‘é‡ $v\\_d^s$ å’Œå¯¹åº”çš„ç‰¹å¾å€¼ $\\lambda\\_d^s$ é€‰å–å‰ K ä¸ªæœ€å¤§çš„ç‰¹å¾å€¼ $\\lambda\\_1^s, \\dots, \\lambda\\_K^s$ åŠå…¶å¯¹åº”çš„æºåŸºå‘é‡ $v\\_1^s, \\dots, v\\_K^s$ æ¥å®šä¹‰æºå­ç©ºé—´ï¼Œè¿™äº›åŸºå‘é‡å¼ æˆçš„å­ç©ºé—´ä»£è¡¨äº†æºç‰¹å¾æ•°æ®æœ€æœ‰ä»£è¡¨æ€§å’Œæœ€é‡è¦çš„å˜åŒ–æ–¹å‘ ç»´åº¦åŠ æƒ (Dimension weighting)ï¼š\nè€ƒè™‘åˆ°å›å½’æ¨¡å‹ $h\\_\\psi(z)=w^T z + b$ï¼Œå­ç©ºé—´ç»´åº¦ $v\\_d^s$ å¯¹æœ€ç»ˆè¾“å‡ºçš„å½±å“ç”± $w^T v\\_d^s$ å†³å®šï¼ˆå³ç‰¹å¾å‘é‡ä¸å›å½’å™¨æƒé‡å‘é‡çš„ç‚¹ç§¯ï¼‰ ä¸ºäº†ä¼˜å…ˆå¯¹é½é‚£äº›å¯¹è¾“å‡ºå½±å“æ›´å¤§çš„å­ç©ºé—´ç»´åº¦ï¼Œä¸ºæ¯ä¸ªå­ç©ºé—´ç»´åº¦ $d$ å®šä¹‰æƒé‡ $a\\_d$ï¼š $$ a\\_d = 1 + |w^T v\\_d^s| \\quad \\text{(5)} $$ è¿™ä¸ªæƒé‡ $a\\_d$ ä¼šåœ¨å¯¹åº”çš„å­ç©ºé—´åŸºæ–¹å‘å¯¹è¾“å‡ºæœ‰è¾ƒå¤§å½±å“æ—¶å€¼æ›´å¤§ï¼ˆæœ€å°ä¸º 1ï¼‰ã€‚ ç‰¹å¾å¯¹é½ (Feature alignment)ï¼š\nè¿™ä¸€æ­¥åœ¨ç›®æ ‡åŸŸè¿›è¡Œã€‚å¯¹äºç›®æ ‡åŸŸçš„è¿·ä½ æ‰¹æ¬¡ $B$ï¼Œé¦–å…ˆå°†ç›®æ ‡ç‰¹å¾ $z^t = g\\_\\phi(x^t)$ æŠ•å½±åˆ°æºå­ç©ºé—´ã€‚ $$ \\tilde{z}^t = V\\_s^T (z^t - \\mu^s) \\quad \\text{(6)} $$ å…¶ä¸­ $V\\_s = [v\\_1^s, \\dots, v\\_K^s] \\in \\mathbb{R}^{D \\times K}$ æ˜¯ç”±å‰ K ä¸ªæºåŸºå‘é‡æ„æˆçš„çŸ©é˜µï¼Œ$\\tilde{z}^t \\in \\mathbb{R}^K$ æ˜¯æŠ•å½±åçš„ç›®æ ‡ç‰¹å¾ã€‚ ç„¶åï¼Œè®¡ç®—æŠ•å½±åç›®æ ‡ç‰¹å¾çš„è¿·ä½ æ‰¹æ¬¡å‡å€¼ $\\tilde{\\mu}^t$ å’Œæ–¹å·® $\\tilde{\\sigma}^{t2}$ ï¼ˆåŒç†å…¬å¼ (1) ï¼‰ æœ€åï¼Œä½¿ç”¨ç»“åˆå­ç©ºé—´æ£€æµ‹å’Œç»´åº¦åŠ æƒçš„æ–°æŸå¤±å‡½æ•°æ¥æœ€å°åŒ–ç›®æ ‡ç‰¹å¾åˆ†å¸ƒä¸æºç‰¹å¾åˆ†å¸ƒåœ¨å­ç©ºé—´ä¸­çš„å·®å¼‚ã€‚æºåŸŸæŠ•å½±åçš„å‡å€¼æ˜¯ 0ï¼Œæ–¹å·®æ˜¯å…¶ç‰¹å¾å€¼ $\\Lambda^s = [\\lambda\\1^s, \\dots, \\lambda\\K^s]$ã€‚ $$ \\begin{align}L\\{TTA}(\\phi) = \u0026amp; \\frac{1}{2} \\sum\\{d=1}^K a\\d \\left{ D\\{KL} (N(0, \\lambda^s\\d)||N(\\tilde{\\mu}^t\\d, \\tilde{\\sigma}^t\\{d}{}^2)) + D\\{KL} (N(\\tilde{\\mu}^t\\d, \\tilde{\\sigma}^t\\{d}{}^2)||N(0, \\lambda^s\\d)) \\right} \\ = \u0026amp; \\sum\\{d=1}^K a\\_d \\left{ \\frac{(\\tilde{\\mu}^t\\_d)^2 + \\lambda^s\\d}{2\\tilde{\\sigma}^t\\{d}{}^2} + \\frac{(\\tilde{\\mu}^t\\d)^2 + \\tilde{\\sigma}^t\\{d}{}^2}{2\\lambda^s\\_d} - 1 \\right} \\quad \\text{(7)} \\end{align}$$ å…¶ä¸­ $a\\_d$ æ˜¯ç»´åº¦æƒé‡ï¼Œ$\\lambda\\_d^s$ æ˜¯æºåŸŸå­ç©ºé—´çš„ç¬¬ $d$ ä¸ªç‰¹å¾å€¼ï¼Œ$\\tilde{\\mu}\\d^t$ å’Œ $\\tilde{\\sigma}\\{d}{}^2$ æ˜¯æŠ•å½±åçš„ç›®æ ‡ç‰¹å¾åœ¨ç¬¬ $d$ ä¸ªç»´åº¦ä¸Šçš„å‡å€¼å’Œæ–¹å·® ä¼ªä»£ç ï¼š\nè¾“å…¥ï¼šé¢„è®­ç»ƒå¥½çš„æºæ¨¡å‹ $f\\_\\theta$ã€æºåŸºå‘é‡ $V\\_s$ã€æºå‡å€¼ $\\mu^s$ã€æºæ–¹å·® $\\Lambda^s$ã€ç›®æ ‡æ•°æ®é›† $T$ è¾“å‡ºï¼šé€‚åº”åçš„æ¨¡å‹ $f\\_\\phi^t$ æ­¥éª¤ï¼š è®¡ç®—æºå­ç©ºé—´ä¸­æ¯ä¸ªç»´åº¦çš„æƒé‡ $a\\_d$ å¯¹äºç›®æ ‡æ•°æ®é›† $T$ ä¸­çš„æ¯ä¸ª mini batch ${x}\\_i^B$ï¼š æå–ç›®æ ‡ç‰¹å¾ $z = g\\_\\phi(x)$ã€‚ å°†ç›®æ ‡ç‰¹å¾æŠ•å½±åˆ°æºå­ç©ºé—´ $\\tilde{z}$ è®¡ç®—æŠ•å½±åç›®æ ‡ç‰¹å¾çš„å‡å€¼ $\\tilde{\\mu}^t$ å’Œæ–¹å·® $\\tilde{\\sigma}^{t2}$ æ›´æ–°ç‰¹å¾æå–å™¨ $g\\\\phi$ ä»¥æœ€å°åŒ–æŸå¤±å‡½æ•° $L\\{TTA}(\\phi)$ é‡å¤ç›´åˆ°æ”¶æ•›ã€‚ å¯¹è§’é«˜æ–¯åˆ†å¸ƒçš„åˆç†æ€§ ä¸ºä»€ä¹ˆå‡è®¾ç‰¹å¾åˆ†å¸ƒä¸ºå¯¹è§’é«˜æ–¯åˆ†å¸ƒæ˜¯åˆç†çš„ï¼š\nä¸­å¿ƒæé™å®šç†ï¼šå½“ç‰¹å¾è¢«æŠ•å½±åˆ°å­ç©ºé—´åï¼Œå¦‚æœåŸå§‹ç‰¹å¾ç»´åº¦ $D$ è¶³å¤Ÿå¤§ï¼Œæ ¹æ®ä¸­å¿ƒæé™å®šç†ï¼ŒæŠ•å½±åçš„ç‰¹å¾åˆ†å¸ƒä¼šå€¾å‘äºé«˜æ–¯åˆ†å¸ƒã€‚ PCA çš„å»ç›¸å…³æ€§ï¼šç”±äºå­ç©ºé—´æ£€æµ‹ä½¿ç”¨äº† PCAï¼ŒæŠ•å½±åˆ°ä¸»æˆåˆ†ä¸Šçš„ç‰¹å¾æ˜¯å»ç›¸å…³çš„ï¼Œè¿™æ„å‘³ç€ä¸åŒç»´åº¦ä¹‹é—´æ˜¯ç‹¬ç«‹çš„ï¼Œè¿™ä½¿å¾—å¯¹è§’é«˜æ–¯åˆ†å¸ƒçš„å‡è®¾ï¼ˆå³å„ç»´åº¦ç‹¬ç«‹ï¼‰å˜å¾—åˆç†ã€‚ Appendix A. LIMITATIONï¼šSSA å‡è®¾æ˜¯åå˜é‡åç§»ï¼Œå³ $p(y|x)$ ä¸å˜ï¼Œæœªæ¥å·¥ä½œå°†è€ƒè™‘ $p(y|x)$ å˜åŒ–çš„æƒ…å†µ\nB. EVALUATION METRICï¼šRÂ²æ¥è¿‘ 1 è¡¨ç¤ºæ¨¡å‹æ‹Ÿåˆæ•ˆæœå¥½ $$ R^2 = 1 - \\frac{\\sum\\_{i=1}^N (y\\_i - \\hat{y}\\i)^2}{\\sum\\{i=1}^N (y\\_i - \\bar{y})^2} \\quad \\text{(10)} $$ å…¶ä¸­ $\\hat{y}\\_i$ æ˜¯é¢„æµ‹å€¼ï¼Œ$y\\_i$ æ˜¯çœŸå®å€¼ï¼Œ$\\bar{y}$ æ˜¯çœŸå®å€¼çš„å¹³å‡å€¼ã€‚\nD. ADDITIONAL EXPERIMENTAL RESULTSï¼š\nD.1 ç‰¹å¾å¯¹é½çš„åº¦é‡ï¼šæ¯”è¾ƒäº† KL æ•£åº¦ã€2WD å’Œ L1 èŒƒæ•°ä½œä¸ºç‰¹å¾å¯¹é½æŸå¤±çš„æ•ˆæœï¼Œç»“æœæ˜¾ç¤º KL æ•£åº¦ç»“åˆå­ç©ºé—´æ£€æµ‹ï¼ˆSSAï¼‰è¡¨ç°æœ€ä½³ã€‚ å…¬å¼ (11)ï¼š2-Wasserstein Distance for Gaussians $$ W\\_2^2 (N(\\mu\\_1, \\sigma\\_1^2), N(\\mu\\_2, \\sigma\\_2^2)) = (\\mu\\_1 - \\mu\\_2)^2 + (\\sigma\\_1 - \\sigma\\_2)^2 $$ å…¬å¼ (12)ï¼šL1 Norm of Statistics $$ L\\_1 (N(\\mu\\_1, \\sigma\\_1^2), N(\\mu\\_2, \\sigma\\_2^2)) = |\\mu\\_1 - \\mu\\_2| + |\\sigma\\_1 - \\sigma\\_2| $$ å…¬å¼ (13)ï¼šSSA Loss with 2WD $$ L\\{TTA-2WD} = \\sum\\{d=1}^K a\\_d \\left{ (\\tilde{\\mu}^t\\_d)^2 + (\\tilde{\\sigma}^t\\_d - \\sqrt{\\lambda^s\\_d})^2 \\right} $$ å…¬å¼ (14)ï¼šSSA Loss with L1 Norm $$ L\\{TTA-L1} = \\sum\\{d=1}^K a\\_d \\left{ |\\tilde{\\mu}^t\\_d| + |\\tilde{\\sigma}^t\\_d - \\sqrt{\\lambda^s\\_d}| \\right} $$ D.2 ç‰¹å¾å¯è§†åŒ–ï¼šé€šè¿‡ PCA å’Œ UMAP ç­‰é™ç»´æŠ€æœ¯å¯è§†åŒ–äº†æºåŸŸå’Œç›®æ ‡åŸŸç‰¹å¾åˆ†å¸ƒï¼ˆå›¾ 4-5ï¼‰ï¼Œç›´è§‚åœ°å±•ç¤ºäº† SSA å¦‚ä½•æˆåŠŸåœ°å°†ç›®æ ‡ç‰¹å¾åˆ†å¸ƒæ‹‰è¿‘æºåŸŸã€‚ D.3 åŸå§‹ç‰¹å¾ç»´åº¦å¯¹å­ç©ºé—´çš„å½±å“ï¼šåˆ†æäº†åŸå§‹ç‰¹å¾ç»´åº¦å¯¹å­ç©ºé—´çš„é‡è¦æ€§ã€‚ å…¬å¼ (15)ï¼šGradient Norm $s\\_d$ $$ s\\_d = ||\\frac{\\partial \\tilde{z}}{\\partial z\\_d}||\\_2 = ||(V\\_s^T)\\d||\\2 = ||[v\\{1,d}^s, \\dots, v\\{K,d}^s]||\\_2, $$ å…¶ä¸­ $(V\\_s^T)\\_d$ æ˜¯ $V\\_s^T$ çš„ç¬¬ $d$ è¡Œã€‚ å‘ç°ï¼šå›å½’æ¨¡å‹çš„ç‰¹å¾å­ç©ºé—´ç¡®å®å—è®¸å¤šåŸå§‹ç‰¹å¾ç»´åº¦å½±å“å¾ˆå°ï¼ˆå›¾ 6ï¼‰ï¼Œè¿™è¿›ä¸€æ­¥ç¡®è®¤äº†å­ç©ºé—´æ£€æµ‹çš„å¿…è¦æ€§ã€‚ D.4 é™„åŠ æ¶ˆèå®éªŒï¼šè¿›ä¸€æ­¥è¯å®äº†å­ç©ºé—´æ£€æµ‹å¯¹äº SSA æ€§èƒ½çš„é‡è¦æ€§ï¼ˆè¡¨ 13-14ï¼‰ã€‚ D.5 Vision Transformer å®éªŒï¼šåœ¨ Vision Transformer ä¸ŠéªŒè¯äº† SSA çš„æœ‰æ•ˆæ€§ï¼ˆè¡¨ 15-16ï¼‰ï¼Œè¡¨æ˜è¯¥æ–¹æ³•å¯¹ä¸åŒæ¨¡å‹æ¶æ„ä¹Ÿé€‚ç”¨ã€‚ D.6 å¤šä»»åŠ¡å›å½’æ¨¡å‹ï¼šå°† SSA åº”ç”¨äºå¤šä»»åŠ¡å›å½’ï¼Œæ¨¡å‹åŒæ—¶è¾“å‡ºå¤šä¸ªé¢„æµ‹å€¼ï¼ˆå¦‚å¤´éƒ¨å§¿æ€çš„ä¿¯ä»°ã€åèˆªã€æ»šè½¬è§’åº¦ï¼‰ï¼Œç»“æœè¡¨æ˜ SSA åŒæ ·æœ‰æ•ˆï¼ˆè¡¨ 17ï¼‰ã€‚ D.7 ä¸åˆ†ç±» TTA ç»“åˆï¼šæ¢ç´¢äº† SSA ä¸åˆ†ç±» TTA ç»“åˆçš„å¯èƒ½æ€§ï¼ˆè¡¨ 18-20ï¼‰ã€‚ D.8 è¶…å‚æ•°æ•æ„Ÿæ€§ï¼šåˆ†æäº†å­¦ä¹ ç‡å’Œæ‰¹æ¬¡å¤§å°ç­‰è¶…å‚æ•°å¯¹ SSA æ€§èƒ½çš„å½±å“ï¼ˆè¡¨ 21-26ï¼‰ï¼Œå‘ç° SSA åœ¨å…¸å‹å‚æ•°èŒƒå›´å†…è¡¨ç°ç¨³å®šã€‚ D.9 é¢å¤–ç»“æœï¼šæä¾›äº† MAE ç­‰å…¶ä»–æŒ‡æ ‡çš„æ€§èƒ½æ•°æ®ï¼ˆè¡¨ 27-28ï¼‰ã€‚ D.10 åœ¨çº¿è®¾ç½®ï¼šSSA åœ¨åˆ†æ‰¹åœ¨çº¿ï¼ˆbatched onlineï¼‰è®¾ç½®ä¸‹ä¹Ÿè¡¨ç°å‡ºè‰²ï¼ˆè¡¨ 29-31ï¼‰ã€‚ ","permalink":"https://diefish1024.github.io/posts/literature-notes/ssa/","summary":"\u003ch2 id=\"introduction\"\u003eIntroduction\u003c/h2\u003e\n\u003cp\u003eTTA åœ¨å›å½’ä»»åŠ¡ä¸Šçš„å±€é™ï¼šä¸ºåˆ†ç±»ä»»åŠ¡è®¾è®¡ï¼Œä¸€èˆ¬åŸºäºç†µæœ€å°åŒ–å’Œç‰¹å¾å¯¹é½ï¼›ç†µæœ€å°åŒ–ä¸é€‚ç”¨ï¼Œå›å½’æ¨¡å‹äº§ç”Ÿå•ä¸€å€¼ï¼Œä¸äº§ç”Ÿæ¦‚ç‡åˆ†å¸ƒï¼›ç®€å•ç‰¹å¾å¯¹é½å¯¹å›å½’æ¨¡å‹æ•ˆæœä¸ä½³ï¼Œå¯èƒ½åè€Œä¼šç¨€é‡Šéœ€è¦å­¦ä¹ çš„ç‰¹å¾\u003c/p\u003e\n\u003ch2 id=\"problem-setting\"\u003eProblem Setting\u003c/h2\u003e\n\u003cp\u003eè€ƒè™‘ä¸€ä¸ªå›å½’æ¨¡å‹ $f\\\u003cem\u003e\\theta: \\mathcal{X} \\to \\mathbb{R}$ï¼Œå¯ä»¥è¿›ä¸€æ­¥åˆ†è§£ä¸º\u003cstrong\u003eç‰¹å¾æå–å™¨\u003c/strong\u003e $g\\\u003c/em\u003e\\phi: \\mathcal{X} \\to \\mathbb{R}^D$ï¼ˆä»è¾“å…¥ $\\mathcal{X}$ æå– $D$ ç»´ç‰¹å¾ $z$ï¼‰å’Œ\u003cstrong\u003eçº¿æ€§å›å½’å™¨\u003c/strong\u003e $h\\\u003cem\u003e\\psi(z) = w^T z + b$ï¼ˆæˆ–è€… $h\\\u003c/em\u003e{\\psi}(z)=Wz+b$ï¼‰\u003c/p\u003e\n\u003cp\u003e$f\\_\\theta$ é¦–å…ˆåœ¨ä¸€ä¸ªæœ‰æ ‡ç­¾çš„\u003cstrong\u003eæºæ•°æ®é›†\u003c/strong\u003e $S = {(x\\_i, y\\\u003cem\u003ei)}\\\u003c/em\u003e{i=1}^{N\\_s}$ ä¸Šè¿›è¡Œé¢„è®­ç»ƒï¼Œæ•°æ®ä»æºåŸŸåˆ†å¸ƒ $p\\_s$ ä¸­é‡‡æ ·\u003c/p\u003e\n\u003cp\u003eç›®æ ‡æ˜¯ä½¿ç”¨ä¸€ä¸ª\u003cstrong\u003eæ— æ ‡ç­¾çš„\u003c/strong\u003eç›®æ ‡æ•°æ®é›† $T = {x\\\u003cem\u003ej}\\\u003c/em\u003e{j=1}^{N\\\u003cem\u003et}$ æ¥é€‚åº”é¢„è®­ç»ƒå¥½çš„æ¨¡å‹ $f\\\u003c/em\u003e\\theta$ åˆ°ç›®æ ‡åŸŸ\u003c/p\u003e\n\u003cp\u003eæˆ‘ä»¬å‡è®¾å­˜åœ¨ \u003cstrong\u003ecovariate shift\u003c/strong\u003e ï¼Œè¿™æ„å‘³ç€ï¼š\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eè¾“å…¥æ•°æ®çš„åˆ†å¸ƒåœ¨æºåŸŸå’Œç›®æ ‡åŸŸä¹‹é—´æ˜¯ä¸åŒçš„ï¼š$p\\_s(x) \\neq p\\_t(x)$\u003c/li\u003e\n\u003cli\u003eä½†ç»™å®šè¾“å…¥åï¼Œè¾“å‡ºçš„æ¡ä»¶åˆ†å¸ƒæ˜¯ç›¸åŒçš„ï¼š$p\\_s(y|x) = p\\_t(y|x)$\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"test-time-adaptation-for-regression\"\u003eTest-time Adaptation for Regression\u003c/h2\u003e\n\u003ch3 id=\"basic-idea-feature-alignment\"\u003eBasic Idea: Feature Alignment\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003eæœ´ç´ å®ç°\u003c/strong\u003eï¼š\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eè®¡ç®—æºåŸŸç‰¹å¾ç»Ÿè®¡é‡\u003c/strong\u003eï¼šåœ¨æºåŸŸè®­ç»ƒåï¼Œè®¡ç®—æºåŸŸç‰¹å¾çš„\u003cstrong\u003eå‡å€¼\u003c/strong\u003e $\\mu^s$ å’Œ\u003cstrong\u003eå…ƒç´ çº§æ–¹å·®\u003c/strong\u003e $\\sigma^{s2}$\n$$ \\mu^s = \\frac{1}{N\\\u003cem\u003es} \\sum\\\u003c/em\u003e{i=1}^{N\\_s} z\\_i^s, \\quad \\sigma^{s2} = \\frac{1}{N\\\u003cem\u003es} \\sum\\\u003c/em\u003e{i=1}^{N\\_s} (z\\_i^s - \\mu^s) \\odot (z\\_i^s - \\mu^s) \\quad \\text{(1)} $$\nå…¶ä¸­ $z\\\u003cem\u003ei^s = g\\\u003c/em\u003e\\phi(x\\_i)$ æ˜¯æºç‰¹å¾ï¼Œ$N\\_s$ æ˜¯æºæ•°æ®æ ·æœ¬æ•°ï¼Œ$\\odot$ è¡¨ç¤ºå…ƒç´ çº§ä¹˜ç§¯\u003c/p\u003e","title":"SSA"},{"content":"Method Problem Set EEG æ•°æ® ${ X\\{s,l}^{i},y\\{s,l}^{i} }\\{i=1}^{n\\{s,l}}$ ï¼Œè¿›è¡Œæ— ç›‘ç£åœ¨çº¿ K åˆ†ç±»\nSource Model Training å¯¹æºæ•°æ®åš Euclidean alignment (EA) æ•°æ®å¯¹é½ï¼Œå‡å°‘ä¸åŒä¸ªä½“ EEG ä¿¡å·å·®å¼‚\nEA è®¡ç®—æ¯ä¸ªä¸ªä½“æ‰€æœ‰ EEG è¯•æ¬¡åæ–¹å·®çŸ©é˜µçš„ç®—æœ¯å¹³å‡å€¼ $$ R\\{s,l} = \\dfrac{1}{n}\\sum\\{i=1}^{n} X\\{i}(X\\{i})^{T} \\implies \\bar{X}\\{i} = R\\{s,l}^{-1/2}X\\_{i} $$ ä¹‹åå†æ•´åˆç»è¿‡å¯¹é½çš„å—è¯•è€…æ•°æ®ï¼Œå½¢æˆâ€œæºåŸŸâ€\nåœ¨æ•´åˆåçš„æ•°æ®ä¸Šç‹¬ç«‹è®­ç»ƒ $M$ ä¸ªæ¨¡å‹\nIncremental EA on Target Data å¯¹æ–°æ•°æ®å¢é‡å¼æ›´æ–°åæ–¹å·®çŸ©é˜µï¼Œå†ç”¨æ–°çš„çŸ©é˜µæ›´æ–°æ‰€æœ‰æµ‹è¯•æ•°æ®\nTarget Label Prediction ç”¨è®­ç»ƒå¥½çš„ $M$ æ¨¡å‹åˆå§‹åŒ–ç”¨äºé€‚åº”ç›®æ ‡åŸŸçš„ $M$ ä¸ª TTA æ¨¡å‹ $f\\_{m}$\næ–°çš„ $X\\{a}$ ç»è¿‡ IEA è¢«å˜æ¢ä¸º $X\\{a}\u0026rsquo;$ åè¢«è¾“å…¥åˆ°æ¯ä¸ªæ¨¡å‹ $f\\{m}$ ä¸­è¿›è¡Œåˆ†ç±»ï¼Œè¾“å‡ºæ¦‚ç‡å‘é‡ $f\\{m}(X\\_{a}\u0026rsquo;)$\nä¹‹åç»“åˆè¿™ $M$ ä¸ªæ¦‚ç‡å‘é‡æ¥è·å¾—æœ€ç»ˆçš„é¢„æµ‹æ ‡ç­¾ $\\hat{y}\\_{a}$\n$a\\leq M$ æ•°æ®é‡è¾ƒå°‘ï¼šç›´æ¥å¯¹æ‰€æœ‰æ¨¡å‹çš„é¢„æµ‹å‘é‡å¹³å‡ $a\u0026gt;M$ æ•°æ®é‡è¾ƒå¤šï¼šä½¿ç”¨è°±å…ƒå­¦ä¹ å™¨å¯¹å„ä¸ªæ¨¡å‹è¿›è¡ŒåŠ æƒå¹³å‡ï¼Œæ ¹æ®å†å²è¡¨ç°ï¼ˆé¢„æµ‹çš„åæ–¹å·®çŸ©é˜µï¼‰åˆ†é…ä¸åŒçš„æƒé‡ Target Model Update åœ¨æ•°æ®é‡è¶³å¤Ÿä»¥åï¼ˆ$a\u0026gt;B$ï¼‰ä½¿ç”¨ä¸€ä¸ªæ»‘åŠ¨æ‰¹æ¬¡çš„æ•°æ®æ›´æ–°æ¨¡å‹ï¼Œåœ¨æ­¤ä¹‹å‰æ¨¡å‹ä¸å˜\nç»„åˆæŸå¤±å‡½æ•°ï¼š $$ L\\{M} = L\\{CEM}(f\\{m};{ X\u0026rsquo;\\{i} }\\{i=a-B+1}^{a}) + L\\{MDR}(f\\{m};{ X\u0026rsquo;\\{i} }\\_{i=a-B+1}^{a}) $$ æœ‰ä¸¤ä¸ªéƒ¨åˆ†\n1) Conditional Entropy Minimization æ¡ä»¶ç†µæœ€å°åŒ–\nä½¿åˆ†ç±»è¾¹ç•Œæ›´åŠ æ¸…æ™° é€šè¿‡æœ€å°åŒ–æ¯ä¸ªé¢„æµ‹çš„æ¡ä»¶ç†µï¼ˆä½¿ç”¨æ¸©åº¦ç¼©æ”¾å› å­ $T$ è¿›è¡Œæ ¡å‡†ï¼‰ï¼Œä½¿æ¨¡å‹å€¾å‘äºè¾“å‡ºæ¥è¿‘ 0 æˆ– 1 çš„æ¦‚ç‡ 2) Adaptive Marginal Distribution Regularization è‡ªé€‚åº”è¾¹ç¼˜åˆ†å¸ƒæ­£åˆ™åŒ–\né˜²æ­¢å‡ºç°æ‰€æœ‰æ•°æ®éƒ½åœ¨å•ç±»åˆ«å’Œå¯¹é”™è¯¯ç»“æœè¿‡äºè‡ªä¿¡çš„ä¸è‰¯ç»“æœ è®¡ç®—å½“å‰æ‰¹æ¬¡æ¯ä¸ªç±»åˆ«çš„å¹³å‡é¢„æµ‹æ¦‚ç‡ $p\\_{k}$ é€šè¿‡è®¾ç½®é˜ˆå€¼å¾—åˆ°ä¼ªæ ‡ç­¾ï¼Œä¼°è®¡ç›®æ ‡åŸŸçš„ç±»åˆ«è¯„è®º $z\\_{k}$ æ ¡å‡†å¹³å‡é¢„æµ‹æ¦‚ç‡ $q\u0026rsquo;\\{k}$ $$ q\\{k} = \\dfrac{p\\{k}}{c+z\\{k}},\\quad q\u0026rsquo;\\{k} = \\dfrac{q\\{k}}{\\sum q} $$ $L\\{MDR} = \\sum\\{k=1}^{K}q\u0026rsquo;\\{k}\\log q\u0026rsquo;\\{k}$ ï¼ˆé‡‡ç”¨è´Ÿç†µçš„å½¢å¼ï¼‰ Complete T-TIME Algorithm å…ˆé¢„æµ‹ï¼Œåå°å¹¶è¡Œåœ°æ›´æ–°æ¨¡å‹\nExperiment ä½¿ç”¨ä¸‰ä¸ªè¿åŠ¨æƒ³è±¡æ•°æ®é›†\næ¯æ¬¡æŠŠä¸€ä¸ªå—è¯•è€…çš„æ•°æ®ä½œä¸ºç›®æ ‡åŸŸï¼Œå…¶ä½™ä½œä¸ºæºåŸŸ\nClassification Accuracies on Balanced Classes è¿‡äºå¤æ‚çš„ç®—æ³•ç”±äºæ•°æ®ä¸è¶³ï¼Œæ€§èƒ½åè€Œä¸‹é™ åŸºäºç†µçš„æ–¹æ³•æ™®éè¡¨ç°è‰¯å¥½ï¼ŒMCC åœ¨ç¦»çº¿è¿ç§»å­¦ä¹ ä¸­è¡¨ç°æœ€å¥½ T-TIME åœ¨æ‰€æœ‰åœ¨çº¿è¿ç§»å­¦ä¹ ç®—æ³•ä¸­è¡¨ç°æœ€ä½³ï¼Œå¹¶ä¸”å…¶æ€§èƒ½ä¸è¡¨ç°æœ€ä½³çš„ç¦»çº¿è¿ç§»å­¦ä¹ æ–¹æ³•ç›¸å½“ Classification Performance Under Class-Imbalance ä½¿ç”¨éšæœºç§»é™¤æ•°æ®æ¥åˆ›å»ºä¸å¹³è¡¡æ•°æ®é›†\nä¼ ç»Ÿæ–¹æ³•è¡¨ç°è¾ƒå¼± T-TIME è¡¨ç°çªå‡º ","permalink":"https://diefish1024.github.io/posts/literature-notes/t-time/","summary":"\u003ch1 id=\"method\"\u003eMethod\u003c/h1\u003e\n\u003ch3 id=\"problem-set\"\u003eProblem Set\u003c/h3\u003e\n\u003cp\u003eEEG æ•°æ® ${ X\\\u003cem\u003e{s,l}^{i},y\\\u003c/em\u003e{s,l}^{i} }\\\u003cem\u003e{i=1}^{n\\\u003c/em\u003e{s,l}}$ ï¼Œè¿›è¡Œæ— ç›‘ç£åœ¨çº¿ K åˆ†ç±»\u003c/p\u003e\n\u003ch3 id=\"source-model-training\"\u003eSource Model Training\u003c/h3\u003e\n\u003cp\u003eå¯¹æºæ•°æ®åš Euclidean alignment (EA) æ•°æ®å¯¹é½ï¼Œå‡å°‘ä¸åŒä¸ªä½“ EEG ä¿¡å·å·®å¼‚\u003c/p\u003e\n\u003cp\u003eEA è®¡ç®—æ¯ä¸ªä¸ªä½“æ‰€æœ‰ EEG è¯•æ¬¡åæ–¹å·®çŸ©é˜µçš„ç®—æœ¯å¹³å‡å€¼\n$$\nR\\\u003cem\u003e{s,l} = \\dfrac{1}{n}\\sum\\\u003c/em\u003e{i=1}^{n} X\\\u003cem\u003e{i}(X\\\u003c/em\u003e{i})^{T} \\implies \\bar{X}\\\u003cem\u003e{i} = R\\\u003c/em\u003e{s,l}^{-1/2}X\\_{i}\n$$\nä¹‹åå†æ•´åˆç»è¿‡å¯¹é½çš„å—è¯•è€…æ•°æ®ï¼Œå½¢æˆâ€œæºåŸŸâ€\u003c/p\u003e\n\u003cp\u003eåœ¨æ•´åˆåçš„æ•°æ®ä¸Šç‹¬ç«‹è®­ç»ƒ $M$ ä¸ªæ¨¡å‹\u003c/p\u003e\n\u003ch3 id=\"incremental-ea-on-target-data\"\u003eIncremental EA on Target Data\u003c/h3\u003e\n\u003cp\u003eå¯¹æ–°æ•°æ®å¢é‡å¼æ›´æ–°åæ–¹å·®çŸ©é˜µï¼Œå†ç”¨æ–°çš„çŸ©é˜µæ›´æ–°æ‰€æœ‰æµ‹è¯•æ•°æ®\u003c/p\u003e\n\u003ch3 id=\"target-label-prediction\"\u003eTarget Label Prediction\u003c/h3\u003e\n\u003cp\u003eç”¨è®­ç»ƒå¥½çš„ $M$ æ¨¡å‹åˆå§‹åŒ–ç”¨äºé€‚åº”ç›®æ ‡åŸŸçš„ $M$ ä¸ª TTA æ¨¡å‹ $f\\_{m}$\u003c/p\u003e\n\u003cp\u003eæ–°çš„ $X\\\u003cem\u003e{a}$ ç»è¿‡ IEA è¢«å˜æ¢ä¸º $X\\\u003c/em\u003e{a}\u0026rsquo;$ åè¢«è¾“å…¥åˆ°æ¯ä¸ªæ¨¡å‹ $f\\\u003cem\u003e{m}$ ä¸­è¿›è¡Œåˆ†ç±»ï¼Œè¾“å‡ºæ¦‚ç‡å‘é‡ $f\\\u003c/em\u003e{m}(X\\_{a}\u0026rsquo;)$\u003c/p\u003e\n\u003cp\u003eä¹‹åç»“åˆè¿™ $M$ ä¸ªæ¦‚ç‡å‘é‡æ¥è·å¾—æœ€ç»ˆçš„é¢„æµ‹æ ‡ç­¾ $\\hat{y}\\_{a}$\u003c/p\u003e","title":"T-TIME"},{"content":"Setting Fully Test-Time Adaptation æ˜¯ä¸€ç§ç‹¬ç‰¹çš„æ¨¡å‹é€‚åº”è®¾å®šã€‚åœ¨æ­¤è®¾å®šä¸‹ï¼Œæ¨¡å‹ $f\\_\\theta(x)$ åœ¨è®­ç»ƒé˜¶æ®µå·²é€šè¿‡æºæ•°æ® $x^s$ å’Œæ ‡ç­¾ $y^s$ å®Œæˆè®­ç»ƒï¼Œè·å¾—å‚æ•° $\\theta$ã€‚ä½†åœ¨æµ‹è¯•é˜¶æ®µï¼Œæ¨¡å‹å°†é‡åˆ°ä¸æºæ•°æ®åˆ†å¸ƒä¸åŒçš„æ— æ ‡ç­¾ç›®æ ‡æ•°æ® $x^t$ã€‚\nFTT-Adaptation ä¸ä»¥ä¸‹æ–¹æ³•ä¸åŒï¼š\nFine-tuningï¼šéœ€è¦ç›®æ ‡æ ‡ç­¾è¿›è¡Œé‡æ–°è®­ç»ƒã€‚ Domain Adaptationï¼šéœ€è¦æºæ•°æ®å’Œç›®æ ‡æ•°æ®è¿›è¡Œè”åˆè®­ç»ƒã€‚ Test-Time Training (TTT)ï¼šéœ€è¦ä¿®æ”¹è®­ç»ƒè¿‡ç¨‹å¹¶å…±åŒä¼˜åŒ–æœ‰ç›‘ç£åŠè‡ªç›‘ç£æŸå¤±ã€‚ ç›¸æ¯”ä¹‹ä¸‹ï¼ŒFTT-Adaptation ä»…èƒ½åˆ©ç”¨é¢„è®­ç»ƒæ¨¡å‹ $f\\_\\theta$ å’Œæ— æ ‡ç­¾ç›®æ ‡æ•°æ® $x^t$ è¿›è¡Œé€‚åº”ï¼Œä¸ä¾èµ–æºæ•°æ®æˆ–é¢å¤–çš„ç›‘ç£ä¿¡æ¯ã€‚\nMethod è®ºæ–‡çš„æ ¸å¿ƒè´¡çŒ®æ˜¯æå‡ºäº† Tent æ–¹æ³•ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯é€šè¿‡æœ€å°åŒ–æµ‹è¯•ç†µï¼ˆTest Entropy Minimizationï¼‰æ¥é€‚åº”æ¨¡å‹é¢„æµ‹ï¼Œæ—¨åœ¨ä½¿æ¨¡å‹å¯¹æµ‹è¯•æ•°æ®çš„é¢„æµ‹ç»“æœæ›´â€œæœ‰ä¿¡å¿ƒâ€ã€‚\nEntropy Objective Tent çš„æµ‹è¯•æ—¶ç›®æ ‡å‡½æ•°æ˜¯æœ€å°åŒ–æ¨¡å‹é¢„æµ‹ $\\hat{y} = f\\_\\theta(x^t)$ çš„ç†µ $H(\\hat{y})$ã€‚è®ºæ–‡ä¸­ä½¿ç”¨çš„é¦™å†œç†µè®¡ç®—å…¬å¼å¦‚ä¸‹ï¼š\n$$ H(\\hat{y}) = - \\sum\\_c p(\\hat{y}\\_c) \\log p(\\hat{y}\\_c) $$\nå…¶ä¸­ï¼Œ $p(\\hat{y}\\_c)$ è¡¨ç¤ºæ¨¡å‹é¢„æµ‹ç›®æ ‡æ•°æ® $x^t$ å±äºç±»åˆ« $c$ çš„æ¦‚ç‡ã€‚\næœ€å°åŒ–ç†µä¿ƒä½¿æ¨¡å‹è¾“å‡ºæ›´â€œå°–é”â€æˆ–æ›´â€œç¡®å®šâ€çš„é¢„æµ‹åˆ†å¸ƒã€‚ ä¼˜åŠ¿ï¼šç†µæ˜¯ä¸€ç§æ— ç›‘ç£ç›®æ ‡ï¼Œä»…ä¾èµ–äºæ¨¡å‹é¢„æµ‹ï¼Œä¸éœ€è¦çœŸå®æ ‡ç­¾ã€‚æœ€å°åŒ–ç†µä¸å‡å°‘é¢„æµ‹è¯¯å·®å’Œæ•°æ®æ¼‚ç§»ä¹‹é—´å­˜åœ¨å†…åœ¨è”ç³»ï¼Œå› ä¸ºæ›´ç¡®å®šçš„é¢„æµ‹é€šå¸¸æ„å‘³ç€æ›´æ­£ç¡®çš„é¢„æµ‹ã€‚ Modulation Parameters Tent ä¸ç›´æ¥ä¿®æ”¹åŸå§‹æ¨¡å‹çš„å…¨éƒ¨å‚æ•° $\\theta$ã€‚ç›¸åï¼Œå®ƒä»…æ›´æ–°æ¨¡å‹å†…éƒ¨å½’ä¸€åŒ–å±‚ï¼ˆå¦‚Batch Normalization layersï¼‰ä¸­çš„çº¿æ€§ä¸”ä½ç»´åº¦çš„ä»¿å°„å˜æ¢å‚æ•°ï¼šå°ºåº¦å‚æ•° $\\gamma$ å’Œåç§»å‚æ•° $\\beta$ã€‚\nè¿™ä¸€é€‰æ‹©çš„ç†ç”±æ˜¯ï¼šè¿™äº›å‚æ•°åªå æ¨¡å‹æ€»å‚æ•°çš„æå°éƒ¨åˆ†ï¼ˆ\u0026lt;1%ï¼‰ï¼Œä¼˜åŒ–æ•ˆç‡é«˜ä¸”ç¨³å®šã€‚ ç‰¹å¾è°ƒåˆ¶è¿‡ç¨‹åŒ…å«ä¸¤ä¸ªæ­¥éª¤ï¼š 1.Normalization (æ ‡å‡†åŒ–)ï¼šæ ¹æ®å½“å‰æ‰¹æ¬¡æµ‹è¯•æ•°æ®çš„å‡å€¼ $\\mu$ å’Œæ ‡å‡†å·® $\\sigma$ æ¥æ ‡å‡†åŒ–ç‰¹å¾ $x$ï¼Œå³ $\\hat{x} = (x - \\mu)/\\sigma$ã€‚è¿™é‡Œçš„ $\\mu, \\sigma$ æ˜¯åœ¨æµ‹è¯•æ—¶ä»å½“å‰æ‰¹æ¬¡æ•°æ®ä¸­ä¼°è®¡çš„ã€‚ 2.Transformation (ä»¿å°„å˜æ¢)ï¼šå¯¹æ ‡å‡†åŒ–åçš„ç‰¹å¾ $\\hat{x}$ åº”ç”¨ä»¿å°„å˜æ¢ï¼Œå³ $x\u0026rsquo; = \\gamma \\hat{x} + \\beta$ã€‚å‚æ•° $\\gamma$ å’Œ $\\beta$ é€šè¿‡æœ€å°åŒ–ç†µç›®æ ‡å‡½æ•°è¿›è¡Œä¼˜åŒ–ã€‚ Algorithm Tent ç®—æ³•çš„æµç¨‹å¦‚ä¸‹ï¼š\nInitializationï¼š åŠ è½½é¢„è®­ç»ƒå¥½çš„æºæ¨¡å‹å‚æ•° $\\theta$ã€‚ å›ºå®šæ‰€æœ‰éä»¿å°„å˜æ¢çš„å‚æ•°ã€‚ ä¸¢å¼ƒæºæ•°æ®ä¸­ä¼°è®¡çš„å½’ä¸€åŒ–ç»Ÿè®¡é‡ã€‚ ä¼˜åŒ–å™¨æ”¶é›†æ‰€æœ‰å½’ä¸€åŒ–å±‚çš„é€šé“çº§ä»¿å°„å˜æ¢å‚æ•° ${\\gamma\\{l,k}, \\beta\\{l,k}}$ã€‚ Iterationï¼šåœ¨çº¿å¤„ç†æ•°æ®æ‰¹æ¬¡ã€‚ Forward Passï¼šå¯¹æ¯ä¸ªæ•°æ®æ‰¹æ¬¡ï¼Œé€å±‚ä¼°è®¡è¯¥æ‰¹æ¬¡æ•°æ®çš„å½’ä¸€åŒ–ç»Ÿè®¡é‡ ($\\mu, \\sigma$)ã€‚ Backward Passï¼šè®¡ç®—é¢„æµ‹ç†µ $H(\\hat{y})$ ç›¸å¯¹äºä»¿å°„å˜æ¢å‚æ•° $\\gamma, \\beta$ çš„æ¢¯åº¦ $\\nabla H(\\hat{y})$ã€‚ Updateï¼šä½¿ç”¨æ¢¯åº¦æ›´æ–° $\\gamma, \\beta$ å‚æ•°ã€‚Tent é‡‡ç”¨é«˜æ•ˆçš„åœ¨çº¿æ›´æ–°ç­–ç•¥ï¼Œæ¯æ¬¡æ›´æ–°åªå½±å“ä¸‹ä¸€ä¸ªæ‰¹æ¬¡çš„æ•°æ®å¤„ç†ã€‚ Terminationï¼šå¯¹äºåœ¨çº¿é€‚åº”ï¼Œé€‚åº”è¿‡ç¨‹åªè¦æœ‰æµ‹è¯•æ•°æ®å°±æŒç»­è¿›è¡Œã€‚å¯¹äºç¦»çº¿é€‚åº”ï¼Œæ¨¡å‹ä¼šå…ˆè¿›è¡Œæ›´æ–°ï¼Œç„¶åé‡å¤æ¨æ–­ï¼Œé€‚åº”å¯ä»¥æŒç»­å¤šä¸ªEpochsã€‚ Experiments è®ºæ–‡åœ¨å¤šç§è®¡ç®—æœºè§†è§‰ä»»åŠ¡å’Œæ•°æ®é›†ä¸Šå¯¹ Tent è¿›è¡Œäº†å…¨é¢è¯„ä¼°ã€‚\nRobustness To Corruptions åœ¨å›¾åƒåˆ†ç±»çš„é²æ£’æ€§åŸºå‡†æµ‹è¯•ä¸­ï¼Œä½¿ç”¨å—æŸç‰ˆæœ¬çš„ CIFAR-10/100-C å’Œ ImageNet-C æ•°æ®é›†ï¼ˆ15 ç§æŸåç±»å‹ï¼Œä¸åŒä¸¥é‡ç¨‹åº¦ï¼‰ã€‚\nä¸»è¦å‘ç°ï¼š Tent åœ¨ ImageNet-C ä¸Šè¾¾åˆ°äº† 44.0% çš„æœ€ä½é”™è¯¯ç‡ï¼Œä¼˜äº SOTA é²æ£’æ€§è®­ç»ƒæ–¹æ³•ï¼ˆå¦‚Adversarial Noise Training (ANT) çš„ 50.2%ï¼‰å’ŒTest-Time Normalization (BN) åŸºçº¿ï¼ˆ49.9%ï¼‰ã€‚ åœ¨ CIFAR-10/100-C ä¸Šï¼ŒTent ä¹Ÿæ˜¾è‘—ä¼˜äºå…¶ä»– TTA baselineï¼ˆBN, Pseudo-Labeling (PL)ï¼‰ä»¥åŠéœ€è¦è”åˆè®­ç»ƒæºåŸŸå’Œç›®æ ‡åŸŸçš„Domain Adaptationï¼ˆRG, UDA-SSï¼‰å’ŒTest-Time Training (TTT) æ–¹æ³•ã€‚ è¿™äº›æ”¹è¿›ä»…é€šè¿‡ä¸€æ¬¡Epochçš„æµ‹è¯•æ—¶ä¼˜åŒ–å®ç°ï¼Œä¸”æœªæ”¹å˜åŸå§‹æ¨¡å‹è®­ç»ƒã€‚ Source-Free Domain Adaptation è¯„ä¼° Tent åœ¨æ— æºåŸŸé€‚åº”åœºæ™¯ä¸‹çš„æ€§èƒ½ï¼ŒåŒ…æ‹¬æ•°å­—è¯†åˆ«ï¼ˆä» SVHN åˆ° MNIST/MNIST-M/USPSï¼‰å’Œè¯­ä¹‰åˆ†å‰²ï¼ˆä» GTA åˆ° Cityscapesï¼‰ã€‚\nä¸»è¦å‘ç°ï¼š åœ¨æ•°å­—è¯†åˆ«ä»»åŠ¡ä¸­ï¼ŒTent å¤§å¤šæ•°æƒ…å†µä¸‹é”™è¯¯ç‡ä½äºæºæ¨¡å‹å’ŒBNï¼Œéƒ¨åˆ†æƒ…å†µç”šè‡³ä¼˜äºéœ€è¦æºæ•°æ®çš„Domain Adaptationæ–¹æ³•ï¼ˆRG, UDA-SSï¼‰ã€‚ è¯­ä¹‰åˆ†å‰²ä»»åŠ¡ä¸­ï¼ŒTent å°†Intersection-Over-Union (IOU) åˆ†æ•°ä»æºæ¨¡å‹çš„ 28.8% æé«˜åˆ° 35.8%ï¼Œæ˜¾è‘—ä¼˜äº BN çš„ 31.4%ã€‚ Analysis è®ºæ–‡é€šè¿‡å¤šé¡¹åˆ†æå®éªŒæ¢ç©¶äº† Tent çš„å·¥ä½œåŸç†å’Œç‰¹æ€§ï¼š\nTent é™ä½ç†µå’Œè¯¯å·®ï¼šå®éªŒè¯å®ï¼ŒTent æˆåŠŸé™ä½äº†é¢„æµ‹çš„ç†µå€¼å’Œä»»åŠ¡æŸå¤±ï¼ˆå¦‚Softmax Cross-Entropyï¼‰ï¼Œå°è¯äº†ç†µæœ€å°åŒ–ä¸è¯¯å·®å‡å°‘ä¹‹é—´çš„æ­£ç›¸å…³æ€§ã€‚ Tent éœ€è¦ç‰¹å¾è°ƒåˆ¶ï¼šä¸æ›´æ–°å½’ä¸€åŒ–ç»Ÿè®¡é‡æˆ–ä¸ä¼˜åŒ–ä»¿å°„å˜æ¢å‚æ•°ä¼šæ˜¾è‘—é™ä½ Tent æ€§èƒ½ï¼Œè¯´æ˜è¿™äº›ç‰¹å¾è°ƒåˆ¶æ­¥éª¤å¯¹äºé€‚åº”ä¸å¯æˆ–ç¼ºã€‚ Tent æ³›åŒ–åˆ°ä¸åŒçš„ç›®æ ‡æ•°æ®ï¼šé€‚åº”è¿‡ç¨‹å¯¹æœªç”¨äºæ›´æ–°çš„å…¶ä»–æµ‹è¯•æ•°æ®ç‚¹åŒæ ·æœ‰æ•ˆï¼Œè¡¨æ˜å…¶å­¦ä¹ åˆ°çš„è°ƒåˆ¶æ˜¯é€šç”¨çš„ã€‚ Tent è°ƒåˆ¶ä¸å½’ä¸€åŒ–ä¸åŒï¼šå¯¹æ¯”åˆ†ææ˜¾ç¤ºï¼ŒTent çš„ç‰¹å¾è°ƒåˆ¶ä½¿ç‰¹å¾æ›´æ¥è¿‘åœ¨ç›®æ ‡æ ‡ç­¾ä¸Šä¼˜åŒ–çš„Oracleæ¨¡å‹ï¼ˆç†æƒ³æ¨¡å‹ï¼‰ï¼Œè€Œéä»…åƒBatch Normalizationé‚£æ ·æ¥è¿‘åŸå§‹å‚è€ƒåˆ†å¸ƒã€‚ Tent é€‚åº”å…¶ä»–ç½‘ç»œæ¶æ„ï¼šTent åœ¨åŸºäºSelf-Attention å’ŒEquilibrium Solving (MDEQ) çš„æ¨¡å‹ä¸Šä¹Ÿèƒ½æœ‰æ•ˆé™ä½è¯¯å·®ï¼Œå±•ç°äº†å…¶æ™®é€‚æ€§ã€‚ Related Work è®ºæ–‡å›é¡¾äº†ä¸ Tent ç›¸å…³çš„ç°æœ‰å·¥ä½œï¼š\nTrain-Time Adaptation æ–¹æ³•ï¼šä¼ ç»Ÿçš„Domain Adaptationã€Test-Time Training (TTT) ç­‰ï¼Œé€šå¸¸éœ€è¦æºæ•°æ®æˆ–è®­ç»ƒé˜¶æ®µä¿®æ”¹æ¨¡å‹ã€‚ Source-Free Adaptation æ–¹æ³•ï¼šè¿‘æœŸä¸€äº›ä¸ä¾èµ–æºæ•°æ®çš„æ–¹æ³•ï¼Œä½†é€šå¸¸éœ€è¦æ›´å¤æ‚çš„è®¾è®¡ã€ç¦»çº¿ä¼˜åŒ–æˆ–ä¿®æ”¹è®­ç»ƒè¿‡ç¨‹ã€‚Tent çš„ä¼˜åŠ¿åœ¨äºå…¶åœ¨çº¿ã€é«˜æ•ˆä¸”ä¸æ”¹å˜è®­ç»ƒè¿‡ç¨‹ã€‚ Entropy Minimizationï¼šç†µæœ€å°åŒ–å·²è¢«å¹¿æ³›ç”¨äºSemi-Supervised Learningå’ŒDomain Adaptationçš„æ­£åˆ™åŒ–é¡¹ï¼Œä½† Tent é¦–æ¬¡å°†å…¶ä½œä¸ºFully Test-Time Adaptationä¸­å”¯ä¸€çš„æ— ç›‘ç£æŸå¤±æ¥é©±åŠ¨æ¨¡å‹é€‚åº”ã€‚ Feature Modulationï¼šå½’ä¸€åŒ–å±‚å’Œä»¿å°„å˜æ¢å·²è¢«ç”¨äºå„ç§ä»»åŠ¡çš„ç‰¹å¾è°ƒåˆ¶ï¼Œä½† Tent å°†å…¶ä½œä¸ºåœ¨æµ‹è¯•æ—¶é€šè¿‡æ— ç›‘ç£ç›®æ ‡è¿›è¡Œä¼˜åŒ–çš„æ ¸å¿ƒæœºåˆ¶ã€‚ Discussion Tent é€šè¿‡Test Entropy Minimizationå®ç°äº†åœ¨æ•°æ®æ¼‚ç§»æƒ…å†µä¸‹çš„æ³›åŒ–è¯¯å·®é™ä½ã€‚å…¶æ ¸å¿ƒåœ¨äºæ¨¡å‹çš„è‡ªç›‘ç£è‡ªæˆ‘æ”¹è¿›ï¼Œå³ä¾æ®è‡ªèº«çš„é¢„æµ‹åé¦ˆè¿›è¡Œè°ƒæ•´ã€‚\nä¼˜åŠ¿æ€»ç»“ï¼š é«˜æ•ˆï¼šä»…é€šè¿‡åœ¨çº¿ä¼˜åŒ–å°‘æ•°å‚æ•°ï¼ˆ$\\gamma, \\beta$ï¼‰å®ç°ã€‚ å®ç”¨ï¼šæ— éœ€æºæ•°æ®è®¿é—®ï¼Œä¸æ”¹å˜æ¨¡å‹è®­ç»ƒè¿‡ç¨‹ã€‚ é€šç”¨ï¼šé€‚ç”¨äºå¤šç§æ•°æ®æ¼‚ç§»ç±»å‹å’Œä¸åŒç½‘ç»œæ¶æ„ã€‚ å°½ç®¡ Tent åœ¨å¹¿æ³›çš„åœºæ™¯ä¸­è¡¨ç°å‡ºè‰²ï¼Œä½†ä»å­˜åœ¨æŒ‘æˆ˜ï¼Œä¾‹å¦‚åœ¨ç‰¹å®šå›°éš¾çš„æ•°æ®æ¼‚ç§»ï¼ˆå¦‚ SVHN åˆ° MNIST-M/USPSï¼‰ä¸Šä»æœ‰æå‡ç©ºé—´ã€‚æœªæ¥ç ”ç©¶æ–¹å‘å¯æ¢ç´¢æ›´å…¨é¢çš„å‚æ•°è°ƒæ•´ã€æ›´é€šç”¨çš„Test-Time Adaptation Lossä»¥åŠè¿›ä¸€æ­¥æå‡æ•ˆç‡çš„æ–¹æ³•ã€‚æ€»è€Œè¨€ä¹‹ï¼ŒTent ä¸ºFully Test-Time Adaptation æä¾›äº†ä¸€ä¸ªåˆ›æ–°ä¸”å®ç”¨çš„èŒƒå¼ï¼Œä½¿å¾—æ¨¡å‹èƒ½å¤Ÿåœ¨éƒ¨ç½²åï¼Œåœ¨é¢å¯¹æœªçŸ¥ä¸”æ— æ ‡ç­¾çš„æµ‹è¯•æ•°æ®æ—¶ï¼Œå…·å¤‡å¼ºå¤§çš„è‡ªæˆ‘é€‚åº”èƒ½åŠ›ã€‚\n","permalink":"https://diefish1024.github.io/posts/literature-notes/tent/","summary":"\u003ch1 id=\"setting\"\u003eSetting\u003c/h1\u003e\n\u003cp\u003e\u003cstrong\u003eFully Test-Time Adaptation\u003c/strong\u003e æ˜¯ä¸€ç§ç‹¬ç‰¹çš„æ¨¡å‹é€‚åº”è®¾å®šã€‚åœ¨æ­¤è®¾å®šä¸‹ï¼Œæ¨¡å‹ $f\\_\\theta(x)$ åœ¨è®­ç»ƒé˜¶æ®µå·²é€šè¿‡æºæ•°æ® $x^s$ å’Œæ ‡ç­¾ $y^s$ å®Œæˆè®­ç»ƒï¼Œè·å¾—å‚æ•° $\\theta$ã€‚ä½†åœ¨æµ‹è¯•é˜¶æ®µï¼Œæ¨¡å‹å°†é‡åˆ°ä¸æºæ•°æ®åˆ†å¸ƒä¸åŒçš„æ— æ ‡ç­¾ç›®æ ‡æ•°æ® $x^t$ã€‚\u003c/p\u003e\n\u003cp\u003eFTT-Adaptation ä¸ä»¥ä¸‹æ–¹æ³•ä¸åŒï¼š\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eFine-tuning\u003c/strong\u003eï¼šéœ€è¦ç›®æ ‡æ ‡ç­¾è¿›è¡Œé‡æ–°è®­ç»ƒã€‚\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eDomain Adaptation\u003c/strong\u003eï¼šéœ€è¦æºæ•°æ®å’Œç›®æ ‡æ•°æ®è¿›è¡Œè”åˆè®­ç»ƒã€‚\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eTest-Time Training (TTT)\u003c/strong\u003eï¼šéœ€è¦ä¿®æ”¹è®­ç»ƒè¿‡ç¨‹å¹¶å…±åŒä¼˜åŒ–æœ‰ç›‘ç£åŠè‡ªç›‘ç£æŸå¤±ã€‚\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eç›¸æ¯”ä¹‹ä¸‹ï¼ŒFTT-Adaptation ä»…èƒ½åˆ©ç”¨é¢„è®­ç»ƒæ¨¡å‹ $f\\_\\theta$ å’Œæ— æ ‡ç­¾ç›®æ ‡æ•°æ® $x^t$ è¿›è¡Œé€‚åº”ï¼Œä¸ä¾èµ–æºæ•°æ®æˆ–é¢å¤–çš„ç›‘ç£ä¿¡æ¯ã€‚\u003c/p\u003e\n\u003ch2 id=\"method\"\u003eMethod\u003c/h2\u003e\n\u003cp\u003eè®ºæ–‡çš„æ ¸å¿ƒè´¡çŒ®æ˜¯æå‡ºäº† \u003cstrong\u003eTent\u003c/strong\u003e æ–¹æ³•ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯é€šè¿‡\u003cstrong\u003eæœ€å°åŒ–æµ‹è¯•ç†µ\u003c/strong\u003eï¼ˆ\u003cstrong\u003eTest Entropy Minimization\u003c/strong\u003eï¼‰æ¥é€‚åº”æ¨¡å‹é¢„æµ‹ï¼Œæ—¨åœ¨ä½¿æ¨¡å‹å¯¹æµ‹è¯•æ•°æ®çš„é¢„æµ‹ç»“æœæ›´â€œæœ‰ä¿¡å¿ƒâ€ã€‚\u003c/p\u003e\n\u003ch3 id=\"entropy-objective\"\u003eEntropy Objective\u003c/h3\u003e\n\u003cp\u003eTent çš„æµ‹è¯•æ—¶ç›®æ ‡å‡½æ•°æ˜¯æœ€å°åŒ–æ¨¡å‹é¢„æµ‹ $\\hat{y} = f\\_\\theta(x^t)$ çš„\u003cstrong\u003eç†µ $H(\\hat{y})$\u003c/strong\u003eã€‚è®ºæ–‡ä¸­ä½¿ç”¨çš„\u003cstrong\u003eé¦™å†œç†µ\u003c/strong\u003eè®¡ç®—å…¬å¼å¦‚ä¸‹ï¼š\u003c/p\u003e\n\u003cp\u003e$$\nH(\\hat{y}) = - \\sum\\_c p(\\hat{y}\\_c) \\log p(\\hat{y}\\_c)\n$$\u003c/p\u003e\n\u003cp\u003eå…¶ä¸­ï¼Œ $p(\\hat{y}\\_c)$ è¡¨ç¤ºæ¨¡å‹é¢„æµ‹ç›®æ ‡æ•°æ® $x^t$ å±äºç±»åˆ« $c$ çš„æ¦‚ç‡ã€‚\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eæœ€å°åŒ–ç†µä¿ƒä½¿æ¨¡å‹è¾“å‡ºæ›´â€œå°–é”â€æˆ–æ›´â€œç¡®å®šâ€çš„é¢„æµ‹åˆ†å¸ƒã€‚\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eä¼˜åŠ¿\u003c/strong\u003eï¼šç†µæ˜¯ä¸€ç§\u003cstrong\u003eæ— ç›‘ç£ç›®æ ‡\u003c/strong\u003eï¼Œä»…ä¾èµ–äºæ¨¡å‹é¢„æµ‹ï¼Œä¸éœ€è¦çœŸå®æ ‡ç­¾ã€‚æœ€å°åŒ–ç†µä¸å‡å°‘é¢„æµ‹è¯¯å·®å’Œæ•°æ®æ¼‚ç§»ä¹‹é—´å­˜åœ¨å†…åœ¨è”ç³»ï¼Œå› ä¸ºæ›´ç¡®å®šçš„é¢„æµ‹é€šå¸¸æ„å‘³ç€æ›´æ­£ç¡®çš„é¢„æµ‹ã€‚\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"modulation-parameters\"\u003eModulation Parameters\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003eTent\u003c/strong\u003e ä¸ç›´æ¥ä¿®æ”¹åŸå§‹æ¨¡å‹çš„å…¨éƒ¨å‚æ•° $\\theta$ã€‚ç›¸åï¼Œå®ƒä»…æ›´æ–°æ¨¡å‹å†…éƒ¨å½’ä¸€åŒ–å±‚ï¼ˆå¦‚\u003cstrong\u003eBatch Normalization layers\u003c/strong\u003eï¼‰ä¸­çš„çº¿æ€§ä¸”ä½ç»´åº¦çš„\u003cstrong\u003eä»¿å°„å˜æ¢\u003c/strong\u003eå‚æ•°ï¼šå°ºåº¦å‚æ•° $\\gamma$ å’Œåç§»å‚æ•° $\\beta$ã€‚\u003c/p\u003e","title":"Tent"}]