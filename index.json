[{"content":"同步和条件变量 互斥实现了原子性，但是无法实现确定性，也就是无法正确实现 \u0026ldquo;happens-before\u0026rdquo; 的关系\n因此需要引入条件变量来实现线程的同步，形成受控制的并发事件的发生顺序（可以用乐团指挥来类比），把一系列不确定的状态在某一个时间点同步到了一个确定的状态，将发散的并发程序状态 “收束”\n实现同步\n实现 $A\\to B$：\n1 2 3 4 5 6 7 A; can_proceed = true; (signal) while(!can_proceed); B // B: wait until the condition is satisfied 这样的思路大致正确，但是自选的循环有很大的性能问题，因此需要一个更加底层的机制来帮助实现这一点\n最理想的 API 是 wait_until(cond) ，但是过去为了简化设计，变成了\n条件不满足时等待：wait - 直接睡眠等待 条件满足时继续：signal/broadcast - 唤醒所有线程 （小时候的 scratch 编程其实已经有了这样的思想😂）\n在 c++ 代码中我们可以把条件放到 $\\lambda$ 表达式中：\n1 2 3 4 5 6 7 8 9 10 11 12 std::mutex mtx; std::condition_variable cv; void T_player() { std::unique_lock lk(mtx); cv.wait(lk, []{ return can_proceed; } ); cv.notify_all(); lk.unlock(); } 注意条件变量在等待时需要带着一把锁（需要确保检查和等待是原子操作）\n使用条件变量解决同步问题 大部分的同步问题都可以用经典的生产者 - 消费者问题归纳：\nProducer 和 Consumer 共享一个缓冲区，其中\nProducer 看到缓冲区有空位就会放入，否则等待 Consumer 看到缓冲区有数据就回去走，否则等待 显然一个对象的生产和消费必须满足 \u0026ldquo;happens-before\u0026rdquo; 的关系\n可以等价成打印匹配的括号，并且嵌套深度有上限（缓冲区的深度）\n处理这样的问题首先要想清楚程序继续执行的条件，比如生产的条件是 $d\u0026lt;n$ ，而消费的条件是 $d\u0026gt;0$ ，然后套入固定的模板代码即可：\n1 2 3 4 5 6 mutex_lock(lk); while (!cond) { // cond can be any calculate cond_wait(\u0026amp;cv, lk); } assert(cond); mutex_lock(lk); 1 2 3 4 mutex_lock(lk); cond = true cond_broadcast(\u0026amp;cv); //⚠️ mutex_unlock(lk); 注意：全局广播 cond_broadcast 不能被替换成单独唤醒一个线程 cond_signal ，在这里显然可能会导致所有进程都被锁住无法触发新的同步变量；并发编程很多看起来正确的地方都需要仔细思考\n遇到任何同步问题的核心都是同步条件是什么，比如括号打印可以拓展成打印 \u0026lt;\u0026gt;\u0026lt; 或者 \u0026gt;\u0026lt;\u0026gt; 两种形状，核心也是画出状态机，找到同步条件，再套入模板就解决了问题\n计算图与并发控制 并行计算的模型可以用一个 DAG 计算图去理解，任务之间存在依赖关系，通过拓扑排序的顺序去解决问题，相互不存在 \u0026ldquo;happens-before\u0026rdquo; 依赖关系的任务都可以并发解决\n为了优化效率，我们对计算任务的分配需要保证每个节点计算的消耗是远大于同步和锁的开销的，因此实际上可能是把很多个小的任务聚合成一个大的并发计算节点，交给一个线程去执行\n实现计算图有两种思路，第一种是朴素的为每个节点设置一个线程和条件变量\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 // The dependency edge is u-\u0026gt;v void T_u() { // calculate u mutex_lock(v-\u0026gt;lock); v-\u0026gt;num_done++; cond_signal(v-\u0026gt;cv); // it\u0026#39;s okay mutex_unlock(v-\u0026gt;lock); } void T_v() { mutex_lock(v-\u0026gt;lock); while (!(v-\u0026gt;num_done == v-\u0026gt;num_predecessors)){ cond_wait(v-\u0026gt;cv, v-\u0026gt;lock); } mutex_unlock(v-\u0026gt;lock); // calculate v } 但是这样实际会产生过多的线程，造成不必要的性能开销（比如产生了多余 CPU 的 core 数量的线程），实际上更优的办法是创建一个任务调度器线程 $T\\{\\text{scheduler}}$ 来专门控制产生 $T\\{\\text{worker}}$ ：\n1 2 3 4 5 6 7 8 9 10 11 12 13 mutex_lock(lk); while (!(all_done || has_job(tid))) { cond_wait(\u0026amp;worker_cv[tid], lk); } mutex_unlock(lk); if (all_done) { break; } else { process_job(tid); } signal(\u0026amp;sched_cv); ","permalink":"https://diefish1024.github.io/posts/nju-os-2025/15-%E5%B9%B6%E5%8F%91%E6%8E%A7%E5%88%B6%E5%90%8C%E6%AD%A5%E6%9D%A1%E4%BB%B6%E5%8F%98%E9%87%8F/","summary":"\u003ch2 id=\"同步和条件变量\"\u003e同步和条件变量\u003c/h2\u003e\n\u003cp\u003e互斥实现了\u003cstrong\u003e原子性\u003c/strong\u003e，但是无法实现\u003cstrong\u003e确定性\u003c/strong\u003e，也就是无法正确实现 \u0026ldquo;happens-before\u0026rdquo; 的关系\u003c/p\u003e\n\u003cp\u003e因此需要引入条件变量来实现线程的同步，形成受控制的并发事件的\u003cstrong\u003e发生顺序\u003c/strong\u003e（可以用乐团指挥来类比），把一系列不确定的状态在某一个时间点同步到了一个确定的状态，将发散的并发程序状态 “收束”\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e实现同步\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e实现 $A\\to B$：\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cdiv class=\"chroma\"\u003e\n\u003ctable class=\"lntable\"\u003e\u003ctr\u003e\u003ctd class=\"lntd\"\u003e\n\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode\u003e\u003cspan class=\"lnt\"\u003e1\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e2\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e3\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e4\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e5\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e6\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e7\n\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\n\u003ctd class=\"lntd\"\u003e\n\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-gdscript3\" data-lang=\"gdscript3\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003eA\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003ecan_proceed\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"bp\"\u003etrue\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"k\"\u003esignal\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"k\"\u003ewhile\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"o\"\u003e!\u003c/span\u003e\u003cspan class=\"n\"\u003ecan_proceed\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003eB\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"o\"\u003e//\u003c/span\u003e \u003cspan class=\"n\"\u003eB\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"n\"\u003ewait\u003c/span\u003e \u003cspan class=\"n\"\u003euntil\u003c/span\u003e \u003cspan class=\"n\"\u003ethe\u003c/span\u003e \u003cspan class=\"n\"\u003econdition\u003c/span\u003e \u003cspan class=\"n\"\u003eis\u003c/span\u003e \u003cspan class=\"n\"\u003esatisfied\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\u003c/tr\u003e\u003c/table\u003e\n\u003c/div\u003e\n\u003c/div\u003e\u003cp\u003e这样的思路大致正确，但是自选的循环有很大的性能问题，因此需要一个更加底层的机制来帮助实现这一点\u003c/p\u003e\n\u003cp\u003e最理想的 API 是 \u003ccode\u003ewait_until(cond)\u003c/code\u003e ，但是过去为了简化设计，变成了\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e条件不满足时等待：\u003ccode\u003ewait\u003c/code\u003e - 直接睡眠等待\u003c/li\u003e\n\u003cli\u003e条件满足时继续：\u003ccode\u003esignal/broadcast\u003c/code\u003e - 唤醒所有线程\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e（小时候的 scratch 编程其实已经有了这样的思想😂）\u003c/p\u003e\n\u003cp\u003e在 c++ 代码中我们可以把条件放到 $\\lambda$ 表达式中：\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cdiv class=\"chroma\"\u003e\n\u003ctable class=\"lntable\"\u003e\u003ctr\u003e\u003ctd class=\"lntd\"\u003e\n\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode\u003e\u003cspan class=\"lnt\"\u003e 1\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 2\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 3\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 4\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 5\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 6\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 7\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 8\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 9\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e10\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e11\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e12\n\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\n\u003ctd class=\"lntd\"\u003e\n\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-c++\" data-lang=\"c++\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003estd\u003c/span\u003e\u003cspan class=\"o\"\u003e::\u003c/span\u003e\u003cspan class=\"n\"\u003emutex\u003c/span\u003e \u003cspan class=\"n\"\u003emtx\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003estd\u003c/span\u003e\u003cspan class=\"o\"\u003e::\u003c/span\u003e\u003cspan class=\"n\"\u003econdition_variable\u003c/span\u003e \u003cspan class=\"n\"\u003ecv\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"kt\"\u003evoid\u003c/span\u003e \u003cspan class=\"nf\"\u003eT_player\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\t\u003cspan class=\"n\"\u003estd\u003c/span\u003e\u003cspan class=\"o\"\u003e::\u003c/span\u003e\u003cspan class=\"n\"\u003eunique_lock\u003c/span\u003e \u003cspan class=\"n\"\u003elk\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003emtx\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\t\u003cspan class=\"n\"\u003ecv\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ewait\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003elk\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\t\t\u003cspan class=\"p\"\u003e[]{\u003c/span\u003e \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"n\"\u003ecan_proceed\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e \u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\t\u003cspan class=\"p\"\u003e);\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\t\u003cspan class=\"n\"\u003ecv\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003enotify_all\u003c/span\u003e\u003cspan class=\"p\"\u003e();\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\t\u003cspan class=\"n\"\u003elk\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eunlock\u003c/span\u003e\u003cspan class=\"p\"\u003e();\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\u003c/tr\u003e\u003c/table\u003e\n\u003c/div\u003e\n\u003c/div\u003e\u003cp\u003e注意条件变量在等待时需要带着一把锁（需要确保检查和等待是原子操作）\u003c/p\u003e","title":"15. 并发控制：同步条件变量"},{"content":"Introduction 类似 GAN 的对抗训练思想\nDomain Adaptation 给定源域 $D\\{S}$ （有标签）和目标域 $D\\{T}$ （无标签），目标是训练一个分类器 $\\eta: X\\to Y$ 使其在目标域上的目标风险 $$ R\\{D\\{T}}(\\eta) = \\underset{(\\mathbf{x},y)\\sim D\\_{T}}{\\mathrm{Pr}}(\\eta(\\mathbf{x}) \\neq y) $$ 最小\nDomain Divergence 需要量化两个领域的“相似度”，从而引出了 H- 散度 的概念： $$ d\\_{\\mathcal{H}}(D\\S, D\\T) = 2 \\sup\\{\\eta \\in \\mathcal{H}} \\left| \\Pr\\{x \\sim D\\S}[\\eta(x) = 1] - \\Pr\\{x \\sim D\\_T}[\\eta(x) = 1] \\right| $$ 含义是最优的分类器将目标域和源域判定为 1 的可能性之差，当 H- 散度非常小时，说明两个领域很难被区分，也就说明学习的特征实现了领域不变性的效果\n由于理论 H 散度是理想数据分布上的定义，实际中只有有限的样本集 $S$ 和 $T$ ，因此需要一定的近似，于是需要经验 H- 散度 $$ \\hat{d}\\{\\mathcal{H}}(S, T) = 2 \\left(1 - \\min\\{\\eta \\in \\mathcal{H}} \\left[ \\dfrac{1}{n}\\sum\\_{i=1}^n \\mathcal{I}[\\eta(x\\i) = 0] + \\dfrac{1}{n\u0026rsquo;}\\sum\\{i=n+1}^N \\mathcal{I}[\\eta(x\\_i) = 1] \\right] \\right) $$ 其中 $\\mathcal{I}[\\cdot]$ 表示条件为真时为 1，否则为 0\nProxy Distance 经验 H- 散度也需要直接遍历所有的 $\\eta$ ，在计算上不现实，需要一个进一步的近似方法，因此考虑 Proxy A-distance (PAD)\n构造用于领域分类的数据集 $$ U = { (\\mathbf{x}\\{i},0) }\\{i=1}^{n} \\cup { (\\mathbf{x}\\{i},1) }\\{i=n+1}^{N} $$ 用这个数据集训练分类器，设 $\\epsilon$ 为在数据集 $U$ 上训练出的最优领域分类器所达到的最小错误率，那么可以用 $$ \\hat{d}\\_{\\mathcal{A}} = 2(1-2\\epsilon) $$ 来近似 H- 散度\nGeneralization Bound on the Target Risk 有效性证明\n理论研究说明模型的目标风险可以通过源风险和两个领域的散度来限制，主要思想是 $$ R\\_{D\\T}(\\eta) \\le R\\S(\\eta) + \\text{Domain Divergence Terms} + \\text{Complexity Terms} + \\beta $$ 其中 $\\text{Domain Divergence Terms}\\approx d\\{\\mathcal{H}}(S, T)$ ，可以用上面的 $\\hat{d}\\{\\mathcal{A}}$ 近似；$\\text{Complexity Terms}$ 是一个比较小的常数项，和模型本身训练有关（原公式没看懂。。）；$\\beta$ 是一个理想化的项，表示最好情况下在目标域和源域上同时取得的最低错误率\nDANN 优化目标： $$ E(\\theta\\_f, \\theta\\_y, \\theta\\d) = \\frac{1}{n} \\sum\\{i=1}^n \\mathcal{L}\\_y(\\theta\\_f, \\theta\\y) - \\lambda \\left( \\frac{1}{n} \\sum\\{i=1}^n \\mathcal{L}\\_d(\\theta\\_f, \\theta\\d) + \\frac{1}{n\u0026rsquo;} \\sum\\{i=n+1}^N \\mathcal{L}\\_d(\\theta\\_f, \\theta\\_d) \\right) $$ 核心是 Saddle Point Problem ，找到需要找到鞍点而非最小值\n如何实现对抗：\n标签预测参数： $$ \\theta\\{y} \\leftarrow \\theta\\{y} - \\mu \\dfrac{ \\partial \\mathcal{L}\\{y} }{ \\partial \\theta\\{y} } $$ 领域分类参数： $$ \\theta\\{d} \\leftarrow \\theta\\{d} - \\mu \\lambda \\dfrac{ \\partial \\mathcal{L}\\{d} }{ \\partial \\theta\\{d} } $$ 特征提取参数： $$ \\theta\\{f} \\leftarrow \\theta\\{f} - \\mu\\left( \\dfrac{ \\partial \\mathcal{L}\\{y} }{ \\partial \\theta\\{f} } - \\lambda \\dfrac{ \\partial \\mathcal{L}\\{d} }{ \\partial \\theta\\{f} } \\right) $$ 核心需要最大化 $\\mathcal{L}\\_{d}$ ，因此需要沿着梯度的正向优化 Gradient Reversal Layer (GRL) 是实现对抗的核心组件，具体原理是在前向传播时表现为 $R(x)=x$ ，但是反向传播时 $\\dfrac{\\mathrm{d} R}{\\mathrm{d}x}=-I$ ，这样可以直接利用内置的自动微分优雅实现对抗\n","permalink":"https://diefish1024.github.io/posts/literature-notes/dann/","summary":"\u003ch2 id=\"introduction\"\u003eIntroduction\u003c/h2\u003e\n\u003cp\u003e类似 GAN 的对抗训练思想\u003c/p\u003e\n\u003ch2 id=\"domain-adaptation\"\u003eDomain Adaptation\u003c/h2\u003e\n\u003cp\u003e给定源域 $D\\\u003cem\u003e{S}$ （有标签）和目标域 $D\\\u003c/em\u003e{T}$ （无标签），目标是训练一个分类器 $\\eta: X\\to Y$ 使其在目标域上的目标风险\n$$\nR\\\u003cem\u003e{D\\\u003c/em\u003e{T}}(\\eta) = \\underset{(\\mathbf{x},y)\\sim D\\_{T}}{\\mathrm{Pr}}(\\eta(\\mathbf{x}) \\neq y)\n$$\n最小\u003c/p\u003e\n\u003ch4 id=\"domain-divergence\"\u003eDomain Divergence\u003c/h4\u003e\n\u003cp\u003e需要量化两个领域的“相似度”，从而引出了 \u003cstrong\u003eH- 散度\u003c/strong\u003e 的概念：\n$$\nd\\_{\\mathcal{H}}(D\\\u003cem\u003eS, D\\\u003cem\u003eT) = 2 \\sup\\\u003c/em\u003e{\\eta \\in \\mathcal{H}} \\left| \\Pr\\\u003c/em\u003e{x \\sim D\\\u003cem\u003eS}[\\eta(x) = 1] - \\Pr\\\u003c/em\u003e{x \\sim D\\_T}[\\eta(x) = 1] \\right|\n$$\n含义是最优的分类器将目标域和源域判定为 1 的可能性之差，当 H- 散度非常小时，说明两个领域很难被区分，也就说明学习的特征实现了领域不变性的效果\u003c/p\u003e\n\u003cp\u003e由于理论 H 散度是理想数据分布上的定义，实际中只有有限的样本集 $S$ 和 $T$ ，因此需要一定的近似，于是需要经验 H- 散度\n$$\n\\hat{d}\\\u003cem\u003e{\\mathcal{H}}(S, T) = 2 \\left(1 - \\min\\\u003c/em\u003e{\\eta \\in \\mathcal{H}} \\left[ \\dfrac{1}{n}\\sum\\_{i=1}^n \\mathcal{I}[\\eta(x\\\u003cem\u003ei) = 0] + \\dfrac{1}{n\u0026rsquo;}\\sum\\\u003c/em\u003e{i=n+1}^N \\mathcal{I}[\\eta(x\\_i) = 1] \\right] \\right)\n$$\n其中 $\\mathcal{I}[\\cdot]$ 表示条件为真时为 1，否则为 0\u003c/p\u003e","title":"DANN"},{"content":"推理效率对于 llm 是一个至关重要的问题。当模型生成文本时，尤其是以自回归方式逐词生成时，效率瓶颈会变得非常明显。KV Cache 就是为了解决这一问题而诞生的技术。\n1. What is KV Cache? KV Cache，全称 Key-Value Cache，是一种优化技术，用于加速 Transformer 架构在自回归生成过程中的推理速度。它的核心思想是缓存并重用在注意力机制中计算得到的 Key (K) 和 Value (V) 向量。\n2. Transformer Attention Mechanism Review 要理解 KV Cache，首先需要对 Transformer 架构中的自注意力机制有一个基本认识。自注意力机制允许模型在处理序列中的某个词时，考虑序列中所有其他词的重要性。\n每个输入 token（词或子词）在进入注意力层时，都会被转换成三个不同的向量：\nQ 向量：代表当前 token 的“查询”信息 K 向量：代表所有 token 的“键”信息，用于与 Query 进行匹配 V 向量：代表所有 token 的“值”信息，用于加权求和，得到最终的输出 自注意力机制的计算过程为以下步骤：\n计算 Query 与所有 Key 的点积，得到注意力分数 将注意力分数进行缩放，除以 $\\sqrt{d\\_k}$（$d\\_k$ 是 Key 向量的维度) 对缩放后的分数进行 Softmax，将其转换为注意力权重，表示每个 token 对当前 token 的重要性 将注意力权重与 Value 向量进行加权求和，得到当前 token 的注意力输出 公式为： $$ \\text{Attention}(Q, K, V) = \\text{softmax}\\left(\\frac{QK^T}{\\sqrt{d\\_k}}\\right)V $$ 其中矩阵 $Q,K,V \\in \\mathbb{R}^{L \\times d}$ ，$L$ 为当前上下文长度\n（处于简洁性的考虑，忽略了 Causal Mask ，实际上 $QK^{T}$ 应该 Mask 成下三角矩阵来强制不能看到序列未来的信息）\n3. The Problem KV Cache Solves 在大型语言模型中，当模型以自回归方式生成文本时（每次生成一个新 token，并将其添加到输入序列中，然后根据整个序列生成下一个 token），会遇到一个效率问题：\n假设我们要生成“中华人民”\n输入：“中” 模型计算“中”的 $Q, K, V$ 计算 attention ，生成“华” 输入：“中华” 模型再次计算“中”和“华”的 $Q, K, V$ 计算 attention ，生成“人” 输入：“中华人” 模型再次计算“中”、“华”和“人”的 $Q, K, V$ 计算 attention ，生成“民” 可以看到，在每一步生成新 token 时，都需要重新计算之前已经处理过的所有 token 的 $K$ 和 $V$ 向量。这种重复计算在序列较长时会消耗大量的计算资源和时间，效率低下。\n4. How KV Cache Works 根据上面分析得到的问题，很容易想到 KV Cache 的核心思想：将已经计算过的 Key 和 Value 向量缓存起来，在后续的生成步骤中直接重用，而不是重新计算。\n以生成“中华人民”为例，使用 KV Cache 的流程如下：\n输入：“中” 计算“中”的 $K\\_1, V\\_1$ 将 $K\\_1, V\\_1$ 存入 KV Cache 使用 $Q\\_1, K\\_1, V\\_1$ 计算 attention ，生成“华” 输入：“华”（当前 token 只有“华”，但注意力要关注整个序列“中华”） 计算“华”的 $K\\_2, V\\_2$ 将 $K\\_2, V\\_2$ 添加到 KV Cache。此时 KV Cache 包含 $[K\\_1, K\\_2]$ 和 $[V\\_1, V\\_2]$ 使用当前 $Q\\_2$ 和缓存中的 $[K\\_1, K\\_2], [V\\_1, V\\_2]$ 计算 attention ，生成“人” 输入：“人” 计算“人”的 $K\\_3, V\\_3$ 将 $K\\_3, V\\_3$ 添加到 KV Cache。此时 KV Cache 包含 $[K\\_1, K\\_2, K\\_3]$ 和 $[V\\_1, V\\_2, V\\_3]$ 使用当前 $Q\\_3$ 和缓存中的 $[K\\_1, K\\_2, K\\_3], [V\\_1, V\\_2, V\\_3]$ 计算 attention ，生成“民” 通过这种方式，每一步只需要计算当前新生成 token 的 $K, V$ 向量，而无需重新计算之前所有 token 的 $K, V$。\n5. Why Not QKV Cache? 可能会好奇，既然 K 和 V 都需要缓存，为什么不也缓存 Q 呢？也就是说，为什么是 KV Cache 而不是 QKV Cache？\n原因在于 Q 向量的性质：\nQ 向量是用来“查询”当前 token 与序列中其他 token 的相关性的。在自回归生成过程中，每一步生成一个新的 token，这个新 token 对应的 Query 向量是新的，它基于当前步的隐藏状态计算得出。换句话说，每次生成新 token 时，其对应的 $Q$ 向量都是独一无二的，并且需要重新计算以反映最新的生成上下文。 K 和 V 向量则代表了序列中每个 token 的“内容”信息。对于已经处理过的 token，它们的 $K$ 和 $V$ 向量一旦计算出来，其内容信息就是固定不变的。因此，这些 $K$ 和 $V$ 向量可以直接被缓存并反复使用，而无需重新计算。 因此，不缓存 Q 是因为它在每一步都是一个新的计算结果；而缓存 K 和 V 则可以显著减少重复计算，从而提高效率。\n6. KV Cache in Attention Mechanism 在数学上，当使用 KV Cache 进行自回归解码时，注意力公式中的 $K$ 和 $V$ 矩阵会随着生成过程的进行而不断增长。\n假设我们正在生成第 $t$ 个 token。\n当前 token 的 Q 向量是 $Q\\_t$ ，这是一个行向量，代表当前第 $t$ 个 token 的 Query ，维度为 $1 \\times d\\_k$ K 矩阵 $K\\{\\text{cached}}$ 将包含从第一个 token 到第 $t$ 个 token 的所有 K 向量： $K\\{\\text{cached}} = [K\\_1^T, K\\_2^T, \\dots, K\\_t^T]^T$ ，维度为 $t \\times d\\_k$ V 矩阵 $V\\{\\text{cached}}$ 将包含从第一个 token 到第 $t$ 个 token 的所有 V 向量： $V\\{\\text{cached}} = [V\\_1^T, V\\_2^T, \\dots, V\\_t^T]^T$ 。其维度为 $t \\times d\\_v$ 那么，第 $t$ 个 token 的注意力计算变为： $$ \\text{Attention}\\{t}(Q\\t, K\\{\\text{cached}}, V\\{\\text{cached}}) = \\text{softmax}\\left(\\frac{Q\\t K\\{\\text{cached}}^T}{\\sqrt{d\\k}}\\right)V\\{\\text{cached}} $$ 其中\n$Q\\t K\\{\\text{cached}}^T$ 是一个 $1 \\times t$ 的行向量，代表当前 Query 与所有历史 Key 的相关性分数 $\\text{softmax}$ 操作将这个 $1 \\times t$ 的向量转化为注意力权重 这个 $1 \\times t$ 的注意力权重向量再与 $V\\_{\\text{cached}}$ 矩阵（维度 $t \\times d\\_v$）相乘，得到最终的注意力输出，维度是 $1 \\times d\\_v$ 每次生成新的 token $t+1$ 时，我们只需要计算新的 $Q\\{t+1}$，将新计算的 $K\\{t+1}$ 和 $V\\{t+1}$ 拼接到 $K\\{\\text{cached}}$ 和 $V\\{\\text{cached}}$ 末尾，形成 $K\u0026rsquo;\\{\\text{cached}} = \\text{concat}(K\\{\\text{cached}}, K\\{t+1})$ 和 $V\u0026rsquo;\\{\\text{cached}} = \\text{concat}(V\\{\\text{cached}}, V\\_{t+1})$\n7. Limitations and Considerations 尽管 KV Cache 带来了巨大的性能提升，但也存在一些问题：\n内存占用：KV Cache 需要存储所有已处理 token 的 Key 和 Value 向量。对于大型模型和长上下文序列，这些缓存可能非常大，导致显存（GPU Memory）成为瓶颈。 上下文长度限制：由于内存限制，KV Cache 会限制模型能够处理的最大上下文长度。一旦达到内存上限，就需要采取策略来管理缓存，例如丢弃最早的 Key/Value 对（类似于循环缓冲区），但这可能会影响模型对长距离依赖的理解。 Summary KV Cache 是 Transformer 模型在自回归推理过程中非常重要的一种优化技术。通过缓存并重用已经计算过的 Key 和 Value 向量，它极大地减少了重复计算，从而显著提升了大型语言模型的生成速度。\nReferences KV Cache 原理讲解 （Bilibili） 注意：此视频内容存在部分错误 看图学KV Cache（知乎） 为什么没有Q Cache（知乎） ","permalink":"https://diefish1024.github.io/posts/ai-infra/kv-cache-%E5%85%A5%E9%97%A8/","summary":"\u003cp\u003e推理效率对于 llm 是一个至关重要的问题。当模型生成文本时，尤其是以自回归方式逐词生成时，效率瓶颈会变得非常明显。KV Cache 就是为了解决这一问题而诞生的技术。\u003c/p\u003e\n\u003ch3 id=\"1-what-is-kv-cache\"\u003e1. What is KV Cache?\u003c/h3\u003e\n\u003cp\u003eKV Cache，全称 \u003cstrong\u003eKey-Value Cache\u003c/strong\u003e，是一种优化技术，用于加速 Transformer 架构在自回归生成过程中的推理速度。它的核心思想是\u003cstrong\u003e缓存\u003c/strong\u003e并\u003cstrong\u003e重用\u003c/strong\u003e在注意力机制中计算得到的 \u003cstrong\u003eKey (K)\u003c/strong\u003e 和 \u003cstrong\u003eValue (V)\u003c/strong\u003e 向量。\u003c/p\u003e\n\u003ch3 id=\"2-transformer-attention-mechanism-review\"\u003e2. Transformer Attention Mechanism Review\u003c/h3\u003e\n\u003cp\u003e要理解 KV Cache，首先需要对 Transformer 架构中的自注意力机制有一个基本认识。自注意力机制允许模型在处理序列中的某个词时，考虑序列中所有其他词的重要性。\u003c/p\u003e\n\u003cp\u003e每个输入 token（词或子词）在进入注意力层时，都会被转换成三个不同的向量：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eQ 向量：代表当前 token 的“查询”信息\u003c/li\u003e\n\u003cli\u003eK 向量：代表所有 token 的“键”信息，用于与 Query 进行匹配\u003c/li\u003e\n\u003cli\u003eV 向量：代表所有 token 的“值”信息，用于加权求和，得到最终的输出\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e自注意力机制的计算过程为以下步骤：\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e计算 Query 与所有 Key 的点积，得到\u003cstrong\u003e注意力分数\u003c/strong\u003e\u003c/li\u003e\n\u003cli\u003e将注意力分数进行缩放，除以 $\\sqrt{d\\_k}$（$d\\_k$ 是 Key 向量的维度)\u003c/li\u003e\n\u003cli\u003e对缩放后的分数进行 Softmax，将其转换为\u003cstrong\u003e注意力权重\u003c/strong\u003e，表示每个 token 对当前 token 的重要性\u003c/li\u003e\n\u003cli\u003e将注意力权重与 Value 向量进行加权求和，得到当前 token 的注意力输出\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e公式为：\n$$\n\\text{Attention}(Q, K, V) = \\text{softmax}\\left(\\frac{QK^T}{\\sqrt{d\\_k}}\\right)V\n$$\n其中矩阵 $Q,K,V \\in \\mathbb{R}^{L \\times d}$ ，$L$ 为当前上下文长度\u003c/p\u003e","title":"KV Cache 入门"},{"content":"Introduction TTA 在回归任务上的局限：为分类任务设计，一般基于熵最小化和特征对齐；熵最小化不适用，回归模型产生单一值，不产生概率分布；简单特征对齐对回归模型效果不佳，可能反而会稀释需要学习的特征\nProblem Setting 考虑一个回归模型 $f\\\\theta: \\mathcal{X} \\to \\mathbb{R}$，可以进一步分解为特征提取器 $g\\\\phi: \\mathcal{X} \\to \\mathbb{R}^D$（从输入 $\\mathcal{X}$ 提取 $D$ 维特征 $z$）和线性回归器 $h\\\\psi(z) = w^T z + b$（或者 $h\\{\\psi}(z)=Wz+b$）\n$f\\_\\theta$ 首先在一个有标签的源数据集 $S = {(x\\_i, y\\i)}\\{i=1}^{N\\_s}$ 上进行预训练，数据从源域分布 $p\\_s$ 中采样\n目标是使用一个无标签的目标数据集 $T = {x\\j}\\{j=1}^{N\\t}$ 来适应预训练好的模型 $f\\\\theta$ 到目标域\n我们假设存在 covariate shift ，这意味着：\n输入数据的分布在源域和目标域之间是不同的：$p\\_s(x) \\neq p\\_t(x)$ 但给定输入后，输出的条件分布是相同的：$p\\_s(y|x) = p\\_t(y|x)$ Test-time Adaptation for Regression Basic Idea: Feature Alignment 朴素实现：\n计算源域特征统计量：在源域训练后，计算源域特征的均值 $\\mu^s$ 和元素级方差 $\\sigma^{s2}$ $$ \\mu^s = \\frac{1}{N\\s} \\sum\\{i=1}^{N\\_s} z\\_i^s, \\quad \\sigma^{s2} = \\frac{1}{N\\s} \\sum\\{i=1}^{N\\_s} (z\\_i^s - \\mu^s) \\odot (z\\_i^s - \\mu^s) \\quad \\text{(1)} $$ 其中 $z\\i^s = g\\\\phi(x\\_i)$ 是源特征，$N\\_s$ 是源数据样本数，$\\odot$ 表示元素级乘积\n目标域特征统计量：在目标域，对每个迷你批次（mini-batch）$B = {x\\j}\\{j=1}^{N\\_B}$，计算其特征均值 $\\hat{\\mu}^t$ 和方差 $\\hat{\\sigma}^{t2}$，计算方式与公式 (1) 类似\n对齐损失函数：使用 KL 散度来衡量两个对角高斯分布 $N(\\mu^s, \\sigma^{s2})$ 和 $N(\\hat{\\mu}^t, \\hat{\\sigma}^{t2})$ 之间的差异，并最小化该差异。 $$ L\\{TTA} (\\phi) = \\frac{1}{2} \\sum\\{d=1}^D \\left{ D\\{KL} (N(\\mu^s\\d, \\sigma^s\\{d}{}^2)||N(\\hat{\\mu}^t\\d, \\hat{\\sigma}^t\\{d}{}^2)) + D\\{KL} (N(\\hat{\\mu}^t\\d, \\hat{\\sigma}^t\\{d}{}^2)||N(\\mu^s\\d, \\sigma^s\\{d}{}^2)) \\right} \\quad \\text{(2)} $$ 这里的 $d$ 表示向量的第 $d$ 个元素。之所以使用双向的 KL 散度，是为了经验上获得更好的结果\n一维高斯 KL 散度公式： $$ D\\_{KL} (N(\\mu\\_1, \\sigma\\_1^2)||N(\\mu\\_2, \\sigma\\_2^2)) = \\dfrac{\\left[ \\log(\\sigma\\_2^2/\\sigma\\_1^2) + \\dfrac{(\\mu\\_1 - \\mu\\_2)^2 + \\sigma\\_1^2}{\\sigma\\_2^2} - 1 \\right]}{2} \\quad \\text{(3)} $$\n朴素对齐的问题：\n回归模型特征倾向于分布在一个小型的子空间中，许多特征维度方差为零或接近零 公式 (3) 中涉及到方差在分母上，使得这种朴素对齐在面对零方差维度时变得不稳定 对所有维度“一视同仁”地对齐不适用于回归任务的特性，因为许多维度对最终输出影响很小 Significant-subspace Alignment SSA 的三个步骤：\n子空间检测 (Subspace detection)：\n在源数据集 $S$ 上进行训练后，检测源特征分布所在的子空间。不计算每个维度的方差，而是计算协方差矩阵： $$ \\Sigma^s = \\frac{1}{N\\s} \\sum\\{i=1}^{N\\_s} (z\\_i^s - \\mu^s) (z\\_i^s - \\mu^s)^T \\quad \\text{(4)} $$ 其中 $\\mu^s$ 是源特征的均值向量（同理 (1)） 基于 PCA 的思想，通过对 $\\Sigma^s$ 进行特征分解，得到特征向量 $v\\_d^s$ 和对应的特征值 $\\lambda\\_d^s$ 选取前 K 个最大的特征值 $\\lambda\\_1^s, \\dots, \\lambda\\_K^s$ 及其对应的源基向量 $v\\_1^s, \\dots, v\\_K^s$ 来定义源子空间，这些基向量张成的子空间代表了源特征数据最有代表性和最重要的变化方向 维度加权 (Dimension weighting)：\n考虑到回归模型 $h\\_\\psi(z)=w^T z + b$，子空间维度 $v\\_d^s$ 对最终输出的影响由 $w^T v\\_d^s$ 决定（即特征向量与回归器权重向量的点积） 为了优先对齐那些对输出影响更大的子空间维度，为每个子空间维度 $d$ 定义权重 $a\\_d$： $$ a\\_d = 1 + |w^T v\\_d^s| \\quad \\text{(5)} $$ 这个权重 $a\\_d$ 会在对应的子空间基方向对输出有较大影响时值更大（最小为 1）。 特征对齐 (Feature alignment)：\n这一步在目标域进行。对于目标域的迷你批次 $B$，首先将目标特征 $z^t = g\\_\\phi(x^t)$ 投影到源子空间。 $$ \\tilde{z}^t = V\\_s^T (z^t - \\mu^s) \\quad \\text{(6)} $$ 其中 $V\\_s = [v\\_1^s, \\dots, v\\_K^s] \\in \\mathbb{R}^{D \\times K}$ 是由前 K 个源基向量构成的矩阵，$\\tilde{z}^t \\in \\mathbb{R}^K$ 是投影后的目标特征。 然后，计算投影后目标特征的迷你批次均值 $\\tilde{\\mu}^t$ 和方差 $\\tilde{\\sigma}^{t2}$ （同理公式 (1) ） 最后，使用结合子空间检测和维度加权的新损失函数来最小化目标特征分布与源特征分布在子空间中的差异。源域投影后的均值是 0，方差是其特征值 $\\Lambda^s = [\\lambda\\1^s, \\dots, \\lambda\\K^s]$。 $$ \\begin{align}L\\{TTA}(\\phi) = \u0026amp; \\frac{1}{2} \\sum\\{d=1}^K a\\d \\left{ D\\{KL} (N(0, \\lambda^s\\d)||N(\\tilde{\\mu}^t\\d, \\tilde{\\sigma}^t\\{d}{}^2)) + D\\{KL} (N(\\tilde{\\mu}^t\\d, \\tilde{\\sigma}^t\\{d}{}^2)||N(0, \\lambda^s\\d)) \\right} \\ = \u0026amp; \\sum\\{d=1}^K a\\_d \\left{ \\frac{(\\tilde{\\mu}^t\\_d)^2 + \\lambda^s\\d}{2\\tilde{\\sigma}^t\\{d}{}^2} + \\frac{(\\tilde{\\mu}^t\\d)^2 + \\tilde{\\sigma}^t\\{d}{}^2}{2\\lambda^s\\_d} - 1 \\right} \\quad \\text{(7)} \\end{align}$$ 其中 $a\\_d$ 是维度权重，$\\lambda\\_d^s$ 是源域子空间的第 $d$ 个特征值，$\\tilde{\\mu}\\d^t$ 和 $\\tilde{\\sigma}\\{d}{}^2$ 是投影后的目标特征在第 $d$ 个维度上的均值和方差 伪代码：\n输入：预训练好的源模型 $f\\_\\theta$、源基向量 $V\\_s$、源均值 $\\mu^s$、源方差 $\\Lambda^s$、目标数据集 $T$ 输出：适应后的模型 $f\\_\\phi^t$ 步骤： 计算源子空间中每个维度的权重 $a\\_d$ 对于目标数据集 $T$ 中的每个 mini batch ${x}\\_i^B$： 提取目标特征 $z = g\\_\\phi(x)$。 将目标特征投影到源子空间 $\\tilde{z}$ 计算投影后目标特征的均值 $\\tilde{\\mu}^t$ 和方差 $\\tilde{\\sigma}^{t2}$ 更新特征提取器 $g\\\\phi$ 以最小化损失函数 $L\\{TTA}(\\phi)$ 重复直到收敛。 对角高斯分布的合理性 为什么假设特征分布为对角高斯分布是合理的：\n中心极限定理：当特征被投影到子空间后，如果原始特征维度 $D$ 足够大，根据中心极限定理，投影后的特征分布会倾向于高斯分布。 PCA 的去相关性：由于子空间检测使用了 PCA，投影到主成分上的特征是去相关的，这意味着不同维度之间是独立的，这使得对角高斯分布的假设（即各维度独立）变得合理。 Appendix A. LIMITATION：SSA 假设是协变量偏移，即 $p(y|x)$ 不变，未来工作将考虑 $p(y|x)$ 变化的情况\nB. EVALUATION METRIC：R²接近 1 表示模型拟合效果好 $$ R^2 = 1 - \\frac{\\sum\\_{i=1}^N (y\\_i - \\hat{y}\\i)^2}{\\sum\\{i=1}^N (y\\_i - \\bar{y})^2} \\quad \\text{(10)} $$ 其中 $\\hat{y}\\_i$ 是预测值，$y\\_i$ 是真实值，$\\bar{y}$ 是真实值的平均值。\nD. ADDITIONAL EXPERIMENTAL RESULTS：\nD.1 特征对齐的度量：比较了 KL 散度、2WD 和 L1 范数作为特征对齐损失的效果，结果显示 KL 散度结合子空间检测（SSA）表现最佳。 公式 (11)：2-Wasserstein Distance for Gaussians $$ W\\_2^2 (N(\\mu\\_1, \\sigma\\_1^2), N(\\mu\\_2, \\sigma\\_2^2)) = (\\mu\\_1 - \\mu\\_2)^2 + (\\sigma\\_1 - \\sigma\\_2)^2 $$ 公式 (12)：L1 Norm of Statistics $$ L\\_1 (N(\\mu\\_1, \\sigma\\_1^2), N(\\mu\\_2, \\sigma\\_2^2)) = |\\mu\\_1 - \\mu\\_2| + |\\sigma\\_1 - \\sigma\\_2| $$ 公式 (13)：SSA Loss with 2WD $$ L\\{TTA-2WD} = \\sum\\{d=1}^K a\\_d \\left{ (\\tilde{\\mu}^t\\_d)^2 + (\\tilde{\\sigma}^t\\_d - \\sqrt{\\lambda^s\\_d})^2 \\right} $$ 公式 (14)：SSA Loss with L1 Norm $$ L\\{TTA-L1} = \\sum\\{d=1}^K a\\_d \\left{ |\\tilde{\\mu}^t\\_d| + |\\tilde{\\sigma}^t\\_d - \\sqrt{\\lambda^s\\_d}| \\right} $$ D.2 特征可视化：通过 PCA 和 UMAP 等降维技术可视化了源域和目标域特征分布（图 4-5），直观地展示了 SSA 如何成功地将目标特征分布拉近源域。 D.3 原始特征维度对子空间的影响：分析了原始特征维度对子空间的重要性。 公式 (15)：Gradient Norm $s\\_d$ $$ s\\_d = ||\\frac{\\partial \\tilde{z}}{\\partial z\\_d}||\\_2 = ||(V\\_s^T)\\d||\\2 = ||[v\\{1,d}^s, \\dots, v\\{K,d}^s]||\\_2, $$ 其中 $(V\\_s^T)\\_d$ 是 $V\\_s^T$ 的第 $d$ 行。 发现：回归模型的特征子空间确实受许多原始特征维度影响很小（图 6），这进一步确认了子空间检测的必要性。 D.4 附加消融实验：进一步证实了子空间检测对于 SSA 性能的重要性（表 13-14）。 D.5 Vision Transformer 实验：在 Vision Transformer 上验证了 SSA 的有效性（表 15-16），表明该方法对不同模型架构也适用。 D.6 多任务回归模型：将 SSA 应用于多任务回归，模型同时输出多个预测值（如头部姿态的俯仰、偏航、滚转角度），结果表明 SSA 同样有效（表 17）。 D.7 与分类 TTA 结合：探索了 SSA 与分类 TTA 结合的可能性（表 18-20）。 D.8 超参数敏感性：分析了学习率和批次大小等超参数对 SSA 性能的影响（表 21-26），发现 SSA 在典型参数范围内表现稳定。 D.9 额外结果：提供了 MAE 等其他指标的性能数据（表 27-28）。 D.10 在线设置：SSA 在分批在线（batched online）设置下也表现出色（表 29-31）。 ","permalink":"https://diefish1024.github.io/posts/literature-notes/ssa/","summary":"\u003ch2 id=\"introduction\"\u003eIntroduction\u003c/h2\u003e\n\u003cp\u003eTTA 在回归任务上的局限：为分类任务设计，一般基于熵最小化和特征对齐；熵最小化不适用，回归模型产生单一值，不产生概率分布；简单特征对齐对回归模型效果不佳，可能反而会稀释需要学习的特征\u003c/p\u003e\n\u003ch2 id=\"problem-setting\"\u003eProblem Setting\u003c/h2\u003e\n\u003cp\u003e考虑一个回归模型 $f\\\u003cem\u003e\\theta: \\mathcal{X} \\to \\mathbb{R}$，可以进一步分解为\u003cstrong\u003e特征提取器\u003c/strong\u003e $g\\\u003c/em\u003e\\phi: \\mathcal{X} \\to \\mathbb{R}^D$（从输入 $\\mathcal{X}$ 提取 $D$ 维特征 $z$）和\u003cstrong\u003e线性回归器\u003c/strong\u003e $h\\\u003cem\u003e\\psi(z) = w^T z + b$（或者 $h\\\u003c/em\u003e{\\psi}(z)=Wz+b$）\u003c/p\u003e\n\u003cp\u003e$f\\_\\theta$ 首先在一个有标签的\u003cstrong\u003e源数据集\u003c/strong\u003e $S = {(x\\_i, y\\\u003cem\u003ei)}\\\u003c/em\u003e{i=1}^{N\\_s}$ 上进行预训练，数据从源域分布 $p\\_s$ 中采样\u003c/p\u003e\n\u003cp\u003e目标是使用一个\u003cstrong\u003e无标签的\u003c/strong\u003e目标数据集 $T = {x\\\u003cem\u003ej}\\\u003c/em\u003e{j=1}^{N\\\u003cem\u003et}$ 来适应预训练好的模型 $f\\\u003c/em\u003e\\theta$ 到目标域\u003c/p\u003e\n\u003cp\u003e我们假设存在 \u003cstrong\u003ecovariate shift\u003c/strong\u003e ，这意味着：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e输入数据的分布在源域和目标域之间是不同的：$p\\_s(x) \\neq p\\_t(x)$\u003c/li\u003e\n\u003cli\u003e但给定输入后，输出的条件分布是相同的：$p\\_s(y|x) = p\\_t(y|x)$\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"test-time-adaptation-for-regression\"\u003eTest-time Adaptation for Regression\u003c/h2\u003e\n\u003ch3 id=\"basic-idea-feature-alignment\"\u003eBasic Idea: Feature Alignment\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003e朴素实现\u003c/strong\u003e：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e计算源域特征统计量\u003c/strong\u003e：在源域训练后，计算源域特征的\u003cstrong\u003e均值\u003c/strong\u003e $\\mu^s$ 和\u003cstrong\u003e元素级方差\u003c/strong\u003e $\\sigma^{s2}$\n$$ \\mu^s = \\frac{1}{N\\\u003cem\u003es} \\sum\\\u003c/em\u003e{i=1}^{N\\_s} z\\_i^s, \\quad \\sigma^{s2} = \\frac{1}{N\\\u003cem\u003es} \\sum\\\u003c/em\u003e{i=1}^{N\\_s} (z\\_i^s - \\mu^s) \\odot (z\\_i^s - \\mu^s) \\quad \\text{(1)} $$\n其中 $z\\\u003cem\u003ei^s = g\\\u003c/em\u003e\\phi(x\\_i)$ 是源特征，$N\\_s$ 是源数据样本数，$\\odot$ 表示元素级乘积\u003c/p\u003e","title":"SSA"},{"content":"Method Problem Set EEG 数据 ${ X\\{s,l}^{i},y\\{s,l}^{i} }\\{i=1}^{n\\{s,l}}$ ，进行无监督在线 K 分类\nSource Model Training 对源数据做 Euclidean alignment (EA) 数据对齐，减少不同个体 EEG 信号差异\nEA 计算每个个体所有 EEG 试次协方差矩阵的算术平均值 $$ R\\{s,l} = \\dfrac{1}{n}\\sum\\{i=1}^{n} X\\{i}(X\\{i})^{T} \\implies \\bar{X}\\{i} = R\\{s,l}^{-1/2}X\\_{i} $$ 之后再整合经过对齐的受试者数据，形成“源域”\n在整合后的数据上独立训练 $M$ 个模型\nIncremental EA on Target Data 对新数据增量式更新协方差矩阵，再用新的矩阵更新所有测试数据\nTarget Label Prediction 用训练好的 $M$ 模型初始化用于适应目标域的 $M$ 个 TTA 模型 $f\\_{m}$\n新的 $X\\{a}$ 经过 IEA 被变换为 $X\\{a}\u0026rsquo;$ 后被输入到每个模型 $f\\{m}$ 中进行分类，输出概率向量 $f\\{m}(X\\_{a}\u0026rsquo;)$\n之后结合这 $M$ 个概率向量来获得最终的预测标签 $\\hat{y}\\_{a}$\n$a\\leq M$ 数据量较少：直接对所有模型的预测向量平均 $a\u0026gt;M$ 数据量较多：使用谱元学习器对各个模型进行加权平均，根据历史表现（预测的协方差矩阵）分配不同的权重 Target Model Update 在数据量足够以后（$a\u0026gt;B$）使用一个滑动批次的数据更新模型，在此之前模型不变\n组合损失函数： $$ L\\{M} = L\\{CEM}(f\\{m};{ X\u0026rsquo;\\{i} }\\{i=a-B+1}^{a}) + L\\{MDR}(f\\{m};{ X\u0026rsquo;\\{i} }\\_{i=a-B+1}^{a}) $$ 有两个部分\n1) Conditional Entropy Minimization 条件熵最小化\n使分类边界更加清晰 通过最小化每个预测的条件熵（使用温度缩放因子 $T$ 进行校准），使模型倾向于输出接近 0 或 1 的概率 2) Adaptive Marginal Distribution Regularization 自适应边缘分布正则化\n防止出现所有数据都在单类别和对错误结果过于自信的不良结果 计算当前批次每个类别的平均预测概率 $p\\_{k}$ 通过设置阈值得到伪标签，估计目标域的类别评论 $z\\_{k}$ 校准平均预测概率 $q\u0026rsquo;\\{k}$ $$ q\\{k} = \\dfrac{p\\{k}}{c+z\\{k}},\\quad q\u0026rsquo;\\{k} = \\dfrac{q\\{k}}{\\sum q} $$ $L\\{MDR} = \\sum\\{k=1}^{K}q\u0026rsquo;\\{k}\\log q\u0026rsquo;\\{k}$ （采用负熵的形式） Complete T-TIME Algorithm 先预测，后台并行地更新模型\nExperiment 使用三个运动想象数据集\n每次把一个受试者的数据作为目标域，其余作为源域\nClassification Accuracies on Balanced Classes 过于复杂的算法由于数据不足，性能反而下降 基于熵的方法普遍表现良好，MCC 在离线迁移学习中表现最好 T-TIME 在所有在线迁移学习算法中表现最佳，并且其性能与表现最佳的离线迁移学习方法相当 Classification Performance Under Class-Imbalance 使用随机移除数据来创建不平衡数据集\n传统方法表现较弱 T-TIME 表现突出 ","permalink":"https://diefish1024.github.io/posts/literature-notes/t-time/","summary":"\u003ch1 id=\"method\"\u003eMethod\u003c/h1\u003e\n\u003ch3 id=\"problem-set\"\u003eProblem Set\u003c/h3\u003e\n\u003cp\u003eEEG 数据 ${ X\\\u003cem\u003e{s,l}^{i},y\\\u003c/em\u003e{s,l}^{i} }\\\u003cem\u003e{i=1}^{n\\\u003c/em\u003e{s,l}}$ ，进行无监督在线 K 分类\u003c/p\u003e\n\u003ch3 id=\"source-model-training\"\u003eSource Model Training\u003c/h3\u003e\n\u003cp\u003e对源数据做 Euclidean alignment (EA) 数据对齐，减少不同个体 EEG 信号差异\u003c/p\u003e\n\u003cp\u003eEA 计算每个个体所有 EEG 试次协方差矩阵的算术平均值\n$$\nR\\\u003cem\u003e{s,l} = \\dfrac{1}{n}\\sum\\\u003c/em\u003e{i=1}^{n} X\\\u003cem\u003e{i}(X\\\u003c/em\u003e{i})^{T} \\implies \\bar{X}\\\u003cem\u003e{i} = R\\\u003c/em\u003e{s,l}^{-1/2}X\\_{i}\n$$\n之后再整合经过对齐的受试者数据，形成“源域”\u003c/p\u003e\n\u003cp\u003e在整合后的数据上独立训练 $M$ 个模型\u003c/p\u003e\n\u003ch3 id=\"incremental-ea-on-target-data\"\u003eIncremental EA on Target Data\u003c/h3\u003e\n\u003cp\u003e对新数据增量式更新协方差矩阵，再用新的矩阵更新所有测试数据\u003c/p\u003e\n\u003ch3 id=\"target-label-prediction\"\u003eTarget Label Prediction\u003c/h3\u003e\n\u003cp\u003e用训练好的 $M$ 模型初始化用于适应目标域的 $M$ 个 TTA 模型 $f\\_{m}$\u003c/p\u003e\n\u003cp\u003e新的 $X\\\u003cem\u003e{a}$ 经过 IEA 被变换为 $X\\\u003c/em\u003e{a}\u0026rsquo;$ 后被输入到每个模型 $f\\\u003cem\u003e{m}$ 中进行分类，输出概率向量 $f\\\u003c/em\u003e{m}(X\\_{a}\u0026rsquo;)$\u003c/p\u003e\n\u003cp\u003e之后结合这 $M$ 个概率向量来获得最终的预测标签 $\\hat{y}\\_{a}$\u003c/p\u003e","title":"T-TIME"},{"content":"Setting Fully Test-Time Adaptation 是一种独特的模型适应设定。在此设定下，模型 $f\\_\\theta(x)$ 在训练阶段已通过源数据 $x^s$ 和标签 $y^s$ 完成训练，获得参数 $\\theta$。但在测试阶段，模型将遇到与源数据分布不同的无标签目标数据 $x^t$。\nFTT-Adaptation 与以下方法不同：\nFine-tuning：需要目标标签进行重新训练。 Domain Adaptation：需要源数据和目标数据进行联合训练。 Test-Time Training (TTT)：需要修改训练过程并共同优化有监督及自监督损失。 相比之下，FTT-Adaptation 仅能利用预训练模型 $f\\_\\theta$ 和无标签目标数据 $x^t$ 进行适应，不依赖源数据或额外的监督信息。\nMethod 论文的核心贡献是提出了 Tent 方法，其核心思想是通过最小化测试熵（Test Entropy Minimization）来适应模型预测，旨在使模型对测试数据的预测结果更“有信心”。\nEntropy Objective Tent 的测试时目标函数是最小化模型预测 $\\hat{y} = f\\_\\theta(x^t)$ 的熵 $H(\\hat{y})$。论文中使用的香农熵计算公式如下：\n$$ H(\\hat{y}) = - \\sum\\_c p(\\hat{y}\\_c) \\log p(\\hat{y}\\_c) $$\n其中， $p(\\hat{y}\\_c)$ 表示模型预测目标数据 $x^t$ 属于类别 $c$ 的概率。\n最小化熵促使模型输出更“尖锐”或更“确定”的预测分布。 优势：熵是一种无监督目标，仅依赖于模型预测，不需要真实标签。最小化熵与减少预测误差和数据漂移之间存在内在联系，因为更确定的预测通常意味着更正确的预测。 Modulation Parameters Tent 不直接修改原始模型的全部参数 $\\theta$。相反，它仅更新模型内部归一化层（如Batch Normalization layers）中的线性且低维度的仿射变换参数：尺度参数 $\\gamma$ 和偏移参数 $\\beta$。\n这一选择的理由是：这些参数只占模型总参数的极小部分（\u0026lt;1%），优化效率高且稳定。 特征调制过程包含两个步骤： 1.Normalization (标准化)：根据当前批次测试数据的均值 $\\mu$ 和标准差 $\\sigma$ 来标准化特征 $x$，即 $\\hat{x} = (x - \\mu)/\\sigma$。这里的 $\\mu, \\sigma$ 是在测试时从当前批次数据中估计的。 2.Transformation (仿射变换)：对标准化后的特征 $\\hat{x}$ 应用仿射变换，即 $x\u0026rsquo; = \\gamma \\hat{x} + \\beta$。参数 $\\gamma$ 和 $\\beta$ 通过最小化熵目标函数进行优化。 Algorithm Tent 算法的流程如下：\nInitialization： 加载预训练好的源模型参数 $\\theta$。 固定所有非仿射变换的参数。 丢弃源数据中估计的归一化统计量。 优化器收集所有归一化层的通道级仿射变换参数 ${\\gamma\\{l,k}, \\beta\\{l,k}}$。 Iteration：在线处理数据批次。 Forward Pass：对每个数据批次，逐层估计该批次数据的归一化统计量 ($\\mu, \\sigma$)。 Backward Pass：计算预测熵 $H(\\hat{y})$ 相对于仿射变换参数 $\\gamma, \\beta$ 的梯度 $\\nabla H(\\hat{y})$。 Update：使用梯度更新 $\\gamma, \\beta$ 参数。Tent 采用高效的在线更新策略，每次更新只影响下一个批次的数据处理。 Termination：对于在线适应，适应过程只要有测试数据就持续进行。对于离线适应，模型会先进行更新，然后重复推断，适应可以持续多个Epochs。 Experiments 论文在多种计算机视觉任务和数据集上对 Tent 进行了全面评估。\nRobustness To Corruptions 在图像分类的鲁棒性基准测试中，使用受损版本的 CIFAR-10/100-C 和 ImageNet-C 数据集（15 种损坏类型，不同严重程度）。\n主要发现： Tent 在 ImageNet-C 上达到了 44.0% 的最低错误率，优于 SOTA 鲁棒性训练方法（如Adversarial Noise Training (ANT) 的 50.2%）和Test-Time Normalization (BN) 基线（49.9%）。 在 CIFAR-10/100-C 上，Tent 也显著优于其他 TTA baseline（BN, Pseudo-Labeling (PL)）以及需要联合训练源域和目标域的Domain Adaptation（RG, UDA-SS）和Test-Time Training (TTT) 方法。 这些改进仅通过一次Epoch的测试时优化实现，且未改变原始模型训练。 Source-Free Domain Adaptation 评估 Tent 在无源域适应场景下的性能，包括数字识别（从 SVHN 到 MNIST/MNIST-M/USPS）和语义分割（从 GTA 到 Cityscapes）。\n主要发现： 在数字识别任务中，Tent 大多数情况下错误率低于源模型和BN，部分情况甚至优于需要源数据的Domain Adaptation方法（RG, UDA-SS）。 语义分割任务中，Tent 将Intersection-Over-Union (IOU) 分数从源模型的 28.8% 提高到 35.8%，显著优于 BN 的 31.4%。 Analysis 论文通过多项分析实验探究了 Tent 的工作原理和特性：\nTent 降低熵和误差：实验证实，Tent 成功降低了预测的熵值和任务损失（如Softmax Cross-Entropy），印证了熵最小化与误差减少之间的正相关性。 Tent 需要特征调制：不更新归一化统计量或不优化仿射变换参数会显著降低 Tent 性能，说明这些特征调制步骤对于适应不可或缺。 Tent 泛化到不同的目标数据：适应过程对未用于更新的其他测试数据点同样有效，表明其学习到的调制是通用的。 Tent 调制与归一化不同：对比分析显示，Tent 的特征调制使特征更接近在目标标签上优化的Oracle模型（理想模型），而非仅像Batch Normalization那样接近原始参考分布。 Tent 适应其他网络架构：Tent 在基于Self-Attention 和Equilibrium Solving (MDEQ) 的模型上也能有效降低误差，展现了其普适性。 Related Work 论文回顾了与 Tent 相关的现有工作：\nTrain-Time Adaptation 方法：传统的Domain Adaptation、Test-Time Training (TTT) 等，通常需要源数据或训练阶段修改模型。 Source-Free Adaptation 方法：近期一些不依赖源数据的方法，但通常需要更复杂的设计、离线优化或修改训练过程。Tent 的优势在于其在线、高效且不改变训练过程。 Entropy Minimization：熵最小化已被广泛用于Semi-Supervised Learning和Domain Adaptation的正则化项，但 Tent 首次将其作为Fully Test-Time Adaptation中唯一的无监督损失来驱动模型适应。 Feature Modulation：归一化层和仿射变换已被用于各种任务的特征调制，但 Tent 将其作为在测试时通过无监督目标进行优化的核心机制。 Discussion Tent 通过Test Entropy Minimization实现了在数据漂移情况下的泛化误差降低。其核心在于模型的自监督自我改进，即依据自身的预测反馈进行调整。\n优势总结： 高效：仅通过在线优化少数参数（$\\gamma, \\beta$）实现。 实用：无需源数据访问，不改变模型训练过程。 通用：适用于多种数据漂移类型和不同网络架构。 尽管 Tent 在广泛的场景中表现出色，但仍存在挑战，例如在特定困难的数据漂移（如 SVHN 到 MNIST-M/USPS）上仍有提升空间。未来研究方向可探索更全面的参数调整、更通用的Test-Time Adaptation Loss以及进一步提升效率的方法。总而言之，Tent 为Fully Test-Time Adaptation 提供了一个创新且实用的范式，使得模型能够在部署后，在面对未知且无标签的测试数据时，具备强大的自我适应能力。\n","permalink":"https://diefish1024.github.io/posts/literature-notes/tent/","summary":"\u003ch1 id=\"setting\"\u003eSetting\u003c/h1\u003e\n\u003cp\u003e\u003cstrong\u003eFully Test-Time Adaptation\u003c/strong\u003e 是一种独特的模型适应设定。在此设定下，模型 $f\\_\\theta(x)$ 在训练阶段已通过源数据 $x^s$ 和标签 $y^s$ 完成训练，获得参数 $\\theta$。但在测试阶段，模型将遇到与源数据分布不同的无标签目标数据 $x^t$。\u003c/p\u003e\n\u003cp\u003eFTT-Adaptation 与以下方法不同：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eFine-tuning\u003c/strong\u003e：需要目标标签进行重新训练。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eDomain Adaptation\u003c/strong\u003e：需要源数据和目标数据进行联合训练。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eTest-Time Training (TTT)\u003c/strong\u003e：需要修改训练过程并共同优化有监督及自监督损失。\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e相比之下，FTT-Adaptation 仅能利用预训练模型 $f\\_\\theta$ 和无标签目标数据 $x^t$ 进行适应，不依赖源数据或额外的监督信息。\u003c/p\u003e\n\u003ch2 id=\"method\"\u003eMethod\u003c/h2\u003e\n\u003cp\u003e论文的核心贡献是提出了 \u003cstrong\u003eTent\u003c/strong\u003e 方法，其核心思想是通过\u003cstrong\u003e最小化测试熵\u003c/strong\u003e（\u003cstrong\u003eTest Entropy Minimization\u003c/strong\u003e）来适应模型预测，旨在使模型对测试数据的预测结果更“有信心”。\u003c/p\u003e\n\u003ch3 id=\"entropy-objective\"\u003eEntropy Objective\u003c/h3\u003e\n\u003cp\u003eTent 的测试时目标函数是最小化模型预测 $\\hat{y} = f\\_\\theta(x^t)$ 的\u003cstrong\u003e熵 $H(\\hat{y})$\u003c/strong\u003e。论文中使用的\u003cstrong\u003e香农熵\u003c/strong\u003e计算公式如下：\u003c/p\u003e\n\u003cp\u003e$$\nH(\\hat{y}) = - \\sum\\_c p(\\hat{y}\\_c) \\log p(\\hat{y}\\_c)\n$$\u003c/p\u003e\n\u003cp\u003e其中， $p(\\hat{y}\\_c)$ 表示模型预测目标数据 $x^t$ 属于类别 $c$ 的概率。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e最小化熵促使模型输出更“尖锐”或更“确定”的预测分布。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e优势\u003c/strong\u003e：熵是一种\u003cstrong\u003e无监督目标\u003c/strong\u003e，仅依赖于模型预测，不需要真实标签。最小化熵与减少预测误差和数据漂移之间存在内在联系，因为更确定的预测通常意味着更正确的预测。\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"modulation-parameters\"\u003eModulation Parameters\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003eTent\u003c/strong\u003e 不直接修改原始模型的全部参数 $\\theta$。相反，它仅更新模型内部归一化层（如\u003cstrong\u003eBatch Normalization layers\u003c/strong\u003e）中的线性且低维度的\u003cstrong\u003e仿射变换\u003c/strong\u003e参数：尺度参数 $\\gamma$ 和偏移参数 $\\beta$。\u003c/p\u003e","title":"Tent"}]