<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Literature-Note | diefish's blog</title><meta name=keywords content><meta name=description content="A freshman at SJTU John class."><meta name=author content="diefish"><link rel=canonical href=https://diefish1024.github.io/categories/literature-note/><link crossorigin=anonymous href=/assets/css/stylesheet.8fe10233a706bc87f2e08b3cf97b8bd4c0a80f10675a143675d59212121037c0.css integrity="sha256-j+ECM6cGvIfy4Is8+XuL1MCoDxBnWhQ2ddWSEhIQN8A=" rel="preload stylesheet" as=style><link rel=icon href=https://diefish1024.github.io/images/avatar.jpg><link rel=icon type=image/png sizes=16x16 href=https://diefish1024.github.io/images/avatar.jpg><link rel=icon type=image/png sizes=32x32 href=https://diefish1024.github.io/images/avatar.jpg><link rel=apple-touch-icon href=https://diefish1024.github.io/images/avatar.jpg><link rel=mask-icon href=https://diefish1024.github.io/images/avatar.jpg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate type=application/rss+xml href=https://diefish1024.github.io/categories/literature-note/index.xml><link rel=alternate hreflang=en href=https://diefish1024.github.io/categories/literature-note/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.css integrity=sha384-MlJdn/WNKDGXveldHDdyRP1R4CTHr3FeuDNfhsLPYrq2t0UBkUdK2jyTnXPEK1NQ crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.js integrity=sha384-VQ8d8WVFw0yHhCk5E8I86oOhv48xLpnDZx5T9GogA/Y84DcCKWXDmSDfn13bzFZY crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/contrib/auto-render.min.js integrity=sha384-+XBljXPPiv+OzfbB3cVmLHf4hdUFHlWNZN5spNQ7rmHTXpd7WvJum6fIACpNNfIR crossorigin=anonymous onload=renderMathInElement(document.body)></script><script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}]})})</script><meta property="og:url" content="https://diefish1024.github.io/categories/literature-note/"><meta property="og:site_name" content="diefish's blog"><meta property="og:title" content="Literature-Note"><meta property="og:description" content="A freshman at SJTU John class."><meta property="og:locale" content="zh-cn"><meta property="og:type" content="website"><meta property="og:image" content="https://diefish1024.github.io/images/avatar.jpg"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://diefish1024.github.io/images/avatar.jpg"><meta name=twitter:title content="Literature-Note"><meta name=twitter:description content="A freshman at SJTU John class."></head><body class=list id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://diefish1024.github.io/ accesskey=h title="Home (Alt + H)"><img src=https://diefish1024.github.io/images/avatar.jpg alt aria-label=logo height=35>Home</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://diefish1024.github.io/posts/ title=posts><span>posts</span></a></li><li><a href=https://diefish1024.github.io/tags/ title=tags><span>tags</span></a></li><li><a href=https://diefish1024.github.io/search title="search (Alt + /)" accesskey=/><span>search</span></a></li></ul></nav></header><main class=main><header class=page-header><div class=breadcrumbs><a href=https://diefish1024.github.io/>Home</a>&nbsp;»&nbsp;<a href=https://diefish1024.github.io/categories/>Categories</a></div><h1>Literature-Note</h1></header><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>DANN</h2></header><div class=entry-content><p>Introduction 类似 GAN 的对抗训练思想
Domain Adaptation 给定源域 $D\{S}$ （有标签）和目标域 $D\{T}$ （无标签），目标是训练一个分类器 $\eta: X\to Y$ 使其在目标域上的目标风险 $$ R\{D\{T}}(\eta) = \underset{(\mathbf{x},y)\sim D\_{T}}{\mathrm{Pr}}(\eta(\mathbf{x}) \neq y) $$ 最小
Domain Divergence 需要量化两个领域的“相似度”，从而引出了 H- 散度 的概念： $$ d\_{\mathcal{H}}(D\S, D\T) = 2 \sup\{\eta \in \mathcal{H}} \left| \Pr\{x \sim D\S}[\eta(x) = 1] - \Pr\{x \sim D\_T}[\eta(x) = 1] \right| $$ 含义是最优的分类器将目标域和源域判定为 1 的可能性之差，当 H- 散度非常小时，说明两个领域很难被区分，也就说明学习的特征实现了领域不变性的效果
由于理论 H 散度是理想数据分布上的定义，实际中只有有限的样本集 $S$ 和 $T$ ，因此需要一定的近似，于是需要经验 H- 散度 $$ \hat{d}\{\mathcal{H}}(S, T) = 2 \left(1 - \min\{\eta \in \mathcal{H}} \left[ \dfrac{1}{n}\sum\_{i=1}^n \mathcal{I}[\eta(x\i) = 0] + \dfrac{1}{n’}\sum\{i=n+1}^N \mathcal{I}[\eta(x\_i) = 1] \right] \right) $$ 其中 $\mathcal{I}[\cdot]$ 表示条件为真时为 1，否则为 0
...</p></div><footer class=entry-footer>2 min&nbsp;·&nbsp;diefish</footer><a class=entry-link aria-label="post link to DANN" href=https://diefish1024.github.io/posts/literature-notes/dann/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>SSA</h2></header><div class=entry-content><p>Introduction TTA 在回归任务上的局限：为分类任务设计，一般基于熵最小化和特征对齐；熵最小化不适用，回归模型产生单一值，不产生概率分布；简单特征对齐对回归模型效果不佳，可能反而会稀释需要学习的特征
Problem Setting 考虑一个回归模型 $f\\theta: \mathcal{X} \to \mathbb{R}$，可以进一步分解为特征提取器 $g\\phi: \mathcal{X} \to \mathbb{R}^D$（从输入 $\mathcal{X}$ 提取 $D$ 维特征 $z$）和线性回归器 $h\\psi(z) = w^T z + b$（或者 $h\{\psi}(z)=Wz+b$）
$f\_\theta$ 首先在一个有标签的源数据集 $S = {(x\_i, y\i)}\{i=1}^{N\_s}$ 上进行预训练，数据从源域分布 $p\_s$ 中采样
目标是使用一个无标签的目标数据集 $T = {x\j}\{j=1}^{N\t}$ 来适应预训练好的模型 $f\\theta$ 到目标域
我们假设存在 covariate shift ，这意味着：
输入数据的分布在源域和目标域之间是不同的：$p\_s(x) \neq p\_t(x)$ 但给定输入后，输出的条件分布是相同的：$p\_s(y|x) = p\_t(y|x)$ Test-time Adaptation for Regression Basic Idea: Feature Alignment 朴素实现：
计算源域特征统计量：在源域训练后，计算源域特征的均值 $\mu^s$ 和元素级方差 $\sigma^{s2}$ $$ \mu^s = \frac{1}{N\s} \sum\{i=1}^{N\_s} z\_i^s, \quad \sigma^{s2} = \frac{1}{N\s} \sum\{i=1}^{N\_s} (z\_i^s - \mu^s) \odot (z\_i^s - \mu^s) \quad \text{(1)} $$ 其中 $z\i^s = g\\phi(x\_i)$ 是源特征，$N\_s$ 是源数据样本数，$\odot$ 表示元素级乘积
...</p></div><footer class=entry-footer>3 min&nbsp;·&nbsp;diefish</footer><a class=entry-link aria-label="post link to SSA" href=https://diefish1024.github.io/posts/literature-notes/ssa/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>T-TIME</h2></header><div class=entry-content><p>Method Problem Set EEG 数据 ${ X\{s,l}^{i},y\{s,l}^{i} }\{i=1}^{n\{s,l}}$ ，进行无监督在线 K 分类
Source Model Training 对源数据做 Euclidean alignment (EA) 数据对齐，减少不同个体 EEG 信号差异
EA 计算每个个体所有 EEG 试次协方差矩阵的算术平均值 $$ R\{s,l} = \dfrac{1}{n}\sum\{i=1}^{n} X\{i}(X\{i})^{T} \implies \bar{X}\{i} = R\{s,l}^{-1/2}X\_{i} $$ 之后再整合经过对齐的受试者数据，形成“源域”
在整合后的数据上独立训练 $M$ 个模型
Incremental EA on Target Data 对新数据增量式更新协方差矩阵，再用新的矩阵更新所有测试数据
Target Label Prediction 用训练好的 $M$ 模型初始化用于适应目标域的 $M$ 个 TTA 模型 $f\_{m}$
新的 $X\{a}$ 经过 IEA 被变换为 $X\{a}’$ 后被输入到每个模型 $f\{m}$ 中进行分类，输出概率向量 $f\{m}(X\_{a}’)$
之后结合这 $M$ 个概率向量来获得最终的预测标签 $\hat{y}\_{a}$
...</p></div><footer class=entry-footer>1 min&nbsp;·&nbsp;diefish</footer><a class=entry-link aria-label="post link to T-TIME" href=https://diefish1024.github.io/posts/literature-notes/t-time/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>Tent</h2></header><div class=entry-content><p>Setting Fully Test-Time Adaptation 是一种独特的模型适应设定。在此设定下，模型 $f\_\theta(x)$ 在训练阶段已通过源数据 $x^s$ 和标签 $y^s$ 完成训练，获得参数 $\theta$。但在测试阶段，模型将遇到与源数据分布不同的无标签目标数据 $x^t$。
FTT-Adaptation 与以下方法不同：
Fine-tuning：需要目标标签进行重新训练。 Domain Adaptation：需要源数据和目标数据进行联合训练。 Test-Time Training (TTT)：需要修改训练过程并共同优化有监督及自监督损失。 相比之下，FTT-Adaptation 仅能利用预训练模型 $f\_\theta$ 和无标签目标数据 $x^t$ 进行适应，不依赖源数据或额外的监督信息。
Method 论文的核心贡献是提出了 Tent 方法，其核心思想是通过最小化测试熵（Test Entropy Minimization）来适应模型预测，旨在使模型对测试数据的预测结果更“有信心”。
Entropy Objective Tent 的测试时目标函数是最小化模型预测 $\hat{y} = f\_\theta(x^t)$ 的熵 $H(\hat{y})$。论文中使用的香农熵计算公式如下：
$$ H(\hat{y}) = - \sum\_c p(\hat{y}\_c) \log p(\hat{y}\_c) $$
其中， $p(\hat{y}\_c)$ 表示模型预测目标数据 $x^t$ 属于类别 $c$ 的概率。
最小化熵促使模型输出更“尖锐”或更“确定”的预测分布。 优势：熵是一种无监督目标，仅依赖于模型预测，不需要真实标签。最小化熵与减少预测误差和数据漂移之间存在内在联系，因为更确定的预测通常意味着更正确的预测。 Modulation Parameters Tent 不直接修改原始模型的全部参数 $\theta$。相反，它仅更新模型内部归一化层（如Batch Normalization layers）中的线性且低维度的仿射变换参数：尺度参数 $\gamma$ 和偏移参数 $\beta$。
...</p></div><footer class=entry-footer>2 min&nbsp;·&nbsp;diefish</footer><a class=entry-link aria-label="post link to Tent" href=https://diefish1024.github.io/posts/literature-notes/tent/></a></article></main><footer class=footer><span>&copy; 2025 <a href=https://diefish1024.github.io/>diefish's blog</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>