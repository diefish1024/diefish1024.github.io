<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Literature-Note on diefish&#39;s blog</title>
    <link>https://diefish1024.github.io/tags/literature-note/</link>
    <description>Recent content in Literature-Note on diefish&#39;s blog</description>
    <image>
      <title>diefish&#39;s blog</title>
      <url>https://diefish1024.github.io/images/avatar.jpg</url>
      <link>https://diefish1024.github.io/images/avatar.jpg</link>
    </image>
    <generator>Hugo -- 0.148.2</generator>
    <language>zh-cn</language>
    <atom:link href="https://diefish1024.github.io/tags/literature-note/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>DANN</title>
      <link>https://diefish1024.github.io/posts/literature-notes/dann/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://diefish1024.github.io/posts/literature-notes/dann/</guid>
      <description>&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;类似 GAN 的对抗训练思想&lt;/p&gt;
&lt;h2 id=&#34;domain-adaptation&#34;&gt;Domain Adaptation&lt;/h2&gt;
&lt;p&gt;给定源域 $D_{S}$ （有标签）和目标域 $D_{T}$ （无标签），目标是训练一个分类器 $\eta: X\to Y$ 使其在目标域上的目标风险
$$
R_{D_{T}}(\eta) = \underset{(\mathbf{x},y)\sim D_{T}}{\mathrm{Pr}}(\eta(\mathbf{x}) \neq y)
$$
最小&lt;/p&gt;
&lt;h4 id=&#34;domain-divergence&#34;&gt;Domain Divergence&lt;/h4&gt;
&lt;p&gt;需要量化两个领域的“相似度”，从而引出了 &lt;strong&gt;H- 散度&lt;/strong&gt; 的概念：
$$
d_{\mathcal{H}}(D_S, D_T) = 2 \sup_{\eta \in \mathcal{H}} \left| \Pr_{x \sim D_S}[\eta(x) = 1] - \Pr_{x \sim D_T}[\eta(x) = 1] \right|
$$
含义是最优的分类器将目标域和源域判定为 1 的可能性之差，当 H- 散度非常小时，说明两个领域很难被区分，也就说明学习的特征实现了领域不变性的效果&lt;/p&gt;
&lt;p&gt;由于理论 H 散度是理想数据分布上的定义，实际中只有有限的样本集 $S$ 和 $T$ ，因此需要一定的近似，于是需要经验 H- 散度
$$
\hat{d}&lt;em&gt;{\mathcal{H}}(S, T) = 2 \left(1 - \min&lt;/em&gt;{\eta \in \mathcal{H}} \left[ \dfrac{1}{n}\sum_{i=1}^n \mathcal{I}[\eta(x_i) = 0] + \dfrac{1}{n&amp;rsquo;}\sum_{i=n+1}^N \mathcal{I}[\eta(x_i) = 1] \right] \right)
$$
其中 $\mathcal{I}[\cdot]$ 表示条件为真时为 1，否则为 0&lt;/p&gt;</description>
    </item>
    <item>
      <title>SSA</title>
      <link>https://diefish1024.github.io/posts/literature-notes/ssa/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://diefish1024.github.io/posts/literature-notes/ssa/</guid>
      <description>&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;TTA 在回归任务上的局限：为分类任务设计，一般基于熵最小化和特征对齐；熵最小化不适用，回归模型产生单一值，不产生概率分布；简单特征对齐对回归模型效果不佳，可能反而会稀释需要学习的特征&lt;/p&gt;
&lt;h2 id=&#34;problem-setting&#34;&gt;Problem Setting&lt;/h2&gt;
&lt;p&gt;考虑一个回归模型 $f_\theta: \mathcal{X} \to \mathbb{R}$，可以进一步分解为&lt;strong&gt;特征提取器&lt;/strong&gt; $g_\phi: \mathcal{X} \to \mathbb{R}^D$（从输入 $\mathcal{X}$ 提取 $D$ 维特征 $z$）和&lt;strong&gt;线性回归器&lt;/strong&gt; $h_\psi(z) = w^T z + b$（或者 $h_{\psi}(z)=Wz+b$）&lt;/p&gt;
&lt;p&gt;$f_\theta$ 首先在一个有标签的&lt;strong&gt;源数据集&lt;/strong&gt; $S = {(x_i, y_i)}_{i=1}^{N_s}$ 上进行预训练，数据从源域分布 $p_s$ 中采样&lt;/p&gt;
&lt;p&gt;目标是使用一个&lt;strong&gt;无标签的&lt;/strong&gt;目标数据集 $T = {x_j}&lt;em&gt;{j=1}^{N_t}$ 来适应预训练好的模型 $f&lt;/em&gt;\theta$ 到目标域&lt;/p&gt;
&lt;p&gt;我们假设存在 &lt;strong&gt;covariate shift&lt;/strong&gt; ，这意味着：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;输入数据的分布在源域和目标域之间是不同的：$p_s(x) \neq p_t(x)$&lt;/li&gt;
&lt;li&gt;但给定输入后，输出的条件分布是相同的：$p_s(y|x) = p_t(y|x)$&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;test-time-adaptation-for-regression&#34;&gt;Test-time Adaptation for Regression&lt;/h2&gt;
&lt;h3 id=&#34;basic-idea-feature-alignment&#34;&gt;Basic Idea: Feature Alignment&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;朴素实现&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;计算源域特征统计量&lt;/strong&gt;：在源域训练后，计算源域特征的&lt;strong&gt;均值&lt;/strong&gt; $\mu^s$ 和&lt;strong&gt;元素级方差&lt;/strong&gt; $\sigma^{s2}$
$$ \mu^s = \frac{1}{N_s} \sum_{i=1}^{N_s} z_i^s, \quad \sigma^{s2} = \frac{1}{N_s} \sum_{i=1}^{N_s} (z_i^s - \mu^s) \odot (z_i^s - \mu^s) \quad \text{(1)} $$
其中 $z_i^s = g_\phi(x_i)$ 是源特征，$N_s$ 是源数据样本数，$\odot$ 表示元素级乘积&lt;/p&gt;</description>
    </item>
    <item>
      <title>T-TIME</title>
      <link>https://diefish1024.github.io/posts/literature-notes/t-time/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://diefish1024.github.io/posts/literature-notes/t-time/</guid>
      <description>&lt;h1 id=&#34;method&#34;&gt;Method&lt;/h1&gt;
&lt;h3 id=&#34;problem-set&#34;&gt;Problem Set&lt;/h3&gt;
&lt;p&gt;EEG 数据 ${ X_{s,l}^{i},y_{s,l}^{i} }&lt;em&gt;{i=1}^{n&lt;/em&gt;{s,l}}$ ，进行无监督在线 K 分类&lt;/p&gt;
&lt;h3 id=&#34;source-model-training&#34;&gt;Source Model Training&lt;/h3&gt;
&lt;p&gt;对源数据做 Euclidean alignment (EA) 数据对齐，减少不同个体 EEG 信号差异&lt;/p&gt;
&lt;p&gt;EA 计算每个个体所有 EEG 试次协方差矩阵的算术平均值
$$
R_{s,l} = \dfrac{1}{n}\sum_{i=1}^{n} X_{i}(X_{i})^{T} \implies \bar{X}&lt;em&gt;{i} = R&lt;/em&gt;{s,l}^{-1/2}X_{i}
$$
之后再整合经过对齐的受试者数据，形成“源域”&lt;/p&gt;
&lt;p&gt;在整合后的数据上独立训练 $M$ 个模型&lt;/p&gt;
&lt;h3 id=&#34;incremental-ea-on-target-data&#34;&gt;Incremental EA on Target Data&lt;/h3&gt;
&lt;p&gt;对新数据增量式更新协方差矩阵，再用新的矩阵更新所有测试数据&lt;/p&gt;
&lt;h3 id=&#34;target-label-prediction&#34;&gt;Target Label Prediction&lt;/h3&gt;
&lt;p&gt;用训练好的 $M$ 模型初始化用于适应目标域的 $M$ 个 TTA 模型 $f_{m}$&lt;/p&gt;
&lt;p&gt;新的 $X_{a}$ 经过 IEA 被变换为 $X_{a}&amp;rsquo;$ 后被输入到每个模型 $f_{m}$ 中进行分类，输出概率向量 $f_{m}(X_{a}&amp;rsquo;)$&lt;/p&gt;
&lt;p&gt;之后结合这 $M$ 个概率向量来获得最终的预测标签 $\hat{y}_{a}$&lt;/p&gt;</description>
    </item>
    <item>
      <title>Tent</title>
      <link>https://diefish1024.github.io/posts/literature-notes/tent/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://diefish1024.github.io/posts/literature-notes/tent/</guid>
      <description>&lt;h1 id=&#34;setting&#34;&gt;Setting&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;Fully Test-Time Adaptation&lt;/strong&gt; 是一种独特的模型适应设定。在此设定下，模型 $f_\theta(x)$ 在训练阶段已通过源数据 $x^s$ 和标签 $y^s$ 完成训练，获得参数 $\theta$。但在测试阶段，模型将遇到与源数据分布不同的无标签目标数据 $x^t$。&lt;/p&gt;
&lt;p&gt;FTT-Adaptation 与以下方法不同：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Fine-tuning&lt;/strong&gt;：需要目标标签进行重新训练。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Domain Adaptation&lt;/strong&gt;：需要源数据和目标数据进行联合训练。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Test-Time Training (TTT)&lt;/strong&gt;：需要修改训练过程并共同优化有监督及自监督损失。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;相比之下，FTT-Adaptation 仅能利用预训练模型 $f_\theta$ 和无标签目标数据 $x^t$ 进行适应，不依赖源数据或额外的监督信息。&lt;/p&gt;
&lt;h2 id=&#34;method&#34;&gt;Method&lt;/h2&gt;
&lt;p&gt;论文的核心贡献是提出了 &lt;strong&gt;Tent&lt;/strong&gt; 方法，其核心思想是通过&lt;strong&gt;最小化测试熵&lt;/strong&gt;（&lt;strong&gt;Test Entropy Minimization&lt;/strong&gt;）来适应模型预测，旨在使模型对测试数据的预测结果更“有信心”。&lt;/p&gt;
&lt;h3 id=&#34;entropy-objective&#34;&gt;Entropy Objective&lt;/h3&gt;
&lt;p&gt;Tent 的测试时目标函数是最小化模型预测 $\hat{y} = f_\theta(x^t)$ 的&lt;strong&gt;熵 $H(\hat{y})$&lt;/strong&gt;。论文中使用的&lt;strong&gt;香农熵&lt;/strong&gt;计算公式如下：&lt;/p&gt;
&lt;p&gt;$$
H(\hat{y}) = - \sum_c p(\hat{y}_c) \log p(\hat{y}_c)
$$&lt;/p&gt;
&lt;p&gt;其中， $p(\hat{y}_c)$ 表示模型预测目标数据 $x^t$ 属于类别 $c$ 的概率。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;最小化熵促使模型输出更“尖锐”或更“确定”的预测分布。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;优势&lt;/strong&gt;：熵是一种&lt;strong&gt;无监督目标&lt;/strong&gt;，仅依赖于模型预测，不需要真实标签。最小化熵与减少预测误差和数据漂移之间存在内在联系，因为更确定的预测通常意味着更正确的预测。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;modulation-parameters&#34;&gt;Modulation Parameters&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Tent&lt;/strong&gt; 不直接修改原始模型的全部参数 $\theta$。相反，它仅更新模型内部归一化层（如&lt;strong&gt;Batch Normalization layers&lt;/strong&gt;）中的线性且低维度的&lt;strong&gt;仿射变换&lt;/strong&gt;参数：尺度参数 $\gamma$ 和偏移参数 $\beta$。&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
